2025-04-11 23:37:09,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-11 23:37:09,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-11 23:37:09,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-11 23:37:09,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 00:15:56,525:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_27560\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-12 18:03:19,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 18:03:19,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 18:03:19,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 18:03:19,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 19:11:42,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 19:11:42,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 19:11:42,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 19:11:42,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 19:12:00,168:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_2236\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-12 19:27:21,919:INFO:PyCaret ClassificationExperiment
2025-04-12 19:27:21,919:INFO:Logging name: clf-default-name
2025-04-12 19:27:21,920:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-12 19:27:21,920:INFO:version 3.0.4
2025-04-12 19:27:21,920:INFO:Initializing setup()
2025-04-12 19:27:21,920:INFO:self.USI: e5c1
2025-04-12 19:27:21,920:INFO:self._variable_keys: {'X', 'html_param', 'seed', 'memory', 'y_train', 'X_train', 'fold_generator', 'pipeline', '_available_plots', 'idx', 'log_plots_param', 'fix_imbalance', 'target_param', 'fold_groups_param', 'X_test', 'gpu_n_jobs_param', 'USI', '_ml_usecase', 'y', 'data', 'is_multiclass', 'y_test', 'logging_param', 'n_jobs_param', 'fold_shuffle_param', 'exp_id', 'gpu_param', 'exp_name_log'}
2025-04-12 19:27:21,920:INFO:Checking environment
2025-04-12 19:27:21,920:INFO:python_version: 3.10.5
2025-04-12 19:27:21,920:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-12 19:27:21,920:INFO:machine: AMD64
2025-04-12 19:27:21,920:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-12 19:27:21,926:INFO:Memory: svmem(total=25042907136, available=8653307904, percent=65.4, used=16389599232, free=8653307904)
2025-04-12 19:27:21,927:INFO:Physical Core: 6
2025-04-12 19:27:21,927:INFO:Logical Core: 12
2025-04-12 19:27:21,927:INFO:Checking libraries
2025-04-12 19:27:21,927:INFO:System:
2025-04-12 19:27:21,927:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-12 19:27:21,927:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-12 19:27:21,927:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-12 19:27:21,927:INFO:PyCaret required dependencies:
2025-04-12 19:27:22,012:INFO:                 pip: 25.0.1
2025-04-12 19:27:22,012:INFO:          setuptools: 58.1.0
2025-04-12 19:27:22,012:INFO:             pycaret: 3.0.4
2025-04-12 19:27:22,012:INFO:             IPython: 8.29.0
2025-04-12 19:27:22,012:INFO:          ipywidgets: 8.1.6
2025-04-12 19:27:22,012:INFO:                tqdm: 4.67.1
2025-04-12 19:27:22,012:INFO:               numpy: 1.23.5
2025-04-12 19:27:22,012:INFO:              pandas: 1.5.3
2025-04-12 19:27:22,012:INFO:              jinja2: 3.1.4
2025-04-12 19:27:22,013:INFO:               scipy: 1.11.4
2025-04-12 19:27:22,013:INFO:              joblib: 1.3.2
2025-04-12 19:27:22,013:INFO:             sklearn: 1.2.2
2025-04-12 19:27:22,013:INFO:                pyod: 2.0.4
2025-04-12 19:27:22,013:INFO:            imblearn: 0.10.1
2025-04-12 19:27:22,013:INFO:   category_encoders: 2.7.0
2025-04-12 19:27:22,013:INFO:            lightgbm: 4.6.0
2025-04-12 19:27:22,013:INFO:               numba: 0.60.0
2025-04-12 19:27:22,013:INFO:            requests: 2.32.3
2025-04-12 19:27:22,013:INFO:          matplotlib: 3.7.5
2025-04-12 19:27:22,013:INFO:          scikitplot: 0.3.7
2025-04-12 19:27:22,013:INFO:         yellowbrick: 1.5
2025-04-12 19:27:22,013:INFO:              plotly: 5.24.1
2025-04-12 19:27:22,013:INFO:    plotly-resampler: Not installed
2025-04-12 19:27:22,013:INFO:             kaleido: 0.2.1
2025-04-12 19:27:22,013:INFO:           schemdraw: 0.15
2025-04-12 19:27:22,013:INFO:         statsmodels: 0.14.4
2025-04-12 19:27:22,013:INFO:              sktime: 0.26.0
2025-04-12 19:27:22,013:INFO:               tbats: 1.1.3
2025-04-12 19:27:22,013:INFO:            pmdarima: 2.0.4
2025-04-12 19:27:22,013:INFO:              psutil: 6.1.0
2025-04-12 19:27:22,013:INFO:          markupsafe: 3.0.2
2025-04-12 19:27:22,013:INFO:             pickle5: Not installed
2025-04-12 19:27:22,013:INFO:         cloudpickle: 3.1.1
2025-04-12 19:27:22,013:INFO:         deprecation: 2.1.0
2025-04-12 19:27:22,013:INFO:              xxhash: 3.5.0
2025-04-12 19:27:22,013:INFO:           wurlitzer: Not installed
2025-04-12 19:27:22,013:INFO:PyCaret optional dependencies:
2025-04-12 19:27:22,024:INFO:                shap: Not installed
2025-04-12 19:27:22,024:INFO:           interpret: Not installed
2025-04-12 19:27:22,024:INFO:                umap: Not installed
2025-04-12 19:27:22,024:INFO:    pandas_profiling: Not installed
2025-04-12 19:27:22,024:INFO:  explainerdashboard: Not installed
2025-04-12 19:27:22,024:INFO:             autoviz: Not installed
2025-04-12 19:27:22,024:INFO:           fairlearn: Not installed
2025-04-12 19:27:22,024:INFO:          deepchecks: Not installed
2025-04-12 19:27:22,024:INFO:             xgboost: 1.7.6
2025-04-12 19:27:22,024:INFO:            catboost: Not installed
2025-04-12 19:27:22,024:INFO:              kmodes: Not installed
2025-04-12 19:27:22,024:INFO:             mlxtend: Not installed
2025-04-12 19:27:22,024:INFO:       statsforecast: Not installed
2025-04-12 19:27:22,024:INFO:        tune_sklearn: Not installed
2025-04-12 19:27:22,024:INFO:                 ray: Not installed
2025-04-12 19:27:22,024:INFO:            hyperopt: Not installed
2025-04-12 19:27:22,024:INFO:              optuna: Not installed
2025-04-12 19:27:22,025:INFO:               skopt: Not installed
2025-04-12 19:27:22,025:INFO:              mlflow: Not installed
2025-04-12 19:27:22,025:INFO:              gradio: Not installed
2025-04-12 19:27:22,025:INFO:             fastapi: Not installed
2025-04-12 19:27:22,025:INFO:             uvicorn: Not installed
2025-04-12 19:27:22,025:INFO:              m2cgen: Not installed
2025-04-12 19:27:22,025:INFO:           evidently: Not installed
2025-04-12 19:27:22,025:INFO:               fugue: Not installed
2025-04-12 19:27:22,025:INFO:           streamlit: 1.42.0
2025-04-12 19:27:22,025:INFO:             prophet: Not installed
2025-04-12 19:27:22,025:INFO:None
2025-04-12 19:27:22,025:INFO:Set up data.
2025-04-12 19:27:22,037:INFO:Set up train/test split.
2025-04-12 19:27:22,042:INFO:Set up index.
2025-04-12 19:27:22,043:INFO:Set up folding strategy.
2025-04-12 19:27:22,043:INFO:Assigning column types.
2025-04-12 19:27:22,054:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-12 19:27:22,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 19:27:22,102:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 19:27:22,127:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 19:27:22,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 19:27:22,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 19:27:22,162:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 19:27:22,182:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 19:27:22,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 19:27:22,185:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-12 19:27:22,218:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 19:27:22,239:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 19:27:22,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 19:27:22,276:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 19:27:22,297:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 19:27:22,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 19:27:22,299:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-12 19:27:22,354:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 19:27:22,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 19:27:22,414:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 19:27:22,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 19:27:22,419:INFO:Preparing preprocessing pipeline...
2025-04-12 19:27:22,421:INFO:Set up simple imputation.
2025-04-12 19:27:22,423:INFO:Set up encoding of ordinal features.
2025-04-12 19:27:22,424:INFO:Set up encoding of categorical features.
2025-04-12 19:27:22,424:INFO:Set up imbalanced handling.
2025-04-12 19:27:22,424:INFO:Set up feature normalization.
2025-04-12 20:17:49,804:INFO:PyCaret ClassificationExperiment
2025-04-12 20:17:49,804:INFO:Logging name: clf-default-name
2025-04-12 20:17:49,804:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-12 20:17:49,804:INFO:version 3.0.4
2025-04-12 20:17:49,804:INFO:Initializing setup()
2025-04-12 20:17:49,804:INFO:self.USI: 5e21
2025-04-12 20:17:49,804:INFO:self._variable_keys: {'X', 'html_param', 'seed', 'memory', 'y_train', 'X_train', 'fold_generator', 'pipeline', '_available_plots', 'idx', 'log_plots_param', 'fix_imbalance', 'target_param', 'fold_groups_param', 'X_test', 'gpu_n_jobs_param', 'USI', '_ml_usecase', 'y', 'data', 'is_multiclass', 'y_test', 'logging_param', 'n_jobs_param', 'fold_shuffle_param', 'exp_id', 'gpu_param', 'exp_name_log'}
2025-04-12 20:17:49,804:INFO:Checking environment
2025-04-12 20:17:49,805:INFO:python_version: 3.10.5
2025-04-12 20:17:49,805:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-12 20:17:49,805:INFO:machine: AMD64
2025-04-12 20:17:49,805:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-12 20:17:49,812:INFO:Memory: svmem(total=25042907136, available=12733616128, percent=49.2, used=12309291008, free=12733616128)
2025-04-12 20:17:49,812:INFO:Physical Core: 6
2025-04-12 20:17:49,814:INFO:Logical Core: 12
2025-04-12 20:17:49,814:INFO:Checking libraries
2025-04-12 20:17:49,814:INFO:System:
2025-04-12 20:17:49,814:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-12 20:17:49,814:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-12 20:17:49,814:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-12 20:17:49,814:INFO:PyCaret required dependencies:
2025-04-12 20:17:49,814:INFO:                 pip: 25.0.1
2025-04-12 20:17:49,814:INFO:          setuptools: 58.1.0
2025-04-12 20:17:49,814:INFO:             pycaret: 3.0.4
2025-04-12 20:17:49,814:INFO:             IPython: 8.29.0
2025-04-12 20:17:49,814:INFO:          ipywidgets: 8.1.6
2025-04-12 20:17:49,814:INFO:                tqdm: 4.67.1
2025-04-12 20:17:49,814:INFO:               numpy: 1.23.5
2025-04-12 20:17:49,814:INFO:              pandas: 1.5.3
2025-04-12 20:17:49,814:INFO:              jinja2: 3.1.4
2025-04-12 20:17:49,814:INFO:               scipy: 1.11.4
2025-04-12 20:17:49,814:INFO:              joblib: 1.3.2
2025-04-12 20:17:49,814:INFO:             sklearn: 1.2.2
2025-04-12 20:17:49,814:INFO:                pyod: 2.0.4
2025-04-12 20:17:49,814:INFO:            imblearn: 0.10.1
2025-04-12 20:17:49,814:INFO:   category_encoders: 2.7.0
2025-04-12 20:17:49,814:INFO:            lightgbm: 4.6.0
2025-04-12 20:17:49,814:INFO:               numba: 0.60.0
2025-04-12 20:17:49,814:INFO:            requests: 2.32.3
2025-04-12 20:17:49,814:INFO:          matplotlib: 3.7.5
2025-04-12 20:17:49,814:INFO:          scikitplot: 0.3.7
2025-04-12 20:17:49,814:INFO:         yellowbrick: 1.5
2025-04-12 20:17:49,814:INFO:              plotly: 5.24.1
2025-04-12 20:17:49,814:INFO:    plotly-resampler: Not installed
2025-04-12 20:17:49,815:INFO:             kaleido: 0.2.1
2025-04-12 20:17:49,815:INFO:           schemdraw: 0.15
2025-04-12 20:17:49,815:INFO:         statsmodels: 0.14.4
2025-04-12 20:17:49,815:INFO:              sktime: 0.26.0
2025-04-12 20:17:49,815:INFO:               tbats: 1.1.3
2025-04-12 20:17:49,815:INFO:            pmdarima: 2.0.4
2025-04-12 20:17:49,815:INFO:              psutil: 6.1.0
2025-04-12 20:17:49,815:INFO:          markupsafe: 3.0.2
2025-04-12 20:17:49,815:INFO:             pickle5: Not installed
2025-04-12 20:17:49,815:INFO:         cloudpickle: 3.1.1
2025-04-12 20:17:49,815:INFO:         deprecation: 2.1.0
2025-04-12 20:17:49,815:INFO:              xxhash: 3.5.0
2025-04-12 20:17:49,815:INFO:           wurlitzer: Not installed
2025-04-12 20:17:49,815:INFO:PyCaret optional dependencies:
2025-04-12 20:17:49,816:INFO:                shap: Not installed
2025-04-12 20:17:49,816:INFO:           interpret: Not installed
2025-04-12 20:17:49,816:INFO:                umap: Not installed
2025-04-12 20:17:49,816:INFO:    pandas_profiling: Not installed
2025-04-12 20:17:49,816:INFO:  explainerdashboard: Not installed
2025-04-12 20:17:49,816:INFO:             autoviz: Not installed
2025-04-12 20:17:49,816:INFO:           fairlearn: Not installed
2025-04-12 20:17:49,816:INFO:          deepchecks: Not installed
2025-04-12 20:17:49,816:INFO:             xgboost: 1.7.6
2025-04-12 20:17:49,816:INFO:            catboost: Not installed
2025-04-12 20:17:49,816:INFO:              kmodes: Not installed
2025-04-12 20:17:49,816:INFO:             mlxtend: Not installed
2025-04-12 20:17:49,816:INFO:       statsforecast: Not installed
2025-04-12 20:17:49,816:INFO:        tune_sklearn: Not installed
2025-04-12 20:17:49,816:INFO:                 ray: Not installed
2025-04-12 20:17:49,816:INFO:            hyperopt: Not installed
2025-04-12 20:17:49,816:INFO:              optuna: Not installed
2025-04-12 20:17:49,816:INFO:               skopt: Not installed
2025-04-12 20:17:49,816:INFO:              mlflow: Not installed
2025-04-12 20:17:49,816:INFO:              gradio: Not installed
2025-04-12 20:17:49,816:INFO:             fastapi: Not installed
2025-04-12 20:17:49,816:INFO:             uvicorn: Not installed
2025-04-12 20:17:49,816:INFO:              m2cgen: Not installed
2025-04-12 20:17:49,816:INFO:           evidently: Not installed
2025-04-12 20:17:49,816:INFO:               fugue: Not installed
2025-04-12 20:17:49,816:INFO:           streamlit: 1.42.0
2025-04-12 20:17:49,816:INFO:             prophet: Not installed
2025-04-12 20:17:49,816:INFO:None
2025-04-12 20:17:49,816:INFO:Set up data.
2025-04-12 20:17:49,835:INFO:Set up train/test split.
2025-04-12 20:17:49,845:INFO:Set up index.
2025-04-12 20:17:49,845:INFO:Set up folding strategy.
2025-04-12 20:17:49,845:INFO:Assigning column types.
2025-04-12 20:17:49,850:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-12 20:17:49,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:17:49,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:17:49,910:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:17:49,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:17:49,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:17:49,948:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:17:49,968:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:17:49,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:17:49,971:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-12 20:17:50,006:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:17:50,027:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:17:50,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:17:50,067:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:17:50,088:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:17:50,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:17:50,091:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-12 20:17:50,144:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:17:50,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:17:50,198:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:17:50,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:17:50,204:INFO:Preparing preprocessing pipeline...
2025-04-12 20:17:50,205:INFO:Set up simple imputation.
2025-04-12 20:17:50,207:INFO:Set up encoding of ordinal features.
2025-04-12 20:17:50,208:INFO:Set up encoding of categorical features.
2025-04-12 20:17:50,208:INFO:Set up imbalanced handling.
2025-04-12 20:17:50,208:INFO:Set up feature normalization.
2025-04-12 20:17:50,642:INFO:Finished creating preprocessing pipeline.
2025-04-12 20:17:50,665:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'P...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-12 20:17:50,665:INFO:Creating final display dataframe.
2025-04-12 20:17:50,972:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 35)
4        Transformed data shape        (1548, 53)
5   Transformed train set shape        (1230, 53)
6    Transformed test set shape         (318, 53)
7               Ignore features                 1
8              Ordinal features                 2
9              Numeric features                25
10         Categorical features                 8
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              5e21
2025-04-12 20:17:51,030:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:17:51,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:17:51,089:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:17:51,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:17:51,092:INFO:setup() successfully completed in 1.29s...............
2025-04-12 20:19:12,223:INFO:Initializing compare_models()
2025-04-12 20:19:12,223:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-12 20:19:12,223:INFO:Checking exceptions
2025-04-12 20:19:12,226:INFO:Preparing display monitor
2025-04-12 20:19:12,251:INFO:Initializing Logistic Regression
2025-04-12 20:19:12,252:INFO:Total runtime is 1.3868014017740885e-05 minutes
2025-04-12 20:19:12,254:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:12,254:INFO:Initializing create_model()
2025-04-12 20:19:12,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:12,255:INFO:Checking exceptions
2025-04-12 20:19:12,255:INFO:Importing libraries
2025-04-12 20:19:12,255:INFO:Copying training dataset
2025-04-12 20:19:12,261:INFO:Defining folds
2025-04-12 20:19:12,261:INFO:Declaring metric variables
2025-04-12 20:19:12,264:INFO:Importing untrained model
2025-04-12 20:19:12,268:INFO:Logistic Regression Imported successfully
2025-04-12 20:19:12,276:INFO:Starting cross validation
2025-04-12 20:19:12,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:22,956:INFO:Calculating mean and std
2025-04-12 20:19:22,957:INFO:Creating metrics dataframe
2025-04-12 20:19:22,974:INFO:Uploading results into container
2025-04-12 20:19:22,975:INFO:Uploading model into container now
2025-04-12 20:19:22,975:INFO:_master_model_container: 1
2025-04-12 20:19:22,975:INFO:_display_container: 2
2025-04-12 20:19:22,976:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-12 20:19:22,976:INFO:create_model() successfully completed......................................
2025-04-12 20:19:23,080:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:23,080:INFO:Creating metrics dataframe
2025-04-12 20:19:23,087:INFO:Initializing K Neighbors Classifier
2025-04-12 20:19:23,087:INFO:Total runtime is 0.1806098699569702 minutes
2025-04-12 20:19:23,092:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:23,092:INFO:Initializing create_model()
2025-04-12 20:19:23,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:23,093:INFO:Checking exceptions
2025-04-12 20:19:23,093:INFO:Importing libraries
2025-04-12 20:19:23,093:INFO:Copying training dataset
2025-04-12 20:19:23,102:INFO:Defining folds
2025-04-12 20:19:23,102:INFO:Declaring metric variables
2025-04-12 20:19:23,113:INFO:Importing untrained model
2025-04-12 20:19:23,118:INFO:K Neighbors Classifier Imported successfully
2025-04-12 20:19:23,126:INFO:Starting cross validation
2025-04-12 20:19:23,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:25,383:INFO:Calculating mean and std
2025-04-12 20:19:25,385:INFO:Creating metrics dataframe
2025-04-12 20:19:25,400:INFO:Uploading results into container
2025-04-12 20:19:25,400:INFO:Uploading model into container now
2025-04-12 20:19:25,402:INFO:_master_model_container: 2
2025-04-12 20:19:25,402:INFO:_display_container: 2
2025-04-12 20:19:25,402:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-12 20:19:25,402:INFO:create_model() successfully completed......................................
2025-04-12 20:19:25,508:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:25,508:INFO:Creating metrics dataframe
2025-04-12 20:19:25,515:INFO:Initializing Naive Bayes
2025-04-12 20:19:25,515:INFO:Total runtime is 0.22107027769088744 minutes
2025-04-12 20:19:25,518:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:25,518:INFO:Initializing create_model()
2025-04-12 20:19:25,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:25,518:INFO:Checking exceptions
2025-04-12 20:19:25,518:INFO:Importing libraries
2025-04-12 20:19:25,518:INFO:Copying training dataset
2025-04-12 20:19:25,523:INFO:Defining folds
2025-04-12 20:19:25,523:INFO:Declaring metric variables
2025-04-12 20:19:25,527:INFO:Importing untrained model
2025-04-12 20:19:25,532:INFO:Naive Bayes Imported successfully
2025-04-12 20:19:25,540:INFO:Starting cross validation
2025-04-12 20:19:25,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:26,112:INFO:Calculating mean and std
2025-04-12 20:19:26,114:INFO:Creating metrics dataframe
2025-04-12 20:19:26,128:INFO:Uploading results into container
2025-04-12 20:19:26,129:INFO:Uploading model into container now
2025-04-12 20:19:26,129:INFO:_master_model_container: 3
2025-04-12 20:19:26,129:INFO:_display_container: 2
2025-04-12 20:19:26,129:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-12 20:19:26,129:INFO:create_model() successfully completed......................................
2025-04-12 20:19:26,230:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:26,230:INFO:Creating metrics dataframe
2025-04-12 20:19:26,240:INFO:Initializing Decision Tree Classifier
2025-04-12 20:19:26,240:INFO:Total runtime is 0.23315714995066325 minutes
2025-04-12 20:19:26,243:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:26,244:INFO:Initializing create_model()
2025-04-12 20:19:26,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:26,244:INFO:Checking exceptions
2025-04-12 20:19:26,244:INFO:Importing libraries
2025-04-12 20:19:26,244:INFO:Copying training dataset
2025-04-12 20:19:26,250:INFO:Defining folds
2025-04-12 20:19:26,250:INFO:Declaring metric variables
2025-04-12 20:19:26,258:INFO:Importing untrained model
2025-04-12 20:19:26,262:INFO:Decision Tree Classifier Imported successfully
2025-04-12 20:19:26,274:INFO:Starting cross validation
2025-04-12 20:19:26,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:26,857:INFO:Calculating mean and std
2025-04-12 20:19:26,858:INFO:Creating metrics dataframe
2025-04-12 20:19:26,869:INFO:Uploading results into container
2025-04-12 20:19:26,869:INFO:Uploading model into container now
2025-04-12 20:19:26,870:INFO:_master_model_container: 4
2025-04-12 20:19:26,870:INFO:_display_container: 2
2025-04-12 20:19:26,871:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-12 20:19:26,871:INFO:create_model() successfully completed......................................
2025-04-12 20:19:26,975:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:26,975:INFO:Creating metrics dataframe
2025-04-12 20:19:26,982:INFO:Initializing SVM - Linear Kernel
2025-04-12 20:19:26,982:INFO:Total runtime is 0.24551788965861002 minutes
2025-04-12 20:19:26,984:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:26,984:INFO:Initializing create_model()
2025-04-12 20:19:26,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:26,985:INFO:Checking exceptions
2025-04-12 20:19:26,985:INFO:Importing libraries
2025-04-12 20:19:26,985:INFO:Copying training dataset
2025-04-12 20:19:26,992:INFO:Defining folds
2025-04-12 20:19:26,992:INFO:Declaring metric variables
2025-04-12 20:19:26,996:INFO:Importing untrained model
2025-04-12 20:19:26,999:INFO:SVM - Linear Kernel Imported successfully
2025-04-12 20:19:27,005:INFO:Starting cross validation
2025-04-12 20:19:27,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:27,348:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,353:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,358:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,361:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,372:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,372:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,373:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,389:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,404:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:19:27,460:INFO:Calculating mean and std
2025-04-12 20:19:27,462:INFO:Creating metrics dataframe
2025-04-12 20:19:27,473:INFO:Uploading results into container
2025-04-12 20:19:27,473:INFO:Uploading model into container now
2025-04-12 20:19:27,474:INFO:_master_model_container: 5
2025-04-12 20:19:27,474:INFO:_display_container: 2
2025-04-12 20:19:27,474:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-12 20:19:27,474:INFO:create_model() successfully completed......................................
2025-04-12 20:19:27,575:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:27,575:INFO:Creating metrics dataframe
2025-04-12 20:19:27,584:INFO:Initializing Ridge Classifier
2025-04-12 20:19:27,584:INFO:Total runtime is 0.255547833442688 minutes
2025-04-12 20:19:27,587:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:27,587:INFO:Initializing create_model()
2025-04-12 20:19:27,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:27,587:INFO:Checking exceptions
2025-04-12 20:19:27,587:INFO:Importing libraries
2025-04-12 20:19:27,588:INFO:Copying training dataset
2025-04-12 20:19:27,593:INFO:Defining folds
2025-04-12 20:19:27,593:INFO:Declaring metric variables
2025-04-12 20:19:27,597:INFO:Importing untrained model
2025-04-12 20:19:27,601:INFO:Ridge Classifier Imported successfully
2025-04-12 20:19:27,609:INFO:Starting cross validation
2025-04-12 20:19:27,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:27,943:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:27,946:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:27,947:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:27,957:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:27,966:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:27,970:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:27,974:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:27,985:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:27,987:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:19:28,046:INFO:Calculating mean and std
2025-04-12 20:19:28,047:INFO:Creating metrics dataframe
2025-04-12 20:19:28,058:INFO:Uploading results into container
2025-04-12 20:19:28,060:INFO:Uploading model into container now
2025-04-12 20:19:28,060:INFO:_master_model_container: 6
2025-04-12 20:19:28,060:INFO:_display_container: 2
2025-04-12 20:19:28,060:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-12 20:19:28,060:INFO:create_model() successfully completed......................................
2025-04-12 20:19:28,159:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:28,160:INFO:Creating metrics dataframe
2025-04-12 20:19:28,169:INFO:Initializing Random Forest Classifier
2025-04-12 20:19:28,170:INFO:Total runtime is 0.26531349023183187 minutes
2025-04-12 20:19:28,172:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:28,173:INFO:Initializing create_model()
2025-04-12 20:19:28,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:28,173:INFO:Checking exceptions
2025-04-12 20:19:28,173:INFO:Importing libraries
2025-04-12 20:19:28,173:INFO:Copying training dataset
2025-04-12 20:19:28,180:INFO:Defining folds
2025-04-12 20:19:28,180:INFO:Declaring metric variables
2025-04-12 20:19:28,183:INFO:Importing untrained model
2025-04-12 20:19:28,187:INFO:Random Forest Classifier Imported successfully
2025-04-12 20:19:28,193:INFO:Starting cross validation
2025-04-12 20:19:28,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:29,567:INFO:Calculating mean and std
2025-04-12 20:19:29,568:INFO:Creating metrics dataframe
2025-04-12 20:19:29,588:INFO:Uploading results into container
2025-04-12 20:19:29,588:INFO:Uploading model into container now
2025-04-12 20:19:29,589:INFO:_master_model_container: 7
2025-04-12 20:19:29,589:INFO:_display_container: 2
2025-04-12 20:19:29,590:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-12 20:19:29,590:INFO:create_model() successfully completed......................................
2025-04-12 20:19:29,696:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:29,696:INFO:Creating metrics dataframe
2025-04-12 20:19:29,705:INFO:Initializing Quadratic Discriminant Analysis
2025-04-12 20:19:29,705:INFO:Total runtime is 0.2909012277921041 minutes
2025-04-12 20:19:29,708:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:29,708:INFO:Initializing create_model()
2025-04-12 20:19:29,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:29,708:INFO:Checking exceptions
2025-04-12 20:19:29,708:INFO:Importing libraries
2025-04-12 20:19:29,708:INFO:Copying training dataset
2025-04-12 20:19:29,712:INFO:Defining folds
2025-04-12 20:19:29,712:INFO:Declaring metric variables
2025-04-12 20:19:29,717:INFO:Importing untrained model
2025-04-12 20:19:29,720:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-12 20:19:29,725:INFO:Starting cross validation
2025-04-12 20:19:29,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:29,965:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:29,974:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:29,981:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:29,981:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:29,985:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:29,988:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:29,992:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:29,993:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:30,017:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:30,030:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:19:30,337:INFO:Calculating mean and std
2025-04-12 20:19:30,338:INFO:Creating metrics dataframe
2025-04-12 20:19:30,355:INFO:Uploading results into container
2025-04-12 20:19:30,356:INFO:Uploading model into container now
2025-04-12 20:19:30,356:INFO:_master_model_container: 8
2025-04-12 20:19:30,356:INFO:_display_container: 2
2025-04-12 20:19:30,357:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-12 20:19:30,357:INFO:create_model() successfully completed......................................
2025-04-12 20:19:30,461:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:30,461:INFO:Creating metrics dataframe
2025-04-12 20:19:30,469:INFO:Initializing Ada Boost Classifier
2025-04-12 20:19:30,469:INFO:Total runtime is 0.30364172061284384 minutes
2025-04-12 20:19:30,472:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:30,472:INFO:Initializing create_model()
2025-04-12 20:19:30,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:30,472:INFO:Checking exceptions
2025-04-12 20:19:30,473:INFO:Importing libraries
2025-04-12 20:19:30,473:INFO:Copying training dataset
2025-04-12 20:19:30,478:INFO:Defining folds
2025-04-12 20:19:30,478:INFO:Declaring metric variables
2025-04-12 20:19:30,482:INFO:Importing untrained model
2025-04-12 20:19:30,488:INFO:Ada Boost Classifier Imported successfully
2025-04-12 20:19:30,494:INFO:Starting cross validation
2025-04-12 20:19:30,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:31,559:INFO:Calculating mean and std
2025-04-12 20:19:31,560:INFO:Creating metrics dataframe
2025-04-12 20:19:31,584:INFO:Uploading results into container
2025-04-12 20:19:31,585:INFO:Uploading model into container now
2025-04-12 20:19:31,585:INFO:_master_model_container: 9
2025-04-12 20:19:31,585:INFO:_display_container: 2
2025-04-12 20:19:31,585:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-12 20:19:31,585:INFO:create_model() successfully completed......................................
2025-04-12 20:19:31,691:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:31,691:INFO:Creating metrics dataframe
2025-04-12 20:19:31,701:INFO:Initializing Gradient Boosting Classifier
2025-04-12 20:19:31,702:INFO:Total runtime is 0.3241806705792745 minutes
2025-04-12 20:19:31,705:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:31,705:INFO:Initializing create_model()
2025-04-12 20:19:31,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:31,705:INFO:Checking exceptions
2025-04-12 20:19:31,705:INFO:Importing libraries
2025-04-12 20:19:31,705:INFO:Copying training dataset
2025-04-12 20:19:31,711:INFO:Defining folds
2025-04-12 20:19:31,711:INFO:Declaring metric variables
2025-04-12 20:19:31,714:INFO:Importing untrained model
2025-04-12 20:19:31,721:INFO:Gradient Boosting Classifier Imported successfully
2025-04-12 20:19:31,727:INFO:Starting cross validation
2025-04-12 20:19:31,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:33,427:INFO:Calculating mean and std
2025-04-12 20:19:33,428:INFO:Creating metrics dataframe
2025-04-12 20:19:33,463:INFO:Uploading results into container
2025-04-12 20:19:33,463:INFO:Uploading model into container now
2025-04-12 20:19:33,464:INFO:_master_model_container: 10
2025-04-12 20:19:33,464:INFO:_display_container: 2
2025-04-12 20:19:33,464:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-12 20:19:33,464:INFO:create_model() successfully completed......................................
2025-04-12 20:19:33,568:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:33,568:INFO:Creating metrics dataframe
2025-04-12 20:19:33,578:INFO:Initializing Linear Discriminant Analysis
2025-04-12 20:19:33,578:INFO:Total runtime is 0.3554485162099203 minutes
2025-04-12 20:19:33,581:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:33,581:INFO:Initializing create_model()
2025-04-12 20:19:33,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:33,582:INFO:Checking exceptions
2025-04-12 20:19:33,582:INFO:Importing libraries
2025-04-12 20:19:33,582:INFO:Copying training dataset
2025-04-12 20:19:33,588:INFO:Defining folds
2025-04-12 20:19:33,588:INFO:Declaring metric variables
2025-04-12 20:19:33,592:INFO:Importing untrained model
2025-04-12 20:19:33,600:INFO:Linear Discriminant Analysis Imported successfully
2025-04-12 20:19:33,607:INFO:Starting cross validation
2025-04-12 20:19:33,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:34,324:INFO:Calculating mean and std
2025-04-12 20:19:34,325:INFO:Creating metrics dataframe
2025-04-12 20:19:34,362:INFO:Uploading results into container
2025-04-12 20:19:34,362:INFO:Uploading model into container now
2025-04-12 20:19:34,362:INFO:_master_model_container: 11
2025-04-12 20:19:34,362:INFO:_display_container: 2
2025-04-12 20:19:34,362:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-12 20:19:34,362:INFO:create_model() successfully completed......................................
2025-04-12 20:19:34,465:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:34,465:INFO:Creating metrics dataframe
2025-04-12 20:19:34,473:INFO:Initializing Extra Trees Classifier
2025-04-12 20:19:34,473:INFO:Total runtime is 0.3703663070996603 minutes
2025-04-12 20:19:34,477:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:34,478:INFO:Initializing create_model()
2025-04-12 20:19:34,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:34,478:INFO:Checking exceptions
2025-04-12 20:19:34,478:INFO:Importing libraries
2025-04-12 20:19:34,478:INFO:Copying training dataset
2025-04-12 20:19:34,482:INFO:Defining folds
2025-04-12 20:19:34,482:INFO:Declaring metric variables
2025-04-12 20:19:34,488:INFO:Importing untrained model
2025-04-12 20:19:34,492:INFO:Extra Trees Classifier Imported successfully
2025-04-12 20:19:34,500:INFO:Starting cross validation
2025-04-12 20:19:34,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:35,811:INFO:Calculating mean and std
2025-04-12 20:19:35,812:INFO:Creating metrics dataframe
2025-04-12 20:19:35,852:INFO:Uploading results into container
2025-04-12 20:19:35,853:INFO:Uploading model into container now
2025-04-12 20:19:35,853:INFO:_master_model_container: 12
2025-04-12 20:19:35,853:INFO:_display_container: 2
2025-04-12 20:19:35,853:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-12 20:19:35,853:INFO:create_model() successfully completed......................................
2025-04-12 20:19:35,961:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:35,961:INFO:Creating metrics dataframe
2025-04-12 20:19:35,972:INFO:Initializing Extreme Gradient Boosting
2025-04-12 20:19:35,972:INFO:Total runtime is 0.3953499794006348 minutes
2025-04-12 20:19:35,975:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:35,975:INFO:Initializing create_model()
2025-04-12 20:19:35,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:35,975:INFO:Checking exceptions
2025-04-12 20:19:35,975:INFO:Importing libraries
2025-04-12 20:19:35,975:INFO:Copying training dataset
2025-04-12 20:19:35,980:INFO:Defining folds
2025-04-12 20:19:35,980:INFO:Declaring metric variables
2025-04-12 20:19:35,984:INFO:Importing untrained model
2025-04-12 20:19:35,990:INFO:Extreme Gradient Boosting Imported successfully
2025-04-12 20:19:35,997:INFO:Starting cross validation
2025-04-12 20:19:35,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:39,112:INFO:Calculating mean and std
2025-04-12 20:19:39,113:INFO:Creating metrics dataframe
2025-04-12 20:19:39,156:INFO:Uploading results into container
2025-04-12 20:19:39,157:INFO:Uploading model into container now
2025-04-12 20:19:39,157:INFO:_master_model_container: 13
2025-04-12 20:19:39,157:INFO:_display_container: 2
2025-04-12 20:19:39,158:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-12 20:19:39,158:INFO:create_model() successfully completed......................................
2025-04-12 20:19:39,262:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:39,262:INFO:Creating metrics dataframe
2025-04-12 20:19:39,273:INFO:Initializing Light Gradient Boosting Machine
2025-04-12 20:19:39,273:INFO:Total runtime is 0.45037021239598596 minutes
2025-04-12 20:19:39,275:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:39,275:INFO:Initializing create_model()
2025-04-12 20:19:39,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:39,276:INFO:Checking exceptions
2025-04-12 20:19:39,276:INFO:Importing libraries
2025-04-12 20:19:39,276:INFO:Copying training dataset
2025-04-12 20:19:39,281:INFO:Defining folds
2025-04-12 20:19:39,281:INFO:Declaring metric variables
2025-04-12 20:19:39,290:INFO:Importing untrained model
2025-04-12 20:19:39,296:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 20:19:39,304:INFO:Starting cross validation
2025-04-12 20:19:39,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:41,655:INFO:Calculating mean and std
2025-04-12 20:19:41,656:INFO:Creating metrics dataframe
2025-04-12 20:19:41,719:INFO:Uploading results into container
2025-04-12 20:19:41,720:INFO:Uploading model into container now
2025-04-12 20:19:41,720:INFO:_master_model_container: 14
2025-04-12 20:19:41,720:INFO:_display_container: 2
2025-04-12 20:19:41,721:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 20:19:41,721:INFO:create_model() successfully completed......................................
2025-04-12 20:19:41,838:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:41,838:INFO:Creating metrics dataframe
2025-04-12 20:19:41,849:INFO:Initializing Dummy Classifier
2025-04-12 20:19:41,849:INFO:Total runtime is 0.49330990711847944 minutes
2025-04-12 20:19:41,853:INFO:SubProcess create_model() called ==================================
2025-04-12 20:19:41,853:INFO:Initializing create_model()
2025-04-12 20:19:41,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B7A216E90>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:41,853:INFO:Checking exceptions
2025-04-12 20:19:41,854:INFO:Importing libraries
2025-04-12 20:19:41,854:INFO:Copying training dataset
2025-04-12 20:19:41,859:INFO:Defining folds
2025-04-12 20:19:41,859:INFO:Declaring metric variables
2025-04-12 20:19:41,865:INFO:Importing untrained model
2025-04-12 20:19:41,871:INFO:Dummy Classifier Imported successfully
2025-04-12 20:19:41,879:INFO:Starting cross validation
2025-04-12 20:19:41,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:19:42,345:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,345:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,347:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,361:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,362:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,362:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,370:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,375:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,386:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,390:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:19:42,756:INFO:Calculating mean and std
2025-04-12 20:19:42,757:INFO:Creating metrics dataframe
2025-04-12 20:19:42,812:INFO:Uploading results into container
2025-04-12 20:19:42,812:INFO:Uploading model into container now
2025-04-12 20:19:42,812:INFO:_master_model_container: 15
2025-04-12 20:19:42,812:INFO:_display_container: 2
2025-04-12 20:19:42,813:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-12 20:19:42,813:INFO:create_model() successfully completed......................................
2025-04-12 20:19:42,919:INFO:SubProcess create_model() end ==================================
2025-04-12 20:19:42,919:INFO:Creating metrics dataframe
2025-04-12 20:19:42,936:INFO:Initializing create_model()
2025-04-12 20:19:42,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:19:42,936:INFO:Checking exceptions
2025-04-12 20:19:42,939:INFO:Importing libraries
2025-04-12 20:19:42,939:INFO:Copying training dataset
2025-04-12 20:19:42,945:INFO:Defining folds
2025-04-12 20:19:42,945:INFO:Declaring metric variables
2025-04-12 20:19:42,945:INFO:Importing untrained model
2025-04-12 20:19:42,945:INFO:Declaring custom model
2025-04-12 20:19:42,946:INFO:Gradient Boosting Classifier Imported successfully
2025-04-12 20:19:42,949:INFO:Cross validation set to False
2025-04-12 20:19:42,949:INFO:Fitting Model
2025-04-12 20:19:43,816:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-12 20:19:43,816:INFO:create_model() successfully completed......................................
2025-04-12 20:19:43,953:INFO:_master_model_container: 15
2025-04-12 20:19:43,953:INFO:_display_container: 2
2025-04-12 20:19:43,955:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-12 20:19:43,955:INFO:compare_models() successfully completed......................................
2025-04-12 20:19:43,956:INFO:Initializing evaluate_model()
2025-04-12 20:19:43,956:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-12 20:19:43,967:INFO:Initializing plot_model()
2025-04-12 20:19:43,968:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C367D00>, system=True)
2025-04-12 20:19:43,968:INFO:Checking exceptions
2025-04-12 20:19:43,969:INFO:Preloading libraries
2025-04-12 20:19:43,976:INFO:Copying training dataset
2025-04-12 20:19:43,976:INFO:Plot type: pipeline
2025-04-12 20:19:44,179:INFO:Visual Rendered Successfully
2025-04-12 20:19:44,288:INFO:plot_model() successfully completed......................................
2025-04-12 20:38:29,795:INFO:PyCaret ClassificationExperiment
2025-04-12 20:38:29,795:INFO:Logging name: clf-default-name
2025-04-12 20:38:29,795:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-12 20:38:29,795:INFO:version 3.0.4
2025-04-12 20:38:29,795:INFO:Initializing setup()
2025-04-12 20:38:29,795:INFO:self.USI: 2711
2025-04-12 20:38:29,795:INFO:self._variable_keys: {'X', 'html_param', 'seed', 'memory', 'y_train', 'X_train', 'fold_generator', 'pipeline', '_available_plots', 'idx', 'log_plots_param', 'fix_imbalance', 'target_param', 'fold_groups_param', 'X_test', 'gpu_n_jobs_param', 'USI', '_ml_usecase', 'y', 'data', 'is_multiclass', 'y_test', 'logging_param', 'n_jobs_param', 'fold_shuffle_param', 'exp_id', 'gpu_param', 'exp_name_log'}
2025-04-12 20:38:29,795:INFO:Checking environment
2025-04-12 20:38:29,795:INFO:python_version: 3.10.5
2025-04-12 20:38:29,795:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-12 20:38:29,795:INFO:machine: AMD64
2025-04-12 20:38:29,795:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-12 20:38:29,803:INFO:Memory: svmem(total=25042907136, available=9951305728, percent=60.3, used=15091601408, free=9951305728)
2025-04-12 20:38:29,803:INFO:Physical Core: 6
2025-04-12 20:38:29,803:INFO:Logical Core: 12
2025-04-12 20:38:29,803:INFO:Checking libraries
2025-04-12 20:38:29,803:INFO:System:
2025-04-12 20:38:29,803:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-12 20:38:29,803:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-12 20:38:29,803:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-12 20:38:29,803:INFO:PyCaret required dependencies:
2025-04-12 20:38:29,803:INFO:                 pip: 25.0.1
2025-04-12 20:38:29,803:INFO:          setuptools: 58.1.0
2025-04-12 20:38:29,804:INFO:             pycaret: 3.0.4
2025-04-12 20:38:29,804:INFO:             IPython: 8.29.0
2025-04-12 20:38:29,804:INFO:          ipywidgets: 8.1.6
2025-04-12 20:38:29,804:INFO:                tqdm: 4.67.1
2025-04-12 20:38:29,804:INFO:               numpy: 1.23.5
2025-04-12 20:38:29,804:INFO:              pandas: 1.5.3
2025-04-12 20:38:29,804:INFO:              jinja2: 3.1.4
2025-04-12 20:38:29,804:INFO:               scipy: 1.11.4
2025-04-12 20:38:29,804:INFO:              joblib: 1.3.2
2025-04-12 20:38:29,804:INFO:             sklearn: 1.2.2
2025-04-12 20:38:29,804:INFO:                pyod: 2.0.4
2025-04-12 20:38:29,804:INFO:            imblearn: 0.10.1
2025-04-12 20:38:29,804:INFO:   category_encoders: 2.7.0
2025-04-12 20:38:29,804:INFO:            lightgbm: 4.6.0
2025-04-12 20:38:29,804:INFO:               numba: 0.60.0
2025-04-12 20:38:29,804:INFO:            requests: 2.32.3
2025-04-12 20:38:29,804:INFO:          matplotlib: 3.7.5
2025-04-12 20:38:29,804:INFO:          scikitplot: 0.3.7
2025-04-12 20:38:29,804:INFO:         yellowbrick: 1.5
2025-04-12 20:38:29,804:INFO:              plotly: 5.24.1
2025-04-12 20:38:29,804:INFO:    plotly-resampler: Not installed
2025-04-12 20:38:29,804:INFO:             kaleido: 0.2.1
2025-04-12 20:38:29,804:INFO:           schemdraw: 0.15
2025-04-12 20:38:29,804:INFO:         statsmodels: 0.14.4
2025-04-12 20:38:29,804:INFO:              sktime: 0.26.0
2025-04-12 20:38:29,804:INFO:               tbats: 1.1.3
2025-04-12 20:38:29,804:INFO:            pmdarima: 2.0.4
2025-04-12 20:38:29,804:INFO:              psutil: 6.1.0
2025-04-12 20:38:29,804:INFO:          markupsafe: 3.0.2
2025-04-12 20:38:29,804:INFO:             pickle5: Not installed
2025-04-12 20:38:29,804:INFO:         cloudpickle: 3.1.1
2025-04-12 20:38:29,804:INFO:         deprecation: 2.1.0
2025-04-12 20:38:29,804:INFO:              xxhash: 3.5.0
2025-04-12 20:38:29,804:INFO:           wurlitzer: Not installed
2025-04-12 20:38:29,804:INFO:PyCaret optional dependencies:
2025-04-12 20:38:29,805:INFO:                shap: Not installed
2025-04-12 20:38:29,805:INFO:           interpret: Not installed
2025-04-12 20:38:29,805:INFO:                umap: Not installed
2025-04-12 20:38:29,805:INFO:    pandas_profiling: Not installed
2025-04-12 20:38:29,805:INFO:  explainerdashboard: Not installed
2025-04-12 20:38:29,805:INFO:             autoviz: Not installed
2025-04-12 20:38:29,805:INFO:           fairlearn: Not installed
2025-04-12 20:38:29,805:INFO:          deepchecks: Not installed
2025-04-12 20:38:29,805:INFO:             xgboost: 1.7.6
2025-04-12 20:38:29,805:INFO:            catboost: Not installed
2025-04-12 20:38:29,805:INFO:              kmodes: Not installed
2025-04-12 20:38:29,805:INFO:             mlxtend: Not installed
2025-04-12 20:38:29,805:INFO:       statsforecast: Not installed
2025-04-12 20:38:29,805:INFO:        tune_sklearn: Not installed
2025-04-12 20:38:29,805:INFO:                 ray: Not installed
2025-04-12 20:38:29,805:INFO:            hyperopt: Not installed
2025-04-12 20:38:29,805:INFO:              optuna: Not installed
2025-04-12 20:38:29,805:INFO:               skopt: Not installed
2025-04-12 20:38:29,805:INFO:              mlflow: Not installed
2025-04-12 20:38:29,805:INFO:              gradio: Not installed
2025-04-12 20:38:29,805:INFO:             fastapi: Not installed
2025-04-12 20:38:29,805:INFO:             uvicorn: Not installed
2025-04-12 20:38:29,805:INFO:              m2cgen: Not installed
2025-04-12 20:38:29,805:INFO:           evidently: Not installed
2025-04-12 20:38:29,805:INFO:               fugue: Not installed
2025-04-12 20:38:29,805:INFO:           streamlit: 1.42.0
2025-04-12 20:38:29,805:INFO:             prophet: Not installed
2025-04-12 20:38:29,805:INFO:None
2025-04-12 20:38:29,805:INFO:Set up data.
2025-04-12 20:38:29,813:INFO:Set up train/test split.
2025-04-12 20:38:29,817:INFO:Set up index.
2025-04-12 20:38:29,817:INFO:Set up folding strategy.
2025-04-12 20:38:29,817:INFO:Assigning column types.
2025-04-12 20:38:29,820:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-12 20:38:29,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:38:29,855:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:38:29,878:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:38:29,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:38:29,914:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:38:29,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:38:29,935:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:38:29,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:38:29,937:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-12 20:38:29,968:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:38:29,988:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:38:29,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:38:30,026:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:38:30,046:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:38:30,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:38:30,049:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-12 20:38:30,100:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:38:30,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:38:30,153:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:38:30,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:38:30,156:INFO:Preparing preprocessing pipeline...
2025-04-12 20:38:30,157:INFO:Set up simple imputation.
2025-04-12 20:38:30,157:INFO:Set up imbalanced handling.
2025-04-12 20:38:30,157:INFO:Set up feature normalization.
2025-04-12 20:38:30,187:INFO:Finished creating preprocessing pipeline.
2025-04-12 20:38:30,190:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-12 20:38:30,190:INFO:Creating final display dataframe.
2025-04-12 20:38:30,275:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 35)
4        Transformed data shape        (1548, 34)
5   Transformed train set shape        (1230, 34)
6    Transformed test set shape         (318, 34)
7               Ignore features                 1
8              Numeric features                33
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                Fix imbalance              True
14         Fix imbalance method             SMOTE
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              2711
2025-04-12 20:38:30,327:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:38:30,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:38:30,382:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:38:30,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:38:30,384:INFO:setup() successfully completed in 0.64s...............
2025-04-12 20:38:32,265:INFO:Initializing compare_models()
2025-04-12 20:38:32,265:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-12 20:38:32,265:INFO:Checking exceptions
2025-04-12 20:38:32,269:INFO:Preparing display monitor
2025-04-12 20:38:32,288:INFO:Initializing Logistic Regression
2025-04-12 20:38:32,288:INFO:Total runtime is 0.0 minutes
2025-04-12 20:38:32,290:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:32,290:INFO:Initializing create_model()
2025-04-12 20:38:32,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:32,290:INFO:Checking exceptions
2025-04-12 20:38:32,291:INFO:Importing libraries
2025-04-12 20:38:32,291:INFO:Copying training dataset
2025-04-12 20:38:32,296:INFO:Defining folds
2025-04-12 20:38:32,296:INFO:Declaring metric variables
2025-04-12 20:38:32,300:INFO:Importing untrained model
2025-04-12 20:38:32,303:INFO:Logistic Regression Imported successfully
2025-04-12 20:38:32,309:INFO:Starting cross validation
2025-04-12 20:38:32,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:44,780:INFO:Calculating mean and std
2025-04-12 20:38:44,782:INFO:Creating metrics dataframe
2025-04-12 20:38:44,885:INFO:Uploading results into container
2025-04-12 20:38:44,886:INFO:Uploading model into container now
2025-04-12 20:38:44,888:INFO:_master_model_container: 1
2025-04-12 20:38:44,888:INFO:_display_container: 2
2025-04-12 20:38:44,889:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-12 20:38:44,889:INFO:create_model() successfully completed......................................
2025-04-12 20:38:45,028:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:45,028:INFO:Creating metrics dataframe
2025-04-12 20:38:45,040:INFO:Initializing K Neighbors Classifier
2025-04-12 20:38:45,040:INFO:Total runtime is 0.21253488858540853 minutes
2025-04-12 20:38:45,046:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:45,046:INFO:Initializing create_model()
2025-04-12 20:38:45,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:45,048:INFO:Checking exceptions
2025-04-12 20:38:45,048:INFO:Importing libraries
2025-04-12 20:38:45,048:INFO:Copying training dataset
2025-04-12 20:38:45,054:INFO:Defining folds
2025-04-12 20:38:45,054:INFO:Declaring metric variables
2025-04-12 20:38:45,061:INFO:Importing untrained model
2025-04-12 20:38:45,067:INFO:K Neighbors Classifier Imported successfully
2025-04-12 20:38:45,081:INFO:Starting cross validation
2025-04-12 20:38:45,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:48,798:INFO:Calculating mean and std
2025-04-12 20:38:48,800:INFO:Creating metrics dataframe
2025-04-12 20:38:48,903:INFO:Uploading results into container
2025-04-12 20:38:48,904:INFO:Uploading model into container now
2025-04-12 20:38:48,905:INFO:_master_model_container: 2
2025-04-12 20:38:48,905:INFO:_display_container: 2
2025-04-12 20:38:48,905:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-12 20:38:48,907:INFO:create_model() successfully completed......................................
2025-04-12 20:38:49,037:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:49,037:INFO:Creating metrics dataframe
2025-04-12 20:38:49,053:INFO:Initializing Naive Bayes
2025-04-12 20:38:49,053:INFO:Total runtime is 0.27941666046778363 minutes
2025-04-12 20:38:49,057:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:49,057:INFO:Initializing create_model()
2025-04-12 20:38:49,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:49,058:INFO:Checking exceptions
2025-04-12 20:38:49,060:INFO:Importing libraries
2025-04-12 20:38:49,060:INFO:Copying training dataset
2025-04-12 20:38:49,068:INFO:Defining folds
2025-04-12 20:38:49,068:INFO:Declaring metric variables
2025-04-12 20:38:49,076:INFO:Importing untrained model
2025-04-12 20:38:49,085:INFO:Naive Bayes Imported successfully
2025-04-12 20:38:49,095:INFO:Starting cross validation
2025-04-12 20:38:49,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:49,957:INFO:Calculating mean and std
2025-04-12 20:38:49,958:INFO:Creating metrics dataframe
2025-04-12 20:38:50,017:INFO:Uploading results into container
2025-04-12 20:38:50,017:INFO:Uploading model into container now
2025-04-12 20:38:50,018:INFO:_master_model_container: 3
2025-04-12 20:38:50,018:INFO:_display_container: 2
2025-04-12 20:38:50,018:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-12 20:38:50,018:INFO:create_model() successfully completed......................................
2025-04-12 20:38:50,127:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:50,127:INFO:Creating metrics dataframe
2025-04-12 20:38:50,135:INFO:Initializing Decision Tree Classifier
2025-04-12 20:38:50,135:INFO:Total runtime is 0.2974537531534831 minutes
2025-04-12 20:38:50,139:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:50,139:INFO:Initializing create_model()
2025-04-12 20:38:50,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:50,139:INFO:Checking exceptions
2025-04-12 20:38:50,139:INFO:Importing libraries
2025-04-12 20:38:50,139:INFO:Copying training dataset
2025-04-12 20:38:50,142:INFO:Defining folds
2025-04-12 20:38:50,142:INFO:Declaring metric variables
2025-04-12 20:38:50,147:INFO:Importing untrained model
2025-04-12 20:38:50,151:INFO:Decision Tree Classifier Imported successfully
2025-04-12 20:38:50,157:INFO:Starting cross validation
2025-04-12 20:38:50,159:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:50,794:INFO:Calculating mean and std
2025-04-12 20:38:50,796:INFO:Creating metrics dataframe
2025-04-12 20:38:50,858:INFO:Uploading results into container
2025-04-12 20:38:50,858:INFO:Uploading model into container now
2025-04-12 20:38:50,858:INFO:_master_model_container: 4
2025-04-12 20:38:50,858:INFO:_display_container: 2
2025-04-12 20:38:50,860:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-12 20:38:50,860:INFO:create_model() successfully completed......................................
2025-04-12 20:38:50,965:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:50,965:INFO:Creating metrics dataframe
2025-04-12 20:38:50,973:INFO:Initializing SVM - Linear Kernel
2025-04-12 20:38:50,973:INFO:Total runtime is 0.3114154140154521 minutes
2025-04-12 20:38:50,975:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:50,975:INFO:Initializing create_model()
2025-04-12 20:38:50,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:50,975:INFO:Checking exceptions
2025-04-12 20:38:50,976:INFO:Importing libraries
2025-04-12 20:38:50,976:INFO:Copying training dataset
2025-04-12 20:38:50,980:INFO:Defining folds
2025-04-12 20:38:50,980:INFO:Declaring metric variables
2025-04-12 20:38:50,983:INFO:Importing untrained model
2025-04-12 20:38:50,988:INFO:SVM - Linear Kernel Imported successfully
2025-04-12 20:38:50,994:INFO:Starting cross validation
2025-04-12 20:38:50,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:51,106:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,106:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,117:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,117:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,119:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,120:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,135:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,156:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,156:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:38:51,601:INFO:Calculating mean and std
2025-04-12 20:38:51,602:INFO:Creating metrics dataframe
2025-04-12 20:38:51,655:INFO:Uploading results into container
2025-04-12 20:38:51,656:INFO:Uploading model into container now
2025-04-12 20:38:51,656:INFO:_master_model_container: 5
2025-04-12 20:38:51,656:INFO:_display_container: 2
2025-04-12 20:38:51,657:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-12 20:38:51,657:INFO:create_model() successfully completed......................................
2025-04-12 20:38:51,757:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:51,758:INFO:Creating metrics dataframe
2025-04-12 20:38:51,765:INFO:Initializing Ridge Classifier
2025-04-12 20:38:51,765:INFO:Total runtime is 0.32461942036946617 minutes
2025-04-12 20:38:51,767:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:51,767:INFO:Initializing create_model()
2025-04-12 20:38:51,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:51,767:INFO:Checking exceptions
2025-04-12 20:38:51,767:INFO:Importing libraries
2025-04-12 20:38:51,768:INFO:Copying training dataset
2025-04-12 20:38:51,772:INFO:Defining folds
2025-04-12 20:38:51,772:INFO:Declaring metric variables
2025-04-12 20:38:51,776:INFO:Importing untrained model
2025-04-12 20:38:51,780:INFO:Ridge Classifier Imported successfully
2025-04-12 20:38:51,789:INFO:Starting cross validation
2025-04-12 20:38:51,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:51,888:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:51,889:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:51,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:51,899:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:51,904:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:51,922:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:51,923:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:51,923:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:51,926:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:38:52,344:INFO:Calculating mean and std
2025-04-12 20:38:52,345:INFO:Creating metrics dataframe
2025-04-12 20:38:52,405:INFO:Uploading results into container
2025-04-12 20:38:52,406:INFO:Uploading model into container now
2025-04-12 20:38:52,406:INFO:_master_model_container: 6
2025-04-12 20:38:52,406:INFO:_display_container: 2
2025-04-12 20:38:52,406:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-12 20:38:52,406:INFO:create_model() successfully completed......................................
2025-04-12 20:38:52,509:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:52,509:INFO:Creating metrics dataframe
2025-04-12 20:38:52,517:INFO:Initializing Random Forest Classifier
2025-04-12 20:38:52,517:INFO:Total runtime is 0.33715533415476484 minutes
2025-04-12 20:38:52,519:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:52,519:INFO:Initializing create_model()
2025-04-12 20:38:52,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:52,520:INFO:Checking exceptions
2025-04-12 20:38:52,520:INFO:Importing libraries
2025-04-12 20:38:52,520:INFO:Copying training dataset
2025-04-12 20:38:52,523:INFO:Defining folds
2025-04-12 20:38:52,523:INFO:Declaring metric variables
2025-04-12 20:38:52,527:INFO:Importing untrained model
2025-04-12 20:38:52,530:INFO:Random Forest Classifier Imported successfully
2025-04-12 20:38:52,539:INFO:Starting cross validation
2025-04-12 20:38:52,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:53,752:INFO:Calculating mean and std
2025-04-12 20:38:53,754:INFO:Creating metrics dataframe
2025-04-12 20:38:53,820:INFO:Uploading results into container
2025-04-12 20:38:53,820:INFO:Uploading model into container now
2025-04-12 20:38:53,821:INFO:_master_model_container: 7
2025-04-12 20:38:53,821:INFO:_display_container: 2
2025-04-12 20:38:53,821:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-12 20:38:53,821:INFO:create_model() successfully completed......................................
2025-04-12 20:38:53,923:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:53,923:INFO:Creating metrics dataframe
2025-04-12 20:38:53,931:INFO:Initializing Quadratic Discriminant Analysis
2025-04-12 20:38:53,931:INFO:Total runtime is 0.3607236385345459 minutes
2025-04-12 20:38:53,933:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:53,933:INFO:Initializing create_model()
2025-04-12 20:38:53,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:53,935:INFO:Checking exceptions
2025-04-12 20:38:53,935:INFO:Importing libraries
2025-04-12 20:38:53,935:INFO:Copying training dataset
2025-04-12 20:38:53,939:INFO:Defining folds
2025-04-12 20:38:53,939:INFO:Declaring metric variables
2025-04-12 20:38:53,942:INFO:Importing untrained model
2025-04-12 20:38:53,946:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-12 20:38:53,958:INFO:Starting cross validation
2025-04-12 20:38:53,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:54,070:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,072:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,081:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,084:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,087:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,104:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,105:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,116:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,116:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,124:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:38:54,633:INFO:Calculating mean and std
2025-04-12 20:38:54,634:INFO:Creating metrics dataframe
2025-04-12 20:38:54,696:INFO:Uploading results into container
2025-04-12 20:38:54,697:INFO:Uploading model into container now
2025-04-12 20:38:54,698:INFO:_master_model_container: 8
2025-04-12 20:38:54,698:INFO:_display_container: 2
2025-04-12 20:38:54,698:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-12 20:38:54,698:INFO:create_model() successfully completed......................................
2025-04-12 20:38:54,801:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:54,801:INFO:Creating metrics dataframe
2025-04-12 20:38:54,810:INFO:Initializing Ada Boost Classifier
2025-04-12 20:38:54,810:INFO:Total runtime is 0.3753724495569865 minutes
2025-04-12 20:38:54,812:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:54,812:INFO:Initializing create_model()
2025-04-12 20:38:54,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:54,812:INFO:Checking exceptions
2025-04-12 20:38:54,812:INFO:Importing libraries
2025-04-12 20:38:54,812:INFO:Copying training dataset
2025-04-12 20:38:54,818:INFO:Defining folds
2025-04-12 20:38:54,818:INFO:Declaring metric variables
2025-04-12 20:38:54,821:INFO:Importing untrained model
2025-04-12 20:38:54,824:INFO:Ada Boost Classifier Imported successfully
2025-04-12 20:38:54,832:INFO:Starting cross validation
2025-04-12 20:38:54,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:55,877:INFO:Calculating mean and std
2025-04-12 20:38:55,878:INFO:Creating metrics dataframe
2025-04-12 20:38:55,949:INFO:Uploading results into container
2025-04-12 20:38:55,950:INFO:Uploading model into container now
2025-04-12 20:38:55,950:INFO:_master_model_container: 9
2025-04-12 20:38:55,951:INFO:_display_container: 2
2025-04-12 20:38:55,951:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-12 20:38:55,951:INFO:create_model() successfully completed......................................
2025-04-12 20:38:56,053:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:56,054:INFO:Creating metrics dataframe
2025-04-12 20:38:56,063:INFO:Initializing Gradient Boosting Classifier
2025-04-12 20:38:56,063:INFO:Total runtime is 0.3962483167648316 minutes
2025-04-12 20:38:56,066:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:56,066:INFO:Initializing create_model()
2025-04-12 20:38:56,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:56,066:INFO:Checking exceptions
2025-04-12 20:38:56,066:INFO:Importing libraries
2025-04-12 20:38:56,066:INFO:Copying training dataset
2025-04-12 20:38:56,069:INFO:Defining folds
2025-04-12 20:38:56,069:INFO:Declaring metric variables
2025-04-12 20:38:56,074:INFO:Importing untrained model
2025-04-12 20:38:56,078:INFO:Gradient Boosting Classifier Imported successfully
2025-04-12 20:38:56,086:INFO:Starting cross validation
2025-04-12 20:38:56,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:57,680:INFO:Calculating mean and std
2025-04-12 20:38:57,681:INFO:Creating metrics dataframe
2025-04-12 20:38:57,749:INFO:Uploading results into container
2025-04-12 20:38:57,750:INFO:Uploading model into container now
2025-04-12 20:38:57,750:INFO:_master_model_container: 10
2025-04-12 20:38:57,750:INFO:_display_container: 2
2025-04-12 20:38:57,750:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-12 20:38:57,750:INFO:create_model() successfully completed......................................
2025-04-12 20:38:57,848:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:57,848:INFO:Creating metrics dataframe
2025-04-12 20:38:57,856:INFO:Initializing Linear Discriminant Analysis
2025-04-12 20:38:57,856:INFO:Total runtime is 0.4261293927828471 minutes
2025-04-12 20:38:57,858:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:57,858:INFO:Initializing create_model()
2025-04-12 20:38:57,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:57,860:INFO:Checking exceptions
2025-04-12 20:38:57,860:INFO:Importing libraries
2025-04-12 20:38:57,860:INFO:Copying training dataset
2025-04-12 20:38:57,863:INFO:Defining folds
2025-04-12 20:38:57,863:INFO:Declaring metric variables
2025-04-12 20:38:57,867:INFO:Importing untrained model
2025-04-12 20:38:57,874:INFO:Linear Discriminant Analysis Imported successfully
2025-04-12 20:38:57,881:INFO:Starting cross validation
2025-04-12 20:38:57,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:38:58,630:INFO:Calculating mean and std
2025-04-12 20:38:58,631:INFO:Creating metrics dataframe
2025-04-12 20:38:58,704:INFO:Uploading results into container
2025-04-12 20:38:58,705:INFO:Uploading model into container now
2025-04-12 20:38:58,706:INFO:_master_model_container: 11
2025-04-12 20:38:58,706:INFO:_display_container: 2
2025-04-12 20:38:58,706:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-12 20:38:58,706:INFO:create_model() successfully completed......................................
2025-04-12 20:38:58,804:INFO:SubProcess create_model() end ==================================
2025-04-12 20:38:58,804:INFO:Creating metrics dataframe
2025-04-12 20:38:58,812:INFO:Initializing Extra Trees Classifier
2025-04-12 20:38:58,812:INFO:Total runtime is 0.44207227230072027 minutes
2025-04-12 20:38:58,814:INFO:SubProcess create_model() called ==================================
2025-04-12 20:38:58,816:INFO:Initializing create_model()
2025-04-12 20:38:58,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:38:58,816:INFO:Checking exceptions
2025-04-12 20:38:58,816:INFO:Importing libraries
2025-04-12 20:38:58,816:INFO:Copying training dataset
2025-04-12 20:38:58,821:INFO:Defining folds
2025-04-12 20:38:58,821:INFO:Declaring metric variables
2025-04-12 20:38:58,824:INFO:Importing untrained model
2025-04-12 20:38:58,831:INFO:Extra Trees Classifier Imported successfully
2025-04-12 20:38:58,838:INFO:Starting cross validation
2025-04-12 20:38:58,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:39:00,123:INFO:Calculating mean and std
2025-04-12 20:39:00,124:INFO:Creating metrics dataframe
2025-04-12 20:39:00,201:INFO:Uploading results into container
2025-04-12 20:39:00,202:INFO:Uploading model into container now
2025-04-12 20:39:00,202:INFO:_master_model_container: 12
2025-04-12 20:39:00,202:INFO:_display_container: 2
2025-04-12 20:39:00,202:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-12 20:39:00,202:INFO:create_model() successfully completed......................................
2025-04-12 20:39:00,300:INFO:SubProcess create_model() end ==================================
2025-04-12 20:39:00,300:INFO:Creating metrics dataframe
2025-04-12 20:39:00,315:INFO:Initializing Extreme Gradient Boosting
2025-04-12 20:39:00,315:INFO:Total runtime is 0.4671184659004212 minutes
2025-04-12 20:39:00,318:INFO:SubProcess create_model() called ==================================
2025-04-12 20:39:00,319:INFO:Initializing create_model()
2025-04-12 20:39:00,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:39:00,319:INFO:Checking exceptions
2025-04-12 20:39:00,319:INFO:Importing libraries
2025-04-12 20:39:00,319:INFO:Copying training dataset
2025-04-12 20:39:00,321:INFO:Defining folds
2025-04-12 20:39:00,321:INFO:Declaring metric variables
2025-04-12 20:39:00,325:INFO:Importing untrained model
2025-04-12 20:39:00,329:INFO:Extreme Gradient Boosting Imported successfully
2025-04-12 20:39:00,335:INFO:Starting cross validation
2025-04-12 20:39:00,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:39:03,341:INFO:Calculating mean and std
2025-04-12 20:39:03,342:INFO:Creating metrics dataframe
2025-04-12 20:39:03,422:INFO:Uploading results into container
2025-04-12 20:39:03,423:INFO:Uploading model into container now
2025-04-12 20:39:03,423:INFO:_master_model_container: 13
2025-04-12 20:39:03,423:INFO:_display_container: 2
2025-04-12 20:39:03,423:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-12 20:39:03,424:INFO:create_model() successfully completed......................................
2025-04-12 20:39:03,522:INFO:SubProcess create_model() end ==================================
2025-04-12 20:39:03,522:INFO:Creating metrics dataframe
2025-04-12 20:39:03,532:INFO:Initializing Light Gradient Boosting Machine
2025-04-12 20:39:03,532:INFO:Total runtime is 0.5207258383433024 minutes
2025-04-12 20:39:03,535:INFO:SubProcess create_model() called ==================================
2025-04-12 20:39:03,535:INFO:Initializing create_model()
2025-04-12 20:39:03,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:39:03,535:INFO:Checking exceptions
2025-04-12 20:39:03,535:INFO:Importing libraries
2025-04-12 20:39:03,535:INFO:Copying training dataset
2025-04-12 20:39:03,539:INFO:Defining folds
2025-04-12 20:39:03,539:INFO:Declaring metric variables
2025-04-12 20:39:03,543:INFO:Importing untrained model
2025-04-12 20:39:03,550:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 20:39:03,559:INFO:Starting cross validation
2025-04-12 20:39:03,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:39:05,350:INFO:Calculating mean and std
2025-04-12 20:39:05,351:INFO:Creating metrics dataframe
2025-04-12 20:39:05,439:INFO:Uploading results into container
2025-04-12 20:39:05,439:INFO:Uploading model into container now
2025-04-12 20:39:05,440:INFO:_master_model_container: 14
2025-04-12 20:39:05,440:INFO:_display_container: 2
2025-04-12 20:39:05,440:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 20:39:05,440:INFO:create_model() successfully completed......................................
2025-04-12 20:39:05,539:INFO:SubProcess create_model() end ==================================
2025-04-12 20:39:05,539:INFO:Creating metrics dataframe
2025-04-12 20:39:05,547:INFO:Initializing Dummy Classifier
2025-04-12 20:39:05,547:INFO:Total runtime is 0.5543142835299174 minutes
2025-04-12 20:39:05,550:INFO:SubProcess create_model() called ==================================
2025-04-12 20:39:05,550:INFO:Initializing create_model()
2025-04-12 20:39:05,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B43326BC0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:39:05,550:INFO:Checking exceptions
2025-04-12 20:39:05,550:INFO:Importing libraries
2025-04-12 20:39:05,550:INFO:Copying training dataset
2025-04-12 20:39:05,555:INFO:Defining folds
2025-04-12 20:39:05,555:INFO:Declaring metric variables
2025-04-12 20:39:05,562:INFO:Importing untrained model
2025-04-12 20:39:05,610:INFO:Dummy Classifier Imported successfully
2025-04-12 20:39:05,618:INFO:Starting cross validation
2025-04-12 20:39:05,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:39:05,739:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,742:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,749:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,749:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,752:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,752:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,757:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,764:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,776:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:05,780:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:39:06,473:INFO:Calculating mean and std
2025-04-12 20:39:06,475:INFO:Creating metrics dataframe
2025-04-12 20:39:06,587:INFO:Uploading results into container
2025-04-12 20:39:06,587:INFO:Uploading model into container now
2025-04-12 20:39:06,588:INFO:_master_model_container: 15
2025-04-12 20:39:06,588:INFO:_display_container: 2
2025-04-12 20:39:06,588:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-12 20:39:06,589:INFO:create_model() successfully completed......................................
2025-04-12 20:39:06,703:INFO:SubProcess create_model() end ==================================
2025-04-12 20:39:06,703:INFO:Creating metrics dataframe
2025-04-12 20:39:06,720:INFO:Initializing create_model()
2025-04-12 20:39:06,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:39:06,720:INFO:Checking exceptions
2025-04-12 20:39:06,723:INFO:Importing libraries
2025-04-12 20:39:06,723:INFO:Copying training dataset
2025-04-12 20:39:06,727:INFO:Defining folds
2025-04-12 20:39:06,727:INFO:Declaring metric variables
2025-04-12 20:39:06,727:INFO:Importing untrained model
2025-04-12 20:39:06,727:INFO:Declaring custom model
2025-04-12 20:39:06,728:INFO:Random Forest Classifier Imported successfully
2025-04-12 20:39:06,729:INFO:Cross validation set to False
2025-04-12 20:39:06,729:INFO:Fitting Model
2025-04-12 20:39:07,066:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-12 20:39:07,066:INFO:create_model() successfully completed......................................
2025-04-12 20:39:07,191:INFO:_master_model_container: 15
2025-04-12 20:39:07,191:INFO:_display_container: 2
2025-04-12 20:39:07,191:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-12 20:39:07,191:INFO:compare_models() successfully completed......................................
2025-04-12 20:39:07,192:INFO:Initializing evaluate_model()
2025-04-12 20:39:07,192:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-12 20:39:07,199:INFO:Initializing plot_model()
2025-04-12 20:39:07,199:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7A444910>, system=True)
2025-04-12 20:39:07,200:INFO:Checking exceptions
2025-04-12 20:39:07,224:INFO:Preloading libraries
2025-04-12 20:39:07,230:INFO:Copying training dataset
2025-04-12 20:39:07,230:INFO:Plot type: pipeline
2025-04-12 20:39:07,352:INFO:Visual Rendered Successfully
2025-04-12 20:39:07,459:INFO:plot_model() successfully completed......................................
2025-04-12 20:42:20,350:INFO:PyCaret ClassificationExperiment
2025-04-12 20:42:20,350:INFO:Logging name: clf-default-name
2025-04-12 20:42:20,350:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-12 20:42:20,350:INFO:version 3.0.4
2025-04-12 20:42:20,350:INFO:Initializing setup()
2025-04-12 20:42:20,350:INFO:self.USI: fbd0
2025-04-12 20:42:20,350:INFO:self._variable_keys: {'X', 'html_param', 'seed', 'memory', 'y_train', 'X_train', 'fold_generator', 'pipeline', '_available_plots', 'idx', 'log_plots_param', 'fix_imbalance', 'target_param', 'fold_groups_param', 'X_test', 'gpu_n_jobs_param', 'USI', '_ml_usecase', 'y', 'data', 'is_multiclass', 'y_test', 'logging_param', 'n_jobs_param', 'fold_shuffle_param', 'exp_id', 'gpu_param', 'exp_name_log'}
2025-04-12 20:42:20,350:INFO:Checking environment
2025-04-12 20:42:20,350:INFO:python_version: 3.10.5
2025-04-12 20:42:20,350:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-12 20:42:20,350:INFO:machine: AMD64
2025-04-12 20:42:20,350:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-12 20:42:20,357:INFO:Memory: svmem(total=25042907136, available=7909560320, percent=68.4, used=17133346816, free=7909560320)
2025-04-12 20:42:20,357:INFO:Physical Core: 6
2025-04-12 20:42:20,357:INFO:Logical Core: 12
2025-04-12 20:42:20,357:INFO:Checking libraries
2025-04-12 20:42:20,357:INFO:System:
2025-04-12 20:42:20,357:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-12 20:42:20,357:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-12 20:42:20,357:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-12 20:42:20,357:INFO:PyCaret required dependencies:
2025-04-12 20:42:20,357:INFO:                 pip: 25.0.1
2025-04-12 20:42:20,357:INFO:          setuptools: 58.1.0
2025-04-12 20:42:20,357:INFO:             pycaret: 3.0.4
2025-04-12 20:42:20,357:INFO:             IPython: 8.29.0
2025-04-12 20:42:20,357:INFO:          ipywidgets: 8.1.6
2025-04-12 20:42:20,357:INFO:                tqdm: 4.67.1
2025-04-12 20:42:20,357:INFO:               numpy: 1.23.5
2025-04-12 20:42:20,357:INFO:              pandas: 1.5.3
2025-04-12 20:42:20,357:INFO:              jinja2: 3.1.4
2025-04-12 20:42:20,357:INFO:               scipy: 1.11.4
2025-04-12 20:42:20,357:INFO:              joblib: 1.3.2
2025-04-12 20:42:20,357:INFO:             sklearn: 1.2.2
2025-04-12 20:42:20,357:INFO:                pyod: 2.0.4
2025-04-12 20:42:20,357:INFO:            imblearn: 0.10.1
2025-04-12 20:42:20,357:INFO:   category_encoders: 2.7.0
2025-04-12 20:42:20,357:INFO:            lightgbm: 4.6.0
2025-04-12 20:42:20,357:INFO:               numba: 0.60.0
2025-04-12 20:42:20,357:INFO:            requests: 2.32.3
2025-04-12 20:42:20,357:INFO:          matplotlib: 3.7.5
2025-04-12 20:42:20,357:INFO:          scikitplot: 0.3.7
2025-04-12 20:42:20,358:INFO:         yellowbrick: 1.5
2025-04-12 20:42:20,358:INFO:              plotly: 5.24.1
2025-04-12 20:42:20,358:INFO:    plotly-resampler: Not installed
2025-04-12 20:42:20,358:INFO:             kaleido: 0.2.1
2025-04-12 20:42:20,358:INFO:           schemdraw: 0.15
2025-04-12 20:42:20,358:INFO:         statsmodels: 0.14.4
2025-04-12 20:42:20,358:INFO:              sktime: 0.26.0
2025-04-12 20:42:20,358:INFO:               tbats: 1.1.3
2025-04-12 20:42:20,358:INFO:            pmdarima: 2.0.4
2025-04-12 20:42:20,358:INFO:              psutil: 6.1.0
2025-04-12 20:42:20,358:INFO:          markupsafe: 3.0.2
2025-04-12 20:42:20,358:INFO:             pickle5: Not installed
2025-04-12 20:42:20,358:INFO:         cloudpickle: 3.1.1
2025-04-12 20:42:20,358:INFO:         deprecation: 2.1.0
2025-04-12 20:42:20,358:INFO:              xxhash: 3.5.0
2025-04-12 20:42:20,358:INFO:           wurlitzer: Not installed
2025-04-12 20:42:20,358:INFO:PyCaret optional dependencies:
2025-04-12 20:42:20,358:INFO:                shap: Not installed
2025-04-12 20:42:20,358:INFO:           interpret: Not installed
2025-04-12 20:42:20,358:INFO:                umap: Not installed
2025-04-12 20:42:20,358:INFO:    pandas_profiling: Not installed
2025-04-12 20:42:20,358:INFO:  explainerdashboard: Not installed
2025-04-12 20:42:20,358:INFO:             autoviz: Not installed
2025-04-12 20:42:20,358:INFO:           fairlearn: Not installed
2025-04-12 20:42:20,358:INFO:          deepchecks: Not installed
2025-04-12 20:42:20,358:INFO:             xgboost: 1.7.6
2025-04-12 20:42:20,358:INFO:            catboost: Not installed
2025-04-12 20:42:20,358:INFO:              kmodes: Not installed
2025-04-12 20:42:20,358:INFO:             mlxtend: Not installed
2025-04-12 20:42:20,358:INFO:       statsforecast: Not installed
2025-04-12 20:42:20,358:INFO:        tune_sklearn: Not installed
2025-04-12 20:42:20,358:INFO:                 ray: Not installed
2025-04-12 20:42:20,358:INFO:            hyperopt: Not installed
2025-04-12 20:42:20,358:INFO:              optuna: Not installed
2025-04-12 20:42:20,358:INFO:               skopt: Not installed
2025-04-12 20:42:20,358:INFO:              mlflow: Not installed
2025-04-12 20:42:20,358:INFO:              gradio: Not installed
2025-04-12 20:42:20,358:INFO:             fastapi: Not installed
2025-04-12 20:42:20,358:INFO:             uvicorn: Not installed
2025-04-12 20:42:20,358:INFO:              m2cgen: Not installed
2025-04-12 20:42:20,358:INFO:           evidently: Not installed
2025-04-12 20:42:20,358:INFO:               fugue: Not installed
2025-04-12 20:42:20,358:INFO:           streamlit: 1.42.0
2025-04-12 20:42:20,358:INFO:             prophet: Not installed
2025-04-12 20:42:20,358:INFO:None
2025-04-12 20:42:20,358:INFO:Set up data.
2025-04-12 20:42:20,367:INFO:Set up train/test split.
2025-04-12 20:42:20,370:INFO:Set up index.
2025-04-12 20:42:20,370:INFO:Set up folding strategy.
2025-04-12 20:42:20,370:INFO:Assigning column types.
2025-04-12 20:42:20,374:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-12 20:42:20,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:42:20,412:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:42:20,434:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:42:20,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:42:20,468:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:42:20,469:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:42:20,488:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:42:20,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:42:20,490:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-12 20:42:20,524:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:42:20,548:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:42:20,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:42:20,583:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:42:20,603:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:42:20,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:42:20,606:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-12 20:42:20,661:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:42:20,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:42:20,716:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:42:20,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:42:20,719:INFO:Preparing preprocessing pipeline...
2025-04-12 20:42:20,720:INFO:Set up simple imputation.
2025-04-12 20:42:20,720:INFO:Set up imbalanced handling.
2025-04-12 20:42:20,720:INFO:Set up feature normalization.
2025-04-12 20:42:20,753:INFO:Finished creating preprocessing pipeline.
2025-04-12 20:42:20,757:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-12 20:42:20,757:INFO:Creating final display dataframe.
2025-04-12 20:42:20,842:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (828, 35)
4        Transformed data shape         (963, 34)
5   Transformed train set shape         (714, 34)
6    Transformed test set shape         (249, 34)
7               Ignore features                 1
8              Numeric features                33
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                Fix imbalance              True
14         Fix imbalance method             SMOTE
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              fbd0
2025-04-12 20:42:20,895:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:42:20,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:42:20,948:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:42:20,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:42:20,950:INFO:setup() successfully completed in 0.69s...............
2025-04-12 20:42:24,197:INFO:Initializing compare_models()
2025-04-12 20:42:24,197:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-12 20:42:24,198:INFO:Checking exceptions
2025-04-12 20:42:24,201:INFO:Preparing display monitor
2025-04-12 20:42:24,220:INFO:Initializing Logistic Regression
2025-04-12 20:42:24,220:INFO:Total runtime is 0.0 minutes
2025-04-12 20:42:24,222:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:24,222:INFO:Initializing create_model()
2025-04-12 20:42:24,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:24,222:INFO:Checking exceptions
2025-04-12 20:42:24,224:INFO:Importing libraries
2025-04-12 20:42:24,224:INFO:Copying training dataset
2025-04-12 20:42:24,227:INFO:Defining folds
2025-04-12 20:42:24,227:INFO:Declaring metric variables
2025-04-12 20:42:24,231:INFO:Importing untrained model
2025-04-12 20:42:24,237:INFO:Logistic Regression Imported successfully
2025-04-12 20:42:24,243:INFO:Starting cross validation
2025-04-12 20:42:24,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:25,184:INFO:Calculating mean and std
2025-04-12 20:42:25,184:INFO:Creating metrics dataframe
2025-04-12 20:42:25,282:INFO:Uploading results into container
2025-04-12 20:42:25,283:INFO:Uploading model into container now
2025-04-12 20:42:25,283:INFO:_master_model_container: 1
2025-04-12 20:42:25,283:INFO:_display_container: 2
2025-04-12 20:42:25,284:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-12 20:42:25,284:INFO:create_model() successfully completed......................................
2025-04-12 20:42:25,488:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:25,488:INFO:Creating metrics dataframe
2025-04-12 20:42:25,493:INFO:Initializing K Neighbors Classifier
2025-04-12 20:42:25,493:INFO:Total runtime is 0.021225825945536295 minutes
2025-04-12 20:42:25,496:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:25,496:INFO:Initializing create_model()
2025-04-12 20:42:25,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:25,496:INFO:Checking exceptions
2025-04-12 20:42:25,496:INFO:Importing libraries
2025-04-12 20:42:25,496:INFO:Copying training dataset
2025-04-12 20:42:25,500:INFO:Defining folds
2025-04-12 20:42:25,500:INFO:Declaring metric variables
2025-04-12 20:42:25,503:INFO:Importing untrained model
2025-04-12 20:42:25,506:INFO:K Neighbors Classifier Imported successfully
2025-04-12 20:42:25,513:INFO:Starting cross validation
2025-04-12 20:42:25,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:26,423:INFO:Calculating mean and std
2025-04-12 20:42:26,424:INFO:Creating metrics dataframe
2025-04-12 20:42:26,510:INFO:Uploading results into container
2025-04-12 20:42:26,511:INFO:Uploading model into container now
2025-04-12 20:42:26,511:INFO:_master_model_container: 2
2025-04-12 20:42:26,511:INFO:_display_container: 2
2025-04-12 20:42:26,511:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-12 20:42:26,511:INFO:create_model() successfully completed......................................
2025-04-12 20:42:26,612:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:26,612:INFO:Creating metrics dataframe
2025-04-12 20:42:26,619:INFO:Initializing Naive Bayes
2025-04-12 20:42:26,619:INFO:Total runtime is 0.039988632996877035 minutes
2025-04-12 20:42:26,622:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:26,623:INFO:Initializing create_model()
2025-04-12 20:42:26,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:26,623:INFO:Checking exceptions
2025-04-12 20:42:26,623:INFO:Importing libraries
2025-04-12 20:42:26,623:INFO:Copying training dataset
2025-04-12 20:42:26,627:INFO:Defining folds
2025-04-12 20:42:26,627:INFO:Declaring metric variables
2025-04-12 20:42:26,631:INFO:Importing untrained model
2025-04-12 20:42:26,635:INFO:Naive Bayes Imported successfully
2025-04-12 20:42:26,642:INFO:Starting cross validation
2025-04-12 20:42:26,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:27,533:INFO:Calculating mean and std
2025-04-12 20:42:27,533:INFO:Creating metrics dataframe
2025-04-12 20:42:27,623:INFO:Uploading results into container
2025-04-12 20:42:27,623:INFO:Uploading model into container now
2025-04-12 20:42:27,624:INFO:_master_model_container: 3
2025-04-12 20:42:27,624:INFO:_display_container: 2
2025-04-12 20:42:27,624:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-12 20:42:27,624:INFO:create_model() successfully completed......................................
2025-04-12 20:42:27,720:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:27,720:INFO:Creating metrics dataframe
2025-04-12 20:42:27,727:INFO:Initializing Decision Tree Classifier
2025-04-12 20:42:27,727:INFO:Total runtime is 0.05845042069753011 minutes
2025-04-12 20:42:27,729:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:27,730:INFO:Initializing create_model()
2025-04-12 20:42:27,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:27,730:INFO:Checking exceptions
2025-04-12 20:42:27,730:INFO:Importing libraries
2025-04-12 20:42:27,730:INFO:Copying training dataset
2025-04-12 20:42:27,735:INFO:Defining folds
2025-04-12 20:42:27,735:INFO:Declaring metric variables
2025-04-12 20:42:27,740:INFO:Importing untrained model
2025-04-12 20:42:27,745:INFO:Decision Tree Classifier Imported successfully
2025-04-12 20:42:27,751:INFO:Starting cross validation
2025-04-12 20:42:27,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:28,629:INFO:Calculating mean and std
2025-04-12 20:42:28,631:INFO:Creating metrics dataframe
2025-04-12 20:42:28,719:INFO:Uploading results into container
2025-04-12 20:42:28,719:INFO:Uploading model into container now
2025-04-12 20:42:28,720:INFO:_master_model_container: 4
2025-04-12 20:42:28,720:INFO:_display_container: 2
2025-04-12 20:42:28,720:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-12 20:42:28,720:INFO:create_model() successfully completed......................................
2025-04-12 20:42:28,820:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:28,820:INFO:Creating metrics dataframe
2025-04-12 20:42:28,828:INFO:Initializing SVM - Linear Kernel
2025-04-12 20:42:28,828:INFO:Total runtime is 0.07680797974268595 minutes
2025-04-12 20:42:28,831:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:28,831:INFO:Initializing create_model()
2025-04-12 20:42:28,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:28,831:INFO:Checking exceptions
2025-04-12 20:42:28,831:INFO:Importing libraries
2025-04-12 20:42:28,832:INFO:Copying training dataset
2025-04-12 20:42:28,836:INFO:Defining folds
2025-04-12 20:42:28,837:INFO:Declaring metric variables
2025-04-12 20:42:28,840:INFO:Importing untrained model
2025-04-12 20:42:28,845:INFO:SVM - Linear Kernel Imported successfully
2025-04-12 20:42:28,853:INFO:Starting cross validation
2025-04-12 20:42:28,855:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:28,960:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:28,963:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:28,969:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:28,973:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:28,984:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:28,985:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:29,002:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:29,003:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:29,003:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:29,012:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:42:29,696:INFO:Calculating mean and std
2025-04-12 20:42:29,698:INFO:Creating metrics dataframe
2025-04-12 20:42:29,790:INFO:Uploading results into container
2025-04-12 20:42:29,791:INFO:Uploading model into container now
2025-04-12 20:42:29,791:INFO:_master_model_container: 5
2025-04-12 20:42:29,791:INFO:_display_container: 2
2025-04-12 20:42:29,792:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-12 20:42:29,792:INFO:create_model() successfully completed......................................
2025-04-12 20:42:29,894:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:29,894:INFO:Creating metrics dataframe
2025-04-12 20:42:29,901:INFO:Initializing Ridge Classifier
2025-04-12 20:42:29,901:INFO:Total runtime is 0.09469351371129353 minutes
2025-04-12 20:42:29,905:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:29,905:INFO:Initializing create_model()
2025-04-12 20:42:29,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:29,905:INFO:Checking exceptions
2025-04-12 20:42:29,905:INFO:Importing libraries
2025-04-12 20:42:29,905:INFO:Copying training dataset
2025-04-12 20:42:29,908:INFO:Defining folds
2025-04-12 20:42:29,908:INFO:Declaring metric variables
2025-04-12 20:42:29,913:INFO:Importing untrained model
2025-04-12 20:42:29,916:INFO:Ridge Classifier Imported successfully
2025-04-12 20:42:29,924:INFO:Starting cross validation
2025-04-12 20:42:29,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:30,027:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,028:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,037:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,041:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,045:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,049:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,068:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,076:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,085:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:42:30,767:INFO:Calculating mean and std
2025-04-12 20:42:30,769:INFO:Creating metrics dataframe
2025-04-12 20:42:30,855:INFO:Uploading results into container
2025-04-12 20:42:30,856:INFO:Uploading model into container now
2025-04-12 20:42:30,856:INFO:_master_model_container: 6
2025-04-12 20:42:30,856:INFO:_display_container: 2
2025-04-12 20:42:30,858:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-12 20:42:30,858:INFO:create_model() successfully completed......................................
2025-04-12 20:42:30,955:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:30,955:INFO:Creating metrics dataframe
2025-04-12 20:42:30,963:INFO:Initializing Random Forest Classifier
2025-04-12 20:42:30,963:INFO:Total runtime is 0.11239051421483356 minutes
2025-04-12 20:42:30,966:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:30,966:INFO:Initializing create_model()
2025-04-12 20:42:30,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:30,966:INFO:Checking exceptions
2025-04-12 20:42:30,966:INFO:Importing libraries
2025-04-12 20:42:30,967:INFO:Copying training dataset
2025-04-12 20:42:30,971:INFO:Defining folds
2025-04-12 20:42:30,971:INFO:Declaring metric variables
2025-04-12 20:42:30,974:INFO:Importing untrained model
2025-04-12 20:42:30,977:INFO:Random Forest Classifier Imported successfully
2025-04-12 20:42:30,985:INFO:Starting cross validation
2025-04-12 20:42:30,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:32,505:INFO:Calculating mean and std
2025-04-12 20:42:32,506:INFO:Creating metrics dataframe
2025-04-12 20:42:32,595:INFO:Uploading results into container
2025-04-12 20:42:32,595:INFO:Uploading model into container now
2025-04-12 20:42:32,595:INFO:_master_model_container: 7
2025-04-12 20:42:32,595:INFO:_display_container: 2
2025-04-12 20:42:32,596:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-12 20:42:32,596:INFO:create_model() successfully completed......................................
2025-04-12 20:42:32,692:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:32,692:INFO:Creating metrics dataframe
2025-04-12 20:42:32,699:INFO:Initializing Quadratic Discriminant Analysis
2025-04-12 20:42:32,699:INFO:Total runtime is 0.141322922706604 minutes
2025-04-12 20:42:32,703:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:32,703:INFO:Initializing create_model()
2025-04-12 20:42:32,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:32,703:INFO:Checking exceptions
2025-04-12 20:42:32,703:INFO:Importing libraries
2025-04-12 20:42:32,703:INFO:Copying training dataset
2025-04-12 20:42:32,707:INFO:Defining folds
2025-04-12 20:42:32,708:INFO:Declaring metric variables
2025-04-12 20:42:32,713:INFO:Importing untrained model
2025-04-12 20:42:32,716:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-12 20:42:32,724:INFO:Starting cross validation
2025-04-12 20:42:32,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:32,801:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:32,809:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:32,817:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:32,817:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:32,827:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:32,841:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:32,842:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:32,850:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:32,862:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:42:33,653:INFO:Calculating mean and std
2025-04-12 20:42:33,654:INFO:Creating metrics dataframe
2025-04-12 20:42:33,748:INFO:Uploading results into container
2025-04-12 20:42:33,749:INFO:Uploading model into container now
2025-04-12 20:42:33,749:INFO:_master_model_container: 8
2025-04-12 20:42:33,749:INFO:_display_container: 2
2025-04-12 20:42:33,749:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-12 20:42:33,749:INFO:create_model() successfully completed......................................
2025-04-12 20:42:33,848:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:33,848:INFO:Creating metrics dataframe
2025-04-12 20:42:33,856:INFO:Initializing Ada Boost Classifier
2025-04-12 20:42:33,856:INFO:Total runtime is 0.16061034202575683 minutes
2025-04-12 20:42:33,859:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:33,859:INFO:Initializing create_model()
2025-04-12 20:42:33,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:33,859:INFO:Checking exceptions
2025-04-12 20:42:33,859:INFO:Importing libraries
2025-04-12 20:42:33,859:INFO:Copying training dataset
2025-04-12 20:42:33,863:INFO:Defining folds
2025-04-12 20:42:33,863:INFO:Declaring metric variables
2025-04-12 20:42:33,866:INFO:Importing untrained model
2025-04-12 20:42:33,871:INFO:Ada Boost Classifier Imported successfully
2025-04-12 20:42:33,879:INFO:Starting cross validation
2025-04-12 20:42:33,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:35,164:INFO:Calculating mean and std
2025-04-12 20:42:35,165:INFO:Creating metrics dataframe
2025-04-12 20:42:35,264:INFO:Uploading results into container
2025-04-12 20:42:35,265:INFO:Uploading model into container now
2025-04-12 20:42:35,265:INFO:_master_model_container: 9
2025-04-12 20:42:35,265:INFO:_display_container: 2
2025-04-12 20:42:35,265:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-12 20:42:35,265:INFO:create_model() successfully completed......................................
2025-04-12 20:42:35,366:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:35,366:INFO:Creating metrics dataframe
2025-04-12 20:42:35,373:INFO:Initializing Gradient Boosting Classifier
2025-04-12 20:42:35,373:INFO:Total runtime is 0.18589127461115518 minutes
2025-04-12 20:42:35,376:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:35,376:INFO:Initializing create_model()
2025-04-12 20:42:35,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:35,376:INFO:Checking exceptions
2025-04-12 20:42:35,376:INFO:Importing libraries
2025-04-12 20:42:35,377:INFO:Copying training dataset
2025-04-12 20:42:35,380:INFO:Defining folds
2025-04-12 20:42:35,380:INFO:Declaring metric variables
2025-04-12 20:42:35,385:INFO:Importing untrained model
2025-04-12 20:42:35,389:INFO:Gradient Boosting Classifier Imported successfully
2025-04-12 20:42:35,397:INFO:Starting cross validation
2025-04-12 20:42:35,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:36,871:INFO:Calculating mean and std
2025-04-12 20:42:36,872:INFO:Creating metrics dataframe
2025-04-12 20:42:36,981:INFO:Uploading results into container
2025-04-12 20:42:36,981:INFO:Uploading model into container now
2025-04-12 20:42:36,982:INFO:_master_model_container: 10
2025-04-12 20:42:36,982:INFO:_display_container: 2
2025-04-12 20:42:36,982:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-12 20:42:36,982:INFO:create_model() successfully completed......................................
2025-04-12 20:42:37,083:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:37,083:INFO:Creating metrics dataframe
2025-04-12 20:42:37,091:INFO:Initializing Linear Discriminant Analysis
2025-04-12 20:42:37,091:INFO:Total runtime is 0.2145204146703084 minutes
2025-04-12 20:42:37,094:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:37,094:INFO:Initializing create_model()
2025-04-12 20:42:37,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:37,095:INFO:Checking exceptions
2025-04-12 20:42:37,095:INFO:Importing libraries
2025-04-12 20:42:37,095:INFO:Copying training dataset
2025-04-12 20:42:37,099:INFO:Defining folds
2025-04-12 20:42:37,099:INFO:Declaring metric variables
2025-04-12 20:42:37,103:INFO:Importing untrained model
2025-04-12 20:42:37,108:INFO:Linear Discriminant Analysis Imported successfully
2025-04-12 20:42:37,118:INFO:Starting cross validation
2025-04-12 20:42:37,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:38,162:INFO:Calculating mean and std
2025-04-12 20:42:38,163:INFO:Creating metrics dataframe
2025-04-12 20:42:38,269:INFO:Uploading results into container
2025-04-12 20:42:38,270:INFO:Uploading model into container now
2025-04-12 20:42:38,270:INFO:_master_model_container: 11
2025-04-12 20:42:38,270:INFO:_display_container: 2
2025-04-12 20:42:38,270:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-12 20:42:38,271:INFO:create_model() successfully completed......................................
2025-04-12 20:42:38,369:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:38,369:INFO:Creating metrics dataframe
2025-04-12 20:42:38,377:INFO:Initializing Extra Trees Classifier
2025-04-12 20:42:38,377:INFO:Total runtime is 0.23595631122589109 minutes
2025-04-12 20:42:38,380:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:38,380:INFO:Initializing create_model()
2025-04-12 20:42:38,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:38,380:INFO:Checking exceptions
2025-04-12 20:42:38,380:INFO:Importing libraries
2025-04-12 20:42:38,380:INFO:Copying training dataset
2025-04-12 20:42:38,384:INFO:Defining folds
2025-04-12 20:42:38,384:INFO:Declaring metric variables
2025-04-12 20:42:38,388:INFO:Importing untrained model
2025-04-12 20:42:38,392:INFO:Extra Trees Classifier Imported successfully
2025-04-12 20:42:38,399:INFO:Starting cross validation
2025-04-12 20:42:38,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:39,932:INFO:Calculating mean and std
2025-04-12 20:42:39,934:INFO:Creating metrics dataframe
2025-04-12 20:42:40,052:INFO:Uploading results into container
2025-04-12 20:42:40,053:INFO:Uploading model into container now
2025-04-12 20:42:40,053:INFO:_master_model_container: 12
2025-04-12 20:42:40,054:INFO:_display_container: 2
2025-04-12 20:42:40,054:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-12 20:42:40,054:INFO:create_model() successfully completed......................................
2025-04-12 20:42:40,207:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:40,207:INFO:Creating metrics dataframe
2025-04-12 20:42:40,217:INFO:Initializing Extreme Gradient Boosting
2025-04-12 20:42:40,217:INFO:Total runtime is 0.2666233499844869 minutes
2025-04-12 20:42:40,220:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:40,220:INFO:Initializing create_model()
2025-04-12 20:42:40,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:40,220:INFO:Checking exceptions
2025-04-12 20:42:40,220:INFO:Importing libraries
2025-04-12 20:42:40,220:INFO:Copying training dataset
2025-04-12 20:42:40,224:INFO:Defining folds
2025-04-12 20:42:40,224:INFO:Declaring metric variables
2025-04-12 20:42:40,227:INFO:Importing untrained model
2025-04-12 20:42:40,230:INFO:Extreme Gradient Boosting Imported successfully
2025-04-12 20:42:40,234:INFO:Starting cross validation
2025-04-12 20:42:40,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:42,313:INFO:Calculating mean and std
2025-04-12 20:42:42,314:INFO:Creating metrics dataframe
2025-04-12 20:42:42,444:INFO:Uploading results into container
2025-04-12 20:42:42,445:INFO:Uploading model into container now
2025-04-12 20:42:42,445:INFO:_master_model_container: 13
2025-04-12 20:42:42,445:INFO:_display_container: 2
2025-04-12 20:42:42,446:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-12 20:42:42,446:INFO:create_model() successfully completed......................................
2025-04-12 20:42:42,553:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:42,553:INFO:Creating metrics dataframe
2025-04-12 20:42:42,564:INFO:Initializing Light Gradient Boosting Machine
2025-04-12 20:42:42,564:INFO:Total runtime is 0.3057350754737854 minutes
2025-04-12 20:42:42,566:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:42,566:INFO:Initializing create_model()
2025-04-12 20:42:42,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:42,566:INFO:Checking exceptions
2025-04-12 20:42:42,566:INFO:Importing libraries
2025-04-12 20:42:42,568:INFO:Copying training dataset
2025-04-12 20:42:42,571:INFO:Defining folds
2025-04-12 20:42:42,571:INFO:Declaring metric variables
2025-04-12 20:42:42,573:INFO:Importing untrained model
2025-04-12 20:42:42,579:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 20:42:42,585:INFO:Starting cross validation
2025-04-12 20:42:42,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:44,657:INFO:Calculating mean and std
2025-04-12 20:42:44,657:INFO:Creating metrics dataframe
2025-04-12 20:42:44,781:INFO:Uploading results into container
2025-04-12 20:42:44,781:INFO:Uploading model into container now
2025-04-12 20:42:44,781:INFO:_master_model_container: 14
2025-04-12 20:42:44,782:INFO:_display_container: 2
2025-04-12 20:42:44,782:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 20:42:44,782:INFO:create_model() successfully completed......................................
2025-04-12 20:42:44,891:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:44,891:INFO:Creating metrics dataframe
2025-04-12 20:42:44,900:INFO:Initializing Dummy Classifier
2025-04-12 20:42:44,900:INFO:Total runtime is 0.3446639696756999 minutes
2025-04-12 20:42:44,903:INFO:SubProcess create_model() called ==================================
2025-04-12 20:42:44,903:INFO:Initializing create_model()
2025-04-12 20:42:44,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00194EE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:44,905:INFO:Checking exceptions
2025-04-12 20:42:44,905:INFO:Importing libraries
2025-04-12 20:42:44,905:INFO:Copying training dataset
2025-04-12 20:42:44,908:INFO:Defining folds
2025-04-12 20:42:44,908:INFO:Declaring metric variables
2025-04-12 20:42:44,913:INFO:Importing untrained model
2025-04-12 20:42:44,917:INFO:Dummy Classifier Imported successfully
2025-04-12 20:42:44,925:INFO:Starting cross validation
2025-04-12 20:42:44,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:42:45,054:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:45,063:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:45,065:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:45,068:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:45,070:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:45,071:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:45,093:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:45,095:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:45,096:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-12 20:42:46,166:INFO:Calculating mean and std
2025-04-12 20:42:46,168:INFO:Creating metrics dataframe
2025-04-12 20:42:46,289:INFO:Uploading results into container
2025-04-12 20:42:46,290:INFO:Uploading model into container now
2025-04-12 20:42:46,290:INFO:_master_model_container: 15
2025-04-12 20:42:46,290:INFO:_display_container: 2
2025-04-12 20:42:46,290:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-12 20:42:46,290:INFO:create_model() successfully completed......................................
2025-04-12 20:42:46,389:INFO:SubProcess create_model() end ==================================
2025-04-12 20:42:46,390:INFO:Creating metrics dataframe
2025-04-12 20:42:46,405:INFO:Initializing create_model()
2025-04-12 20:42:46,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:42:46,405:INFO:Checking exceptions
2025-04-12 20:42:46,407:INFO:Importing libraries
2025-04-12 20:42:46,407:INFO:Copying training dataset
2025-04-12 20:42:46,410:INFO:Defining folds
2025-04-12 20:42:46,411:INFO:Declaring metric variables
2025-04-12 20:42:46,411:INFO:Importing untrained model
2025-04-12 20:42:46,411:INFO:Declaring custom model
2025-04-12 20:42:46,411:INFO:Extra Trees Classifier Imported successfully
2025-04-12 20:42:46,412:INFO:Cross validation set to False
2025-04-12 20:42:46,412:INFO:Fitting Model
2025-04-12 20:42:46,643:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-12 20:42:46,643:INFO:create_model() successfully completed......................................
2025-04-12 20:42:46,772:INFO:_master_model_container: 15
2025-04-12 20:42:46,774:INFO:_display_container: 2
2025-04-12 20:42:46,774:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-12 20:42:46,774:INFO:compare_models() successfully completed......................................
2025-04-12 20:42:46,774:INFO:Initializing evaluate_model()
2025-04-12 20:42:46,774:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-12 20:42:46,783:INFO:Initializing plot_model()
2025-04-12 20:42:46,783:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24CF40>, system=True)
2025-04-12 20:42:46,783:INFO:Checking exceptions
2025-04-12 20:42:46,809:INFO:Preloading libraries
2025-04-12 20:42:46,816:INFO:Copying training dataset
2025-04-12 20:42:46,816:INFO:Plot type: pipeline
2025-04-12 20:42:46,949:INFO:Visual Rendered Successfully
2025-04-12 20:42:47,056:INFO:plot_model() successfully completed......................................
2025-04-12 20:45:28,599:INFO:PyCaret ClassificationExperiment
2025-04-12 20:45:28,599:INFO:Logging name: clf-default-name
2025-04-12 20:45:28,599:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-12 20:45:28,599:INFO:version 3.0.4
2025-04-12 20:45:28,600:INFO:Initializing setup()
2025-04-12 20:45:28,600:INFO:self.USI: 824a
2025-04-12 20:45:28,600:INFO:self._variable_keys: {'X', 'html_param', 'seed', 'memory', 'y_train', 'X_train', 'fold_generator', 'pipeline', '_available_plots', 'idx', 'log_plots_param', 'fix_imbalance', 'target_param', 'fold_groups_param', 'X_test', 'gpu_n_jobs_param', 'USI', '_ml_usecase', 'y', 'data', 'is_multiclass', 'y_test', 'logging_param', 'n_jobs_param', 'fold_shuffle_param', 'exp_id', 'gpu_param', 'exp_name_log'}
2025-04-12 20:45:28,600:INFO:Checking environment
2025-04-12 20:45:28,600:INFO:python_version: 3.10.5
2025-04-12 20:45:28,600:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-12 20:45:28,600:INFO:machine: AMD64
2025-04-12 20:45:28,600:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-12 20:45:28,606:INFO:Memory: svmem(total=25042907136, available=7956901888, percent=68.2, used=17086005248, free=7956901888)
2025-04-12 20:45:28,606:INFO:Physical Core: 6
2025-04-12 20:45:28,606:INFO:Logical Core: 12
2025-04-12 20:45:28,606:INFO:Checking libraries
2025-04-12 20:45:28,606:INFO:System:
2025-04-12 20:45:28,606:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-12 20:45:28,606:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-12 20:45:28,606:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-12 20:45:28,606:INFO:PyCaret required dependencies:
2025-04-12 20:45:28,606:INFO:                 pip: 25.0.1
2025-04-12 20:45:28,606:INFO:          setuptools: 58.1.0
2025-04-12 20:45:28,606:INFO:             pycaret: 3.0.4
2025-04-12 20:45:28,606:INFO:             IPython: 8.29.0
2025-04-12 20:45:28,606:INFO:          ipywidgets: 8.1.6
2025-04-12 20:45:28,606:INFO:                tqdm: 4.67.1
2025-04-12 20:45:28,606:INFO:               numpy: 1.23.5
2025-04-12 20:45:28,606:INFO:              pandas: 1.5.3
2025-04-12 20:45:28,606:INFO:              jinja2: 3.1.4
2025-04-12 20:45:28,606:INFO:               scipy: 1.11.4
2025-04-12 20:45:28,606:INFO:              joblib: 1.3.2
2025-04-12 20:45:28,606:INFO:             sklearn: 1.2.2
2025-04-12 20:45:28,606:INFO:                pyod: 2.0.4
2025-04-12 20:45:28,607:INFO:            imblearn: 0.10.1
2025-04-12 20:45:28,607:INFO:   category_encoders: 2.7.0
2025-04-12 20:45:28,607:INFO:            lightgbm: 4.6.0
2025-04-12 20:45:28,607:INFO:               numba: 0.60.0
2025-04-12 20:45:28,607:INFO:            requests: 2.32.3
2025-04-12 20:45:28,607:INFO:          matplotlib: 3.7.5
2025-04-12 20:45:28,607:INFO:          scikitplot: 0.3.7
2025-04-12 20:45:28,607:INFO:         yellowbrick: 1.5
2025-04-12 20:45:28,607:INFO:              plotly: 5.24.1
2025-04-12 20:45:28,607:INFO:    plotly-resampler: Not installed
2025-04-12 20:45:28,607:INFO:             kaleido: 0.2.1
2025-04-12 20:45:28,607:INFO:           schemdraw: 0.15
2025-04-12 20:45:28,607:INFO:         statsmodels: 0.14.4
2025-04-12 20:45:28,607:INFO:              sktime: 0.26.0
2025-04-12 20:45:28,607:INFO:               tbats: 1.1.3
2025-04-12 20:45:28,607:INFO:            pmdarima: 2.0.4
2025-04-12 20:45:28,607:INFO:              psutil: 6.1.0
2025-04-12 20:45:28,607:INFO:          markupsafe: 3.0.2
2025-04-12 20:45:28,607:INFO:             pickle5: Not installed
2025-04-12 20:45:28,607:INFO:         cloudpickle: 3.1.1
2025-04-12 20:45:28,607:INFO:         deprecation: 2.1.0
2025-04-12 20:45:28,607:INFO:              xxhash: 3.5.0
2025-04-12 20:45:28,607:INFO:           wurlitzer: Not installed
2025-04-12 20:45:28,607:INFO:PyCaret optional dependencies:
2025-04-12 20:45:28,607:INFO:                shap: Not installed
2025-04-12 20:45:28,607:INFO:           interpret: Not installed
2025-04-12 20:45:28,607:INFO:                umap: Not installed
2025-04-12 20:45:28,607:INFO:    pandas_profiling: Not installed
2025-04-12 20:45:28,607:INFO:  explainerdashboard: Not installed
2025-04-12 20:45:28,607:INFO:             autoviz: Not installed
2025-04-12 20:45:28,607:INFO:           fairlearn: Not installed
2025-04-12 20:45:28,607:INFO:          deepchecks: Not installed
2025-04-12 20:45:28,608:INFO:             xgboost: 1.7.6
2025-04-12 20:45:28,608:INFO:            catboost: Not installed
2025-04-12 20:45:28,608:INFO:              kmodes: Not installed
2025-04-12 20:45:28,608:INFO:             mlxtend: Not installed
2025-04-12 20:45:28,608:INFO:       statsforecast: Not installed
2025-04-12 20:45:28,608:INFO:        tune_sklearn: Not installed
2025-04-12 20:45:28,608:INFO:                 ray: Not installed
2025-04-12 20:45:28,608:INFO:            hyperopt: Not installed
2025-04-12 20:45:28,608:INFO:              optuna: Not installed
2025-04-12 20:45:28,608:INFO:               skopt: Not installed
2025-04-12 20:45:28,608:INFO:              mlflow: Not installed
2025-04-12 20:45:28,608:INFO:              gradio: Not installed
2025-04-12 20:45:28,608:INFO:             fastapi: Not installed
2025-04-12 20:45:28,608:INFO:             uvicorn: Not installed
2025-04-12 20:45:28,608:INFO:              m2cgen: Not installed
2025-04-12 20:45:28,608:INFO:           evidently: Not installed
2025-04-12 20:45:28,608:INFO:               fugue: Not installed
2025-04-12 20:45:28,608:INFO:           streamlit: 1.42.0
2025-04-12 20:45:28,608:INFO:             prophet: Not installed
2025-04-12 20:45:28,608:INFO:None
2025-04-12 20:45:28,608:INFO:Set up data.
2025-04-12 20:45:28,618:INFO:Set up train/test split.
2025-04-12 20:45:28,621:INFO:Set up index.
2025-04-12 20:45:28,621:INFO:Set up folding strategy.
2025-04-12 20:45:28,621:INFO:Assigning column types.
2025-04-12 20:45:28,624:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-12 20:45:28,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:45:28,656:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:45:28,676:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:45:28,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:45:28,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:45:28,711:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:45:28,731:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:45:28,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:45:28,733:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-12 20:45:28,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:45:28,785:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:45:28,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:45:28,820:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:45:28,846:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:45:28,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:45:28,848:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-12 20:45:28,906:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:45:28,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:45:28,959:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:45:28,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:45:28,963:INFO:Preparing preprocessing pipeline...
2025-04-12 20:45:28,964:INFO:Set up simple imputation.
2025-04-12 20:45:28,964:INFO:Set up feature normalization.
2025-04-12 20:45:28,978:INFO:Finished creating preprocessing pipeline.
2025-04-12 20:45:28,981:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-12 20:45:28,981:INFO:Creating final display dataframe.
2025-04-12 20:45:29,036:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (828, 35)
4        Transformed data shape         (828, 34)
5   Transformed train set shape         (579, 34)
6    Transformed test set shape         (249, 34)
7               Ignore features                 1
8              Numeric features                33
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              824a
2025-04-12 20:45:29,088:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:45:29,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:45:29,143:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:45:29,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:45:29,145:INFO:setup() successfully completed in 0.67s...............
2025-04-12 20:45:32,548:INFO:Initializing compare_models()
2025-04-12 20:45:32,548:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-12 20:45:32,550:INFO:Checking exceptions
2025-04-12 20:45:32,553:INFO:Preparing display monitor
2025-04-12 20:45:32,571:INFO:Initializing Logistic Regression
2025-04-12 20:45:32,571:INFO:Total runtime is 0.0 minutes
2025-04-12 20:45:32,573:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:32,573:INFO:Initializing create_model()
2025-04-12 20:45:32,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:32,573:INFO:Checking exceptions
2025-04-12 20:45:32,573:INFO:Importing libraries
2025-04-12 20:45:32,575:INFO:Copying training dataset
2025-04-12 20:45:32,579:INFO:Defining folds
2025-04-12 20:45:32,579:INFO:Declaring metric variables
2025-04-12 20:45:32,581:INFO:Importing untrained model
2025-04-12 20:45:32,584:INFO:Logistic Regression Imported successfully
2025-04-12 20:45:32,591:INFO:Starting cross validation
2025-04-12 20:45:32,591:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:33,787:INFO:Calculating mean and std
2025-04-12 20:45:33,788:INFO:Creating metrics dataframe
2025-04-12 20:45:33,920:INFO:Uploading results into container
2025-04-12 20:45:33,922:INFO:Uploading model into container now
2025-04-12 20:45:33,922:INFO:_master_model_container: 1
2025-04-12 20:45:33,922:INFO:_display_container: 2
2025-04-12 20:45:33,923:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-12 20:45:33,923:INFO:create_model() successfully completed......................................
2025-04-12 20:45:34,028:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:34,028:INFO:Creating metrics dataframe
2025-04-12 20:45:34,034:INFO:Initializing K Neighbors Classifier
2025-04-12 20:45:34,034:INFO:Total runtime is 0.024397381146748862 minutes
2025-04-12 20:45:34,037:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:34,038:INFO:Initializing create_model()
2025-04-12 20:45:34,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:34,038:INFO:Checking exceptions
2025-04-12 20:45:34,038:INFO:Importing libraries
2025-04-12 20:45:34,038:INFO:Copying training dataset
2025-04-12 20:45:34,042:INFO:Defining folds
2025-04-12 20:45:34,043:INFO:Declaring metric variables
2025-04-12 20:45:34,047:INFO:Importing untrained model
2025-04-12 20:45:34,051:INFO:K Neighbors Classifier Imported successfully
2025-04-12 20:45:34,059:INFO:Starting cross validation
2025-04-12 20:45:34,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:35,243:INFO:Calculating mean and std
2025-04-12 20:45:35,244:INFO:Creating metrics dataframe
2025-04-12 20:45:35,376:INFO:Uploading results into container
2025-04-12 20:45:35,377:INFO:Uploading model into container now
2025-04-12 20:45:35,377:INFO:_master_model_container: 2
2025-04-12 20:45:35,378:INFO:_display_container: 2
2025-04-12 20:45:35,378:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-12 20:45:35,378:INFO:create_model() successfully completed......................................
2025-04-12 20:45:35,483:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:35,483:INFO:Creating metrics dataframe
2025-04-12 20:45:35,490:INFO:Initializing Naive Bayes
2025-04-12 20:45:35,490:INFO:Total runtime is 0.04865167140960694 minutes
2025-04-12 20:45:35,494:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:35,494:INFO:Initializing create_model()
2025-04-12 20:45:35,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:35,494:INFO:Checking exceptions
2025-04-12 20:45:35,494:INFO:Importing libraries
2025-04-12 20:45:35,495:INFO:Copying training dataset
2025-04-12 20:45:35,499:INFO:Defining folds
2025-04-12 20:45:35,499:INFO:Declaring metric variables
2025-04-12 20:45:35,504:INFO:Importing untrained model
2025-04-12 20:45:35,510:INFO:Naive Bayes Imported successfully
2025-04-12 20:45:35,515:INFO:Starting cross validation
2025-04-12 20:45:35,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:36,683:INFO:Calculating mean and std
2025-04-12 20:45:36,684:INFO:Creating metrics dataframe
2025-04-12 20:45:36,813:INFO:Uploading results into container
2025-04-12 20:45:36,814:INFO:Uploading model into container now
2025-04-12 20:45:36,814:INFO:_master_model_container: 3
2025-04-12 20:45:36,814:INFO:_display_container: 2
2025-04-12 20:45:36,814:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-12 20:45:36,814:INFO:create_model() successfully completed......................................
2025-04-12 20:45:36,915:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:36,916:INFO:Creating metrics dataframe
2025-04-12 20:45:36,922:INFO:Initializing Decision Tree Classifier
2025-04-12 20:45:36,922:INFO:Total runtime is 0.07252637147903443 minutes
2025-04-12 20:45:36,926:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:36,926:INFO:Initializing create_model()
2025-04-12 20:45:36,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:36,926:INFO:Checking exceptions
2025-04-12 20:45:36,926:INFO:Importing libraries
2025-04-12 20:45:36,927:INFO:Copying training dataset
2025-04-12 20:45:36,929:INFO:Defining folds
2025-04-12 20:45:36,931:INFO:Declaring metric variables
2025-04-12 20:45:36,933:INFO:Importing untrained model
2025-04-12 20:45:36,938:INFO:Decision Tree Classifier Imported successfully
2025-04-12 20:45:36,946:INFO:Starting cross validation
2025-04-12 20:45:36,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:38,125:INFO:Calculating mean and std
2025-04-12 20:45:38,127:INFO:Creating metrics dataframe
2025-04-12 20:45:38,306:INFO:Uploading results into container
2025-04-12 20:45:38,307:INFO:Uploading model into container now
2025-04-12 20:45:38,307:INFO:_master_model_container: 4
2025-04-12 20:45:38,309:INFO:_display_container: 2
2025-04-12 20:45:38,309:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-12 20:45:38,309:INFO:create_model() successfully completed......................................
2025-04-12 20:45:38,422:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:38,422:INFO:Creating metrics dataframe
2025-04-12 20:45:38,432:INFO:Initializing SVM - Linear Kernel
2025-04-12 20:45:38,432:INFO:Total runtime is 0.09768930276234945 minutes
2025-04-12 20:45:38,435:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:38,435:INFO:Initializing create_model()
2025-04-12 20:45:38,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:38,435:INFO:Checking exceptions
2025-04-12 20:45:38,435:INFO:Importing libraries
2025-04-12 20:45:38,435:INFO:Copying training dataset
2025-04-12 20:45:38,441:INFO:Defining folds
2025-04-12 20:45:38,441:INFO:Declaring metric variables
2025-04-12 20:45:38,445:INFO:Importing untrained model
2025-04-12 20:45:38,449:INFO:SVM - Linear Kernel Imported successfully
2025-04-12 20:45:38,457:INFO:Starting cross validation
2025-04-12 20:45:38,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:38,535:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,542:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,545:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,546:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,550:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,556:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,565:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,570:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,572:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:38,578:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 20:45:39,574:INFO:Calculating mean and std
2025-04-12 20:45:39,576:INFO:Creating metrics dataframe
2025-04-12 20:45:39,706:INFO:Uploading results into container
2025-04-12 20:45:39,707:INFO:Uploading model into container now
2025-04-12 20:45:39,707:INFO:_master_model_container: 5
2025-04-12 20:45:39,707:INFO:_display_container: 2
2025-04-12 20:45:39,708:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-12 20:45:39,708:INFO:create_model() successfully completed......................................
2025-04-12 20:45:39,807:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:39,808:INFO:Creating metrics dataframe
2025-04-12 20:45:39,815:INFO:Initializing Ridge Classifier
2025-04-12 20:45:39,816:INFO:Total runtime is 0.12075183391571045 minutes
2025-04-12 20:45:39,818:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:39,818:INFO:Initializing create_model()
2025-04-12 20:45:39,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:39,818:INFO:Checking exceptions
2025-04-12 20:45:39,818:INFO:Importing libraries
2025-04-12 20:45:39,818:INFO:Copying training dataset
2025-04-12 20:45:39,823:INFO:Defining folds
2025-04-12 20:45:39,823:INFO:Declaring metric variables
2025-04-12 20:45:39,827:INFO:Importing untrained model
2025-04-12 20:45:39,831:INFO:Ridge Classifier Imported successfully
2025-04-12 20:45:39,838:INFO:Starting cross validation
2025-04-12 20:45:39,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:39,919:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,926:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,927:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,932:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,935:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,938:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,949:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,961:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,974:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:39,979:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 20:45:40,956:INFO:Calculating mean and std
2025-04-12 20:45:40,957:INFO:Creating metrics dataframe
2025-04-12 20:45:41,081:INFO:Uploading results into container
2025-04-12 20:45:41,081:INFO:Uploading model into container now
2025-04-12 20:45:41,082:INFO:_master_model_container: 6
2025-04-12 20:45:41,082:INFO:_display_container: 2
2025-04-12 20:45:41,082:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-12 20:45:41,082:INFO:create_model() successfully completed......................................
2025-04-12 20:45:41,185:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:41,185:INFO:Creating metrics dataframe
2025-04-12 20:45:41,196:INFO:Initializing Random Forest Classifier
2025-04-12 20:45:41,196:INFO:Total runtime is 0.1437479615211487 minutes
2025-04-12 20:45:41,198:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:41,198:INFO:Initializing create_model()
2025-04-12 20:45:41,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:41,198:INFO:Checking exceptions
2025-04-12 20:45:41,198:INFO:Importing libraries
2025-04-12 20:45:41,198:INFO:Copying training dataset
2025-04-12 20:45:41,202:INFO:Defining folds
2025-04-12 20:45:41,202:INFO:Declaring metric variables
2025-04-12 20:45:41,207:INFO:Importing untrained model
2025-04-12 20:45:41,211:INFO:Random Forest Classifier Imported successfully
2025-04-12 20:45:41,217:INFO:Starting cross validation
2025-04-12 20:45:41,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:42,928:INFO:Calculating mean and std
2025-04-12 20:45:42,930:INFO:Creating metrics dataframe
2025-04-12 20:45:43,057:INFO:Uploading results into container
2025-04-12 20:45:43,058:INFO:Uploading model into container now
2025-04-12 20:45:43,059:INFO:_master_model_container: 7
2025-04-12 20:45:43,059:INFO:_display_container: 2
2025-04-12 20:45:43,059:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-12 20:45:43,059:INFO:create_model() successfully completed......................................
2025-04-12 20:45:43,160:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:43,160:INFO:Creating metrics dataframe
2025-04-12 20:45:43,168:INFO:Initializing Quadratic Discriminant Analysis
2025-04-12 20:45:43,168:INFO:Total runtime is 0.17662607034047445 minutes
2025-04-12 20:45:43,170:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:43,170:INFO:Initializing create_model()
2025-04-12 20:45:43,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:43,170:INFO:Checking exceptions
2025-04-12 20:45:43,170:INFO:Importing libraries
2025-04-12 20:45:43,170:INFO:Copying training dataset
2025-04-12 20:45:43,174:INFO:Defining folds
2025-04-12 20:45:43,174:INFO:Declaring metric variables
2025-04-12 20:45:43,178:INFO:Importing untrained model
2025-04-12 20:45:43,181:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-12 20:45:43,187:INFO:Starting cross validation
2025-04-12 20:45:43,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:43,239:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,240:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,240:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,250:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,254:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,257:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,260:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,268:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,282:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:43,284:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 20:45:44,368:INFO:Calculating mean and std
2025-04-12 20:45:44,369:INFO:Creating metrics dataframe
2025-04-12 20:45:44,497:INFO:Uploading results into container
2025-04-12 20:45:44,498:INFO:Uploading model into container now
2025-04-12 20:45:44,498:INFO:_master_model_container: 8
2025-04-12 20:45:44,498:INFO:_display_container: 2
2025-04-12 20:45:44,499:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-12 20:45:44,499:INFO:create_model() successfully completed......................................
2025-04-12 20:45:44,604:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:44,605:INFO:Creating metrics dataframe
2025-04-12 20:45:44,613:INFO:Initializing Ada Boost Classifier
2025-04-12 20:45:44,613:INFO:Total runtime is 0.20070345799128214 minutes
2025-04-12 20:45:44,615:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:44,615:INFO:Initializing create_model()
2025-04-12 20:45:44,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:44,615:INFO:Checking exceptions
2025-04-12 20:45:44,615:INFO:Importing libraries
2025-04-12 20:45:44,615:INFO:Copying training dataset
2025-04-12 20:45:44,619:INFO:Defining folds
2025-04-12 20:45:44,619:INFO:Declaring metric variables
2025-04-12 20:45:44,623:INFO:Importing untrained model
2025-04-12 20:45:44,627:INFO:Ada Boost Classifier Imported successfully
2025-04-12 20:45:44,634:INFO:Starting cross validation
2025-04-12 20:45:44,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:46,045:INFO:Calculating mean and std
2025-04-12 20:45:46,047:INFO:Creating metrics dataframe
2025-04-12 20:45:46,181:INFO:Uploading results into container
2025-04-12 20:45:46,182:INFO:Uploading model into container now
2025-04-12 20:45:46,182:INFO:_master_model_container: 9
2025-04-12 20:45:46,182:INFO:_display_container: 2
2025-04-12 20:45:46,182:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-12 20:45:46,182:INFO:create_model() successfully completed......................................
2025-04-12 20:45:46,288:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:46,288:INFO:Creating metrics dataframe
2025-04-12 20:45:46,296:INFO:Initializing Gradient Boosting Classifier
2025-04-12 20:45:46,296:INFO:Total runtime is 0.228762423992157 minutes
2025-04-12 20:45:46,298:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:46,298:INFO:Initializing create_model()
2025-04-12 20:45:46,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:46,298:INFO:Checking exceptions
2025-04-12 20:45:46,298:INFO:Importing libraries
2025-04-12 20:45:46,298:INFO:Copying training dataset
2025-04-12 20:45:46,303:INFO:Defining folds
2025-04-12 20:45:46,303:INFO:Declaring metric variables
2025-04-12 20:45:46,306:INFO:Importing untrained model
2025-04-12 20:45:46,309:INFO:Gradient Boosting Classifier Imported successfully
2025-04-12 20:45:46,317:INFO:Starting cross validation
2025-04-12 20:45:46,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:47,986:INFO:Calculating mean and std
2025-04-12 20:45:47,987:INFO:Creating metrics dataframe
2025-04-12 20:45:48,147:INFO:Uploading results into container
2025-04-12 20:45:48,148:INFO:Uploading model into container now
2025-04-12 20:45:48,148:INFO:_master_model_container: 10
2025-04-12 20:45:48,148:INFO:_display_container: 2
2025-04-12 20:45:48,150:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-12 20:45:48,150:INFO:create_model() successfully completed......................................
2025-04-12 20:45:48,251:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:48,251:INFO:Creating metrics dataframe
2025-04-12 20:45:48,260:INFO:Initializing Linear Discriminant Analysis
2025-04-12 20:45:48,260:INFO:Total runtime is 0.261492919921875 minutes
2025-04-12 20:45:48,264:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:48,264:INFO:Initializing create_model()
2025-04-12 20:45:48,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:48,264:INFO:Checking exceptions
2025-04-12 20:45:48,264:INFO:Importing libraries
2025-04-12 20:45:48,264:INFO:Copying training dataset
2025-04-12 20:45:48,270:INFO:Defining folds
2025-04-12 20:45:48,270:INFO:Declaring metric variables
2025-04-12 20:45:48,275:INFO:Importing untrained model
2025-04-12 20:45:48,278:INFO:Linear Discriminant Analysis Imported successfully
2025-04-12 20:45:48,285:INFO:Starting cross validation
2025-04-12 20:45:48,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:49,653:INFO:Calculating mean and std
2025-04-12 20:45:49,654:INFO:Creating metrics dataframe
2025-04-12 20:45:49,793:INFO:Uploading results into container
2025-04-12 20:45:49,794:INFO:Uploading model into container now
2025-04-12 20:45:49,794:INFO:_master_model_container: 11
2025-04-12 20:45:49,795:INFO:_display_container: 2
2025-04-12 20:45:49,795:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-12 20:45:49,795:INFO:create_model() successfully completed......................................
2025-04-12 20:45:49,896:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:49,896:INFO:Creating metrics dataframe
2025-04-12 20:45:49,906:INFO:Initializing Extra Trees Classifier
2025-04-12 20:45:49,906:INFO:Total runtime is 0.28891628980636597 minutes
2025-04-12 20:45:49,909:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:49,909:INFO:Initializing create_model()
2025-04-12 20:45:49,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:49,909:INFO:Checking exceptions
2025-04-12 20:45:49,909:INFO:Importing libraries
2025-04-12 20:45:49,909:INFO:Copying training dataset
2025-04-12 20:45:49,913:INFO:Defining folds
2025-04-12 20:45:49,913:INFO:Declaring metric variables
2025-04-12 20:45:49,916:INFO:Importing untrained model
2025-04-12 20:45:49,922:INFO:Extra Trees Classifier Imported successfully
2025-04-12 20:45:49,929:INFO:Starting cross validation
2025-04-12 20:45:49,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:51,715:INFO:Calculating mean and std
2025-04-12 20:45:51,716:INFO:Creating metrics dataframe
2025-04-12 20:45:51,865:INFO:Uploading results into container
2025-04-12 20:45:51,866:INFO:Uploading model into container now
2025-04-12 20:45:51,866:INFO:_master_model_container: 12
2025-04-12 20:45:51,867:INFO:_display_container: 2
2025-04-12 20:45:51,867:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-12 20:45:51,867:INFO:create_model() successfully completed......................................
2025-04-12 20:45:51,975:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:51,976:INFO:Creating metrics dataframe
2025-04-12 20:45:51,986:INFO:Initializing Extreme Gradient Boosting
2025-04-12 20:45:51,986:INFO:Total runtime is 0.323593799273173 minutes
2025-04-12 20:45:51,989:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:51,989:INFO:Initializing create_model()
2025-04-12 20:45:51,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:51,989:INFO:Checking exceptions
2025-04-12 20:45:51,989:INFO:Importing libraries
2025-04-12 20:45:51,989:INFO:Copying training dataset
2025-04-12 20:45:51,993:INFO:Defining folds
2025-04-12 20:45:51,993:INFO:Declaring metric variables
2025-04-12 20:45:51,994:INFO:Importing untrained model
2025-04-12 20:45:52,000:INFO:Extreme Gradient Boosting Imported successfully
2025-04-12 20:45:52,008:INFO:Starting cross validation
2025-04-12 20:45:52,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:54,257:INFO:Calculating mean and std
2025-04-12 20:45:54,259:INFO:Creating metrics dataframe
2025-04-12 20:45:54,559:INFO:Uploading results into container
2025-04-12 20:45:54,560:INFO:Uploading model into container now
2025-04-12 20:45:54,560:INFO:_master_model_container: 13
2025-04-12 20:45:54,560:INFO:_display_container: 2
2025-04-12 20:45:54,561:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-12 20:45:54,562:INFO:create_model() successfully completed......................................
2025-04-12 20:45:54,699:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:54,699:INFO:Creating metrics dataframe
2025-04-12 20:45:54,716:INFO:Initializing Light Gradient Boosting Machine
2025-04-12 20:45:54,716:INFO:Total runtime is 0.36908622980117795 minutes
2025-04-12 20:45:54,720:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:54,720:INFO:Initializing create_model()
2025-04-12 20:45:54,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:54,720:INFO:Checking exceptions
2025-04-12 20:45:54,720:INFO:Importing libraries
2025-04-12 20:45:54,722:INFO:Copying training dataset
2025-04-12 20:45:54,728:INFO:Defining folds
2025-04-12 20:45:54,728:INFO:Declaring metric variables
2025-04-12 20:45:54,734:INFO:Importing untrained model
2025-04-12 20:45:54,742:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 20:45:54,755:INFO:Starting cross validation
2025-04-12 20:45:54,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:58,164:INFO:Calculating mean and std
2025-04-12 20:45:58,165:INFO:Creating metrics dataframe
2025-04-12 20:45:58,326:INFO:Uploading results into container
2025-04-12 20:45:58,326:INFO:Uploading model into container now
2025-04-12 20:45:58,327:INFO:_master_model_container: 14
2025-04-12 20:45:58,327:INFO:_display_container: 2
2025-04-12 20:45:58,327:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 20:45:58,327:INFO:create_model() successfully completed......................................
2025-04-12 20:45:58,438:INFO:SubProcess create_model() end ==================================
2025-04-12 20:45:58,440:INFO:Creating metrics dataframe
2025-04-12 20:45:58,448:INFO:Initializing Dummy Classifier
2025-04-12 20:45:58,448:INFO:Total runtime is 0.4312914888064066 minutes
2025-04-12 20:45:58,452:INFO:SubProcess create_model() called ==================================
2025-04-12 20:45:58,452:INFO:Initializing create_model()
2025-04-12 20:45:58,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016B00095450>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:45:58,452:INFO:Checking exceptions
2025-04-12 20:45:58,452:INFO:Importing libraries
2025-04-12 20:45:58,452:INFO:Copying training dataset
2025-04-12 20:45:58,455:INFO:Defining folds
2025-04-12 20:45:58,455:INFO:Declaring metric variables
2025-04-12 20:45:58,459:INFO:Importing untrained model
2025-04-12 20:45:58,462:INFO:Dummy Classifier Imported successfully
2025-04-12 20:45:58,469:INFO:Starting cross validation
2025-04-12 20:45:58,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 20:45:59,963:INFO:Calculating mean and std
2025-04-12 20:45:59,965:INFO:Creating metrics dataframe
2025-04-12 20:46:00,122:INFO:Uploading results into container
2025-04-12 20:46:00,122:INFO:Uploading model into container now
2025-04-12 20:46:00,123:INFO:_master_model_container: 15
2025-04-12 20:46:00,123:INFO:_display_container: 2
2025-04-12 20:46:00,123:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-12 20:46:00,123:INFO:create_model() successfully completed......................................
2025-04-12 20:46:00,224:INFO:SubProcess create_model() end ==================================
2025-04-12 20:46:00,224:INFO:Creating metrics dataframe
2025-04-12 20:46:00,244:INFO:Initializing create_model()
2025-04-12 20:46:00,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-12 20:46:00,245:INFO:Checking exceptions
2025-04-12 20:46:00,246:INFO:Importing libraries
2025-04-12 20:46:00,246:INFO:Copying training dataset
2025-04-12 20:46:00,251:INFO:Defining folds
2025-04-12 20:46:00,251:INFO:Declaring metric variables
2025-04-12 20:46:00,251:INFO:Importing untrained model
2025-04-12 20:46:00,251:INFO:Declaring custom model
2025-04-12 20:46:00,253:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 20:46:00,254:INFO:Cross validation set to False
2025-04-12 20:46:00,254:INFO:Fitting Model
2025-04-12 20:46:00,291:INFO:[LightGBM] [Info] Number of positive: 357, number of negative: 222
2025-04-12 20:46:00,292:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 20:46:00,292:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-12 20:46:00,292:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-12 20:46:00,292:INFO:[LightGBM] [Info] Total Bins 944
2025-04-12 20:46:00,292:INFO:[LightGBM] [Info] Number of data points in the train set: 579, number of used features: 30
2025-04-12 20:46:00,293:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616580 -> initscore=0.475058
2025-04-12 20:46:00,293:INFO:[LightGBM] [Info] Start training from score 0.475058
2025-04-12 20:46:00,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:46:00,479:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 20:46:00,479:INFO:create_model() successfully completed......................................
2025-04-12 20:46:00,607:INFO:_master_model_container: 15
2025-04-12 20:46:00,607:INFO:_display_container: 2
2025-04-12 20:46:00,608:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 20:46:00,608:INFO:compare_models() successfully completed......................................
2025-04-12 20:46:00,609:INFO:Initializing evaluate_model()
2025-04-12 20:46:00,609:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-12 20:46:00,616:INFO:Initializing plot_model()
2025-04-12 20:46:00,616:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:46:00,616:INFO:Checking exceptions
2025-04-12 20:46:00,618:INFO:Preloading libraries
2025-04-12 20:46:00,628:INFO:Copying training dataset
2025-04-12 20:46:00,629:INFO:Plot type: pipeline
2025-04-12 20:46:00,785:INFO:Visual Rendered Successfully
2025-04-12 20:46:00,889:INFO:plot_model() successfully completed......................................
2025-04-12 20:53:25,588:INFO:PyCaret ClassificationExperiment
2025-04-12 20:53:25,588:INFO:Logging name: clf-default-name
2025-04-12 20:53:25,588:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-12 20:53:25,588:INFO:version 3.0.4
2025-04-12 20:53:25,588:INFO:Initializing setup()
2025-04-12 20:53:25,588:INFO:self.USI: 708b
2025-04-12 20:53:25,588:INFO:self._variable_keys: {'X', 'html_param', 'seed', 'memory', 'y_train', 'X_train', 'fold_generator', 'pipeline', '_available_plots', 'idx', 'log_plots_param', 'fix_imbalance', 'target_param', 'fold_groups_param', 'X_test', 'gpu_n_jobs_param', 'USI', '_ml_usecase', 'y', 'data', 'is_multiclass', 'y_test', 'logging_param', 'n_jobs_param', 'fold_shuffle_param', 'exp_id', 'gpu_param', 'exp_name_log'}
2025-04-12 20:53:25,588:INFO:Checking environment
2025-04-12 20:53:25,588:INFO:python_version: 3.10.5
2025-04-12 20:53:25,588:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-12 20:53:25,588:INFO:machine: AMD64
2025-04-12 20:53:25,588:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-12 20:53:25,598:INFO:Memory: svmem(total=25042907136, available=9784602624, percent=60.9, used=15258304512, free=9784602624)
2025-04-12 20:53:25,598:INFO:Physical Core: 6
2025-04-12 20:53:25,598:INFO:Logical Core: 12
2025-04-12 20:53:25,598:INFO:Checking libraries
2025-04-12 20:53:25,598:INFO:System:
2025-04-12 20:53:25,598:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-12 20:53:25,598:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-12 20:53:25,598:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-12 20:53:25,598:INFO:PyCaret required dependencies:
2025-04-12 20:53:25,598:INFO:                 pip: 25.0.1
2025-04-12 20:53:25,598:INFO:          setuptools: 58.1.0
2025-04-12 20:53:25,598:INFO:             pycaret: 3.0.4
2025-04-12 20:53:25,598:INFO:             IPython: 8.29.0
2025-04-12 20:53:25,598:INFO:          ipywidgets: 8.1.6
2025-04-12 20:53:25,600:INFO:                tqdm: 4.67.1
2025-04-12 20:53:25,600:INFO:               numpy: 1.23.5
2025-04-12 20:53:25,600:INFO:              pandas: 1.5.3
2025-04-12 20:53:25,600:INFO:              jinja2: 3.1.4
2025-04-12 20:53:25,600:INFO:               scipy: 1.11.4
2025-04-12 20:53:25,600:INFO:              joblib: 1.3.2
2025-04-12 20:53:25,600:INFO:             sklearn: 1.2.2
2025-04-12 20:53:25,600:INFO:                pyod: 2.0.4
2025-04-12 20:53:25,600:INFO:            imblearn: 0.10.1
2025-04-12 20:53:25,600:INFO:   category_encoders: 2.7.0
2025-04-12 20:53:25,600:INFO:            lightgbm: 4.6.0
2025-04-12 20:53:25,600:INFO:               numba: 0.60.0
2025-04-12 20:53:25,600:INFO:            requests: 2.32.3
2025-04-12 20:53:25,600:INFO:          matplotlib: 3.7.5
2025-04-12 20:53:25,600:INFO:          scikitplot: 0.3.7
2025-04-12 20:53:25,600:INFO:         yellowbrick: 1.5
2025-04-12 20:53:25,600:INFO:              plotly: 5.24.1
2025-04-12 20:53:25,600:INFO:    plotly-resampler: Not installed
2025-04-12 20:53:25,600:INFO:             kaleido: 0.2.1
2025-04-12 20:53:25,600:INFO:           schemdraw: 0.15
2025-04-12 20:53:25,600:INFO:         statsmodels: 0.14.4
2025-04-12 20:53:25,600:INFO:              sktime: 0.26.0
2025-04-12 20:53:25,600:INFO:               tbats: 1.1.3
2025-04-12 20:53:25,600:INFO:            pmdarima: 2.0.4
2025-04-12 20:53:25,600:INFO:              psutil: 6.1.0
2025-04-12 20:53:25,600:INFO:          markupsafe: 3.0.2
2025-04-12 20:53:25,600:INFO:             pickle5: Not installed
2025-04-12 20:53:25,600:INFO:         cloudpickle: 3.1.1
2025-04-12 20:53:25,600:INFO:         deprecation: 2.1.0
2025-04-12 20:53:25,600:INFO:              xxhash: 3.5.0
2025-04-12 20:53:25,600:INFO:           wurlitzer: Not installed
2025-04-12 20:53:25,600:INFO:PyCaret optional dependencies:
2025-04-12 20:53:25,600:INFO:                shap: Not installed
2025-04-12 20:53:25,600:INFO:           interpret: Not installed
2025-04-12 20:53:25,600:INFO:                umap: Not installed
2025-04-12 20:53:25,600:INFO:    pandas_profiling: Not installed
2025-04-12 20:53:25,600:INFO:  explainerdashboard: Not installed
2025-04-12 20:53:25,600:INFO:             autoviz: Not installed
2025-04-12 20:53:25,600:INFO:           fairlearn: Not installed
2025-04-12 20:53:25,600:INFO:          deepchecks: Not installed
2025-04-12 20:53:25,600:INFO:             xgboost: 1.7.6
2025-04-12 20:53:25,600:INFO:            catboost: Not installed
2025-04-12 20:53:25,600:INFO:              kmodes: Not installed
2025-04-12 20:53:25,600:INFO:             mlxtend: Not installed
2025-04-12 20:53:25,600:INFO:       statsforecast: Not installed
2025-04-12 20:53:25,600:INFO:        tune_sklearn: Not installed
2025-04-12 20:53:25,600:INFO:                 ray: Not installed
2025-04-12 20:53:25,600:INFO:            hyperopt: Not installed
2025-04-12 20:53:25,600:INFO:              optuna: Not installed
2025-04-12 20:53:25,600:INFO:               skopt: Not installed
2025-04-12 20:53:25,600:INFO:              mlflow: Not installed
2025-04-12 20:53:25,600:INFO:              gradio: Not installed
2025-04-12 20:53:25,600:INFO:             fastapi: Not installed
2025-04-12 20:53:25,600:INFO:             uvicorn: Not installed
2025-04-12 20:53:25,600:INFO:              m2cgen: Not installed
2025-04-12 20:53:25,600:INFO:           evidently: Not installed
2025-04-12 20:53:25,600:INFO:               fugue: Not installed
2025-04-12 20:53:25,600:INFO:           streamlit: 1.42.0
2025-04-12 20:53:25,600:INFO:             prophet: Not installed
2025-04-12 20:53:25,600:INFO:None
2025-04-12 20:53:25,600:INFO:Set up data.
2025-04-12 20:53:25,608:INFO:Set up train/test split.
2025-04-12 20:53:25,608:INFO:Set up index.
2025-04-12 20:53:25,608:INFO:Set up folding strategy.
2025-04-12 20:53:25,608:INFO:Assigning column types.
2025-04-12 20:53:25,614:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-12 20:53:25,645:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:53:25,645:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:53:25,662:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:53:25,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:53:25,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 20:53:25,698:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:53:25,718:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:53:25,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:53:25,718:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-12 20:53:25,757:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:53:25,778:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:53:25,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:53:25,814:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 20:53:25,833:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:53:25,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:53:25,833:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-12 20:53:25,880:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:53:25,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:53:25,940:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:53:25,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:53:25,944:INFO:Preparing preprocessing pipeline...
2025-04-12 20:53:25,944:INFO:Set up simple imputation.
2025-04-12 20:53:25,944:INFO:Set up feature normalization.
2025-04-12 20:53:25,957:INFO:Finished creating preprocessing pipeline.
2025-04-12 20:53:25,961:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-12 20:53:25,961:INFO:Creating final display dataframe.
2025-04-12 20:53:26,008:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (828, 35)
4        Transformed data shape         (828, 34)
5   Transformed train set shape         (579, 34)
6    Transformed test set shape         (249, 34)
7               Ignore features                 1
8              Numeric features                33
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              708b
2025-04-12 20:53:26,069:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:53:26,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:53:26,122:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 20:53:26,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 20:53:26,122:INFO:setup() successfully completed in 0.7s...............
2025-04-12 20:55:21,352:INFO:Initializing plot_model()
2025-04-12 20:55:21,352:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:21,352:INFO:Checking exceptions
2025-04-12 20:55:21,355:INFO:Preloading libraries
2025-04-12 20:55:21,362:INFO:Copying training dataset
2025-04-12 20:55:21,362:INFO:Plot type: parameter
2025-04-12 20:55:21,368:INFO:Visual Rendered Successfully
2025-04-12 20:55:21,494:INFO:plot_model() successfully completed......................................
2025-04-12 20:55:26,289:INFO:Initializing plot_model()
2025-04-12 20:55:26,289:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:26,289:INFO:Checking exceptions
2025-04-12 20:55:26,290:INFO:Preloading libraries
2025-04-12 20:55:26,296:INFO:Copying training dataset
2025-04-12 20:55:26,296:INFO:Plot type: auc
2025-04-12 20:55:26,381:INFO:Fitting Model
2025-04-12 20:55:26,381:INFO:Scoring test/hold-out set
2025-04-12 20:55:27,067:INFO:Initializing plot_model()
2025-04-12 20:55:27,069:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:27,069:INFO:Checking exceptions
2025-04-12 20:55:27,072:INFO:Preloading libraries
2025-04-12 20:55:27,080:INFO:Copying training dataset
2025-04-12 20:55:27,080:INFO:Plot type: parameter
2025-04-12 20:55:27,085:INFO:Visual Rendered Successfully
2025-04-12 20:55:27,223:INFO:plot_model() successfully completed......................................
2025-04-12 20:55:28,045:INFO:Initializing plot_model()
2025-04-12 20:55:28,045:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:28,045:INFO:Checking exceptions
2025-04-12 20:55:28,047:INFO:Preloading libraries
2025-04-12 20:55:28,052:INFO:Copying training dataset
2025-04-12 20:55:28,052:INFO:Plot type: auc
2025-04-12 20:55:28,134:INFO:Fitting Model
2025-04-12 20:55:28,136:INFO:Scoring test/hold-out set
2025-04-12 20:55:34,972:INFO:Initializing plot_model()
2025-04-12 20:55:34,972:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:34,972:INFO:Checking exceptions
2025-04-12 20:55:34,974:INFO:Preloading libraries
2025-04-12 20:55:34,983:INFO:Copying training dataset
2025-04-12 20:55:34,983:INFO:Plot type: confusion_matrix
2025-04-12 20:55:35,070:INFO:Fitting Model
2025-04-12 20:55:35,070:INFO:Scoring test/hold-out set
2025-04-12 20:55:35,197:INFO:Visual Rendered Successfully
2025-04-12 20:55:35,314:INFO:plot_model() successfully completed......................................
2025-04-12 20:55:46,449:INFO:Initializing plot_model()
2025-04-12 20:55:46,449:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:46,449:INFO:Checking exceptions
2025-04-12 20:55:46,451:INFO:Preloading libraries
2025-04-12 20:55:46,458:INFO:Copying training dataset
2025-04-12 20:55:46,458:INFO:Plot type: threshold
2025-04-12 20:55:46,544:INFO:Fitting Model
2025-04-12 20:55:46,548:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:46,548:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2025-04-12 20:55:46,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,550:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 20:55:46,550:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,550:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:46,550:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:46,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,582:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:46,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2025-04-12 20:55:46,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,584:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:46,584:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,584:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:46,584:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,616:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:46,616:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:46,616:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,616:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:46,616:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,616:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:46,616:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,650:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:46,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:46,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,650:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:46,652:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:46,652:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,701:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:46,701:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2025-04-12 20:55:46,701:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,701:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:46,701:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,701:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:46,701:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:46,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,750:INFO:[LightGBM] [Info] Number of positive: 326, number of negative: 195
2025-04-12 20:55:46,750:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:46,750:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,750:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:46,750:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,750:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625720 -> initscore=0.513898
2025-04-12 20:55:46,750:INFO:[LightGBM] [Info] Start training from score 0.513898
2025-04-12 20:55:46,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,784:INFO:[LightGBM] [Info] Number of positive: 326, number of negative: 195
2025-04-12 20:55:46,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2025-04-12 20:55:46,784:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,784:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:46,784:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,784:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625720 -> initscore=0.513898
2025-04-12 20:55:46,784:INFO:[LightGBM] [Info] Start training from score 0.513898
2025-04-12 20:55:46,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,820:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:46,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-04-12 20:55:46,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,822:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:46,822:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,822:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:46,822:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:46,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,856:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:46,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2025-04-12 20:55:46,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,856:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:46,856:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,856:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:46,856:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,894:INFO:[LightGBM] [Info] Number of positive: 323, number of negative: 198
2025-04-12 20:55:46,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:46,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,894:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:46,894:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,894:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.619962 -> initscore=0.489385
2025-04-12 20:55:46,894:INFO:[LightGBM] [Info] Start training from score 0.489385
2025-04-12 20:55:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,928:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:46,928:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 20:55:46,928:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,928:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:46,928:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,930:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:46,930:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,964:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:46,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2025-04-12 20:55:46,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,964:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:46,964:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:46,964:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,999:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 20:55:46,999:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 20:55:46,999:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:46,999:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:46,999:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:46,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 20:55:46,999:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 20:55:46,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:46,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:47,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:47,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,034:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:47,034:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,034:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:47,034:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,068:INFO:[LightGBM] [Info] Number of positive: 330, number of negative: 191
2025-04-12 20:55:47,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2025-04-12 20:55:47,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,069:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:47,069:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,069:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.633397 -> initscore=0.546819
2025-04-12 20:55:47,069:INFO:[LightGBM] [Info] Start training from score 0.546819
2025-04-12 20:55:47,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,126:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 20:55:47,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2025-04-12 20:55:47,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,126:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:47,126:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,126:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 20:55:47,126:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 20:55:47,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,170:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 20:55:47,172:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 20:55:47,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,172:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:47,172:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,172:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 20:55:47,172:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 20:55:47,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,206:INFO:[LightGBM] [Info] Number of positive: 316, number of negative: 205
2025-04-12 20:55:47,206:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 20:55:47,206:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,206:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:47,206:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,206:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.606526 -> initscore=0.432732
2025-04-12 20:55:47,206:INFO:[LightGBM] [Info] Start training from score 0.432732
2025-04-12 20:55:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,240:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:47,242:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2025-04-12 20:55:47,242:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,242:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:47,242:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,242:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:47,242:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,277:INFO:[LightGBM] [Info] Number of positive: 328, number of negative: 193
2025-04-12 20:55:47,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
2025-04-12 20:55:47,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,278:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:47,278:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.629559 -> initscore=0.530323
2025-04-12 20:55:47,278:INFO:[LightGBM] [Info] Start training from score 0.530323
2025-04-12 20:55:47,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Info] Number of positive: 317, number of negative: 204
2025-04-12 20:55:47,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2025-04-12 20:55:47,314:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,314:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:47,314:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,314:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.608445 -> initscore=0.440782
2025-04-12 20:55:47,314:INFO:[LightGBM] [Info] Start training from score 0.440782
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,348:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 20:55:47,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:47,348:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,348:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:47,348:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,348:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 20:55:47,350:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 20:55:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Info] Number of positive: 316, number of negative: 205
2025-04-12 20:55:47,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:47,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,384:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 20:55:47,384:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,384:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.606526 -> initscore=0.432732
2025-04-12 20:55:47,384:INFO:[LightGBM] [Info] Start training from score 0.432732
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,420:INFO:[LightGBM] [Info] Number of positive: 315, number of negative: 206
2025-04-12 20:55:47,422:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:47,422:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,422:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:47,422:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,422:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.604607 -> initscore=0.424696
2025-04-12 20:55:47,422:INFO:[LightGBM] [Info] Start training from score 0.424696
2025-04-12 20:55:47,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,457:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 20:55:47,457:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:47,457:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,457:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:47,457:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,458:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 20:55:47,458:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 20:55:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,516:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:47,516:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
2025-04-12 20:55:47,516:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,516:INFO:[LightGBM] [Info] Total Bins 886
2025-04-12 20:55:47,516:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,517:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:47,517:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:47,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,580:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:47,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2025-04-12 20:55:47,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,580:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:47,580:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,581:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:47,581:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,642:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:47,642:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2025-04-12 20:55:47,642:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,642:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 20:55:47,642:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:47,643:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,685:INFO:[LightGBM] [Info] Number of positive: 318, number of negative: 203
2025-04-12 20:55:47,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-12 20:55:47,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,686:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:47,686:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.610365 -> initscore=0.448845
2025-04-12 20:55:47,686:INFO:[LightGBM] [Info] Start training from score 0.448845
2025-04-12 20:55:47,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,722:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:47,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:47,722:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,722:INFO:[LightGBM] [Info] Total Bins 879
2025-04-12 20:55:47,722:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,722:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:47,722:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,758:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 20:55:47,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.
2025-04-12 20:55:47,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,760:INFO:[LightGBM] [Info] Total Bins 887
2025-04-12 20:55:47,760:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,760:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 20:55:47,760:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 20:55:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,796:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:47,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 20:55:47,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,796:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:47,796:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,796:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:47,796:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,832:INFO:[LightGBM] [Info] Number of positive: 323, number of negative: 198
2025-04-12 20:55:47,832:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2025-04-12 20:55:47,832:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,832:INFO:[LightGBM] [Info] Total Bins 878
2025-04-12 20:55:47,832:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,832:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.619962 -> initscore=0.489385
2025-04-12 20:55:47,832:INFO:[LightGBM] [Info] Start training from score 0.489385
2025-04-12 20:55:47,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,875:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 20:55:47,876:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-04-12 20:55:47,876:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,876:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:47,876:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,876:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 20:55:47,876:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 20:55:47,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,917:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 20:55:47,917:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2025-04-12 20:55:47,917:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,917:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 20:55:47,917:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,917:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 20:55:47,918:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 20:55:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,953:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:47,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-04-12 20:55:47,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:47,954:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:47,954:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:47,954:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:47,954:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:47,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:47,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,002:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:48,003:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2025-04-12 20:55:48,003:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,003:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:48,004:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,004:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:48,004:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:48,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,048:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 20:55:48,048:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2025-04-12 20:55:48,048:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,050:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:48,050:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,050:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 20:55:48,050:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 20:55:48,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,116:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:48,116:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2025-04-12 20:55:48,117:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,118:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:48,118:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,118:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:48,118:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:48,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,169:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:48,170:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.
2025-04-12 20:55:48,170:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,170:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:48,170:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:48,170:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:48,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,204:INFO:[LightGBM] [Info] Number of positive: 317, number of negative: 204
2025-04-12 20:55:48,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2025-04-12 20:55:48,204:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,204:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 20:55:48,204:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.608445 -> initscore=0.440782
2025-04-12 20:55:48,204:INFO:[LightGBM] [Info] Start training from score 0.440782
2025-04-12 20:55:48,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,239:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 20:55:48,239:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:48,239:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,239:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 20:55:48,239:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 20:55:48,239:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 20:55:48,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,273:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 20:55:48,273:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 20:55:48,273:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,273:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:48,274:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,274:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 20:55:48,274:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 20:55:48,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,304:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 20:55:48,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:48,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,308:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:48,308:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,308:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 20:55:48,308:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 20:55:48,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,341:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:48,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:48,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,341:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:48,341:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:48,341:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:48,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,376:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 20:55:48,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:48,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,376:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:48,376:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 20:55:48,376:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 20:55:48,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,412:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:48,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:48,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,414:INFO:[LightGBM] [Info] Total Bins 886
2025-04-12 20:55:48,414:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,414:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:48,414:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:48,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,447:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:48,447:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:48,447:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,447:INFO:[LightGBM] [Info] Total Bins 887
2025-04-12 20:55:48,447:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,447:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:48,447:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,488:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:48,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:48,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,488:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:48,488:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,488:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:48,488:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:48,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,528:INFO:[LightGBM] [Info] Number of positive: 329, number of negative: 192
2025-04-12 20:55:48,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2025-04-12 20:55:48,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:48,528:INFO:[LightGBM] [Info] Total Bins 878
2025-04-12 20:55:48,528:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:48,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.631478 -> initscore=0.538562
2025-04-12 20:55:48,528:INFO:[LightGBM] [Info] Start training from score 0.538562
2025-04-12 20:55:48,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:48,603:INFO:Scoring test/hold-out set
2025-04-12 20:55:48,894:INFO:Visual Rendered Successfully
2025-04-12 20:55:49,006:INFO:plot_model() successfully completed......................................
2025-04-12 20:55:50,031:INFO:Initializing plot_model()
2025-04-12 20:55:50,031:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:50,031:INFO:Checking exceptions
2025-04-12 20:55:50,033:INFO:Preloading libraries
2025-04-12 20:55:50,050:INFO:Copying training dataset
2025-04-12 20:55:50,050:INFO:Plot type: pr
2025-04-12 20:55:50,144:INFO:Fitting Model
2025-04-12 20:55:50,146:INFO:Scoring test/hold-out set
2025-04-12 20:55:50,330:INFO:Visual Rendered Successfully
2025-04-12 20:55:50,450:INFO:plot_model() successfully completed......................................
2025-04-12 20:55:53,586:INFO:Initializing plot_model()
2025-04-12 20:55:53,586:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:53,586:INFO:Checking exceptions
2025-04-12 20:55:53,589:INFO:Preloading libraries
2025-04-12 20:55:53,596:INFO:Copying training dataset
2025-04-12 20:55:53,597:INFO:Plot type: threshold
2025-04-12 20:55:53,678:INFO:Fitting Model
2025-04-12 20:55:53,681:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:53,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2025-04-12 20:55:53,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,684:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 20:55:53,684:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,684:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:53,684:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:53,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,720:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:53,720:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
2025-04-12 20:55:53,720:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,720:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:53,720:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,720:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:53,720:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,752:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:53,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:53,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,754:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:53,754:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,754:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:53,754:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:53,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,789:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:53,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-04-12 20:55:53,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,789:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:53,789:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,789:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:53,789:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:53,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,824:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:53,824:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:53,824:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,824:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:53,824:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,824:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:53,824:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:53,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,860:INFO:[LightGBM] [Info] Number of positive: 326, number of negative: 195
2025-04-12 20:55:53,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:53,862:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,862:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:53,862:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,862:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625720 -> initscore=0.513898
2025-04-12 20:55:53,862:INFO:[LightGBM] [Info] Start training from score 0.513898
2025-04-12 20:55:53,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,897:INFO:[LightGBM] [Info] Number of positive: 326, number of negative: 195
2025-04-12 20:55:53,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 20:55:53,897:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,897:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:53,899:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625720 -> initscore=0.513898
2025-04-12 20:55:53,899:INFO:[LightGBM] [Info] Start training from score 0.513898
2025-04-12 20:55:53,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,936:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:53,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2025-04-12 20:55:53,936:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,937:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:53,937:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:53,937:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:53,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,976:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:53,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.
2025-04-12 20:55:53,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:53,976:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:53,977:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:53,977:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:53,977:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:53,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,015:INFO:[LightGBM] [Info] Number of positive: 323, number of negative: 198
2025-04-12 20:55:54,016:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 20:55:54,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,016:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:54,016:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,016:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.619962 -> initscore=0.489385
2025-04-12 20:55:54,016:INFO:[LightGBM] [Info] Start training from score 0.489385
2025-04-12 20:55:54,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,058:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:54,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2025-04-12 20:55:54,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,059:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:54,059:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,059:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:54,059:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:54,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,098:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:54,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:54,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,098:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:54,099:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,099:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:54,099:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:54,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,134:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 20:55:54,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:54,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,135:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:54,135:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,135:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 20:55:54,135:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 20:55:54,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,170:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:54,170:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:54,170:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,170:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:54,170:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,170:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:54,170:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:54,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,204:INFO:[LightGBM] [Info] Number of positive: 330, number of negative: 191
2025-04-12 20:55:54,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 20:55:54,204:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,204:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:54,204:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.633397 -> initscore=0.546819
2025-04-12 20:55:54,204:INFO:[LightGBM] [Info] Start training from score 0.546819
2025-04-12 20:55:54,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,239:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 20:55:54,239:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:54,240:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,240:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:54,240:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 20:55:54,240:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 20:55:54,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,276:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 20:55:54,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.
2025-04-12 20:55:54,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-12 20:55:54,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-12 20:55:54,276:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:54,276:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,276:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 20:55:54,276:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 20:55:54,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,314:INFO:[LightGBM] [Info] Number of positive: 316, number of negative: 205
2025-04-12 20:55:54,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2025-04-12 20:55:54,314:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,314:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:54,314:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,314:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.606526 -> initscore=0.432732
2025-04-12 20:55:54,314:INFO:[LightGBM] [Info] Start training from score 0.432732
2025-04-12 20:55:54,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,348:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:54,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2025-04-12 20:55:54,348:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,348:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:54,348:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,348:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:54,348:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:54,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,386:INFO:[LightGBM] [Info] Number of positive: 328, number of negative: 193
2025-04-12 20:55:54,386:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:54,386:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,386:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:54,386:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.629559 -> initscore=0.530323
2025-04-12 20:55:54,386:INFO:[LightGBM] [Info] Start training from score 0.530323
2025-04-12 20:55:54,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,420:INFO:[LightGBM] [Info] Number of positive: 317, number of negative: 204
2025-04-12 20:55:54,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2025-04-12 20:55:54,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,420:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:54,420:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,420:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.608445 -> initscore=0.440782
2025-04-12 20:55:54,420:INFO:[LightGBM] [Info] Start training from score 0.440782
2025-04-12 20:55:54,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,451:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 20:55:54,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:54,453:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,453:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:54,453:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 20:55:54,453:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 20:55:54,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,486:INFO:[LightGBM] [Info] Number of positive: 316, number of negative: 205
2025-04-12 20:55:54,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:54,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,488:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 20:55:54,488:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,488:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.606526 -> initscore=0.432732
2025-04-12 20:55:54,488:INFO:[LightGBM] [Info] Start training from score 0.432732
2025-04-12 20:55:54,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,521:INFO:[LightGBM] [Info] Number of positive: 315, number of negative: 206
2025-04-12 20:55:54,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:54,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,521:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:54,521:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.604607 -> initscore=0.424696
2025-04-12 20:55:54,521:INFO:[LightGBM] [Info] Start training from score 0.424696
2025-04-12 20:55:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,558:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 20:55:54,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-12 20:55:54,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,558:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:54,558:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,558:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 20:55:54,558:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 20:55:54,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,594:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:54,594:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.
2025-04-12 20:55:54,594:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,594:INFO:[LightGBM] [Info] Total Bins 886
2025-04-12 20:55:54,594:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,594:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:54,595:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:54,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,628:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:54,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:54,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,628:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:54,628:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:54,628:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:54,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,669:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:54,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2025-04-12 20:55:54,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,669:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 20:55:54,669:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:54,669:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:54,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,708:INFO:[LightGBM] [Info] Number of positive: 318, number of negative: 203
2025-04-12 20:55:54,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2025-04-12 20:55:54,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,708:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:54,708:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,708:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.610365 -> initscore=0.448845
2025-04-12 20:55:54,708:INFO:[LightGBM] [Info] Start training from score 0.448845
2025-04-12 20:55:54,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,747:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:54,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 20:55:54,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,747:INFO:[LightGBM] [Info] Total Bins 879
2025-04-12 20:55:54,747:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,748:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:54,748:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:54,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,789:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 20:55:54,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 20:55:54,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,790:INFO:[LightGBM] [Info] Total Bins 887
2025-04-12 20:55:54,790:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,790:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 20:55:54,790:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 20:55:54,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,831:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:54,831:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:54,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,831:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:54,831:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,832:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:54,832:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:54,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,865:INFO:[LightGBM] [Info] Number of positive: 323, number of negative: 198
2025-04-12 20:55:54,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2025-04-12 20:55:54,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,865:INFO:[LightGBM] [Info] Total Bins 878
2025-04-12 20:55:54,865:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.619962 -> initscore=0.489385
2025-04-12 20:55:54,865:INFO:[LightGBM] [Info] Start training from score 0.489385
2025-04-12 20:55:54,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,900:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 20:55:54,900:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:54,900:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,900:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:54,900:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 20:55:54,900:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 20:55:54,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,937:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 20:55:54,937:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 20:55:54,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,937:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 20:55:54,937:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 20:55:54,937:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 20:55:54,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,972:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:54,972:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 20:55:54,972:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:54,973:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:54,973:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:54,973:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:54,973:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:54,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,007:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:55,007:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:55,007:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,007:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:55,007:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,007:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:55,007:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,042:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 20:55:55,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2025-04-12 20:55:55,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,042:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:55,043:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 20:55:55,043:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 20:55:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,078:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:55,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2025-04-12 20:55:55,078:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,078:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:55,078:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,078:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:55,078:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:55,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,140:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 20:55:55,140:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2025-04-12 20:55:55,140:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,142:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 20:55:55,142:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,142:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 20:55:55,142:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 20:55:55,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,178:INFO:[LightGBM] [Info] Number of positive: 317, number of negative: 204
2025-04-12 20:55:55,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:55,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,178:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 20:55:55,178:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.608445 -> initscore=0.440782
2025-04-12 20:55:55,178:INFO:[LightGBM] [Info] Start training from score 0.440782
2025-04-12 20:55:55,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,211:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 20:55:55,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2025-04-12 20:55:55,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,211:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 20:55:55,211:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,211:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 20:55:55,211:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 20:55:55,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,245:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 20:55:55,245:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2025-04-12 20:55:55,245:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,245:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 20:55:55,245:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,245:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 20:55:55,245:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 20:55:55,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,282:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 20:55:55,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2025-04-12 20:55:55,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,282:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 20:55:55,282:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,282:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 20:55:55,282:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 20:55:55,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,316:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:55,316:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2025-04-12 20:55:55,318:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,318:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:55,318:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,318:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:55,318:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:55,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,353:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 20:55:55,353:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 20:55:55,353:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,353:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:55,353:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,353:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 20:55:55,353:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 20:55:55,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,388:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:55,388:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2025-04-12 20:55:55,388:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,388:INFO:[LightGBM] [Info] Total Bins 886
2025-04-12 20:55:55,388:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,388:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:55,388:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:55,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,422:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 20:55:55,422:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2025-04-12 20:55:55,422:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,424:INFO:[LightGBM] [Info] Total Bins 887
2025-04-12 20:55:55,424:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,424:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 20:55:55,424:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 20:55:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,460:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 20:55:55,460:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 20:55:55,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,461:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 20:55:55,461:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,461:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 20:55:55,461:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 20:55:55,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,496:INFO:[LightGBM] [Info] Number of positive: 329, number of negative: 192
2025-04-12 20:55:55,496:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2025-04-12 20:55:55,496:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 20:55:55,497:INFO:[LightGBM] [Info] Total Bins 878
2025-04-12 20:55:55,497:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 20:55:55,497:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.631478 -> initscore=0.538562
2025-04-12 20:55:55,497:INFO:[LightGBM] [Info] Start training from score 0.538562
2025-04-12 20:55:55,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 20:55:55,567:INFO:Scoring test/hold-out set
2025-04-12 20:55:55,788:INFO:Visual Rendered Successfully
2025-04-12 20:55:55,908:INFO:plot_model() successfully completed......................................
2025-04-12 20:55:57,825:INFO:Initializing plot_model()
2025-04-12 20:55:57,825:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016B7C24F160>, system=True)
2025-04-12 20:55:57,825:INFO:Checking exceptions
2025-04-12 20:55:57,826:INFO:Preloading libraries
2025-04-12 20:55:57,836:INFO:Copying training dataset
2025-04-12 20:55:57,836:INFO:Plot type: pipeline
2025-04-12 20:55:57,983:INFO:Visual Rendered Successfully
2025-04-12 20:55:58,104:INFO:plot_model() successfully completed......................................
2025-04-12 20:57:36,646:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_cff1485c22ca463b822ae1c97159abd0
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,646:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_37365ba8d1c74f2a8acad02c9958e438_43505fa5ba98471ca7f2aee2ff592473
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,646:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_995237e26f5f4a0aac40b80736c80a4d
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,646:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_1cb52c043263459582325cbad33e7efb_05045eb499df428a8527d29ce58bb4ee
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,647:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_0fc29eb8abac42c7b4bb1a0f6c3ef9f9
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,647:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_63cb6cf4e7b343d594a0e254b7f388d8_1b697e8d8ca04508a6ebc4acd60dc91b
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,647:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_668b96de7c814ba2865686d438dabf95
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,647:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d5dd604360b24f96aa67303d3c7e2c85_a3f5b5e0930748079ed6fbc7208fe915
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,647:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_28f07cb2363a4bd2bf8c13baacccd94a
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,647:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_3df1a0120bec402296798602111b551a_2f0b4a3a6a014b118845629bbda703e5
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,647:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_8892a129c4a04d7398a948f604beb21a
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,648:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_13b0b0c6e8c64dbcb81436cb869dec0c_c06cee94288d4449ae76b4ac1ce82685
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,648:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_179f35651e4949e5b065d2f6c1d0d3e7
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,648:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_eddc752de1034ce984acf4d36540a7ca_ebde7439605b44ce9c7d82fe3309b935
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,648:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_863ccc8225bb4a86b5be4ff285ece7f4
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,648:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_0d14458d8702438795763230d3961918_469e56fc4c794f2daa5191b6ec686901
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,648:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_a0ecdfeb9265441480c63635bd49f3a6
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,648:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_4916ceeb4dc445f98939fc424264f941_2b24f1cdd016400fadf015681e742f65
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,649:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_3eb21d1fc4fd4c398c42612231ef1f8b
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,649:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_42170c38d3c14590a73efc0a4d99daed_03ab7560ad9c461e9e618ac842ccd7a2
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,649:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_aaf419e1eb0a487e90a64f206b5c4e8b
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,649:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_aec67d08500c4895942635f1730b9887_a3670044676e4a8dad73c3a5ec82f9e5
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,649:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_e3932c61a06c472ab2d47a12a60806fb
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,649:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_0de76899b94e4b3d9a5bce8cb66b0d04_2cc651fe26ff4186abe675935e44a369
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_434350995f234f138d36e1fe8cca840a
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_c86925c05db646d698050b325fe777c5_337b62ccd0014ec293877cd3f55352a8
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_53b1a1c94d504903b3e1c6ec4f185ebf
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_0f4f08fb9f0a45bab6241ee0c36fb8af_baf47af8bbbc4b54b3d8039edd84c450
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_bf2412833d4a4f0ba956f6059e6eceab
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_c01c6caa601f4ca78bfc2931fe812aaf_01f60f1043ec4b99b93ebdc3a1b3ba82
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_935d4f5506064934abe8c8717a98e28e
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_1cbbda8833ce47449e1a89fa5b1c5063_954f4772150e4f248048e72f42448525
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_487820b9753047f294b2eca5a4e25653
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_197fa93b90fd493d93f8c92ea281974d_80840a437b994a7f9d05172d9ae32781
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_6fdbc629e4414711a3a8f2cf7bf6625e
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_b4193f48e2a047c38dc53e4a9f0fde92_a48f91647cf5408a88bf8b49c286fab5
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_e2d955f8a898418e896ad682590b6c97
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_6fb4ef7146754bcb90a19fa61f466fe3_fa1b742a756c44e2865dd28e0e666c62
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_5cbdda30c5d14042a18c8f05deecba34
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_9f4e04b9e8b8450a91354ba95f000afd_050fdd9254b64b68966c653847e43ab6
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_e34dcb4953a04cd8b79652c0fc72f2b8
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,651:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_e1fdf7f34c0f44ac853c62e6d44f34f8_52c36ef2ad1a4defb4acce40e39e0276
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,652:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_8c715f63acb64a7e9148cb0dca531d36
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,652:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_1210a09f1ac941929e09abe71ee614a3_08f2256f4e5143c3a5172ae6477965d0
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,652:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_4c22a8eaa42e4e8d960a8365adac8606
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,652:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_07970fe2dcce491b8bce2f342ae7a9cd_b39de4036bcd47639e940669b9967b4f
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_2ed4a24a88524be9a86c3ec19ec3898a
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_788cbd60c68f4dfaa27385ab6e1c9742_bdfddfff56284a008ee252e3db6c80e8
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_beef1ef4d2614261b078c68f81245019
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_f050216a29e14f8d8867ed18be4dd8a8_93efa49a382e4367941b2362b2c75991
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_17eab1a11a374feb85a472c92211b900
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_77b505310c064e7983ea2970d654ca94_52aa999ee1374236a4512278e62af7c7
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_399a91675353491ab4881c84000c16aa
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d4829099044249bba10219a419bf09bc_6af14b0c05c14a899b7022b1fb587d44
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,654:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_95bf79cc78754ce5a36fec2f1b55525f
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,654:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_f5d5043ccb1e4ab7895513864e55b6d4_33ffd2467264412b89cde50845f361fb
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,654:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_5bc3aecaa698497499b1f646d3100eba
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,654:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_ea72e465a0e5462ead35368433c5e044_32eba69f10fa4e1389ab55a5091571a9
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,654:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_015f2b0549c84eb682eb02ce9ea69b28
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,654:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_1cc8beafe36f40e7ba10161c422de3d6_9a4f0fc7716447c493bed88934440e26
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,654:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_3b22924a0ab44c56ad38d184c57d7769
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,654:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_5ea7829d789b45969996858d5c7856ce_f6c712e6da3c40da8d70db4b7ed30ebe
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_4863cd33ed644990964f7626b9a13026
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_e9eed6d9f51641e7904f465e55df997c_903ed572a563447aace47b381a1ed476
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_5b13d2bc5bd34945898daf6a35eb5137
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_85d4c310ee464d2e81eea24f3fa66731_e7a0617eb07d4489aad964e7086f6843
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_6bdea05ff2254861bb7bb2743eef8e65
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_162b57d35113434ea715f0b0556c4b5e_2f7a83f9da304875ac51552c9e22043e
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_4cd3e9b69d9f492b95045d1501d9f1e6
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d7f8185aeea44e02bc015db34f98859f_d83893deb0be4fa695961f8064cbcb97
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_428b02db0dce4a4181a5fddb6726ed38
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_9c43246ef92f4ddd8ac04f37562f2bd5_ae014cc6e50746e4ae077db97f1bb7fc
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,655:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_2cb4217321374d72a9e1eb75a8fcf197
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,656:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_c42942e768a4414fa618bf2b8fba138e_e27a122e9f0f49f69a733c381edada46
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,656:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_109dd1b6167e467eac22a310b925ae53
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,656:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_53678ad9889d4ba4bc61b92c3779dc33_017b8a9f79684aa1a1a4858349b26968
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,657:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_6dd0333d67d14015a6239f5f3edef8e8
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,657:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_48a89da0a6b24e5c8ba51b8286c41840_72c285543cdf4c9d82474218c293e6d2
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,657:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_0de614c43e9943ac93335903f7dbb5b7
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,657:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_fefb5426fd114cd48105f77c5e9f3fb0_8750d4f0955b4add92015ead17292134
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,657:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_8c6c53b739be489b857d35990629912e
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,657:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_c4a9ac32bdcc4256920d58744d91da89_2203edaedb584c018266f78e3f281c54
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,657:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_84688a0590f04b6a9f0ef8d08bf32bbb
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_ac4510bd8c134ff4bedab261d31cc421_7763bf7c2648466b965e6badaaa53c49
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_085d7b4591da44049123a211fda8e919
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_1dd86f6d9bbf4c8688daf1f5728934bc_0a922cb3150f40b782594ffe2d724684
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_e8a805526c134bcdb941871ce6c4f06a
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_72c61ef5edb64e51b82afef6d13bf139_3b64c8eab0144c7ca7fab36967ae1ec0
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_c9a5582d860846bfa1083d9fa4697403
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_217e9766a3e849eea801314e094d65de_1a40458e976642038cb0a4e4bca5aaf1
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_6521c2072bd14045bedccff20ee85ab9
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,659:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_ec7c38ad0ac749159c5d0a8373ee459c_39bc3fcf09ed40d0a1ce54b77cafd05e
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,659:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_0b0aa62dbc3d4e3794ff4bc2567fa137
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,659:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_bb177eb6d5eb4e1b9dcc18514c5e4c9d_feee0bbbcf0c430688a2340fb19a2189
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,659:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_f5956be3fd684d01a8102547441f1fe3
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,659:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_b20bdd03a5b143588ca365fb16c6ef5f_99eab2be97af4e32b9dfe01f92aedb85
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,659:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_6c2e6b19107e41a98366f739def63e57
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,659:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_735e155730ab402e9e5d7b9695eabc9d_7a2afffd78e4477991ee894d3f982a91
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,660:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_effcbe0108684095a2ab302c1211990e
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,660:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_c2f99d1d84784d1f95fcd2dfb6d778b9_ea1eb3e6a5e94e07a2c47f19a6e6d19e
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,660:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_cbd9a46e109f4a66891afd4971874d6f
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,660:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_9c90d2f0c75f4956859e55faa24489dc_b529fd79061a448aa3a0745abd0c5037
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,660:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_c7eeeecb80ef4bc3ab17eac21b14c523
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,660:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_6a49426b07024ed69a119c31e471cffa_e3e4ba878a19485b8a1a1a6f3ef26906
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,660:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_add167867d994de7807eec037422a1d0
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,660:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_864dd185376a4c6486b3b9fd91a85a02_cd1011a1880e4f15ac0859cab13a5dfc
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,661:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_abaeb239fe524958bef3a72c55a3cad1
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,661:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_e0b9f55b2cde4b969b5e77a241db8295_1e87adf3fccb4eef982e74aec061b04f
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,661:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_7e605b8601ca49f6a4638f474a5548ad
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,661:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d32e251eeeb541e68920926b5fe923a6_df0a9310569742e1a4ff0c06e6a53109
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,661:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_5180cf927a0a48cf91fff3b82b0c3263
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,661:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_ddc92d9a0d674386b1c6d8f722fe1542_4c7b88f83c844639a14aee7bee4a72a0
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,661:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_9777aaf8ee764ef4aa71f6ebb7659193
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,661:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_c67ad22bb2bf4df785f5e80a37c8c1ae_d723736f45f04a3ea26a1d798fda33d2
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,662:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_c37d12e90262420eae28ce7559147d93
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,662:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_96c7417abe3a4662b9c84359fbf494cc_cbc1984a610d44b8b20252148b9d783f
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,662:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_664b315b958c40d9ba581274a5fa0403
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,662:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_c4dfba28bd3f4d1a95ffa688ceef3b48_f75cc3d630e04ffc8c4b970a044b75a5
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,662:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_2968d80d7b8b479cac0971ee0c6ddcaa
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 20:57:36,662:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2236_d25008404df742628002fcb55104faee_507a7275cc98436b816b70ab20cdc0d5
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-12 21:27:19,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 21:27:19,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 21:27:19,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 21:27:19,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-12 21:27:36,438:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_27660\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-12 21:28:05,208:INFO:PyCaret ClassificationExperiment
2025-04-12 21:28:05,208:INFO:Logging name: clf-default-name
2025-04-12 21:28:05,208:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-12 21:28:05,208:INFO:version 3.0.4
2025-04-12 21:28:05,208:INFO:Initializing setup()
2025-04-12 21:28:05,208:INFO:self.USI: 7da8
2025-04-12 21:28:05,208:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_name_log', 'y_train', 'html_param', 'X_test', 'gpu_param', 'idx', 'logging_param', 'exp_id', 'pipeline', 'X', 'y', 'fold_shuffle_param', 'fix_imbalance', 'is_multiclass', 'X_train', 'log_plots_param', '_available_plots', 'memory', 'target_param', 'y_test', 'data', 'n_jobs_param', 'fold_generator', 'USI', 'seed'}
2025-04-12 21:28:05,208:INFO:Checking environment
2025-04-12 21:28:05,208:INFO:python_version: 3.10.5
2025-04-12 21:28:05,208:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-12 21:28:05,208:INFO:machine: AMD64
2025-04-12 21:28:05,208:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-12 21:28:05,213:INFO:Memory: svmem(total=25042907136, available=13211250688, percent=47.2, used=11831656448, free=13211250688)
2025-04-12 21:28:05,213:INFO:Physical Core: 6
2025-04-12 21:28:05,213:INFO:Logical Core: 12
2025-04-12 21:28:05,213:INFO:Checking libraries
2025-04-12 21:28:05,213:INFO:System:
2025-04-12 21:28:05,213:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-12 21:28:05,213:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-12 21:28:05,213:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-12 21:28:05,213:INFO:PyCaret required dependencies:
2025-04-12 21:28:05,254:INFO:                 pip: 25.0.1
2025-04-12 21:28:05,254:INFO:          setuptools: 58.1.0
2025-04-12 21:28:05,254:INFO:             pycaret: 3.0.4
2025-04-12 21:28:05,254:INFO:             IPython: 8.29.0
2025-04-12 21:28:05,254:INFO:          ipywidgets: 8.1.6
2025-04-12 21:28:05,254:INFO:                tqdm: 4.67.1
2025-04-12 21:28:05,254:INFO:               numpy: 1.23.5
2025-04-12 21:28:05,254:INFO:              pandas: 1.5.3
2025-04-12 21:28:05,254:INFO:              jinja2: 3.1.4
2025-04-12 21:28:05,254:INFO:               scipy: 1.11.4
2025-04-12 21:28:05,254:INFO:              joblib: 1.3.2
2025-04-12 21:28:05,254:INFO:             sklearn: 1.2.2
2025-04-12 21:28:05,254:INFO:                pyod: 2.0.4
2025-04-12 21:28:05,254:INFO:            imblearn: 0.10.1
2025-04-12 21:28:05,254:INFO:   category_encoders: 2.7.0
2025-04-12 21:28:05,254:INFO:            lightgbm: 4.6.0
2025-04-12 21:28:05,254:INFO:               numba: 0.60.0
2025-04-12 21:28:05,254:INFO:            requests: 2.32.3
2025-04-12 21:28:05,254:INFO:          matplotlib: 3.7.5
2025-04-12 21:28:05,254:INFO:          scikitplot: 0.3.7
2025-04-12 21:28:05,254:INFO:         yellowbrick: 1.5
2025-04-12 21:28:05,254:INFO:              plotly: 5.24.1
2025-04-12 21:28:05,254:INFO:    plotly-resampler: Not installed
2025-04-12 21:28:05,254:INFO:             kaleido: 0.2.1
2025-04-12 21:28:05,254:INFO:           schemdraw: 0.15
2025-04-12 21:28:05,254:INFO:         statsmodels: 0.14.4
2025-04-12 21:28:05,254:INFO:              sktime: 0.26.0
2025-04-12 21:28:05,254:INFO:               tbats: 1.1.3
2025-04-12 21:28:05,254:INFO:            pmdarima: 2.0.4
2025-04-12 21:28:05,254:INFO:              psutil: 6.1.0
2025-04-12 21:28:05,254:INFO:          markupsafe: 3.0.2
2025-04-12 21:28:05,254:INFO:             pickle5: Not installed
2025-04-12 21:28:05,254:INFO:         cloudpickle: 3.1.1
2025-04-12 21:28:05,254:INFO:         deprecation: 2.1.0
2025-04-12 21:28:05,254:INFO:              xxhash: 3.5.0
2025-04-12 21:28:05,254:INFO:           wurlitzer: Not installed
2025-04-12 21:28:05,254:INFO:PyCaret optional dependencies:
2025-04-12 21:28:05,270:INFO:                shap: Not installed
2025-04-12 21:28:05,270:INFO:           interpret: Not installed
2025-04-12 21:28:05,270:INFO:                umap: Not installed
2025-04-12 21:28:05,270:INFO:    pandas_profiling: Not installed
2025-04-12 21:28:05,270:INFO:  explainerdashboard: Not installed
2025-04-12 21:28:05,270:INFO:             autoviz: Not installed
2025-04-12 21:28:05,270:INFO:           fairlearn: Not installed
2025-04-12 21:28:05,270:INFO:          deepchecks: Not installed
2025-04-12 21:28:05,270:INFO:             xgboost: 1.7.6
2025-04-12 21:28:05,270:INFO:            catboost: Not installed
2025-04-12 21:28:05,270:INFO:              kmodes: Not installed
2025-04-12 21:28:05,270:INFO:             mlxtend: Not installed
2025-04-12 21:28:05,270:INFO:       statsforecast: Not installed
2025-04-12 21:28:05,270:INFO:        tune_sklearn: Not installed
2025-04-12 21:28:05,270:INFO:                 ray: Not installed
2025-04-12 21:28:05,270:INFO:            hyperopt: Not installed
2025-04-12 21:28:05,270:INFO:              optuna: Not installed
2025-04-12 21:28:05,270:INFO:               skopt: Not installed
2025-04-12 21:28:05,270:INFO:              mlflow: Not installed
2025-04-12 21:28:05,270:INFO:              gradio: Not installed
2025-04-12 21:28:05,270:INFO:             fastapi: Not installed
2025-04-12 21:28:05,270:INFO:             uvicorn: Not installed
2025-04-12 21:28:05,270:INFO:              m2cgen: Not installed
2025-04-12 21:28:05,270:INFO:           evidently: Not installed
2025-04-12 21:28:05,270:INFO:               fugue: Not installed
2025-04-12 21:28:05,270:INFO:           streamlit: 1.42.0
2025-04-12 21:28:05,270:INFO:             prophet: Not installed
2025-04-12 21:28:05,270:INFO:None
2025-04-12 21:28:05,270:INFO:Set up data.
2025-04-12 21:28:05,274:INFO:Set up train/test split.
2025-04-12 21:28:05,274:INFO:Set up index.
2025-04-12 21:28:05,274:INFO:Set up folding strategy.
2025-04-12 21:28:05,274:INFO:Assigning column types.
2025-04-12 21:28:05,282:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-12 21:28:05,312:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 21:28:05,317:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 21:28:05,340:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 21:28:05,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 21:28:05,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-12 21:28:05,374:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 21:28:05,394:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 21:28:05,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 21:28:05,396:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-12 21:28:05,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 21:28:05,451:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 21:28:05,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 21:28:05,482:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-12 21:28:05,503:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 21:28:05,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 21:28:05,503:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-12 21:28:05,557:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 21:28:05,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 21:28:05,602:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 21:28:05,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 21:28:05,614:INFO:Preparing preprocessing pipeline...
2025-04-12 21:28:05,615:INFO:Set up simple imputation.
2025-04-12 21:28:05,615:INFO:Set up feature normalization.
2025-04-12 21:28:05,631:INFO:Finished creating preprocessing pipeline.
2025-04-12 21:28:05,634:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-12 21:28:05,634:INFO:Creating final display dataframe.
2025-04-12 21:28:05,687:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (828, 35)
4        Transformed data shape         (828, 34)
5   Transformed train set shape         (579, 34)
6    Transformed test set shape         (249, 34)
7               Ignore features                 1
8              Numeric features                33
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              7da8
2025-04-12 21:28:05,738:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 21:28:05,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 21:28:05,790:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-12 21:28:05,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-12 21:28:05,792:INFO:setup() successfully completed in 0.74s...............
2025-04-12 21:28:11,386:INFO:Initializing compare_models()
2025-04-12 21:28:11,387:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-12 21:28:11,387:INFO:Checking exceptions
2025-04-12 21:28:11,390:INFO:Preparing display monitor
2025-04-12 21:28:11,412:INFO:Initializing Logistic Regression
2025-04-12 21:28:11,412:INFO:Total runtime is 9.441375732421875e-06 minutes
2025-04-12 21:28:11,415:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:11,416:INFO:Initializing create_model()
2025-04-12 21:28:11,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:11,416:INFO:Checking exceptions
2025-04-12 21:28:11,416:INFO:Importing libraries
2025-04-12 21:28:11,416:INFO:Copying training dataset
2025-04-12 21:28:11,422:INFO:Defining folds
2025-04-12 21:28:11,424:INFO:Declaring metric variables
2025-04-12 21:28:11,428:INFO:Importing untrained model
2025-04-12 21:28:11,432:INFO:Logistic Regression Imported successfully
2025-04-12 21:28:11,438:INFO:Starting cross validation
2025-04-12 21:28:11,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:23,043:INFO:Calculating mean and std
2025-04-12 21:28:23,044:INFO:Creating metrics dataframe
2025-04-12 21:28:23,194:INFO:Uploading results into container
2025-04-12 21:28:23,194:INFO:Uploading model into container now
2025-04-12 21:28:23,197:INFO:_master_model_container: 1
2025-04-12 21:28:23,197:INFO:_display_container: 2
2025-04-12 21:28:23,197:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-12 21:28:23,197:INFO:create_model() successfully completed......................................
2025-04-12 21:28:23,284:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:23,284:INFO:Creating metrics dataframe
2025-04-12 21:28:23,291:INFO:Initializing K Neighbors Classifier
2025-04-12 21:28:23,291:INFO:Total runtime is 0.1979818304379781 minutes
2025-04-12 21:28:23,293:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:23,293:INFO:Initializing create_model()
2025-04-12 21:28:23,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:23,293:INFO:Checking exceptions
2025-04-12 21:28:23,294:INFO:Importing libraries
2025-04-12 21:28:23,294:INFO:Copying training dataset
2025-04-12 21:28:23,297:INFO:Defining folds
2025-04-12 21:28:23,297:INFO:Declaring metric variables
2025-04-12 21:28:23,300:INFO:Importing untrained model
2025-04-12 21:28:23,302:INFO:K Neighbors Classifier Imported successfully
2025-04-12 21:28:23,309:INFO:Starting cross validation
2025-04-12 21:28:23,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:25,472:INFO:Calculating mean and std
2025-04-12 21:28:25,472:INFO:Creating metrics dataframe
2025-04-12 21:28:25,629:INFO:Uploading results into container
2025-04-12 21:28:25,632:INFO:Uploading model into container now
2025-04-12 21:28:25,632:INFO:_master_model_container: 2
2025-04-12 21:28:25,632:INFO:_display_container: 2
2025-04-12 21:28:25,633:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-12 21:28:25,633:INFO:create_model() successfully completed......................................
2025-04-12 21:28:25,712:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:25,712:INFO:Creating metrics dataframe
2025-04-12 21:28:25,719:INFO:Initializing Naive Bayes
2025-04-12 21:28:25,719:INFO:Total runtime is 0.23845053911209105 minutes
2025-04-12 21:28:25,723:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:25,723:INFO:Initializing create_model()
2025-04-12 21:28:25,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:25,723:INFO:Checking exceptions
2025-04-12 21:28:25,723:INFO:Importing libraries
2025-04-12 21:28:25,723:INFO:Copying training dataset
2025-04-12 21:28:25,726:INFO:Defining folds
2025-04-12 21:28:25,726:INFO:Declaring metric variables
2025-04-12 21:28:25,728:INFO:Importing untrained model
2025-04-12 21:28:25,756:INFO:Naive Bayes Imported successfully
2025-04-12 21:28:25,768:INFO:Starting cross validation
2025-04-12 21:28:25,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:27,120:INFO:Calculating mean and std
2025-04-12 21:28:27,121:INFO:Creating metrics dataframe
2025-04-12 21:28:27,270:INFO:Uploading results into container
2025-04-12 21:28:27,270:INFO:Uploading model into container now
2025-04-12 21:28:27,270:INFO:_master_model_container: 3
2025-04-12 21:28:27,270:INFO:_display_container: 2
2025-04-12 21:28:27,272:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-12 21:28:27,272:INFO:create_model() successfully completed......................................
2025-04-12 21:28:27,344:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:27,344:INFO:Creating metrics dataframe
2025-04-12 21:28:27,352:INFO:Initializing Decision Tree Classifier
2025-04-12 21:28:27,352:INFO:Total runtime is 0.2656648715337117 minutes
2025-04-12 21:28:27,356:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:27,356:INFO:Initializing create_model()
2025-04-12 21:28:27,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:27,356:INFO:Checking exceptions
2025-04-12 21:28:27,356:INFO:Importing libraries
2025-04-12 21:28:27,356:INFO:Copying training dataset
2025-04-12 21:28:27,359:INFO:Defining folds
2025-04-12 21:28:27,359:INFO:Declaring metric variables
2025-04-12 21:28:27,362:INFO:Importing untrained model
2025-04-12 21:28:27,367:INFO:Decision Tree Classifier Imported successfully
2025-04-12 21:28:27,373:INFO:Starting cross validation
2025-04-12 21:28:27,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:28,750:INFO:Calculating mean and std
2025-04-12 21:28:28,750:INFO:Creating metrics dataframe
2025-04-12 21:28:28,898:INFO:Uploading results into container
2025-04-12 21:28:28,898:INFO:Uploading model into container now
2025-04-12 21:28:28,898:INFO:_master_model_container: 4
2025-04-12 21:28:28,898:INFO:_display_container: 2
2025-04-12 21:28:28,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-12 21:28:28,901:INFO:create_model() successfully completed......................................
2025-04-12 21:28:28,977:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:28,977:INFO:Creating metrics dataframe
2025-04-12 21:28:28,982:INFO:Initializing SVM - Linear Kernel
2025-04-12 21:28:28,982:INFO:Total runtime is 0.29283290704091386 minutes
2025-04-12 21:28:28,987:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:28,987:INFO:Initializing create_model()
2025-04-12 21:28:28,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:28,988:INFO:Checking exceptions
2025-04-12 21:28:28,988:INFO:Importing libraries
2025-04-12 21:28:28,988:INFO:Copying training dataset
2025-04-12 21:28:28,991:INFO:Defining folds
2025-04-12 21:28:28,991:INFO:Declaring metric variables
2025-04-12 21:28:28,995:INFO:Importing untrained model
2025-04-12 21:28:28,996:INFO:SVM - Linear Kernel Imported successfully
2025-04-12 21:28:29,004:INFO:Starting cross validation
2025-04-12 21:28:29,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:29,092:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,094:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,094:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,096:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,101:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,102:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,110:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,115:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,122:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:29,133:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 21:28:30,362:INFO:Calculating mean and std
2025-04-12 21:28:30,362:INFO:Creating metrics dataframe
2025-04-12 21:28:30,520:INFO:Uploading results into container
2025-04-12 21:28:30,520:INFO:Uploading model into container now
2025-04-12 21:28:30,521:INFO:_master_model_container: 5
2025-04-12 21:28:30,521:INFO:_display_container: 2
2025-04-12 21:28:30,522:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-12 21:28:30,522:INFO:create_model() successfully completed......................................
2025-04-12 21:28:30,597:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:30,598:INFO:Creating metrics dataframe
2025-04-12 21:28:30,606:INFO:Initializing Ridge Classifier
2025-04-12 21:28:30,606:INFO:Total runtime is 0.31990017096201573 minutes
2025-04-12 21:28:30,609:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:30,609:INFO:Initializing create_model()
2025-04-12 21:28:30,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:30,610:INFO:Checking exceptions
2025-04-12 21:28:30,610:INFO:Importing libraries
2025-04-12 21:28:30,610:INFO:Copying training dataset
2025-04-12 21:28:30,613:INFO:Defining folds
2025-04-12 21:28:30,613:INFO:Declaring metric variables
2025-04-12 21:28:30,614:INFO:Importing untrained model
2025-04-12 21:28:30,614:INFO:Ridge Classifier Imported successfully
2025-04-12 21:28:30,623:INFO:Starting cross validation
2025-04-12 21:28:30,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:30,701:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,702:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,712:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,712:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,719:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,726:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,728:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,728:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,742:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:30,754:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 21:28:31,979:INFO:Calculating mean and std
2025-04-12 21:28:31,979:INFO:Creating metrics dataframe
2025-04-12 21:28:32,122:INFO:Uploading results into container
2025-04-12 21:28:32,122:INFO:Uploading model into container now
2025-04-12 21:28:32,126:INFO:_master_model_container: 6
2025-04-12 21:28:32,126:INFO:_display_container: 2
2025-04-12 21:28:32,126:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-12 21:28:32,126:INFO:create_model() successfully completed......................................
2025-04-12 21:28:32,202:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:32,202:INFO:Creating metrics dataframe
2025-04-12 21:28:32,202:INFO:Initializing Random Forest Classifier
2025-04-12 21:28:32,202:INFO:Total runtime is 0.34650170405705766 minutes
2025-04-12 21:28:32,212:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:32,212:INFO:Initializing create_model()
2025-04-12 21:28:32,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:32,213:INFO:Checking exceptions
2025-04-12 21:28:32,213:INFO:Importing libraries
2025-04-12 21:28:32,213:INFO:Copying training dataset
2025-04-12 21:28:32,217:INFO:Defining folds
2025-04-12 21:28:32,217:INFO:Declaring metric variables
2025-04-12 21:28:32,221:INFO:Importing untrained model
2025-04-12 21:28:32,223:INFO:Random Forest Classifier Imported successfully
2025-04-12 21:28:32,235:INFO:Starting cross validation
2025-04-12 21:28:32,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:34,152:INFO:Calculating mean and std
2025-04-12 21:28:34,154:INFO:Creating metrics dataframe
2025-04-12 21:28:34,304:INFO:Uploading results into container
2025-04-12 21:28:34,304:INFO:Uploading model into container now
2025-04-12 21:28:34,304:INFO:_master_model_container: 7
2025-04-12 21:28:34,304:INFO:_display_container: 2
2025-04-12 21:28:34,306:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-12 21:28:34,306:INFO:create_model() successfully completed......................................
2025-04-12 21:28:34,378:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:34,378:INFO:Creating metrics dataframe
2025-04-12 21:28:34,384:INFO:Initializing Quadratic Discriminant Analysis
2025-04-12 21:28:34,384:INFO:Total runtime is 0.38286438385645544 minutes
2025-04-12 21:28:34,384:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:34,384:INFO:Initializing create_model()
2025-04-12 21:28:34,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:34,384:INFO:Checking exceptions
2025-04-12 21:28:34,391:INFO:Importing libraries
2025-04-12 21:28:34,391:INFO:Copying training dataset
2025-04-12 21:28:34,394:INFO:Defining folds
2025-04-12 21:28:34,394:INFO:Declaring metric variables
2025-04-12 21:28:34,396:INFO:Importing untrained model
2025-04-12 21:28:34,401:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-12 21:28:34,407:INFO:Starting cross validation
2025-04-12 21:28:34,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:34,457:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,457:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,464:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,468:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,472:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,489:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,489:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,491:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,502:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:34,509:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 21:28:35,829:INFO:Calculating mean and std
2025-04-12 21:28:35,829:INFO:Creating metrics dataframe
2025-04-12 21:28:35,982:INFO:Uploading results into container
2025-04-12 21:28:35,982:INFO:Uploading model into container now
2025-04-12 21:28:35,982:INFO:_master_model_container: 8
2025-04-12 21:28:35,982:INFO:_display_container: 2
2025-04-12 21:28:35,986:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-12 21:28:35,986:INFO:create_model() successfully completed......................................
2025-04-12 21:28:36,057:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:36,057:INFO:Creating metrics dataframe
2025-04-12 21:28:36,062:INFO:Initializing Ada Boost Classifier
2025-04-12 21:28:36,062:INFO:Total runtime is 0.4108320275942484 minutes
2025-04-12 21:28:36,071:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:36,071:INFO:Initializing create_model()
2025-04-12 21:28:36,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:36,071:INFO:Checking exceptions
2025-04-12 21:28:36,071:INFO:Importing libraries
2025-04-12 21:28:36,071:INFO:Copying training dataset
2025-04-12 21:28:36,074:INFO:Defining folds
2025-04-12 21:28:36,074:INFO:Declaring metric variables
2025-04-12 21:28:36,076:INFO:Importing untrained model
2025-04-12 21:28:36,080:INFO:Ada Boost Classifier Imported successfully
2025-04-12 21:28:36,088:INFO:Starting cross validation
2025-04-12 21:28:36,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:37,705:INFO:Calculating mean and std
2025-04-12 21:28:37,705:INFO:Creating metrics dataframe
2025-04-12 21:28:37,864:INFO:Uploading results into container
2025-04-12 21:28:37,864:INFO:Uploading model into container now
2025-04-12 21:28:37,864:INFO:_master_model_container: 9
2025-04-12 21:28:37,864:INFO:_display_container: 2
2025-04-12 21:28:37,866:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-12 21:28:37,866:INFO:create_model() successfully completed......................................
2025-04-12 21:28:37,944:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:37,944:INFO:Creating metrics dataframe
2025-04-12 21:28:37,952:INFO:Initializing Gradient Boosting Classifier
2025-04-12 21:28:37,952:INFO:Total runtime is 0.4423316915829976 minutes
2025-04-12 21:28:37,953:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:37,954:INFO:Initializing create_model()
2025-04-12 21:28:37,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:37,954:INFO:Checking exceptions
2025-04-12 21:28:37,954:INFO:Importing libraries
2025-04-12 21:28:37,954:INFO:Copying training dataset
2025-04-12 21:28:37,956:INFO:Defining folds
2025-04-12 21:28:37,956:INFO:Declaring metric variables
2025-04-12 21:28:37,961:INFO:Importing untrained model
2025-04-12 21:28:37,966:INFO:Gradient Boosting Classifier Imported successfully
2025-04-12 21:28:37,976:INFO:Starting cross validation
2025-04-12 21:28:37,978:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:39,919:INFO:Calculating mean and std
2025-04-12 21:28:39,920:INFO:Creating metrics dataframe
2025-04-12 21:28:40,082:INFO:Uploading results into container
2025-04-12 21:28:40,082:INFO:Uploading model into container now
2025-04-12 21:28:40,082:INFO:_master_model_container: 10
2025-04-12 21:28:40,082:INFO:_display_container: 2
2025-04-12 21:28:40,082:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-12 21:28:40,082:INFO:create_model() successfully completed......................................
2025-04-12 21:28:40,162:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:40,162:INFO:Creating metrics dataframe
2025-04-12 21:28:40,172:INFO:Initializing Linear Discriminant Analysis
2025-04-12 21:28:40,172:INFO:Total runtime is 0.4793301065762838 minutes
2025-04-12 21:28:40,177:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:40,177:INFO:Initializing create_model()
2025-04-12 21:28:40,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:40,177:INFO:Checking exceptions
2025-04-12 21:28:40,178:INFO:Importing libraries
2025-04-12 21:28:40,178:INFO:Copying training dataset
2025-04-12 21:28:40,180:INFO:Defining folds
2025-04-12 21:28:40,180:INFO:Declaring metric variables
2025-04-12 21:28:40,184:INFO:Importing untrained model
2025-04-12 21:28:40,188:INFO:Linear Discriminant Analysis Imported successfully
2025-04-12 21:28:40,197:INFO:Starting cross validation
2025-04-12 21:28:40,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:41,732:INFO:Calculating mean and std
2025-04-12 21:28:41,732:INFO:Creating metrics dataframe
2025-04-12 21:28:41,884:INFO:Uploading results into container
2025-04-12 21:28:41,884:INFO:Uploading model into container now
2025-04-12 21:28:41,891:INFO:_master_model_container: 11
2025-04-12 21:28:41,892:INFO:_display_container: 2
2025-04-12 21:28:41,892:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-12 21:28:41,892:INFO:create_model() successfully completed......................................
2025-04-12 21:28:41,964:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:41,964:INFO:Creating metrics dataframe
2025-04-12 21:28:41,978:INFO:Initializing Extra Trees Classifier
2025-04-12 21:28:41,978:INFO:Total runtime is 0.5094420313835144 minutes
2025-04-12 21:28:41,982:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:41,982:INFO:Initializing create_model()
2025-04-12 21:28:41,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:41,983:INFO:Checking exceptions
2025-04-12 21:28:41,983:INFO:Importing libraries
2025-04-12 21:28:41,983:INFO:Copying training dataset
2025-04-12 21:28:41,986:INFO:Defining folds
2025-04-12 21:28:41,986:INFO:Declaring metric variables
2025-04-12 21:28:41,989:INFO:Importing untrained model
2025-04-12 21:28:41,993:INFO:Extra Trees Classifier Imported successfully
2025-04-12 21:28:42,000:INFO:Starting cross validation
2025-04-12 21:28:42,002:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:44,044:INFO:Calculating mean and std
2025-04-12 21:28:44,045:INFO:Creating metrics dataframe
2025-04-12 21:28:44,211:INFO:Uploading results into container
2025-04-12 21:28:44,211:INFO:Uploading model into container now
2025-04-12 21:28:44,211:INFO:_master_model_container: 12
2025-04-12 21:28:44,211:INFO:_display_container: 2
2025-04-12 21:28:44,217:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-12 21:28:44,217:INFO:create_model() successfully completed......................................
2025-04-12 21:28:44,292:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:44,293:INFO:Creating metrics dataframe
2025-04-12 21:28:44,302:INFO:Initializing Extreme Gradient Boosting
2025-04-12 21:28:44,302:INFO:Total runtime is 0.5481649080912272 minutes
2025-04-12 21:28:44,304:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:44,305:INFO:Initializing create_model()
2025-04-12 21:28:44,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:44,305:INFO:Checking exceptions
2025-04-12 21:28:44,305:INFO:Importing libraries
2025-04-12 21:28:44,305:INFO:Copying training dataset
2025-04-12 21:28:44,307:INFO:Defining folds
2025-04-12 21:28:44,307:INFO:Declaring metric variables
2025-04-12 21:28:44,310:INFO:Importing untrained model
2025-04-12 21:28:44,312:INFO:Extreme Gradient Boosting Imported successfully
2025-04-12 21:28:44,320:INFO:Starting cross validation
2025-04-12 21:28:44,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:47,880:INFO:Calculating mean and std
2025-04-12 21:28:47,880:INFO:Creating metrics dataframe
2025-04-12 21:28:48,052:INFO:Uploading results into container
2025-04-12 21:28:48,052:INFO:Uploading model into container now
2025-04-12 21:28:48,052:INFO:_master_model_container: 13
2025-04-12 21:28:48,052:INFO:_display_container: 2
2025-04-12 21:28:48,054:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-12 21:28:48,054:INFO:create_model() successfully completed......................................
2025-04-12 21:28:48,130:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:48,130:INFO:Creating metrics dataframe
2025-04-12 21:28:48,137:INFO:Initializing Light Gradient Boosting Machine
2025-04-12 21:28:48,137:INFO:Total runtime is 0.6120823661486308 minutes
2025-04-12 21:28:48,142:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:48,142:INFO:Initializing create_model()
2025-04-12 21:28:48,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:48,142:INFO:Checking exceptions
2025-04-12 21:28:48,142:INFO:Importing libraries
2025-04-12 21:28:48,144:INFO:Copying training dataset
2025-04-12 21:28:48,145:INFO:Defining folds
2025-04-12 21:28:48,146:INFO:Declaring metric variables
2025-04-12 21:28:48,148:INFO:Importing untrained model
2025-04-12 21:28:48,152:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 21:28:48,160:INFO:Starting cross validation
2025-04-12 21:28:48,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:50,587:INFO:Calculating mean and std
2025-04-12 21:28:50,587:INFO:Creating metrics dataframe
2025-04-12 21:28:50,772:INFO:Uploading results into container
2025-04-12 21:28:50,772:INFO:Uploading model into container now
2025-04-12 21:28:50,772:INFO:_master_model_container: 14
2025-04-12 21:28:50,776:INFO:_display_container: 2
2025-04-12 21:28:50,776:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 21:28:50,776:INFO:create_model() successfully completed......................................
2025-04-12 21:28:50,851:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:50,851:INFO:Creating metrics dataframe
2025-04-12 21:28:50,862:INFO:Initializing Dummy Classifier
2025-04-12 21:28:50,862:INFO:Total runtime is 0.6574973940849304 minutes
2025-04-12 21:28:50,864:INFO:SubProcess create_model() called ==================================
2025-04-12 21:28:50,864:INFO:Initializing create_model()
2025-04-12 21:28:50,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A46FD30>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:50,865:INFO:Checking exceptions
2025-04-12 21:28:50,865:INFO:Importing libraries
2025-04-12 21:28:50,865:INFO:Copying training dataset
2025-04-12 21:28:50,868:INFO:Defining folds
2025-04-12 21:28:50,868:INFO:Declaring metric variables
2025-04-12 21:28:50,870:INFO:Importing untrained model
2025-04-12 21:28:50,874:INFO:Dummy Classifier Imported successfully
2025-04-12 21:28:50,887:INFO:Starting cross validation
2025-04-12 21:28:50,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 21:28:52,541:INFO:Calculating mean and std
2025-04-12 21:28:52,541:INFO:Creating metrics dataframe
2025-04-12 21:28:52,728:INFO:Uploading results into container
2025-04-12 21:28:52,728:INFO:Uploading model into container now
2025-04-12 21:28:52,728:INFO:_master_model_container: 15
2025-04-12 21:28:52,728:INFO:_display_container: 2
2025-04-12 21:28:52,728:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-12 21:28:52,728:INFO:create_model() successfully completed......................................
2025-04-12 21:28:52,804:INFO:SubProcess create_model() end ==================================
2025-04-12 21:28:52,804:INFO:Creating metrics dataframe
2025-04-12 21:28:52,821:INFO:Initializing create_model()
2025-04-12 21:28:52,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-12 21:28:52,822:INFO:Checking exceptions
2025-04-12 21:28:52,823:INFO:Importing libraries
2025-04-12 21:28:52,823:INFO:Copying training dataset
2025-04-12 21:28:52,827:INFO:Defining folds
2025-04-12 21:28:52,827:INFO:Declaring metric variables
2025-04-12 21:28:52,828:INFO:Importing untrained model
2025-04-12 21:28:52,828:INFO:Declaring custom model
2025-04-12 21:28:52,828:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 21:28:52,829:INFO:Cross validation set to False
2025-04-12 21:28:52,829:INFO:Fitting Model
2025-04-12 21:28:52,859:INFO:[LightGBM] [Info] Number of positive: 357, number of negative: 222
2025-04-12 21:28:52,859:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.
2025-04-12 21:28:52,859:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-12 21:28:52,861:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-12 21:28:52,861:INFO:[LightGBM] [Info] Total Bins 944
2025-04-12 21:28:52,861:INFO:[LightGBM] [Info] Number of data points in the train set: 579, number of used features: 30
2025-04-12 21:28:52,861:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616580 -> initscore=0.475058
2025-04-12 21:28:52,861:INFO:[LightGBM] [Info] Start training from score 0.475058
2025-04-12 21:28:52,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:52,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 21:28:53,116:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 21:28:53,116:INFO:create_model() successfully completed......................................
2025-04-12 21:28:53,233:INFO:_master_model_container: 15
2025-04-12 21:28:53,233:INFO:_display_container: 2
2025-04-12 21:28:53,235:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 21:28:53,235:INFO:compare_models() successfully completed......................................
2025-04-12 21:28:53,235:INFO:Initializing evaluate_model()
2025-04-12 21:28:53,235:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-12 21:28:53,244:INFO:Initializing plot_model()
2025-04-12 21:28:53,244:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 21:28:53,244:INFO:Checking exceptions
2025-04-12 21:28:53,246:INFO:Preloading libraries
2025-04-12 21:28:53,284:INFO:Copying training dataset
2025-04-12 21:28:53,284:INFO:Plot type: pipeline
2025-04-12 21:28:53,458:INFO:Visual Rendered Successfully
2025-04-12 21:28:53,540:INFO:plot_model() successfully completed......................................
2025-04-12 22:09:14,788:INFO:Initializing compare_models()
2025-04-12 22:09:14,788:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-12 22:09:14,788:INFO:Checking exceptions
2025-04-12 22:09:14,789:INFO:Preparing display monitor
2025-04-12 22:09:14,808:INFO:Initializing Logistic Regression
2025-04-12 22:09:14,808:INFO:Total runtime is 0.0 minutes
2025-04-12 22:09:14,811:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:14,811:INFO:Initializing create_model()
2025-04-12 22:09:14,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:14,812:INFO:Checking exceptions
2025-04-12 22:09:14,812:INFO:Importing libraries
2025-04-12 22:09:14,812:INFO:Copying training dataset
2025-04-12 22:09:14,817:INFO:Defining folds
2025-04-12 22:09:14,817:INFO:Declaring metric variables
2025-04-12 22:09:14,820:INFO:Importing untrained model
2025-04-12 22:09:14,824:INFO:Logistic Regression Imported successfully
2025-04-12 22:09:14,830:INFO:Starting cross validation
2025-04-12 22:09:14,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:25,259:INFO:Calculating mean and std
2025-04-12 22:09:25,261:INFO:Creating metrics dataframe
2025-04-12 22:09:25,449:INFO:Uploading results into container
2025-04-12 22:09:25,449:INFO:Uploading model into container now
2025-04-12 22:09:25,449:INFO:_master_model_container: 16
2025-04-12 22:09:25,451:INFO:_display_container: 3
2025-04-12 22:09:25,451:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-12 22:09:25,451:INFO:create_model() successfully completed......................................
2025-04-12 22:09:25,535:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:25,535:INFO:Creating metrics dataframe
2025-04-12 22:09:25,543:INFO:Initializing K Neighbors Classifier
2025-04-12 22:09:25,543:INFO:Total runtime is 0.17890793482462566 minutes
2025-04-12 22:09:25,545:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:25,545:INFO:Initializing create_model()
2025-04-12 22:09:25,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:25,545:INFO:Checking exceptions
2025-04-12 22:09:25,545:INFO:Importing libraries
2025-04-12 22:09:25,545:INFO:Copying training dataset
2025-04-12 22:09:25,549:INFO:Defining folds
2025-04-12 22:09:25,549:INFO:Declaring metric variables
2025-04-12 22:09:25,553:INFO:Importing untrained model
2025-04-12 22:09:25,556:INFO:K Neighbors Classifier Imported successfully
2025-04-12 22:09:25,562:INFO:Starting cross validation
2025-04-12 22:09:25,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:28,097:INFO:Calculating mean and std
2025-04-12 22:09:28,099:INFO:Creating metrics dataframe
2025-04-12 22:09:28,278:INFO:Uploading results into container
2025-04-12 22:09:28,278:INFO:Uploading model into container now
2025-04-12 22:09:28,280:INFO:_master_model_container: 17
2025-04-12 22:09:28,280:INFO:_display_container: 3
2025-04-12 22:09:28,280:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-12 22:09:28,280:INFO:create_model() successfully completed......................................
2025-04-12 22:09:28,358:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:28,360:INFO:Creating metrics dataframe
2025-04-12 22:09:28,366:INFO:Initializing Naive Bayes
2025-04-12 22:09:28,366:INFO:Total runtime is 0.22595427831013998 minutes
2025-04-12 22:09:28,370:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:28,370:INFO:Initializing create_model()
2025-04-12 22:09:28,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:28,370:INFO:Checking exceptions
2025-04-12 22:09:28,370:INFO:Importing libraries
2025-04-12 22:09:28,370:INFO:Copying training dataset
2025-04-12 22:09:28,374:INFO:Defining folds
2025-04-12 22:09:28,374:INFO:Declaring metric variables
2025-04-12 22:09:28,377:INFO:Importing untrained model
2025-04-12 22:09:28,381:INFO:Naive Bayes Imported successfully
2025-04-12 22:09:28,391:INFO:Starting cross validation
2025-04-12 22:09:28,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:30,121:INFO:Calculating mean and std
2025-04-12 22:09:30,121:INFO:Creating metrics dataframe
2025-04-12 22:09:30,294:INFO:Uploading results into container
2025-04-12 22:09:30,304:INFO:Uploading model into container now
2025-04-12 22:09:30,304:INFO:_master_model_container: 18
2025-04-12 22:09:30,304:INFO:_display_container: 3
2025-04-12 22:09:30,304:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-12 22:09:30,304:INFO:create_model() successfully completed......................................
2025-04-12 22:09:30,379:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:30,384:INFO:Creating metrics dataframe
2025-04-12 22:09:30,390:INFO:Initializing Decision Tree Classifier
2025-04-12 22:09:30,390:INFO:Total runtime is 0.2596856753031413 minutes
2025-04-12 22:09:30,392:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:30,392:INFO:Initializing create_model()
2025-04-12 22:09:30,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:30,393:INFO:Checking exceptions
2025-04-12 22:09:30,393:INFO:Importing libraries
2025-04-12 22:09:30,393:INFO:Copying training dataset
2025-04-12 22:09:30,397:INFO:Defining folds
2025-04-12 22:09:30,397:INFO:Declaring metric variables
2025-04-12 22:09:30,400:INFO:Importing untrained model
2025-04-12 22:09:30,405:INFO:Decision Tree Classifier Imported successfully
2025-04-12 22:09:30,414:INFO:Starting cross validation
2025-04-12 22:09:30,416:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:32,131:INFO:Calculating mean and std
2025-04-12 22:09:32,131:INFO:Creating metrics dataframe
2025-04-12 22:09:32,314:INFO:Uploading results into container
2025-04-12 22:09:32,314:INFO:Uploading model into container now
2025-04-12 22:09:32,315:INFO:_master_model_container: 19
2025-04-12 22:09:32,315:INFO:_display_container: 3
2025-04-12 22:09:32,315:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-12 22:09:32,315:INFO:create_model() successfully completed......................................
2025-04-12 22:09:32,394:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:32,394:INFO:Creating metrics dataframe
2025-04-12 22:09:32,404:INFO:Initializing SVM - Linear Kernel
2025-04-12 22:09:32,404:INFO:Total runtime is 0.29326133330663046 minutes
2025-04-12 22:09:32,408:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:32,408:INFO:Initializing create_model()
2025-04-12 22:09:32,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:32,408:INFO:Checking exceptions
2025-04-12 22:09:32,408:INFO:Importing libraries
2025-04-12 22:09:32,408:INFO:Copying training dataset
2025-04-12 22:09:32,411:INFO:Defining folds
2025-04-12 22:09:32,411:INFO:Declaring metric variables
2025-04-12 22:09:32,415:INFO:Importing untrained model
2025-04-12 22:09:32,431:INFO:SVM - Linear Kernel Imported successfully
2025-04-12 22:09:32,467:INFO:Starting cross validation
2025-04-12 22:09:32,468:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:32,547:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,564:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,570:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,570:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,578:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,578:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,578:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,587:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,589:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:32,598:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-12 22:09:34,123:INFO:Calculating mean and std
2025-04-12 22:09:34,123:INFO:Creating metrics dataframe
2025-04-12 22:09:34,307:INFO:Uploading results into container
2025-04-12 22:09:34,307:INFO:Uploading model into container now
2025-04-12 22:09:34,309:INFO:_master_model_container: 20
2025-04-12 22:09:34,309:INFO:_display_container: 3
2025-04-12 22:09:34,309:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-12 22:09:34,309:INFO:create_model() successfully completed......................................
2025-04-12 22:09:34,385:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:34,385:INFO:Creating metrics dataframe
2025-04-12 22:09:34,396:INFO:Initializing Ridge Classifier
2025-04-12 22:09:34,396:INFO:Total runtime is 0.32645567258199054 minutes
2025-04-12 22:09:34,399:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:34,399:INFO:Initializing create_model()
2025-04-12 22:09:34,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:34,399:INFO:Checking exceptions
2025-04-12 22:09:34,399:INFO:Importing libraries
2025-04-12 22:09:34,399:INFO:Copying training dataset
2025-04-12 22:09:34,400:INFO:Defining folds
2025-04-12 22:09:34,400:INFO:Declaring metric variables
2025-04-12 22:09:34,407:INFO:Importing untrained model
2025-04-12 22:09:34,411:INFO:Ridge Classifier Imported successfully
2025-04-12 22:09:34,422:INFO:Starting cross validation
2025-04-12 22:09:34,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:34,508:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,508:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,512:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,514:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,521:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,538:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,547:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,547:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,556:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:34,564:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-12 22:09:36,121:INFO:Calculating mean and std
2025-04-12 22:09:36,122:INFO:Creating metrics dataframe
2025-04-12 22:09:36,298:INFO:Uploading results into container
2025-04-12 22:09:36,298:INFO:Uploading model into container now
2025-04-12 22:09:36,299:INFO:_master_model_container: 21
2025-04-12 22:09:36,299:INFO:_display_container: 3
2025-04-12 22:09:36,299:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-12 22:09:36,299:INFO:create_model() successfully completed......................................
2025-04-12 22:09:36,379:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:36,379:INFO:Creating metrics dataframe
2025-04-12 22:09:36,387:INFO:Initializing Random Forest Classifier
2025-04-12 22:09:36,387:INFO:Total runtime is 0.35963501532872516 minutes
2025-04-12 22:09:36,389:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:36,389:INFO:Initializing create_model()
2025-04-12 22:09:36,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:36,389:INFO:Checking exceptions
2025-04-12 22:09:36,389:INFO:Importing libraries
2025-04-12 22:09:36,389:INFO:Copying training dataset
2025-04-12 22:09:36,394:INFO:Defining folds
2025-04-12 22:09:36,394:INFO:Declaring metric variables
2025-04-12 22:09:36,396:INFO:Importing untrained model
2025-04-12 22:09:36,400:INFO:Random Forest Classifier Imported successfully
2025-04-12 22:09:36,410:INFO:Starting cross validation
2025-04-12 22:09:36,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:38,301:INFO:Calculating mean and std
2025-04-12 22:09:38,301:INFO:Creating metrics dataframe
2025-04-12 22:09:38,479:INFO:Uploading results into container
2025-04-12 22:09:38,479:INFO:Uploading model into container now
2025-04-12 22:09:38,479:INFO:_master_model_container: 22
2025-04-12 22:09:38,479:INFO:_display_container: 3
2025-04-12 22:09:38,479:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-12 22:09:38,479:INFO:create_model() successfully completed......................................
2025-04-12 22:09:38,564:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:38,564:INFO:Creating metrics dataframe
2025-04-12 22:09:38,572:INFO:Initializing Quadratic Discriminant Analysis
2025-04-12 22:09:38,572:INFO:Total runtime is 0.39605362415313716 minutes
2025-04-12 22:09:38,573:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:38,573:INFO:Initializing create_model()
2025-04-12 22:09:38,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:38,573:INFO:Checking exceptions
2025-04-12 22:09:38,573:INFO:Importing libraries
2025-04-12 22:09:38,575:INFO:Copying training dataset
2025-04-12 22:09:38,579:INFO:Defining folds
2025-04-12 22:09:38,579:INFO:Declaring metric variables
2025-04-12 22:09:38,580:INFO:Importing untrained model
2025-04-12 22:09:38,589:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-12 22:09:38,596:INFO:Starting cross validation
2025-04-12 22:09:38,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:38,653:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,659:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,663:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,666:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,670:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,681:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,686:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,686:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,696:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:38,703:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-12 22:09:40,309:INFO:Calculating mean and std
2025-04-12 22:09:40,309:INFO:Creating metrics dataframe
2025-04-12 22:09:40,486:INFO:Uploading results into container
2025-04-12 22:09:40,487:INFO:Uploading model into container now
2025-04-12 22:09:40,487:INFO:_master_model_container: 23
2025-04-12 22:09:40,487:INFO:_display_container: 3
2025-04-12 22:09:40,487:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-12 22:09:40,487:INFO:create_model() successfully completed......................................
2025-04-12 22:09:40,573:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:40,573:INFO:Creating metrics dataframe
2025-04-12 22:09:40,581:INFO:Initializing Ada Boost Classifier
2025-04-12 22:09:40,581:INFO:Total runtime is 0.42953961292902626 minutes
2025-04-12 22:09:40,584:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:40,584:INFO:Initializing create_model()
2025-04-12 22:09:40,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:40,585:INFO:Checking exceptions
2025-04-12 22:09:40,585:INFO:Importing libraries
2025-04-12 22:09:40,585:INFO:Copying training dataset
2025-04-12 22:09:40,588:INFO:Defining folds
2025-04-12 22:09:40,588:INFO:Declaring metric variables
2025-04-12 22:09:40,594:INFO:Importing untrained model
2025-04-12 22:09:40,599:INFO:Ada Boost Classifier Imported successfully
2025-04-12 22:09:40,608:INFO:Starting cross validation
2025-04-12 22:09:40,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:42,392:INFO:Calculating mean and std
2025-04-12 22:09:42,393:INFO:Creating metrics dataframe
2025-04-12 22:09:42,579:INFO:Uploading results into container
2025-04-12 22:09:42,582:INFO:Uploading model into container now
2025-04-12 22:09:42,582:INFO:_master_model_container: 24
2025-04-12 22:09:42,582:INFO:_display_container: 3
2025-04-12 22:09:42,582:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-12 22:09:42,582:INFO:create_model() successfully completed......................................
2025-04-12 22:09:42,665:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:42,665:INFO:Creating metrics dataframe
2025-04-12 22:09:42,673:INFO:Initializing Gradient Boosting Classifier
2025-04-12 22:09:42,673:INFO:Total runtime is 0.4644165476163228 minutes
2025-04-12 22:09:42,676:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:42,676:INFO:Initializing create_model()
2025-04-12 22:09:42,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:42,676:INFO:Checking exceptions
2025-04-12 22:09:42,676:INFO:Importing libraries
2025-04-12 22:09:42,676:INFO:Copying training dataset
2025-04-12 22:09:42,680:INFO:Defining folds
2025-04-12 22:09:42,680:INFO:Declaring metric variables
2025-04-12 22:09:42,683:INFO:Importing untrained model
2025-04-12 22:09:42,687:INFO:Gradient Boosting Classifier Imported successfully
2025-04-12 22:09:42,693:INFO:Starting cross validation
2025-04-12 22:09:42,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:44,527:INFO:Calculating mean and std
2025-04-12 22:09:44,527:INFO:Creating metrics dataframe
2025-04-12 22:09:44,708:INFO:Uploading results into container
2025-04-12 22:09:44,710:INFO:Uploading model into container now
2025-04-12 22:09:44,710:INFO:_master_model_container: 25
2025-04-12 22:09:44,710:INFO:_display_container: 3
2025-04-12 22:09:44,710:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-12 22:09:44,710:INFO:create_model() successfully completed......................................
2025-04-12 22:09:44,785:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:44,785:INFO:Creating metrics dataframe
2025-04-12 22:09:44,796:INFO:Initializing Linear Discriminant Analysis
2025-04-12 22:09:44,796:INFO:Total runtime is 0.4997878034909566 minutes
2025-04-12 22:09:44,800:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:44,800:INFO:Initializing create_model()
2025-04-12 22:09:44,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:44,800:INFO:Checking exceptions
2025-04-12 22:09:44,800:INFO:Importing libraries
2025-04-12 22:09:44,800:INFO:Copying training dataset
2025-04-12 22:09:44,803:INFO:Defining folds
2025-04-12 22:09:44,803:INFO:Declaring metric variables
2025-04-12 22:09:44,806:INFO:Importing untrained model
2025-04-12 22:09:44,810:INFO:Linear Discriminant Analysis Imported successfully
2025-04-12 22:09:44,819:INFO:Starting cross validation
2025-04-12 22:09:44,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:46,533:INFO:Calculating mean and std
2025-04-12 22:09:46,535:INFO:Creating metrics dataframe
2025-04-12 22:09:46,714:INFO:Uploading results into container
2025-04-12 22:09:46,714:INFO:Uploading model into container now
2025-04-12 22:09:46,714:INFO:_master_model_container: 26
2025-04-12 22:09:46,714:INFO:_display_container: 3
2025-04-12 22:09:46,714:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-12 22:09:46,714:INFO:create_model() successfully completed......................................
2025-04-12 22:09:46,794:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:46,795:INFO:Creating metrics dataframe
2025-04-12 22:09:46,801:INFO:Initializing Extra Trees Classifier
2025-04-12 22:09:46,804:INFO:Total runtime is 0.5332551678021749 minutes
2025-04-12 22:09:46,805:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:46,805:INFO:Initializing create_model()
2025-04-12 22:09:46,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:46,805:INFO:Checking exceptions
2025-04-12 22:09:46,805:INFO:Importing libraries
2025-04-12 22:09:46,805:INFO:Copying training dataset
2025-04-12 22:09:46,811:INFO:Defining folds
2025-04-12 22:09:46,811:INFO:Declaring metric variables
2025-04-12 22:09:46,814:INFO:Importing untrained model
2025-04-12 22:09:46,818:INFO:Extra Trees Classifier Imported successfully
2025-04-12 22:09:46,825:INFO:Starting cross validation
2025-04-12 22:09:46,825:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:48,733:INFO:Calculating mean and std
2025-04-12 22:09:48,734:INFO:Creating metrics dataframe
2025-04-12 22:09:48,915:INFO:Uploading results into container
2025-04-12 22:09:48,917:INFO:Uploading model into container now
2025-04-12 22:09:48,917:INFO:_master_model_container: 27
2025-04-12 22:09:48,917:INFO:_display_container: 3
2025-04-12 22:09:48,917:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-12 22:09:48,917:INFO:create_model() successfully completed......................................
2025-04-12 22:09:48,995:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:48,997:INFO:Creating metrics dataframe
2025-04-12 22:09:49,004:INFO:Initializing Extreme Gradient Boosting
2025-04-12 22:09:49,004:INFO:Total runtime is 0.5699192603429158 minutes
2025-04-12 22:09:49,006:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:49,006:INFO:Initializing create_model()
2025-04-12 22:09:49,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:49,006:INFO:Checking exceptions
2025-04-12 22:09:49,006:INFO:Importing libraries
2025-04-12 22:09:49,009:INFO:Copying training dataset
2025-04-12 22:09:49,010:INFO:Defining folds
2025-04-12 22:09:49,010:INFO:Declaring metric variables
2025-04-12 22:09:49,014:INFO:Importing untrained model
2025-04-12 22:09:49,019:INFO:Extreme Gradient Boosting Imported successfully
2025-04-12 22:09:49,026:INFO:Starting cross validation
2025-04-12 22:09:49,028:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:52,486:INFO:Calculating mean and std
2025-04-12 22:09:52,486:INFO:Creating metrics dataframe
2025-04-12 22:09:52,680:INFO:Uploading results into container
2025-04-12 22:09:52,683:INFO:Uploading model into container now
2025-04-12 22:09:52,683:INFO:_master_model_container: 28
2025-04-12 22:09:52,683:INFO:_display_container: 3
2025-04-12 22:09:52,683:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-12 22:09:52,683:INFO:create_model() successfully completed......................................
2025-04-12 22:09:52,764:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:52,764:INFO:Creating metrics dataframe
2025-04-12 22:09:52,773:INFO:Initializing Light Gradient Boosting Machine
2025-04-12 22:09:52,773:INFO:Total runtime is 0.6327505826950073 minutes
2025-04-12 22:09:52,773:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:52,773:INFO:Initializing create_model()
2025-04-12 22:09:52,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:52,773:INFO:Checking exceptions
2025-04-12 22:09:52,773:INFO:Importing libraries
2025-04-12 22:09:52,773:INFO:Copying training dataset
2025-04-12 22:09:52,779:INFO:Defining folds
2025-04-12 22:09:52,780:INFO:Declaring metric variables
2025-04-12 22:09:52,782:INFO:Importing untrained model
2025-04-12 22:09:52,784:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 22:09:52,791:INFO:Starting cross validation
2025-04-12 22:09:52,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:54,718:INFO:Calculating mean and std
2025-04-12 22:09:54,718:INFO:Creating metrics dataframe
2025-04-12 22:09:54,902:INFO:Uploading results into container
2025-04-12 22:09:54,903:INFO:Uploading model into container now
2025-04-12 22:09:54,903:INFO:_master_model_container: 29
2025-04-12 22:09:54,903:INFO:_display_container: 3
2025-04-12 22:09:54,903:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 22:09:54,903:INFO:create_model() successfully completed......................................
2025-04-12 22:09:54,978:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:54,978:INFO:Creating metrics dataframe
2025-04-12 22:09:54,989:INFO:Initializing Dummy Classifier
2025-04-12 22:09:54,989:INFO:Total runtime is 0.6696792682011922 minutes
2025-04-12 22:09:54,993:INFO:SubProcess create_model() called ==================================
2025-04-12 22:09:54,993:INFO:Initializing create_model()
2025-04-12 22:09:54,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022E2A481C60>, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:54,993:INFO:Checking exceptions
2025-04-12 22:09:54,996:INFO:Importing libraries
2025-04-12 22:09:54,996:INFO:Copying training dataset
2025-04-12 22:09:54,999:INFO:Defining folds
2025-04-12 22:09:54,999:INFO:Declaring metric variables
2025-04-12 22:09:55,001:INFO:Importing untrained model
2025-04-12 22:09:55,006:INFO:Dummy Classifier Imported successfully
2025-04-12 22:09:55,013:INFO:Starting cross validation
2025-04-12 22:09:55,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-12 22:09:56,729:INFO:Calculating mean and std
2025-04-12 22:09:56,729:INFO:Creating metrics dataframe
2025-04-12 22:09:56,908:INFO:Uploading results into container
2025-04-12 22:09:56,908:INFO:Uploading model into container now
2025-04-12 22:09:56,908:INFO:_master_model_container: 30
2025-04-12 22:09:56,908:INFO:_display_container: 3
2025-04-12 22:09:56,908:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-12 22:09:56,908:INFO:create_model() successfully completed......................................
2025-04-12 22:09:56,988:INFO:SubProcess create_model() end ==================================
2025-04-12 22:09:56,988:INFO:Creating metrics dataframe
2025-04-12 22:09:57,003:INFO:Initializing create_model()
2025-04-12 22:09:57,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-12 22:09:57,003:INFO:Checking exceptions
2025-04-12 22:09:57,003:INFO:Importing libraries
2025-04-12 22:09:57,003:INFO:Copying training dataset
2025-04-12 22:09:57,008:INFO:Defining folds
2025-04-12 22:09:57,008:INFO:Declaring metric variables
2025-04-12 22:09:57,009:INFO:Importing untrained model
2025-04-12 22:09:57,009:INFO:Declaring custom model
2025-04-12 22:09:57,009:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 22:09:57,010:INFO:Cross validation set to False
2025-04-12 22:09:57,010:INFO:Fitting Model
2025-04-12 22:09:57,036:INFO:[LightGBM] [Info] Number of positive: 357, number of negative: 222
2025-04-12 22:09:57,036:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2025-04-12 22:09:57,036:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:09:57,036:INFO:[LightGBM] [Info] Total Bins 944
2025-04-12 22:09:57,036:INFO:[LightGBM] [Info] Number of data points in the train set: 579, number of used features: 30
2025-04-12 22:09:57,036:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616580 -> initscore=0.475058
2025-04-12 22:09:57,036:INFO:[LightGBM] [Info] Start training from score 0.475058
2025-04-12 22:09:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:09:57,300:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 22:09:57,300:INFO:create_model() successfully completed......................................
2025-04-12 22:09:57,405:INFO:_master_model_container: 30
2025-04-12 22:09:57,405:INFO:_display_container: 3
2025-04-12 22:09:57,405:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 22:09:57,406:INFO:compare_models() successfully completed......................................
2025-04-12 22:36:47,230:INFO:Initializing evaluate_model()
2025-04-12 22:36:47,230:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-12 22:36:47,238:INFO:Initializing plot_model()
2025-04-12 22:36:47,239:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:36:47,239:INFO:Checking exceptions
2025-04-12 22:36:47,241:INFO:Preloading libraries
2025-04-12 22:36:47,250:INFO:Copying training dataset
2025-04-12 22:36:47,250:INFO:Plot type: pipeline
2025-04-12 22:36:47,427:INFO:Visual Rendered Successfully
2025-04-12 22:36:47,508:INFO:plot_model() successfully completed......................................
2025-04-12 22:36:50,485:INFO:Initializing plot_model()
2025-04-12 22:36:50,485:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:36:50,485:INFO:Checking exceptions
2025-04-12 22:36:50,489:INFO:Preloading libraries
2025-04-12 22:36:50,503:INFO:Copying training dataset
2025-04-12 22:36:50,503:INFO:Plot type: parameter
2025-04-12 22:36:50,509:INFO:Visual Rendered Successfully
2025-04-12 22:36:50,606:INFO:plot_model() successfully completed......................................
2025-04-12 22:36:52,151:INFO:Initializing plot_model()
2025-04-12 22:36:52,151:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:36:52,151:INFO:Checking exceptions
2025-04-12 22:36:52,153:INFO:Preloading libraries
2025-04-12 22:36:52,161:INFO:Copying training dataset
2025-04-12 22:36:52,161:INFO:Plot type: auc
2025-04-12 22:36:52,246:INFO:Fitting Model
2025-04-12 22:36:52,247:INFO:Scoring test/hold-out set
2025-04-12 22:36:52,450:INFO:Visual Rendered Successfully
2025-04-12 22:36:52,527:INFO:plot_model() successfully completed......................................
2025-04-12 22:36:53,563:INFO:Initializing plot_model()
2025-04-12 22:36:53,563:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:36:53,563:INFO:Checking exceptions
2025-04-12 22:36:53,566:INFO:Preloading libraries
2025-04-12 22:36:53,578:INFO:Copying training dataset
2025-04-12 22:36:53,578:INFO:Plot type: confusion_matrix
2025-04-12 22:36:53,667:INFO:Fitting Model
2025-04-12 22:36:53,667:INFO:Scoring test/hold-out set
2025-04-12 22:36:53,790:INFO:Visual Rendered Successfully
2025-04-12 22:36:53,869:INFO:plot_model() successfully completed......................................
2025-04-12 22:36:55,950:INFO:Initializing plot_model()
2025-04-12 22:36:55,951:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:36:55,951:INFO:Checking exceptions
2025-04-12 22:36:55,954:INFO:Preloading libraries
2025-04-12 22:36:55,964:INFO:Copying training dataset
2025-04-12 22:36:55,964:INFO:Plot type: threshold
2025-04-12 22:36:56,054:INFO:Fitting Model
2025-04-12 22:36:56,058:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:56,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2025-04-12 22:36:56,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,058:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 22:36:56,058:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,058:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:56,058:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:56,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,094:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 22:36:56,095:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2025-04-12 22:36:56,095:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,095:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,095:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,095:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 22:36:56,095:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 22:36:56,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,129:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:56,129:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 22:36:56,129:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,129:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:56,129:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:56,129:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:56,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,165:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 22:36:56,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-04-12 22:36:56,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,165:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:56,165:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 22:36:56,166:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 22:36:56,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,208:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 22:36:56,208:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 22:36:56,208:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,208:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,208:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 22:36:56,208:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 22:36:56,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,249:INFO:[LightGBM] [Info] Number of positive: 326, number of negative: 195
2025-04-12 22:36:56,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-12 22:36:56,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,250:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,250:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,250:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625720 -> initscore=0.513898
2025-04-12 22:36:56,250:INFO:[LightGBM] [Info] Start training from score 0.513898
2025-04-12 22:36:56,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,287:INFO:[LightGBM] [Info] Number of positive: 326, number of negative: 195
2025-04-12 22:36:56,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2025-04-12 22:36:56,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,288:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 22:36:56,288:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,288:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.625720 -> initscore=0.513898
2025-04-12 22:36:56,288:INFO:[LightGBM] [Info] Start training from score 0.513898
2025-04-12 22:36:56,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,327:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 22:36:56,327:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 22:36:56,328:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,328:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 22:36:56,328:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 22:36:56,328:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 22:36:56,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,367:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:56,367:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 22:36:56,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,367:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:56,367:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:56,368:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:56,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,406:INFO:[LightGBM] [Info] Number of positive: 323, number of negative: 198
2025-04-12 22:36:56,407:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-12 22:36:56,407:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,407:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:56,407:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,407:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.619962 -> initscore=0.489385
2025-04-12 22:36:56,407:INFO:[LightGBM] [Info] Start training from score 0.489385
2025-04-12 22:36:56,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,445:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 22:36:56,446:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.
2025-04-12 22:36:56,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-12 22:36:56,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-12 22:36:56,446:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,446:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,446:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 22:36:56,446:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 22:36:56,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,486:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 22:36:56,486:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2025-04-12 22:36:56,486:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,486:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 22:36:56,487:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,487:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 22:36:56,487:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 22:36:56,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,525:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 22:36:56,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2025-04-12 22:36:56,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,526:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,526:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 22:36:56,526:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 22:36:56,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,563:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:56,564:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 22:36:56,564:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,564:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,564:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:56,564:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,600:INFO:[LightGBM] [Info] Number of positive: 330, number of negative: 191
2025-04-12 22:36:56,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 22:36:56,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,600:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 22:36:56,600:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,600:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.633397 -> initscore=0.546819
2025-04-12 22:36:56,600:INFO:[LightGBM] [Info] Start training from score 0.546819
2025-04-12 22:36:56,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,636:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 22:36:56,636:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 22:36:56,636:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,636:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:56,636:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 22:36:56,637:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 22:36:56,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,670:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 22:36:56,670:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 22:36:56,670:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,670:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:56,670:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 22:36:56,670:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 22:36:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,708:INFO:[LightGBM] [Info] Number of positive: 316, number of negative: 205
2025-04-12 22:36:56,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2025-04-12 22:36:56,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,708:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:56,708:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,708:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.606526 -> initscore=0.432732
2025-04-12 22:36:56,708:INFO:[LightGBM] [Info] Start training from score 0.432732
2025-04-12 22:36:56,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,743:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 22:36:56,744:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.
2025-04-12 22:36:56,744:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,744:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,744:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,744:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 22:36:56,744:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 22:36:56,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,779:INFO:[LightGBM] [Info] Number of positive: 328, number of negative: 193
2025-04-12 22:36:56,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2025-04-12 22:36:56,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,780:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 22:36:56,780:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,780:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.629559 -> initscore=0.530323
2025-04-12 22:36:56,780:INFO:[LightGBM] [Info] Start training from score 0.530323
2025-04-12 22:36:56,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,816:INFO:[LightGBM] [Info] Number of positive: 317, number of negative: 204
2025-04-12 22:36:56,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-12 22:36:56,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,817:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,817:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,817:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.608445 -> initscore=0.440782
2025-04-12 22:36:56,817:INFO:[LightGBM] [Info] Start training from score 0.440782
2025-04-12 22:36:56,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,851:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 22:36:56,852:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.
2025-04-12 22:36:56,852:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-12 22:36:56,852:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-12 22:36:56,852:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 22:36:56,852:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 22:36:56,852:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 22:36:56,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,889:INFO:[LightGBM] [Info] Number of positive: 316, number of negative: 205
2025-04-12 22:36:56,890:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-12 22:36:56,890:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,890:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 22:36:56,890:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,890:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.606526 -> initscore=0.432732
2025-04-12 22:36:56,890:INFO:[LightGBM] [Info] Start training from score 0.432732
2025-04-12 22:36:56,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,925:INFO:[LightGBM] [Info] Number of positive: 315, number of negative: 206
2025-04-12 22:36:56,926:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.
2025-04-12 22:36:56,926:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,926:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:56,926:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.604607 -> initscore=0.424696
2025-04-12 22:36:56,926:INFO:[LightGBM] [Info] Start training from score 0.424696
2025-04-12 22:36:56,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,963:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 22:36:56,963:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 22:36:56,963:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:56,963:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 22:36:56,963:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:56,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 22:36:56,964:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 22:36:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,000:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:57,000:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 22:36:57,000:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,000:INFO:[LightGBM] [Info] Total Bins 886
2025-04-12 22:36:57,000:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,000:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:57,000:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:57,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,036:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:57,036:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 22:36:57,036:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,036:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 22:36:57,036:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,036:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:57,037:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,071:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:57,071:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 22:36:57,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,071:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 22:36:57,071:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:57,071:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,107:INFO:[LightGBM] [Info] Number of positive: 318, number of negative: 203
2025-04-12 22:36:57,107:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 22:36:57,107:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,107:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:57,107:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,108:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.610365 -> initscore=0.448845
2025-04-12 22:36:57,108:INFO:[LightGBM] [Info] Start training from score 0.448845
2025-04-12 22:36:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,143:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 22:36:57,143:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-04-12 22:36:57,143:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,144:INFO:[LightGBM] [Info] Total Bins 879
2025-04-12 22:36:57,144:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,144:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 22:36:57,144:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 22:36:57,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,180:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 22:36:57,180:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-12 22:36:57,180:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,180:INFO:[LightGBM] [Info] Total Bins 887
2025-04-12 22:36:57,180:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,181:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 22:36:57,181:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 22:36:57,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,220:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:57,220:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 22:36:57,220:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,221:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 22:36:57,221:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:57,221:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:57,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,263:INFO:[LightGBM] [Info] Number of positive: 323, number of negative: 198
2025-04-12 22:36:57,264:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 22:36:57,264:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,264:INFO:[LightGBM] [Info] Total Bins 878
2025-04-12 22:36:57,264:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,264:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.619962 -> initscore=0.489385
2025-04-12 22:36:57,264:INFO:[LightGBM] [Info] Start training from score 0.489385
2025-04-12 22:36:57,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,303:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 22:36:57,303:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2025-04-12 22:36:57,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,303:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:57,303:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 22:36:57,304:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 22:36:57,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,342:INFO:[LightGBM] [Info] Number of positive: 327, number of negative: 194
2025-04-12 22:36:57,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 22:36:57,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,343:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 22:36:57,343:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,343:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.627639 -> initscore=0.522102
2025-04-12 22:36:57,343:INFO:[LightGBM] [Info] Start training from score 0.522102
2025-04-12 22:36:57,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,381:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 22:36:57,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 22:36:57,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,381:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:57,381:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,382:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 22:36:57,382:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 22:36:57,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,416:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 22:36:57,416:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 22:36:57,416:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,416:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:57,417:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 22:36:57,417:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 22:36:57,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,453:INFO:[LightGBM] [Info] Number of positive: 319, number of negative: 202
2025-04-12 22:36:57,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2025-04-12 22:36:57,453:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,453:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:57,454:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.612284 -> initscore=0.456923
2025-04-12 22:36:57,454:INFO:[LightGBM] [Info] Start training from score 0.456923
2025-04-12 22:36:57,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,489:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:57,489:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2025-04-12 22:36:57,489:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,489:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:57,489:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,490:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:57,490:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:57,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,527:INFO:[LightGBM] [Info] Number of positive: 320, number of negative: 201
2025-04-12 22:36:57,527:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2025-04-12 22:36:57,527:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,528:INFO:[LightGBM] [Info] Total Bins 884
2025-04-12 22:36:57,528:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.614203 -> initscore=0.465016
2025-04-12 22:36:57,528:INFO:[LightGBM] [Info] Start training from score 0.465016
2025-04-12 22:36:57,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,563:INFO:[LightGBM] [Info] Number of positive: 317, number of negative: 204
2025-04-12 22:36:57,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 22:36:57,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,563:INFO:[LightGBM] [Info] Total Bins 885
2025-04-12 22:36:57,563:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.608445 -> initscore=0.440782
2025-04-12 22:36:57,564:INFO:[LightGBM] [Info] Start training from score 0.440782
2025-04-12 22:36:57,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,598:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 22:36:57,598:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2025-04-12 22:36:57,598:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,598:INFO:[LightGBM] [Info] Total Bins 882
2025-04-12 22:36:57,598:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 22:36:57,599:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 22:36:57,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,659:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 22:36:57,659:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-04-12 22:36:57,659:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,659:INFO:[LightGBM] [Info] Total Bins 883
2025-04-12 22:36:57,659:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,660:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 22:36:57,660:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 22:36:57,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,695:INFO:[LightGBM] [Info] Number of positive: 325, number of negative: 196
2025-04-12 22:36:57,695:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
2025-04-12 22:36:57,695:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,695:INFO:[LightGBM] [Info] Total Bins 881
2025-04-12 22:36:57,695:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.623800 -> initscore=0.505711
2025-04-12 22:36:57,696:INFO:[LightGBM] [Info] Start training from score 0.505711
2025-04-12 22:36:57,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,731:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 22:36:57,731:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2025-04-12 22:36:57,731:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,731:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 22:36:57,731:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,732:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 22:36:57,732:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 22:36:57,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,772:INFO:[LightGBM] [Info] Number of positive: 324, number of negative: 197
2025-04-12 22:36:57,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2025-04-12 22:36:57,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,773:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 22:36:57,773:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,773:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.621881 -> initscore=0.497540
2025-04-12 22:36:57,773:INFO:[LightGBM] [Info] Start training from score 0.497540
2025-04-12 22:36:57,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,808:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 22:36:57,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2025-04-12 22:36:57,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,808:INFO:[LightGBM] [Info] Total Bins 886
2025-04-12 22:36:57,808:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 22:36:57,808:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 22:36:57,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,843:INFO:[LightGBM] [Info] Number of positive: 322, number of negative: 199
2025-04-12 22:36:57,843:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2025-04-12 22:36:57,843:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,843:INFO:[LightGBM] [Info] Total Bins 887
2025-04-12 22:36:57,843:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,844:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.618042 -> initscore=0.481247
2025-04-12 22:36:57,844:INFO:[LightGBM] [Info] Start training from score 0.481247
2025-04-12 22:36:57,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,880:INFO:[LightGBM] [Info] Number of positive: 321, number of negative: 200
2025-04-12 22:36:57,880:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2025-04-12 22:36:57,880:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,880:INFO:[LightGBM] [Info] Total Bins 880
2025-04-12 22:36:57,880:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616123 -> initscore=0.473124
2025-04-12 22:36:57,881:INFO:[LightGBM] [Info] Start training from score 0.473124
2025-04-12 22:36:57,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,917:INFO:[LightGBM] [Info] Number of positive: 329, number of negative: 192
2025-04-12 22:36:57,917:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2025-04-12 22:36:57,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-04-12 22:36:57,918:INFO:[LightGBM] [Info] Total Bins 878
2025-04-12 22:36:57,918:INFO:[LightGBM] [Info] Number of data points in the train set: 521, number of used features: 30
2025-04-12 22:36:57,918:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.631478 -> initscore=0.538562
2025-04-12 22:36:57,918:INFO:[LightGBM] [Info] Start training from score 0.538562
2025-04-12 22:36:57,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:36:57,993:INFO:Scoring test/hold-out set
2025-04-12 22:36:58,284:INFO:Visual Rendered Successfully
2025-04-12 22:36:58,375:INFO:plot_model() successfully completed......................................
2025-04-12 22:36:58,494:INFO:Initializing plot_model()
2025-04-12 22:36:58,494:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:36:58,494:INFO:Checking exceptions
2025-04-12 22:36:58,497:INFO:Preloading libraries
2025-04-12 22:36:58,501:INFO:Copying training dataset
2025-04-12 22:36:58,501:INFO:Plot type: pr
2025-04-12 22:36:58,578:INFO:Fitting Model
2025-04-12 22:36:58,578:INFO:Scoring test/hold-out set
2025-04-12 22:36:58,765:INFO:Visual Rendered Successfully
2025-04-12 22:36:58,844:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:00,994:INFO:Initializing plot_model()
2025-04-12 22:37:00,994:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:00,994:INFO:Checking exceptions
2025-04-12 22:37:00,996:INFO:Preloading libraries
2025-04-12 22:37:01,005:INFO:Copying training dataset
2025-04-12 22:37:01,006:INFO:Plot type: error
2025-04-12 22:37:01,093:INFO:Fitting Model
2025-04-12 22:37:01,093:INFO:Scoring test/hold-out set
2025-04-12 22:37:01,291:INFO:Visual Rendered Successfully
2025-04-12 22:37:01,378:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:05,066:INFO:Initializing plot_model()
2025-04-12 22:37:05,066:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:05,066:INFO:Checking exceptions
2025-04-12 22:37:05,069:INFO:Preloading libraries
2025-04-12 22:37:05,079:INFO:Copying training dataset
2025-04-12 22:37:05,079:INFO:Plot type: class_report
2025-04-12 22:37:05,163:INFO:Fitting Model
2025-04-12 22:37:05,163:INFO:Scoring test/hold-out set
2025-04-12 22:37:05,361:INFO:Visual Rendered Successfully
2025-04-12 22:37:05,447:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:07,600:INFO:Initializing plot_model()
2025-04-12 22:37:07,600:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:07,600:INFO:Checking exceptions
2025-04-12 22:37:07,601:INFO:Preloading libraries
2025-04-12 22:37:07,611:INFO:Copying training dataset
2025-04-12 22:37:07,611:INFO:Plot type: feature
2025-04-12 22:37:07,613:WARNING:No coef_ found. Trying feature_importances_
2025-04-12 22:37:07,795:INFO:Visual Rendered Successfully
2025-04-12 22:37:07,880:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:08,706:INFO:Initializing plot_model()
2025-04-12 22:37:08,706:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:08,706:INFO:Checking exceptions
2025-04-12 22:37:08,709:INFO:Preloading libraries
2025-04-12 22:37:08,720:INFO:Copying training dataset
2025-04-12 22:37:08,720:INFO:Plot type: feature_all
2025-04-12 22:37:08,745:WARNING:No coef_ found. Trying feature_importances_
2025-04-12 22:37:09,022:INFO:Visual Rendered Successfully
2025-04-12 22:37:09,111:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:09,554:INFO:Initializing plot_model()
2025-04-12 22:37:09,556:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:09,556:INFO:Checking exceptions
2025-04-12 22:37:09,558:INFO:Preloading libraries
2025-04-12 22:37:09,564:INFO:Copying training dataset
2025-04-12 22:37:09,564:INFO:Plot type: boundary
2025-04-12 22:37:09,616:INFO:Fitting StandardScaler()
2025-04-12 22:37:09,620:INFO:Fitting PCA()
2025-04-12 22:37:09,660:INFO:Fitting Model
2025-04-12 22:37:17,297:INFO:Initializing plot_model()
2025-04-12 22:37:17,297:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:17,297:INFO:Checking exceptions
2025-04-12 22:37:17,299:INFO:Preloading libraries
2025-04-12 22:37:17,305:INFO:Copying training dataset
2025-04-12 22:37:17,306:INFO:Plot type: lift
2025-04-12 22:37:17,306:INFO:Generating predictions / predict_proba on X_test
2025-04-12 22:37:17,542:INFO:Visual Rendered Successfully
2025-04-12 22:37:17,661:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:18,705:INFO:Initializing plot_model()
2025-04-12 22:37:18,705:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:18,705:INFO:Checking exceptions
2025-04-12 22:37:18,708:INFO:Preloading libraries
2025-04-12 22:37:18,714:INFO:Copying training dataset
2025-04-12 22:37:18,715:INFO:Plot type: gain
2025-04-12 22:37:18,715:INFO:Generating predictions / predict_proba on X_test
2025-04-12 22:37:18,939:INFO:Visual Rendered Successfully
2025-04-12 22:37:19,034:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:19,848:INFO:Initializing plot_model()
2025-04-12 22:37:19,848:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:19,848:INFO:Checking exceptions
2025-04-12 22:37:21,590:INFO:Initializing plot_model()
2025-04-12 22:37:21,590:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:21,590:INFO:Checking exceptions
2025-04-12 22:37:21,592:INFO:Preloading libraries
2025-04-12 22:37:21,597:INFO:Copying training dataset
2025-04-12 22:37:21,597:INFO:Plot type: gain
2025-04-12 22:37:21,597:INFO:Generating predictions / predict_proba on X_test
2025-04-12 22:37:21,821:INFO:Visual Rendered Successfully
2025-04-12 22:37:21,914:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:23,666:INFO:Initializing plot_model()
2025-04-12 22:37:23,666:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:23,666:INFO:Checking exceptions
2025-04-12 22:37:23,669:INFO:Preloading libraries
2025-04-12 22:37:23,678:INFO:Copying training dataset
2025-04-12 22:37:23,678:INFO:Plot type: ks
2025-04-12 22:37:23,678:INFO:Generating predictions / predict_proba on X_test
2025-04-12 22:37:23,909:INFO:Visual Rendered Successfully
2025-04-12 22:37:24,008:INFO:plot_model() successfully completed......................................
2025-04-12 22:37:25,111:INFO:Initializing plot_model()
2025-04-12 22:37:25,111:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, system=True)
2025-04-12 22:37:25,111:INFO:Checking exceptions
2025-04-12 22:37:25,114:INFO:Preloading libraries
2025-04-12 22:37:25,125:INFO:Copying training dataset
2025-04-12 22:37:25,125:INFO:Plot type: pipeline
2025-04-12 22:37:25,280:INFO:Visual Rendered Successfully
2025-04-12 22:37:25,378:INFO:plot_model() successfully completed......................................
2025-04-12 22:50:19,530:INFO:Initializing finalize_model()
2025-04-12 22:50:19,530:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-12 22:50:19,531:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-12 22:50:19,535:INFO:Initializing create_model()
2025-04-12 22:50:19,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022E297CB4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-04-12 22:50:19,535:INFO:Checking exceptions
2025-04-12 22:50:19,536:INFO:Importing libraries
2025-04-12 22:50:19,536:INFO:Copying training dataset
2025-04-12 22:50:19,536:INFO:Defining folds
2025-04-12 22:50:19,536:INFO:Declaring metric variables
2025-04-12 22:50:19,536:INFO:Importing untrained model
2025-04-12 22:50:19,537:INFO:Declaring custom model
2025-04-12 22:50:19,538:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-12 22:50:19,538:INFO:Cross validation set to False
2025-04-12 22:50:19,538:INFO:Fitting Model
2025-04-12 22:50:19,568:INFO:[LightGBM] [Info] Number of positive: 511, number of negative: 317
2025-04-12 22:50:19,568:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000227 seconds.
2025-04-12 22:50:19,568:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-12 22:50:19,568:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-12 22:50:19,568:INFO:[LightGBM] [Info] Total Bins 1141
2025-04-12 22:50:19,570:INFO:[LightGBM] [Info] Number of data points in the train set: 828, number of used features: 30
2025-04-12 22:50:19,570:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.617150 -> initscore=0.477468
2025-04-12 22:50:19,570:INFO:[LightGBM] [Info] Start training from score 0.477468
2025-04-12 22:50:19,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:50:19,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-12 22:50:19,702:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-04-12 22:50:19,702:INFO:create_model() successfully completed......................................
2025-04-12 22:50:19,808:INFO:_master_model_container: 30
2025-04-12 22:50:19,808:INFO:_display_container: 3
2025-04-12 22:50:19,808:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-04-12 22:50:19,808:INFO:finalize_model() successfully completed......................................
2025-04-12 22:50:19,908:INFO:Initializing save_model()
2025-04-12 22:50:19,908:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=model_attrition, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-04-12 22:50:19,908:INFO:Adding model into prep_pipe
2025-04-12 22:50:19,908:WARNING:Only Model saved as it was a pipeline.
2025-04-12 22:50:19,918:INFO:model_attrition.pkl saved in current working directory
2025-04-12 22:50:19,926:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-04-12 22:50:19,926:INFO:save_model() successfully completed......................................
2025-04-19 19:48:23,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:48:23,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:48:23,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:48:23,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 19:48:58,283:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_30112\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-19 19:49:10,619:INFO:PyCaret ClassificationExperiment
2025-04-19 19:49:10,620:INFO:Logging name: clf-default-name
2025-04-19 19:49:10,620:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 19:49:10,620:INFO:version 3.0.4
2025-04-19 19:49:10,620:INFO:Initializing setup()
2025-04-19 19:49:10,620:INFO:self.USI: 5f32
2025-04-19 19:49:10,620:INFO:self._variable_keys: {'X_test', 'n_jobs_param', 'idx', 'y_test', 'X', 'gpu_n_jobs_param', 'is_multiclass', 'memory', 'exp_id', 'X_train', 'fold_groups_param', 'fold_generator', 'fix_imbalance', 'y_train', 'logging_param', 'gpu_param', 'log_plots_param', 'data', 'USI', 'exp_name_log', 'fold_shuffle_param', 'y', 'pipeline', '_ml_usecase', 'html_param', 'seed', '_available_plots', 'target_param'}
2025-04-19 19:49:10,620:INFO:Checking environment
2025-04-19 19:49:10,621:INFO:python_version: 3.10.5
2025-04-19 19:49:10,621:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 19:49:10,621:INFO:machine: AMD64
2025-04-19 19:49:10,621:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 19:49:10,627:INFO:Memory: svmem(total=25042907136, available=10580897792, percent=57.7, used=14462009344, free=10580897792)
2025-04-19 19:49:10,628:INFO:Physical Core: 6
2025-04-19 19:49:10,628:INFO:Logical Core: 12
2025-04-19 19:49:10,628:INFO:Checking libraries
2025-04-19 19:49:10,628:INFO:System:
2025-04-19 19:49:10,628:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 19:49:10,628:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 19:49:10,628:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 19:49:10,628:INFO:PyCaret required dependencies:
2025-04-19 19:49:10,702:INFO:                 pip: 25.0.1
2025-04-19 19:49:10,702:INFO:          setuptools: 58.1.0
2025-04-19 19:49:10,702:INFO:             pycaret: 3.0.4
2025-04-19 19:49:10,702:INFO:             IPython: 8.29.0
2025-04-19 19:49:10,702:INFO:          ipywidgets: 8.1.6
2025-04-19 19:49:10,702:INFO:                tqdm: 4.67.1
2025-04-19 19:49:10,702:INFO:               numpy: 1.23.5
2025-04-19 19:49:10,702:INFO:              pandas: 1.5.3
2025-04-19 19:49:10,702:INFO:              jinja2: 3.1.4
2025-04-19 19:49:10,702:INFO:               scipy: 1.11.4
2025-04-19 19:49:10,702:INFO:              joblib: 1.3.2
2025-04-19 19:49:10,702:INFO:             sklearn: 1.2.2
2025-04-19 19:49:10,702:INFO:                pyod: 2.0.4
2025-04-19 19:49:10,702:INFO:            imblearn: 0.10.1
2025-04-19 19:49:10,702:INFO:   category_encoders: 2.7.0
2025-04-19 19:49:10,702:INFO:            lightgbm: 4.6.0
2025-04-19 19:49:10,702:INFO:               numba: 0.60.0
2025-04-19 19:49:10,702:INFO:            requests: 2.32.3
2025-04-19 19:49:10,702:INFO:          matplotlib: 3.7.5
2025-04-19 19:49:10,702:INFO:          scikitplot: 0.3.7
2025-04-19 19:49:10,702:INFO:         yellowbrick: 1.5
2025-04-19 19:49:10,702:INFO:              plotly: 5.24.1
2025-04-19 19:49:10,702:INFO:    plotly-resampler: Not installed
2025-04-19 19:49:10,702:INFO:             kaleido: 0.2.1
2025-04-19 19:49:10,702:INFO:           schemdraw: 0.15
2025-04-19 19:49:10,702:INFO:         statsmodels: 0.14.4
2025-04-19 19:49:10,702:INFO:              sktime: 0.26.0
2025-04-19 19:49:10,702:INFO:               tbats: 1.1.3
2025-04-19 19:49:10,702:INFO:            pmdarima: 2.0.4
2025-04-19 19:49:10,702:INFO:              psutil: 6.1.0
2025-04-19 19:49:10,702:INFO:          markupsafe: 3.0.2
2025-04-19 19:49:10,702:INFO:             pickle5: Not installed
2025-04-19 19:49:10,702:INFO:         cloudpickle: 3.1.1
2025-04-19 19:49:10,702:INFO:         deprecation: 2.1.0
2025-04-19 19:49:10,702:INFO:              xxhash: 3.5.0
2025-04-19 19:49:10,702:INFO:           wurlitzer: Not installed
2025-04-19 19:49:10,702:INFO:PyCaret optional dependencies:
2025-04-19 19:49:10,714:INFO:                shap: Not installed
2025-04-19 19:49:10,715:INFO:           interpret: Not installed
2025-04-19 19:49:10,715:INFO:                umap: Not installed
2025-04-19 19:49:10,715:INFO:    pandas_profiling: Not installed
2025-04-19 19:49:10,715:INFO:  explainerdashboard: Not installed
2025-04-19 19:49:10,715:INFO:             autoviz: Not installed
2025-04-19 19:49:10,715:INFO:           fairlearn: Not installed
2025-04-19 19:49:10,715:INFO:          deepchecks: Not installed
2025-04-19 19:49:10,715:INFO:             xgboost: 1.7.6
2025-04-19 19:49:10,715:INFO:            catboost: Not installed
2025-04-19 19:49:10,715:INFO:              kmodes: Not installed
2025-04-19 19:49:10,715:INFO:             mlxtend: Not installed
2025-04-19 19:49:10,715:INFO:       statsforecast: Not installed
2025-04-19 19:49:10,715:INFO:        tune_sklearn: Not installed
2025-04-19 19:49:10,715:INFO:                 ray: Not installed
2025-04-19 19:49:10,715:INFO:            hyperopt: Not installed
2025-04-19 19:49:10,715:INFO:              optuna: Not installed
2025-04-19 19:49:10,715:INFO:               skopt: Not installed
2025-04-19 19:49:10,715:INFO:              mlflow: Not installed
2025-04-19 19:49:10,715:INFO:              gradio: Not installed
2025-04-19 19:49:10,715:INFO:             fastapi: Not installed
2025-04-19 19:49:10,715:INFO:             uvicorn: Not installed
2025-04-19 19:49:10,715:INFO:              m2cgen: Not installed
2025-04-19 19:49:10,715:INFO:           evidently: Not installed
2025-04-19 19:49:10,715:INFO:               fugue: Not installed
2025-04-19 19:49:10,715:INFO:           streamlit: 1.42.0
2025-04-19 19:49:10,715:INFO:             prophet: Not installed
2025-04-19 19:49:10,715:INFO:None
2025-04-19 19:49:10,715:INFO:Set up data.
2025-04-19 19:49:10,725:INFO:Set up train/test split.
2025-04-19 19:49:10,728:INFO:Set up index.
2025-04-19 19:49:10,728:INFO:Set up folding strategy.
2025-04-19 19:49:10,728:INFO:Assigning column types.
2025-04-19 19:49:10,732:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 19:49:10,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:49:10,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:49:10,799:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 19:49:10,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:49:10,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 19:49:10,838:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:49:10,858:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 19:49:10,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:49:10,860:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 19:49:10,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:49:10,917:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 19:49:10,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:49:10,954:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 19:49:10,982:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 19:49:10,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:49:10,985:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 19:49:11,044:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 19:49:11,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:49:11,110:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 19:49:11,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:49:11,115:INFO:Preparing preprocessing pipeline...
2025-04-19 19:49:11,116:INFO:Set up simple imputation.
2025-04-19 19:49:11,116:INFO:Set up feature normalization.
2025-04-19 19:49:11,146:INFO:Finished creating preprocessing pipeline.
2025-04-19 19:49:11,151:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 19:49:11,151:INFO:Creating final display dataframe.
2025-04-19 19:49:11,221:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (828, 35)
4        Transformed data shape         (828, 34)
5   Transformed train set shape         (579, 34)
6    Transformed test set shape         (249, 34)
7               Ignore features                 1
8              Numeric features                33
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              5f32
2025-04-19 19:49:11,274:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 19:49:11,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:49:11,340:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 19:49:11,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 19:49:11,343:INFO:setup() successfully completed in 0.95s...............
2025-04-19 19:49:11,629:INFO:Initializing compare_models()
2025-04-19 19:49:11,629:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 19:49:11,630:INFO:Checking exceptions
2025-04-19 19:49:11,632:INFO:Preparing display monitor
2025-04-19 19:49:11,656:INFO:Initializing Logistic Regression
2025-04-19 19:49:11,656:INFO:Total runtime is 0.0 minutes
2025-04-19 19:49:11,660:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:11,661:INFO:Initializing create_model()
2025-04-19 19:49:11,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:11,661:INFO:Checking exceptions
2025-04-19 19:49:11,661:INFO:Importing libraries
2025-04-19 19:49:11,661:INFO:Copying training dataset
2025-04-19 19:49:11,665:INFO:Defining folds
2025-04-19 19:49:11,666:INFO:Declaring metric variables
2025-04-19 19:49:11,670:INFO:Importing untrained model
2025-04-19 19:49:11,674:INFO:Logistic Regression Imported successfully
2025-04-19 19:49:11,682:INFO:Starting cross validation
2025-04-19 19:49:11,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:24,193:INFO:Calculating mean and std
2025-04-19 19:49:24,194:INFO:Creating metrics dataframe
2025-04-19 19:49:24,536:INFO:Uploading results into container
2025-04-19 19:49:24,537:INFO:Uploading model into container now
2025-04-19 19:49:24,538:INFO:_master_model_container: 1
2025-04-19 19:49:24,538:INFO:_display_container: 2
2025-04-19 19:49:24,538:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 19:49:24,538:INFO:create_model() successfully completed......................................
2025-04-19 19:49:24,652:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:24,652:INFO:Creating metrics dataframe
2025-04-19 19:49:24,664:INFO:Initializing K Neighbors Classifier
2025-04-19 19:49:24,664:INFO:Total runtime is 0.216798992951711 minutes
2025-04-19 19:49:24,669:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:24,669:INFO:Initializing create_model()
2025-04-19 19:49:24,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:24,671:INFO:Checking exceptions
2025-04-19 19:49:24,671:INFO:Importing libraries
2025-04-19 19:49:24,671:INFO:Copying training dataset
2025-04-19 19:49:24,679:INFO:Defining folds
2025-04-19 19:49:24,679:INFO:Declaring metric variables
2025-04-19 19:49:24,685:INFO:Importing untrained model
2025-04-19 19:49:24,694:INFO:K Neighbors Classifier Imported successfully
2025-04-19 19:49:24,705:INFO:Starting cross validation
2025-04-19 19:49:24,706:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:28,731:INFO:Calculating mean and std
2025-04-19 19:49:28,733:INFO:Creating metrics dataframe
2025-04-19 19:49:29,079:INFO:Uploading results into container
2025-04-19 19:49:29,080:INFO:Uploading model into container now
2025-04-19 19:49:29,081:INFO:_master_model_container: 2
2025-04-19 19:49:29,081:INFO:_display_container: 2
2025-04-19 19:49:29,082:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 19:49:29,082:INFO:create_model() successfully completed......................................
2025-04-19 19:49:29,195:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:29,197:INFO:Creating metrics dataframe
2025-04-19 19:49:29,210:INFO:Initializing Naive Bayes
2025-04-19 19:49:29,210:INFO:Total runtime is 0.29255850315093995 minutes
2025-04-19 19:49:29,216:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:29,216:INFO:Initializing create_model()
2025-04-19 19:49:29,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:29,216:INFO:Checking exceptions
2025-04-19 19:49:29,216:INFO:Importing libraries
2025-04-19 19:49:29,217:INFO:Copying training dataset
2025-04-19 19:49:29,224:INFO:Defining folds
2025-04-19 19:49:29,224:INFO:Declaring metric variables
2025-04-19 19:49:29,231:INFO:Importing untrained model
2025-04-19 19:49:29,238:INFO:Naive Bayes Imported successfully
2025-04-19 19:49:29,248:INFO:Starting cross validation
2025-04-19 19:49:29,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:32,428:INFO:Calculating mean and std
2025-04-19 19:49:32,430:INFO:Creating metrics dataframe
2025-04-19 19:49:32,768:INFO:Uploading results into container
2025-04-19 19:49:32,770:INFO:Uploading model into container now
2025-04-19 19:49:32,771:INFO:_master_model_container: 3
2025-04-19 19:49:32,771:INFO:_display_container: 2
2025-04-19 19:49:32,771:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 19:49:32,772:INFO:create_model() successfully completed......................................
2025-04-19 19:49:32,881:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:32,881:INFO:Creating metrics dataframe
2025-04-19 19:49:32,895:INFO:Initializing Decision Tree Classifier
2025-04-19 19:49:32,895:INFO:Total runtime is 0.35397449334462483 minutes
2025-04-19 19:49:32,900:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:32,900:INFO:Initializing create_model()
2025-04-19 19:49:32,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:32,901:INFO:Checking exceptions
2025-04-19 19:49:32,901:INFO:Importing libraries
2025-04-19 19:49:32,901:INFO:Copying training dataset
2025-04-19 19:49:32,908:INFO:Defining folds
2025-04-19 19:49:32,909:INFO:Declaring metric variables
2025-04-19 19:49:32,915:INFO:Importing untrained model
2025-04-19 19:49:32,922:INFO:Decision Tree Classifier Imported successfully
2025-04-19 19:49:32,934:INFO:Starting cross validation
2025-04-19 19:49:32,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:36,165:INFO:Calculating mean and std
2025-04-19 19:49:36,167:INFO:Creating metrics dataframe
2025-04-19 19:49:36,520:INFO:Uploading results into container
2025-04-19 19:49:36,521:INFO:Uploading model into container now
2025-04-19 19:49:36,522:INFO:_master_model_container: 4
2025-04-19 19:49:36,522:INFO:_display_container: 2
2025-04-19 19:49:36,523:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-19 19:49:36,523:INFO:create_model() successfully completed......................................
2025-04-19 19:49:36,628:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:36,628:INFO:Creating metrics dataframe
2025-04-19 19:49:36,643:INFO:Initializing SVM - Linear Kernel
2025-04-19 19:49:36,643:INFO:Total runtime is 0.41643906831741334 minutes
2025-04-19 19:49:36,649:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:36,649:INFO:Initializing create_model()
2025-04-19 19:49:36,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:36,649:INFO:Checking exceptions
2025-04-19 19:49:36,649:INFO:Importing libraries
2025-04-19 19:49:36,649:INFO:Copying training dataset
2025-04-19 19:49:36,657:INFO:Defining folds
2025-04-19 19:49:36,657:INFO:Declaring metric variables
2025-04-19 19:49:36,664:INFO:Importing untrained model
2025-04-19 19:49:36,671:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 19:49:36,682:INFO:Starting cross validation
2025-04-19 19:49:36,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:36,815:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,816:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,820:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,830:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,834:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,848:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,862:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,863:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,872:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:36,878:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 19:49:39,842:INFO:Calculating mean and std
2025-04-19 19:49:39,844:INFO:Creating metrics dataframe
2025-04-19 19:49:40,196:INFO:Uploading results into container
2025-04-19 19:49:40,197:INFO:Uploading model into container now
2025-04-19 19:49:40,198:INFO:_master_model_container: 5
2025-04-19 19:49:40,198:INFO:_display_container: 2
2025-04-19 19:49:40,199:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 19:49:40,199:INFO:create_model() successfully completed......................................
2025-04-19 19:49:40,303:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:40,303:INFO:Creating metrics dataframe
2025-04-19 19:49:40,318:INFO:Initializing Ridge Classifier
2025-04-19 19:49:40,318:INFO:Total runtime is 0.4776983420054118 minutes
2025-04-19 19:49:40,324:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:40,325:INFO:Initializing create_model()
2025-04-19 19:49:40,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:40,325:INFO:Checking exceptions
2025-04-19 19:49:40,325:INFO:Importing libraries
2025-04-19 19:49:40,325:INFO:Copying training dataset
2025-04-19 19:49:40,332:INFO:Defining folds
2025-04-19 19:49:40,332:INFO:Declaring metric variables
2025-04-19 19:49:40,340:INFO:Importing untrained model
2025-04-19 19:49:40,348:INFO:Ridge Classifier Imported successfully
2025-04-19 19:49:40,358:INFO:Starting cross validation
2025-04-19 19:49:40,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:40,481:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:40,494:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:40,501:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:40,509:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:40,514:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:40,518:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:40,532:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:40,537:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:40,541:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 19:49:43,504:INFO:Calculating mean and std
2025-04-19 19:49:43,506:INFO:Creating metrics dataframe
2025-04-19 19:49:43,852:INFO:Uploading results into container
2025-04-19 19:49:43,852:INFO:Uploading model into container now
2025-04-19 19:49:43,854:INFO:_master_model_container: 6
2025-04-19 19:49:43,854:INFO:_display_container: 2
2025-04-19 19:49:43,855:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-19 19:49:43,855:INFO:create_model() successfully completed......................................
2025-04-19 19:49:43,962:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:43,962:INFO:Creating metrics dataframe
2025-04-19 19:49:43,976:INFO:Initializing Random Forest Classifier
2025-04-19 19:49:43,976:INFO:Total runtime is 0.5386627634366353 minutes
2025-04-19 19:49:43,982:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:43,982:INFO:Initializing create_model()
2025-04-19 19:49:43,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:43,984:INFO:Checking exceptions
2025-04-19 19:49:43,984:INFO:Importing libraries
2025-04-19 19:49:43,984:INFO:Copying training dataset
2025-04-19 19:49:43,992:INFO:Defining folds
2025-04-19 19:49:43,992:INFO:Declaring metric variables
2025-04-19 19:49:43,998:INFO:Importing untrained model
2025-04-19 19:49:44,005:INFO:Random Forest Classifier Imported successfully
2025-04-19 19:49:44,014:INFO:Starting cross validation
2025-04-19 19:49:44,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:47,544:INFO:Calculating mean and std
2025-04-19 19:49:47,546:INFO:Creating metrics dataframe
2025-04-19 19:49:47,892:INFO:Uploading results into container
2025-04-19 19:49:47,893:INFO:Uploading model into container now
2025-04-19 19:49:47,893:INFO:_master_model_container: 7
2025-04-19 19:49:47,894:INFO:_display_container: 2
2025-04-19 19:49:47,894:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-19 19:49:47,894:INFO:create_model() successfully completed......................................
2025-04-19 19:49:47,999:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:47,999:INFO:Creating metrics dataframe
2025-04-19 19:49:48,015:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 19:49:48,015:INFO:Total runtime is 0.6059723893801371 minutes
2025-04-19 19:49:48,020:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:48,021:INFO:Initializing create_model()
2025-04-19 19:49:48,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:48,022:INFO:Checking exceptions
2025-04-19 19:49:48,022:INFO:Importing libraries
2025-04-19 19:49:48,023:INFO:Copying training dataset
2025-04-19 19:49:48,030:INFO:Defining folds
2025-04-19 19:49:48,030:INFO:Declaring metric variables
2025-04-19 19:49:48,036:INFO:Importing untrained model
2025-04-19 19:49:48,041:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 19:49:48,054:INFO:Starting cross validation
2025-04-19 19:49:48,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:48,152:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,159:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,168:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,173:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,174:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,176:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,194:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,198:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,208:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:48,210:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 19:49:51,313:INFO:Calculating mean and std
2025-04-19 19:49:51,314:INFO:Creating metrics dataframe
2025-04-19 19:49:51,698:INFO:Uploading results into container
2025-04-19 19:49:51,698:INFO:Uploading model into container now
2025-04-19 19:49:51,700:INFO:_master_model_container: 8
2025-04-19 19:49:51,700:INFO:_display_container: 2
2025-04-19 19:49:51,700:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 19:49:51,700:INFO:create_model() successfully completed......................................
2025-04-19 19:49:51,810:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:51,810:INFO:Creating metrics dataframe
2025-04-19 19:49:51,827:INFO:Initializing Ada Boost Classifier
2025-04-19 19:49:51,828:INFO:Total runtime is 0.6695244709650675 minutes
2025-04-19 19:49:51,834:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:51,834:INFO:Initializing create_model()
2025-04-19 19:49:51,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:51,834:INFO:Checking exceptions
2025-04-19 19:49:51,834:INFO:Importing libraries
2025-04-19 19:49:51,835:INFO:Copying training dataset
2025-04-19 19:49:51,842:INFO:Defining folds
2025-04-19 19:49:51,842:INFO:Declaring metric variables
2025-04-19 19:49:51,849:INFO:Importing untrained model
2025-04-19 19:49:51,855:INFO:Ada Boost Classifier Imported successfully
2025-04-19 19:49:51,870:INFO:Starting cross validation
2025-04-19 19:49:51,871:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:55,408:INFO:Calculating mean and std
2025-04-19 19:49:55,410:INFO:Creating metrics dataframe
2025-04-19 19:49:55,766:INFO:Uploading results into container
2025-04-19 19:49:55,769:INFO:Uploading model into container now
2025-04-19 19:49:55,769:INFO:_master_model_container: 9
2025-04-19 19:49:55,769:INFO:_display_container: 2
2025-04-19 19:49:55,769:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-19 19:49:55,769:INFO:create_model() successfully completed......................................
2025-04-19 19:49:55,876:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:55,876:INFO:Creating metrics dataframe
2025-04-19 19:49:55,897:INFO:Initializing Gradient Boosting Classifier
2025-04-19 19:49:55,898:INFO:Total runtime is 0.7373594959576925 minutes
2025-04-19 19:49:55,903:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:55,904:INFO:Initializing create_model()
2025-04-19 19:49:55,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:55,904:INFO:Checking exceptions
2025-04-19 19:49:55,904:INFO:Importing libraries
2025-04-19 19:49:55,904:INFO:Copying training dataset
2025-04-19 19:49:55,913:INFO:Defining folds
2025-04-19 19:49:55,913:INFO:Declaring metric variables
2025-04-19 19:49:55,921:INFO:Importing untrained model
2025-04-19 19:49:55,929:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 19:49:55,941:INFO:Starting cross validation
2025-04-19 19:49:55,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:49:59,275:INFO:Calculating mean and std
2025-04-19 19:49:59,278:INFO:Creating metrics dataframe
2025-04-19 19:49:59,622:INFO:Uploading results into container
2025-04-19 19:49:59,623:INFO:Uploading model into container now
2025-04-19 19:49:59,623:INFO:_master_model_container: 10
2025-04-19 19:49:59,624:INFO:_display_container: 2
2025-04-19 19:49:59,624:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 19:49:59,624:INFO:create_model() successfully completed......................................
2025-04-19 19:49:59,731:INFO:SubProcess create_model() end ==================================
2025-04-19 19:49:59,733:INFO:Creating metrics dataframe
2025-04-19 19:49:59,749:INFO:Initializing Linear Discriminant Analysis
2025-04-19 19:49:59,749:INFO:Total runtime is 0.8015445073445638 minutes
2025-04-19 19:49:59,754:INFO:SubProcess create_model() called ==================================
2025-04-19 19:49:59,755:INFO:Initializing create_model()
2025-04-19 19:49:59,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:49:59,755:INFO:Checking exceptions
2025-04-19 19:49:59,755:INFO:Importing libraries
2025-04-19 19:49:59,755:INFO:Copying training dataset
2025-04-19 19:49:59,762:INFO:Defining folds
2025-04-19 19:49:59,763:INFO:Declaring metric variables
2025-04-19 19:49:59,768:INFO:Importing untrained model
2025-04-19 19:49:59,775:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 19:49:59,784:INFO:Starting cross validation
2025-04-19 19:49:59,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:50:03,028:INFO:Calculating mean and std
2025-04-19 19:50:03,029:INFO:Creating metrics dataframe
2025-04-19 19:50:03,369:INFO:Uploading results into container
2025-04-19 19:50:03,371:INFO:Uploading model into container now
2025-04-19 19:50:03,371:INFO:_master_model_container: 11
2025-04-19 19:50:03,371:INFO:_display_container: 2
2025-04-19 19:50:03,372:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 19:50:03,372:INFO:create_model() successfully completed......................................
2025-04-19 19:50:03,478:INFO:SubProcess create_model() end ==================================
2025-04-19 19:50:03,478:INFO:Creating metrics dataframe
2025-04-19 19:50:03,495:INFO:Initializing Extra Trees Classifier
2025-04-19 19:50:03,495:INFO:Total runtime is 0.8639795104662578 minutes
2025-04-19 19:50:03,500:INFO:SubProcess create_model() called ==================================
2025-04-19 19:50:03,501:INFO:Initializing create_model()
2025-04-19 19:50:03,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:50:03,501:INFO:Checking exceptions
2025-04-19 19:50:03,501:INFO:Importing libraries
2025-04-19 19:50:03,501:INFO:Copying training dataset
2025-04-19 19:50:03,508:INFO:Defining folds
2025-04-19 19:50:03,508:INFO:Declaring metric variables
2025-04-19 19:50:03,513:INFO:Importing untrained model
2025-04-19 19:50:03,521:INFO:Extra Trees Classifier Imported successfully
2025-04-19 19:50:03,532:INFO:Starting cross validation
2025-04-19 19:50:03,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:50:07,068:INFO:Calculating mean and std
2025-04-19 19:50:07,071:INFO:Creating metrics dataframe
2025-04-19 19:50:07,446:INFO:Uploading results into container
2025-04-19 19:50:07,446:INFO:Uploading model into container now
2025-04-19 19:50:07,448:INFO:_master_model_container: 12
2025-04-19 19:50:07,448:INFO:_display_container: 2
2025-04-19 19:50:07,448:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-19 19:50:07,448:INFO:create_model() successfully completed......................................
2025-04-19 19:50:07,553:INFO:SubProcess create_model() end ==================================
2025-04-19 19:50:07,553:INFO:Creating metrics dataframe
2025-04-19 19:50:07,570:INFO:Initializing Extreme Gradient Boosting
2025-04-19 19:50:07,570:INFO:Total runtime is 0.9318856557210287 minutes
2025-04-19 19:50:07,574:INFO:SubProcess create_model() called ==================================
2025-04-19 19:50:07,575:INFO:Initializing create_model()
2025-04-19 19:50:07,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:50:07,575:INFO:Checking exceptions
2025-04-19 19:50:07,575:INFO:Importing libraries
2025-04-19 19:50:07,575:INFO:Copying training dataset
2025-04-19 19:50:07,581:INFO:Defining folds
2025-04-19 19:50:07,581:INFO:Declaring metric variables
2025-04-19 19:50:07,589:INFO:Importing untrained model
2025-04-19 19:50:07,595:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 19:50:07,606:INFO:Starting cross validation
2025-04-19 19:50:07,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:50:12,779:INFO:Calculating mean and std
2025-04-19 19:50:12,782:INFO:Creating metrics dataframe
2025-04-19 19:50:13,129:INFO:Uploading results into container
2025-04-19 19:50:13,131:INFO:Uploading model into container now
2025-04-19 19:50:13,131:INFO:_master_model_container: 13
2025-04-19 19:50:13,131:INFO:_display_container: 2
2025-04-19 19:50:13,133:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 19:50:13,135:INFO:create_model() successfully completed......................................
2025-04-19 19:50:13,243:INFO:SubProcess create_model() end ==================================
2025-04-19 19:50:13,243:INFO:Creating metrics dataframe
2025-04-19 19:50:13,262:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 19:50:13,262:INFO:Total runtime is 1.0267565210660299 minutes
2025-04-19 19:50:13,267:INFO:SubProcess create_model() called ==================================
2025-04-19 19:50:13,268:INFO:Initializing create_model()
2025-04-19 19:50:13,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:50:13,268:INFO:Checking exceptions
2025-04-19 19:50:13,269:INFO:Importing libraries
2025-04-19 19:50:13,269:INFO:Copying training dataset
2025-04-19 19:50:13,275:INFO:Defining folds
2025-04-19 19:50:13,275:INFO:Declaring metric variables
2025-04-19 19:50:13,283:INFO:Importing untrained model
2025-04-19 19:50:13,291:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 19:50:13,301:INFO:Starting cross validation
2025-04-19 19:50:13,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:50:16,730:INFO:Calculating mean and std
2025-04-19 19:50:16,731:INFO:Creating metrics dataframe
2025-04-19 19:50:17,098:INFO:Uploading results into container
2025-04-19 19:50:17,099:INFO:Uploading model into container now
2025-04-19 19:50:17,100:INFO:_master_model_container: 14
2025-04-19 19:50:17,101:INFO:_display_container: 2
2025-04-19 19:50:17,102:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 19:50:17,102:INFO:create_model() successfully completed......................................
2025-04-19 19:50:17,219:INFO:SubProcess create_model() end ==================================
2025-04-19 19:50:17,219:INFO:Creating metrics dataframe
2025-04-19 19:50:17,237:INFO:Initializing Dummy Classifier
2025-04-19 19:50:17,237:INFO:Total runtime is 1.093008542060852 minutes
2025-04-19 19:50:17,242:INFO:SubProcess create_model() called ==================================
2025-04-19 19:50:17,243:INFO:Initializing create_model()
2025-04-19 19:50:17,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FF97E2D8A0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:50:17,243:INFO:Checking exceptions
2025-04-19 19:50:17,243:INFO:Importing libraries
2025-04-19 19:50:17,243:INFO:Copying training dataset
2025-04-19 19:50:17,252:INFO:Defining folds
2025-04-19 19:50:17,252:INFO:Declaring metric variables
2025-04-19 19:50:17,259:INFO:Importing untrained model
2025-04-19 19:50:17,268:INFO:Dummy Classifier Imported successfully
2025-04-19 19:50:17,301:INFO:Starting cross validation
2025-04-19 19:50:17,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 19:50:20,503:INFO:Calculating mean and std
2025-04-19 19:50:20,505:INFO:Creating metrics dataframe
2025-04-19 19:50:20,850:INFO:Uploading results into container
2025-04-19 19:50:20,851:INFO:Uploading model into container now
2025-04-19 19:50:20,852:INFO:_master_model_container: 15
2025-04-19 19:50:20,852:INFO:_display_container: 2
2025-04-19 19:50:20,852:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-19 19:50:20,852:INFO:create_model() successfully completed......................................
2025-04-19 19:50:20,958:INFO:SubProcess create_model() end ==================================
2025-04-19 19:50:20,959:INFO:Creating metrics dataframe
2025-04-19 19:50:20,999:INFO:Initializing create_model()
2025-04-19 19:50:21,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 19:50:21,001:INFO:Checking exceptions
2025-04-19 19:50:21,004:INFO:Importing libraries
2025-04-19 19:50:21,004:INFO:Copying training dataset
2025-04-19 19:50:21,010:INFO:Defining folds
2025-04-19 19:50:21,010:INFO:Declaring metric variables
2025-04-19 19:50:21,011:INFO:Importing untrained model
2025-04-19 19:50:21,011:INFO:Declaring custom model
2025-04-19 19:50:21,014:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 19:50:21,015:INFO:Cross validation set to False
2025-04-19 19:50:21,015:INFO:Fitting Model
2025-04-19 19:50:21,065:INFO:[LightGBM] [Info] Number of positive: 357, number of negative: 222
2025-04-19 19:50:21,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002418 seconds.
2025-04-19 19:50:21,069:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-04-19 19:50:21,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-04-19 19:50:21,069:INFO:[LightGBM] [Info] Total Bins 944
2025-04-19 19:50:21,070:INFO:[LightGBM] [Info] Number of data points in the train set: 579, number of used features: 30
2025-04-19 19:50:21,070:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.616580 -> initscore=0.475058
2025-04-19 19:50:21,071:INFO:[LightGBM] [Info] Start training from score 0.475058
2025-04-19 19:50:21,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-04-19 19:50:21,581:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 19:50:21,581:INFO:create_model() successfully completed......................................
2025-04-19 19:50:21,733:INFO:_master_model_container: 15
2025-04-19 19:50:21,733:INFO:_display_container: 2
2025-04-19 19:50:21,734:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 19:50:21,735:INFO:compare_models() successfully completed......................................
2025-04-19 19:50:21,748:INFO:Initializing evaluate_model()
2025-04-19 19:50:21,748:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-19 19:50:21,764:INFO:Initializing plot_model()
2025-04-19 19:50:21,764:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF970E78E0>, system=True)
2025-04-19 19:50:21,764:INFO:Checking exceptions
2025-04-19 19:50:21,768:INFO:Preloading libraries
2025-04-19 19:50:21,775:INFO:Copying training dataset
2025-04-19 19:50:21,776:INFO:Plot type: pipeline
2025-04-19 19:50:22,086:INFO:Visual Rendered Successfully
2025-04-19 19:50:22,199:INFO:plot_model() successfully completed......................................
2025-04-19 22:25:01,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 22:25:01,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 22:25:01,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 22:25:01,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-19 22:25:23,012:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_25512\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-19 22:27:18,735:INFO:PyCaret ClassificationExperiment
2025-04-19 22:27:18,735:INFO:Logging name: clf-default-name
2025-04-19 22:27:18,735:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 22:27:18,735:INFO:version 3.0.4
2025-04-19 22:27:18,735:INFO:Initializing setup()
2025-04-19 22:27:18,735:INFO:self.USI: 3e08
2025-04-19 22:27:18,735:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 22:27:18,735:INFO:Checking environment
2025-04-19 22:27:18,735:INFO:python_version: 3.10.5
2025-04-19 22:27:18,736:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 22:27:18,736:INFO:machine: AMD64
2025-04-19 22:27:18,736:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 22:27:18,741:INFO:Memory: svmem(total=25042907136, available=11997970432, percent=52.1, used=13044936704, free=11997970432)
2025-04-19 22:27:18,741:INFO:Physical Core: 6
2025-04-19 22:27:18,741:INFO:Logical Core: 12
2025-04-19 22:27:18,741:INFO:Checking libraries
2025-04-19 22:27:18,741:INFO:System:
2025-04-19 22:27:18,741:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 22:27:18,741:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 22:27:18,743:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 22:27:18,743:INFO:PyCaret required dependencies:
2025-04-19 22:27:18,814:INFO:                 pip: 25.0.1
2025-04-19 22:27:18,814:INFO:          setuptools: 58.1.0
2025-04-19 22:27:18,814:INFO:             pycaret: 3.0.4
2025-04-19 22:27:18,814:INFO:             IPython: 8.29.0
2025-04-19 22:27:18,814:INFO:          ipywidgets: 8.1.6
2025-04-19 22:27:18,814:INFO:                tqdm: 4.67.1
2025-04-19 22:27:18,814:INFO:               numpy: 1.23.5
2025-04-19 22:27:18,814:INFO:              pandas: 1.5.3
2025-04-19 22:27:18,814:INFO:              jinja2: 3.1.4
2025-04-19 22:27:18,814:INFO:               scipy: 1.11.4
2025-04-19 22:27:18,814:INFO:              joblib: 1.3.2
2025-04-19 22:27:18,814:INFO:             sklearn: 1.2.2
2025-04-19 22:27:18,814:INFO:                pyod: 2.0.4
2025-04-19 22:27:18,814:INFO:            imblearn: 0.10.1
2025-04-19 22:27:18,814:INFO:   category_encoders: 2.7.0
2025-04-19 22:27:18,814:INFO:            lightgbm: 4.6.0
2025-04-19 22:27:18,814:INFO:               numba: 0.60.0
2025-04-19 22:27:18,814:INFO:            requests: 2.32.3
2025-04-19 22:27:18,814:INFO:          matplotlib: 3.7.5
2025-04-19 22:27:18,814:INFO:          scikitplot: 0.3.7
2025-04-19 22:27:18,814:INFO:         yellowbrick: 1.5
2025-04-19 22:27:18,814:INFO:              plotly: 5.24.1
2025-04-19 22:27:18,815:INFO:    plotly-resampler: Not installed
2025-04-19 22:27:18,815:INFO:             kaleido: 0.2.1
2025-04-19 22:27:18,815:INFO:           schemdraw: 0.15
2025-04-19 22:27:18,815:INFO:         statsmodels: 0.14.4
2025-04-19 22:27:18,815:INFO:              sktime: 0.26.0
2025-04-19 22:27:18,815:INFO:               tbats: 1.1.3
2025-04-19 22:27:18,815:INFO:            pmdarima: 2.0.4
2025-04-19 22:27:18,815:INFO:              psutil: 6.1.0
2025-04-19 22:27:18,815:INFO:          markupsafe: 3.0.2
2025-04-19 22:27:18,815:INFO:             pickle5: Not installed
2025-04-19 22:27:18,815:INFO:         cloudpickle: 3.1.1
2025-04-19 22:27:18,815:INFO:         deprecation: 2.1.0
2025-04-19 22:27:18,815:INFO:              xxhash: 3.5.0
2025-04-19 22:27:18,815:INFO:           wurlitzer: Not installed
2025-04-19 22:27:18,815:INFO:PyCaret optional dependencies:
2025-04-19 22:27:18,827:INFO:                shap: Not installed
2025-04-19 22:27:18,827:INFO:           interpret: Not installed
2025-04-19 22:27:18,827:INFO:                umap: Not installed
2025-04-19 22:27:18,827:INFO:    pandas_profiling: Not installed
2025-04-19 22:27:18,827:INFO:  explainerdashboard: Not installed
2025-04-19 22:27:18,827:INFO:             autoviz: Not installed
2025-04-19 22:27:18,827:INFO:           fairlearn: Not installed
2025-04-19 22:27:18,827:INFO:          deepchecks: Not installed
2025-04-19 22:27:18,827:INFO:             xgboost: 1.7.6
2025-04-19 22:27:18,828:INFO:            catboost: Not installed
2025-04-19 22:27:18,828:INFO:              kmodes: Not installed
2025-04-19 22:27:18,828:INFO:             mlxtend: Not installed
2025-04-19 22:27:18,828:INFO:       statsforecast: Not installed
2025-04-19 22:27:18,828:INFO:        tune_sklearn: Not installed
2025-04-19 22:27:18,828:INFO:                 ray: Not installed
2025-04-19 22:27:18,828:INFO:            hyperopt: Not installed
2025-04-19 22:27:18,828:INFO:              optuna: Not installed
2025-04-19 22:27:18,828:INFO:               skopt: Not installed
2025-04-19 22:27:18,828:INFO:              mlflow: Not installed
2025-04-19 22:27:18,828:INFO:              gradio: Not installed
2025-04-19 22:27:18,828:INFO:             fastapi: Not installed
2025-04-19 22:27:18,828:INFO:             uvicorn: Not installed
2025-04-19 22:27:18,828:INFO:              m2cgen: Not installed
2025-04-19 22:27:18,828:INFO:           evidently: Not installed
2025-04-19 22:27:18,828:INFO:               fugue: Not installed
2025-04-19 22:27:18,828:INFO:           streamlit: 1.42.0
2025-04-19 22:27:18,828:INFO:             prophet: Not installed
2025-04-19 22:27:18,828:INFO:None
2025-04-19 22:27:18,828:INFO:Set up data.
2025-04-19 22:27:18,841:INFO:Set up train/test split.
2025-04-19 22:27:18,847:INFO:Set up index.
2025-04-19 22:27:18,847:INFO:Set up folding strategy.
2025-04-19 22:27:18,847:INFO:Assigning column types.
2025-04-19 22:27:18,850:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 22:27:18,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:27:18,896:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:27:18,930:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:18,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:18,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:27:18,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:27:18,997:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:19,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:19,000:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 22:27:19,041:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:27:19,066:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:19,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:19,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:27:19,137:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:19,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:19,139:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 22:27:19,206:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:19,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:19,275:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:19,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:19,280:INFO:Preparing preprocessing pipeline...
2025-04-19 22:27:19,282:INFO:Set up simple imputation.
2025-04-19 22:27:19,285:INFO:Set up encoding of ordinal features.
2025-04-19 22:27:19,287:INFO:Set up encoding of categorical features.
2025-04-19 22:27:19,287:INFO:Set up imbalanced handling.
2025-04-19 22:27:19,287:INFO:Set up feature normalization.
2025-04-19 22:27:19,287:INFO:Set up feature selection.
2025-04-19 22:27:19,353:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:19,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:19,799:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(

2025-04-19 22:27:20,020:INFO:Finished creating preprocessing pipeline.
2025-04-19 22:27:20,071:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'P...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 22:27:20,071:INFO:Creating final display dataframe.
2025-04-19 22:27:45,181:INFO:PyCaret ClassificationExperiment
2025-04-19 22:27:45,181:INFO:Logging name: clf-default-name
2025-04-19 22:27:45,181:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 22:27:45,181:INFO:version 3.0.4
2025-04-19 22:27:45,181:INFO:Initializing setup()
2025-04-19 22:27:45,181:INFO:self.USI: 949e
2025-04-19 22:27:45,181:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 22:27:45,183:INFO:Checking environment
2025-04-19 22:27:45,183:INFO:python_version: 3.10.5
2025-04-19 22:27:45,183:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 22:27:45,183:INFO:machine: AMD64
2025-04-19 22:27:45,183:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 22:27:45,188:INFO:Memory: svmem(total=25042907136, available=11965698048, percent=52.2, used=13077209088, free=11965698048)
2025-04-19 22:27:45,188:INFO:Physical Core: 6
2025-04-19 22:27:45,188:INFO:Logical Core: 12
2025-04-19 22:27:45,188:INFO:Checking libraries
2025-04-19 22:27:45,188:INFO:System:
2025-04-19 22:27:45,188:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 22:27:45,188:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 22:27:45,188:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 22:27:45,189:INFO:PyCaret required dependencies:
2025-04-19 22:27:45,189:INFO:                 pip: 25.0.1
2025-04-19 22:27:45,189:INFO:          setuptools: 58.1.0
2025-04-19 22:27:45,189:INFO:             pycaret: 3.0.4
2025-04-19 22:27:45,189:INFO:             IPython: 8.29.0
2025-04-19 22:27:45,189:INFO:          ipywidgets: 8.1.6
2025-04-19 22:27:45,189:INFO:                tqdm: 4.67.1
2025-04-19 22:27:45,189:INFO:               numpy: 1.23.5
2025-04-19 22:27:45,189:INFO:              pandas: 1.5.3
2025-04-19 22:27:45,189:INFO:              jinja2: 3.1.4
2025-04-19 22:27:45,189:INFO:               scipy: 1.11.4
2025-04-19 22:27:45,189:INFO:              joblib: 1.3.2
2025-04-19 22:27:45,189:INFO:             sklearn: 1.2.2
2025-04-19 22:27:45,189:INFO:                pyod: 2.0.4
2025-04-19 22:27:45,189:INFO:            imblearn: 0.10.1
2025-04-19 22:27:45,189:INFO:   category_encoders: 2.7.0
2025-04-19 22:27:45,189:INFO:            lightgbm: 4.6.0
2025-04-19 22:27:45,189:INFO:               numba: 0.60.0
2025-04-19 22:27:45,189:INFO:            requests: 2.32.3
2025-04-19 22:27:45,189:INFO:          matplotlib: 3.7.5
2025-04-19 22:27:45,189:INFO:          scikitplot: 0.3.7
2025-04-19 22:27:45,189:INFO:         yellowbrick: 1.5
2025-04-19 22:27:45,189:INFO:              plotly: 5.24.1
2025-04-19 22:27:45,189:INFO:    plotly-resampler: Not installed
2025-04-19 22:27:45,190:INFO:             kaleido: 0.2.1
2025-04-19 22:27:45,190:INFO:           schemdraw: 0.15
2025-04-19 22:27:45,190:INFO:         statsmodels: 0.14.4
2025-04-19 22:27:45,190:INFO:              sktime: 0.26.0
2025-04-19 22:27:45,190:INFO:               tbats: 1.1.3
2025-04-19 22:27:45,190:INFO:            pmdarima: 2.0.4
2025-04-19 22:27:45,190:INFO:              psutil: 6.1.0
2025-04-19 22:27:45,190:INFO:          markupsafe: 3.0.2
2025-04-19 22:27:45,190:INFO:             pickle5: Not installed
2025-04-19 22:27:45,190:INFO:         cloudpickle: 3.1.1
2025-04-19 22:27:45,190:INFO:         deprecation: 2.1.0
2025-04-19 22:27:45,190:INFO:              xxhash: 3.5.0
2025-04-19 22:27:45,190:INFO:           wurlitzer: Not installed
2025-04-19 22:27:45,190:INFO:PyCaret optional dependencies:
2025-04-19 22:27:45,190:INFO:                shap: Not installed
2025-04-19 22:27:45,190:INFO:           interpret: Not installed
2025-04-19 22:27:45,190:INFO:                umap: Not installed
2025-04-19 22:27:45,190:INFO:    pandas_profiling: Not installed
2025-04-19 22:27:45,190:INFO:  explainerdashboard: Not installed
2025-04-19 22:27:45,190:INFO:             autoviz: Not installed
2025-04-19 22:27:45,190:INFO:           fairlearn: Not installed
2025-04-19 22:27:45,190:INFO:          deepchecks: Not installed
2025-04-19 22:27:45,190:INFO:             xgboost: 1.7.6
2025-04-19 22:27:45,190:INFO:            catboost: Not installed
2025-04-19 22:27:45,190:INFO:              kmodes: Not installed
2025-04-19 22:27:45,190:INFO:             mlxtend: Not installed
2025-04-19 22:27:45,190:INFO:       statsforecast: Not installed
2025-04-19 22:27:45,190:INFO:        tune_sklearn: Not installed
2025-04-19 22:27:45,191:INFO:                 ray: Not installed
2025-04-19 22:27:45,191:INFO:            hyperopt: Not installed
2025-04-19 22:27:45,191:INFO:              optuna: Not installed
2025-04-19 22:27:45,191:INFO:               skopt: Not installed
2025-04-19 22:27:45,191:INFO:              mlflow: Not installed
2025-04-19 22:27:45,191:INFO:              gradio: Not installed
2025-04-19 22:27:45,191:INFO:             fastapi: Not installed
2025-04-19 22:27:45,191:INFO:             uvicorn: Not installed
2025-04-19 22:27:45,191:INFO:              m2cgen: Not installed
2025-04-19 22:27:45,191:INFO:           evidently: Not installed
2025-04-19 22:27:45,191:INFO:               fugue: Not installed
2025-04-19 22:27:45,191:INFO:           streamlit: 1.42.0
2025-04-19 22:27:45,191:INFO:             prophet: Not installed
2025-04-19 22:27:45,191:INFO:None
2025-04-19 22:27:45,191:INFO:Set up data.
2025-04-19 22:27:45,202:INFO:Set up train/test split.
2025-04-19 22:27:45,208:INFO:Set up index.
2025-04-19 22:27:45,208:INFO:Set up folding strategy.
2025-04-19 22:27:45,208:INFO:Assigning column types.
2025-04-19 22:27:45,212:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 22:27:45,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:27:45,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:27:45,282:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:45,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:45,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:27:45,328:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:27:45,355:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:45,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:45,358:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 22:27:45,400:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:27:45,425:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:45,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:45,469:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:27:45,495:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:45,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:45,498:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 22:27:45,567:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:45,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:45,640:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:45,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:45,644:INFO:Preparing preprocessing pipeline...
2025-04-19 22:27:45,645:INFO:Set up simple imputation.
2025-04-19 22:27:45,648:INFO:Set up encoding of ordinal features.
2025-04-19 22:27:45,651:INFO:Set up encoding of categorical features.
2025-04-19 22:27:45,651:INFO:Set up imbalanced handling.
2025-04-19 22:27:45,651:INFO:Set up feature normalization.
2025-04-19 22:27:45,795:INFO:Finished creating preprocessing pipeline.
2025-04-19 22:27:45,824:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'P...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 22:27:45,824:INFO:Creating final display dataframe.
2025-04-19 22:27:46,182:INFO:Setup _display_container:                     Description             Value
0                    Session id             11058
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 35)
4        Transformed data shape        (1548, 53)
5   Transformed train set shape        (1230, 53)
6    Transformed test set shape         (318, 53)
7               Ignore features                 1
8              Ordinal features                 2
9              Numeric features                25
10         Categorical features                 8
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              949e
2025-04-19 22:27:46,259:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:46,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:46,333:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:27:46,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:27:46,336:INFO:setup() successfully completed in 1.34s...............
2025-04-19 22:27:49,695:INFO:Initializing compare_models()
2025-04-19 22:27:49,695:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 22:27:49,695:INFO:Checking exceptions
2025-04-19 22:27:49,700:INFO:Preparing display monitor
2025-04-19 22:27:49,729:INFO:Initializing Logistic Regression
2025-04-19 22:27:49,729:INFO:Total runtime is 0.0 minutes
2025-04-19 22:27:49,733:INFO:SubProcess create_model() called ==================================
2025-04-19 22:27:49,734:INFO:Initializing create_model()
2025-04-19 22:27:49,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:27:49,734:INFO:Checking exceptions
2025-04-19 22:27:49,734:INFO:Importing libraries
2025-04-19 22:27:49,734:INFO:Copying training dataset
2025-04-19 22:27:49,743:INFO:Defining folds
2025-04-19 22:27:49,743:INFO:Declaring metric variables
2025-04-19 22:27:49,748:INFO:Importing untrained model
2025-04-19 22:27:49,755:INFO:Logistic Regression Imported successfully
2025-04-19 22:27:49,763:INFO:Starting cross validation
2025-04-19 22:27:49,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:04,043:INFO:Calculating mean and std
2025-04-19 22:28:04,045:INFO:Creating metrics dataframe
2025-04-19 22:28:04,323:INFO:Uploading results into container
2025-04-19 22:28:04,323:INFO:Uploading model into container now
2025-04-19 22:28:04,324:INFO:_master_model_container: 1
2025-04-19 22:28:04,324:INFO:_display_container: 2
2025-04-19 22:28:04,326:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=11058, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 22:28:04,326:INFO:create_model() successfully completed......................................
2025-04-19 22:28:04,448:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:04,448:INFO:Creating metrics dataframe
2025-04-19 22:28:04,457:INFO:Initializing K Neighbors Classifier
2025-04-19 22:28:04,457:INFO:Total runtime is 0.2454584201176961 minutes
2025-04-19 22:28:04,460:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:04,460:INFO:Initializing create_model()
2025-04-19 22:28:04,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:04,461:INFO:Checking exceptions
2025-04-19 22:28:04,461:INFO:Importing libraries
2025-04-19 22:28:04,461:INFO:Copying training dataset
2025-04-19 22:28:04,467:INFO:Defining folds
2025-04-19 22:28:04,467:INFO:Declaring metric variables
2025-04-19 22:28:04,471:INFO:Importing untrained model
2025-04-19 22:28:04,474:INFO:K Neighbors Classifier Imported successfully
2025-04-19 22:28:04,478:INFO:Starting cross validation
2025-04-19 22:28:04,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:09,213:INFO:Calculating mean and std
2025-04-19 22:28:09,217:INFO:Creating metrics dataframe
2025-04-19 22:28:09,689:INFO:Uploading results into container
2025-04-19 22:28:09,690:INFO:Uploading model into container now
2025-04-19 22:28:09,691:INFO:_master_model_container: 2
2025-04-19 22:28:09,691:INFO:_display_container: 2
2025-04-19 22:28:09,692:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 22:28:09,692:INFO:create_model() successfully completed......................................
2025-04-19 22:28:09,856:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:09,856:INFO:Creating metrics dataframe
2025-04-19 22:28:09,873:INFO:Initializing Naive Bayes
2025-04-19 22:28:09,873:INFO:Total runtime is 0.33572863340377807 minutes
2025-04-19 22:28:09,879:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:09,880:INFO:Initializing create_model()
2025-04-19 22:28:09,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:09,880:INFO:Checking exceptions
2025-04-19 22:28:09,880:INFO:Importing libraries
2025-04-19 22:28:09,880:INFO:Copying training dataset
2025-04-19 22:28:09,890:INFO:Defining folds
2025-04-19 22:28:09,890:INFO:Declaring metric variables
2025-04-19 22:28:09,896:INFO:Importing untrained model
2025-04-19 22:28:09,901:INFO:Naive Bayes Imported successfully
2025-04-19 22:28:09,923:INFO:Starting cross validation
2025-04-19 22:28:09,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:14,489:INFO:Calculating mean and std
2025-04-19 22:28:14,492:INFO:Creating metrics dataframe
2025-04-19 22:28:14,977:INFO:Uploading results into container
2025-04-19 22:28:14,978:INFO:Uploading model into container now
2025-04-19 22:28:14,979:INFO:_master_model_container: 3
2025-04-19 22:28:14,979:INFO:_display_container: 2
2025-04-19 22:28:14,980:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 22:28:14,980:INFO:create_model() successfully completed......................................
2025-04-19 22:28:15,115:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:15,115:INFO:Creating metrics dataframe
2025-04-19 22:28:15,131:INFO:Initializing Decision Tree Classifier
2025-04-19 22:28:15,131:INFO:Total runtime is 0.4233671267827352 minutes
2025-04-19 22:28:15,138:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:15,138:INFO:Initializing create_model()
2025-04-19 22:28:15,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:15,139:INFO:Checking exceptions
2025-04-19 22:28:15,139:INFO:Importing libraries
2025-04-19 22:28:15,139:INFO:Copying training dataset
2025-04-19 22:28:15,151:INFO:Defining folds
2025-04-19 22:28:15,151:INFO:Declaring metric variables
2025-04-19 22:28:15,158:INFO:Importing untrained model
2025-04-19 22:28:15,165:INFO:Decision Tree Classifier Imported successfully
2025-04-19 22:28:15,176:INFO:Starting cross validation
2025-04-19 22:28:15,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:19,652:INFO:Calculating mean and std
2025-04-19 22:28:19,655:INFO:Creating metrics dataframe
2025-04-19 22:28:20,153:INFO:Uploading results into container
2025-04-19 22:28:20,154:INFO:Uploading model into container now
2025-04-19 22:28:20,156:INFO:_master_model_container: 4
2025-04-19 22:28:20,156:INFO:_display_container: 2
2025-04-19 22:28:20,156:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=11058, splitter='best')
2025-04-19 22:28:20,157:INFO:create_model() successfully completed......................................
2025-04-19 22:28:20,289:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:20,289:INFO:Creating metrics dataframe
2025-04-19 22:28:20,304:INFO:Initializing SVM - Linear Kernel
2025-04-19 22:28:20,304:INFO:Total runtime is 0.5095832665761312 minutes
2025-04-19 22:28:20,310:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:20,310:INFO:Initializing create_model()
2025-04-19 22:28:20,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:20,310:INFO:Checking exceptions
2025-04-19 22:28:20,312:INFO:Importing libraries
2025-04-19 22:28:20,312:INFO:Copying training dataset
2025-04-19 22:28:20,322:INFO:Defining folds
2025-04-19 22:28:20,322:INFO:Declaring metric variables
2025-04-19 22:28:20,329:INFO:Importing untrained model
2025-04-19 22:28:20,336:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 22:28:20,348:INFO:Starting cross validation
2025-04-19 22:28:20,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:21,225:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,226:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,226:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,228:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,232:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,250:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,255:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,283:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,289:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:21,292:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:28:25,014:INFO:Calculating mean and std
2025-04-19 22:28:25,017:INFO:Creating metrics dataframe
2025-04-19 22:28:25,529:INFO:Uploading results into container
2025-04-19 22:28:25,531:INFO:Uploading model into container now
2025-04-19 22:28:25,532:INFO:_master_model_container: 5
2025-04-19 22:28:25,532:INFO:_display_container: 2
2025-04-19 22:28:25,534:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=11058, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 22:28:25,534:INFO:create_model() successfully completed......................................
2025-04-19 22:28:25,703:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:25,703:INFO:Creating metrics dataframe
2025-04-19 22:28:25,725:INFO:Initializing Ridge Classifier
2025-04-19 22:28:25,727:INFO:Total runtime is 0.5999550938606262 minutes
2025-04-19 22:28:25,733:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:25,735:INFO:Initializing create_model()
2025-04-19 22:28:25,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:25,735:INFO:Checking exceptions
2025-04-19 22:28:25,735:INFO:Importing libraries
2025-04-19 22:28:25,735:INFO:Copying training dataset
2025-04-19 22:28:25,748:INFO:Defining folds
2025-04-19 22:28:25,748:INFO:Declaring metric variables
2025-04-19 22:28:25,786:INFO:Importing untrained model
2025-04-19 22:28:25,799:INFO:Ridge Classifier Imported successfully
2025-04-19 22:28:25,815:INFO:Starting cross validation
2025-04-19 22:28:25,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:26,598:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,606:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,615:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,626:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,639:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,644:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,645:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,650:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,682:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:26,689:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:28:30,417:INFO:Calculating mean and std
2025-04-19 22:28:30,419:INFO:Creating metrics dataframe
2025-04-19 22:28:30,929:INFO:Uploading results into container
2025-04-19 22:28:30,929:INFO:Uploading model into container now
2025-04-19 22:28:30,931:INFO:_master_model_container: 6
2025-04-19 22:28:30,931:INFO:_display_container: 2
2025-04-19 22:28:30,933:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=11058,
                solver='auto', tol=0.0001)
2025-04-19 22:28:30,933:INFO:create_model() successfully completed......................................
2025-04-19 22:28:31,066:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:31,067:INFO:Creating metrics dataframe
2025-04-19 22:28:31,084:INFO:Initializing Random Forest Classifier
2025-04-19 22:28:31,084:INFO:Total runtime is 0.6892478267351786 minutes
2025-04-19 22:28:31,091:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:31,092:INFO:Initializing create_model()
2025-04-19 22:28:31,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:31,092:INFO:Checking exceptions
2025-04-19 22:28:31,093:INFO:Importing libraries
2025-04-19 22:28:31,093:INFO:Copying training dataset
2025-04-19 22:28:31,105:INFO:Defining folds
2025-04-19 22:28:31,105:INFO:Declaring metric variables
2025-04-19 22:28:31,113:INFO:Importing untrained model
2025-04-19 22:28:31,121:INFO:Random Forest Classifier Imported successfully
2025-04-19 22:28:31,134:INFO:Starting cross validation
2025-04-19 22:28:31,138:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:37,394:INFO:Calculating mean and std
2025-04-19 22:28:37,396:INFO:Creating metrics dataframe
2025-04-19 22:28:37,935:INFO:Uploading results into container
2025-04-19 22:28:37,936:INFO:Uploading model into container now
2025-04-19 22:28:37,937:INFO:_master_model_container: 7
2025-04-19 22:28:37,937:INFO:_display_container: 2
2025-04-19 22:28:37,937:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=11058, verbose=0, warm_start=False)
2025-04-19 22:28:37,938:INFO:create_model() successfully completed......................................
2025-04-19 22:28:38,074:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:38,074:INFO:Creating metrics dataframe
2025-04-19 22:28:38,095:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 22:28:38,095:INFO:Total runtime is 0.8061030666033426 minutes
2025-04-19 22:28:38,101:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:38,103:INFO:Initializing create_model()
2025-04-19 22:28:38,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:38,103:INFO:Checking exceptions
2025-04-19 22:28:38,103:INFO:Importing libraries
2025-04-19 22:28:38,103:INFO:Copying training dataset
2025-04-19 22:28:38,111:INFO:Defining folds
2025-04-19 22:28:38,113:INFO:Declaring metric variables
2025-04-19 22:28:38,120:INFO:Importing untrained model
2025-04-19 22:28:38,126:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 22:28:38,140:INFO:Starting cross validation
2025-04-19 22:28:38,144:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:38,526:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,536:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,546:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,556:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,560:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,565:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,585:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,592:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,612:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:38,612:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:28:41,944:INFO:Calculating mean and std
2025-04-19 22:28:41,946:INFO:Creating metrics dataframe
2025-04-19 22:28:42,274:INFO:Uploading results into container
2025-04-19 22:28:42,275:INFO:Uploading model into container now
2025-04-19 22:28:42,276:INFO:_master_model_container: 8
2025-04-19 22:28:42,276:INFO:_display_container: 2
2025-04-19 22:28:42,276:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 22:28:42,276:INFO:create_model() successfully completed......................................
2025-04-19 22:28:42,394:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:42,394:INFO:Creating metrics dataframe
2025-04-19 22:28:42,404:INFO:Initializing Ada Boost Classifier
2025-04-19 22:28:42,404:INFO:Total runtime is 0.877917726834615 minutes
2025-04-19 22:28:42,409:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:42,409:INFO:Initializing create_model()
2025-04-19 22:28:42,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:42,409:INFO:Checking exceptions
2025-04-19 22:28:42,409:INFO:Importing libraries
2025-04-19 22:28:42,409:INFO:Copying training dataset
2025-04-19 22:28:42,414:INFO:Defining folds
2025-04-19 22:28:42,414:INFO:Declaring metric variables
2025-04-19 22:28:42,418:INFO:Importing untrained model
2025-04-19 22:28:42,421:INFO:Ada Boost Classifier Imported successfully
2025-04-19 22:28:42,428:INFO:Starting cross validation
2025-04-19 22:28:42,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:45,910:INFO:Calculating mean and std
2025-04-19 22:28:45,911:INFO:Creating metrics dataframe
2025-04-19 22:28:46,250:INFO:Uploading results into container
2025-04-19 22:28:46,252:INFO:Uploading model into container now
2025-04-19 22:28:46,252:INFO:_master_model_container: 9
2025-04-19 22:28:46,252:INFO:_display_container: 2
2025-04-19 22:28:46,252:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=11058)
2025-04-19 22:28:46,252:INFO:create_model() successfully completed......................................
2025-04-19 22:28:46,365:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:46,365:INFO:Creating metrics dataframe
2025-04-19 22:28:46,376:INFO:Initializing Gradient Boosting Classifier
2025-04-19 22:28:46,376:INFO:Total runtime is 0.9441142400105793 minutes
2025-04-19 22:28:46,380:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:46,380:INFO:Initializing create_model()
2025-04-19 22:28:46,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:46,380:INFO:Checking exceptions
2025-04-19 22:28:46,380:INFO:Importing libraries
2025-04-19 22:28:46,380:INFO:Copying training dataset
2025-04-19 22:28:46,385:INFO:Defining folds
2025-04-19 22:28:46,385:INFO:Declaring metric variables
2025-04-19 22:28:46,388:INFO:Importing untrained model
2025-04-19 22:28:46,393:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 22:28:46,399:INFO:Starting cross validation
2025-04-19 22:28:46,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:50,720:INFO:Calculating mean and std
2025-04-19 22:28:50,721:INFO:Creating metrics dataframe
2025-04-19 22:28:51,078:INFO:Uploading results into container
2025-04-19 22:28:51,079:INFO:Uploading model into container now
2025-04-19 22:28:51,079:INFO:_master_model_container: 10
2025-04-19 22:28:51,079:INFO:_display_container: 2
2025-04-19 22:28:51,080:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=11058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:28:51,080:INFO:create_model() successfully completed......................................
2025-04-19 22:28:51,188:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:51,188:INFO:Creating metrics dataframe
2025-04-19 22:28:51,198:INFO:Initializing Linear Discriminant Analysis
2025-04-19 22:28:51,198:INFO:Total runtime is 1.0244815587997436 minutes
2025-04-19 22:28:51,202:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:51,202:INFO:Initializing create_model()
2025-04-19 22:28:51,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:51,202:INFO:Checking exceptions
2025-04-19 22:28:51,202:INFO:Importing libraries
2025-04-19 22:28:51,202:INFO:Copying training dataset
2025-04-19 22:28:51,208:INFO:Defining folds
2025-04-19 22:28:51,208:INFO:Declaring metric variables
2025-04-19 22:28:51,212:INFO:Importing untrained model
2025-04-19 22:28:51,216:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 22:28:51,223:INFO:Starting cross validation
2025-04-19 22:28:51,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:54,365:INFO:Calculating mean and std
2025-04-19 22:28:54,366:INFO:Creating metrics dataframe
2025-04-19 22:28:54,729:INFO:Uploading results into container
2025-04-19 22:28:54,729:INFO:Uploading model into container now
2025-04-19 22:28:54,729:INFO:_master_model_container: 11
2025-04-19 22:28:54,729:INFO:_display_container: 2
2025-04-19 22:28:54,730:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 22:28:54,730:INFO:create_model() successfully completed......................................
2025-04-19 22:28:54,845:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:54,845:INFO:Creating metrics dataframe
2025-04-19 22:28:54,858:INFO:Initializing Extra Trees Classifier
2025-04-19 22:28:54,858:INFO:Total runtime is 1.0854837417602539 minutes
2025-04-19 22:28:54,861:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:54,862:INFO:Initializing create_model()
2025-04-19 22:28:54,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:54,862:INFO:Checking exceptions
2025-04-19 22:28:54,862:INFO:Importing libraries
2025-04-19 22:28:54,862:INFO:Copying training dataset
2025-04-19 22:28:54,869:INFO:Defining folds
2025-04-19 22:28:54,869:INFO:Declaring metric variables
2025-04-19 22:28:54,873:INFO:Importing untrained model
2025-04-19 22:28:54,877:INFO:Extra Trees Classifier Imported successfully
2025-04-19 22:28:54,885:INFO:Starting cross validation
2025-04-19 22:28:54,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:28:58,898:INFO:Calculating mean and std
2025-04-19 22:28:58,899:INFO:Creating metrics dataframe
2025-04-19 22:28:59,273:INFO:Uploading results into container
2025-04-19 22:28:59,275:INFO:Uploading model into container now
2025-04-19 22:28:59,275:INFO:_master_model_container: 12
2025-04-19 22:28:59,275:INFO:_display_container: 2
2025-04-19 22:28:59,276:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=11058, verbose=0, warm_start=False)
2025-04-19 22:28:59,276:INFO:create_model() successfully completed......................................
2025-04-19 22:28:59,381:INFO:SubProcess create_model() end ==================================
2025-04-19 22:28:59,381:INFO:Creating metrics dataframe
2025-04-19 22:28:59,394:INFO:Initializing Extreme Gradient Boosting
2025-04-19 22:28:59,394:INFO:Total runtime is 1.1610733191172282 minutes
2025-04-19 22:28:59,397:INFO:SubProcess create_model() called ==================================
2025-04-19 22:28:59,398:INFO:Initializing create_model()
2025-04-19 22:28:59,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:28:59,398:INFO:Checking exceptions
2025-04-19 22:28:59,398:INFO:Importing libraries
2025-04-19 22:28:59,398:INFO:Copying training dataset
2025-04-19 22:28:59,403:INFO:Defining folds
2025-04-19 22:28:59,404:INFO:Declaring metric variables
2025-04-19 22:28:59,408:INFO:Importing untrained model
2025-04-19 22:28:59,414:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 22:28:59,421:INFO:Starting cross validation
2025-04-19 22:28:59,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:05,281:INFO:Calculating mean and std
2025-04-19 22:29:05,283:INFO:Creating metrics dataframe
2025-04-19 22:29:05,669:INFO:Uploading results into container
2025-04-19 22:29:05,669:INFO:Uploading model into container now
2025-04-19 22:29:05,670:INFO:_master_model_container: 13
2025-04-19 22:29:05,670:INFO:_display_container: 2
2025-04-19 22:29:05,671:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 22:29:05,671:INFO:create_model() successfully completed......................................
2025-04-19 22:29:05,788:INFO:SubProcess create_model() end ==================================
2025-04-19 22:29:05,788:INFO:Creating metrics dataframe
2025-04-19 22:29:05,801:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 22:29:05,802:INFO:Total runtime is 1.2678809881210327 minutes
2025-04-19 22:29:05,806:INFO:SubProcess create_model() called ==================================
2025-04-19 22:29:05,807:INFO:Initializing create_model()
2025-04-19 22:29:05,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:05,807:INFO:Checking exceptions
2025-04-19 22:29:05,807:INFO:Importing libraries
2025-04-19 22:29:05,807:INFO:Copying training dataset
2025-04-19 22:29:05,813:INFO:Defining folds
2025-04-19 22:29:05,813:INFO:Declaring metric variables
2025-04-19 22:29:05,818:INFO:Importing untrained model
2025-04-19 22:29:05,821:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 22:29:05,826:INFO:Starting cross validation
2025-04-19 22:29:05,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:12,736:INFO:Calculating mean and std
2025-04-19 22:29:12,737:INFO:Creating metrics dataframe
2025-04-19 22:29:13,139:INFO:Uploading results into container
2025-04-19 22:29:13,139:INFO:Uploading model into container now
2025-04-19 22:29:13,140:INFO:_master_model_container: 14
2025-04-19 22:29:13,140:INFO:_display_container: 2
2025-04-19 22:29:13,141:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=11058, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 22:29:13,141:INFO:create_model() successfully completed......................................
2025-04-19 22:29:13,268:INFO:SubProcess create_model() end ==================================
2025-04-19 22:29:13,269:INFO:Creating metrics dataframe
2025-04-19 22:29:13,280:INFO:Initializing Dummy Classifier
2025-04-19 22:29:13,280:INFO:Total runtime is 1.3925192117691039 minutes
2025-04-19 22:29:13,284:INFO:SubProcess create_model() called ==================================
2025-04-19 22:29:13,284:INFO:Initializing create_model()
2025-04-19 22:29:13,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132180490>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:13,284:INFO:Checking exceptions
2025-04-19 22:29:13,284:INFO:Importing libraries
2025-04-19 22:29:13,284:INFO:Copying training dataset
2025-04-19 22:29:13,289:INFO:Defining folds
2025-04-19 22:29:13,290:INFO:Declaring metric variables
2025-04-19 22:29:13,293:INFO:Importing untrained model
2025-04-19 22:29:13,296:INFO:Dummy Classifier Imported successfully
2025-04-19 22:29:13,303:INFO:Starting cross validation
2025-04-19 22:29:13,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:13,827:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,827:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,836:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,840:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,841:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,849:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,851:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,856:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,873:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:13,942:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:29:16,823:INFO:Calculating mean and std
2025-04-19 22:29:16,825:INFO:Creating metrics dataframe
2025-04-19 22:29:17,227:INFO:Uploading results into container
2025-04-19 22:29:17,227:INFO:Uploading model into container now
2025-04-19 22:29:17,229:INFO:_master_model_container: 15
2025-04-19 22:29:17,229:INFO:_display_container: 2
2025-04-19 22:29:17,229:INFO:DummyClassifier(constant=None, random_state=11058, strategy='prior')
2025-04-19 22:29:17,229:INFO:create_model() successfully completed......................................
2025-04-19 22:29:17,335:INFO:SubProcess create_model() end ==================================
2025-04-19 22:29:17,335:INFO:Creating metrics dataframe
2025-04-19 22:29:17,358:INFO:Initializing create_model()
2025-04-19 22:29:17,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332532B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=11058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:17,358:INFO:Checking exceptions
2025-04-19 22:29:17,359:INFO:Importing libraries
2025-04-19 22:29:17,359:INFO:Copying training dataset
2025-04-19 22:29:17,363:INFO:Defining folds
2025-04-19 22:29:17,363:INFO:Declaring metric variables
2025-04-19 22:29:17,364:INFO:Importing untrained model
2025-04-19 22:29:17,364:INFO:Declaring custom model
2025-04-19 22:29:17,364:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 22:29:17,365:INFO:Cross validation set to False
2025-04-19 22:29:17,366:INFO:Fitting Model
2025-04-19 22:29:18,706:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=11058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:29:18,706:INFO:create_model() successfully completed......................................
2025-04-19 22:29:18,855:INFO:_master_model_container: 15
2025-04-19 22:29:18,855:INFO:_display_container: 2
2025-04-19 22:29:18,855:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=11058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:29:18,856:INFO:compare_models() successfully completed......................................
2025-04-19 22:29:32,481:INFO:PyCaret ClassificationExperiment
2025-04-19 22:29:32,481:INFO:Logging name: clf-default-name
2025-04-19 22:29:32,481:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 22:29:32,481:INFO:version 3.0.4
2025-04-19 22:29:32,481:INFO:Initializing setup()
2025-04-19 22:29:32,481:INFO:self.USI: 227e
2025-04-19 22:29:32,481:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 22:29:32,481:INFO:Checking environment
2025-04-19 22:29:32,481:INFO:python_version: 3.10.5
2025-04-19 22:29:32,481:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 22:29:32,481:INFO:machine: AMD64
2025-04-19 22:29:32,481:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 22:29:32,489:INFO:Memory: svmem(total=25042907136, available=10124931072, percent=59.6, used=14917976064, free=10124931072)
2025-04-19 22:29:32,489:INFO:Physical Core: 6
2025-04-19 22:29:32,489:INFO:Logical Core: 12
2025-04-19 22:29:32,489:INFO:Checking libraries
2025-04-19 22:29:32,489:INFO:System:
2025-04-19 22:29:32,489:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 22:29:32,489:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 22:29:32,489:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 22:29:32,489:INFO:PyCaret required dependencies:
2025-04-19 22:29:32,489:INFO:                 pip: 25.0.1
2025-04-19 22:29:32,489:INFO:          setuptools: 58.1.0
2025-04-19 22:29:32,489:INFO:             pycaret: 3.0.4
2025-04-19 22:29:32,489:INFO:             IPython: 8.29.0
2025-04-19 22:29:32,489:INFO:          ipywidgets: 8.1.6
2025-04-19 22:29:32,489:INFO:                tqdm: 4.67.1
2025-04-19 22:29:32,489:INFO:               numpy: 1.23.5
2025-04-19 22:29:32,489:INFO:              pandas: 1.5.3
2025-04-19 22:29:32,489:INFO:              jinja2: 3.1.4
2025-04-19 22:29:32,490:INFO:               scipy: 1.11.4
2025-04-19 22:29:32,490:INFO:              joblib: 1.3.2
2025-04-19 22:29:32,490:INFO:             sklearn: 1.2.2
2025-04-19 22:29:32,490:INFO:                pyod: 2.0.4
2025-04-19 22:29:32,490:INFO:            imblearn: 0.10.1
2025-04-19 22:29:32,490:INFO:   category_encoders: 2.7.0
2025-04-19 22:29:32,490:INFO:            lightgbm: 4.6.0
2025-04-19 22:29:32,490:INFO:               numba: 0.60.0
2025-04-19 22:29:32,490:INFO:            requests: 2.32.3
2025-04-19 22:29:32,490:INFO:          matplotlib: 3.7.5
2025-04-19 22:29:32,490:INFO:          scikitplot: 0.3.7
2025-04-19 22:29:32,490:INFO:         yellowbrick: 1.5
2025-04-19 22:29:32,490:INFO:              plotly: 5.24.1
2025-04-19 22:29:32,490:INFO:    plotly-resampler: Not installed
2025-04-19 22:29:32,490:INFO:             kaleido: 0.2.1
2025-04-19 22:29:32,490:INFO:           schemdraw: 0.15
2025-04-19 22:29:32,490:INFO:         statsmodels: 0.14.4
2025-04-19 22:29:32,490:INFO:              sktime: 0.26.0
2025-04-19 22:29:32,490:INFO:               tbats: 1.1.3
2025-04-19 22:29:32,490:INFO:            pmdarima: 2.0.4
2025-04-19 22:29:32,490:INFO:              psutil: 6.1.0
2025-04-19 22:29:32,490:INFO:          markupsafe: 3.0.2
2025-04-19 22:29:32,490:INFO:             pickle5: Not installed
2025-04-19 22:29:32,491:INFO:         cloudpickle: 3.1.1
2025-04-19 22:29:32,491:INFO:         deprecation: 2.1.0
2025-04-19 22:29:32,491:INFO:              xxhash: 3.5.0
2025-04-19 22:29:32,491:INFO:           wurlitzer: Not installed
2025-04-19 22:29:32,491:INFO:PyCaret optional dependencies:
2025-04-19 22:29:32,491:INFO:                shap: Not installed
2025-04-19 22:29:32,491:INFO:           interpret: Not installed
2025-04-19 22:29:32,491:INFO:                umap: Not installed
2025-04-19 22:29:32,491:INFO:    pandas_profiling: Not installed
2025-04-19 22:29:32,491:INFO:  explainerdashboard: Not installed
2025-04-19 22:29:32,491:INFO:             autoviz: Not installed
2025-04-19 22:29:32,491:INFO:           fairlearn: Not installed
2025-04-19 22:29:32,491:INFO:          deepchecks: Not installed
2025-04-19 22:29:32,491:INFO:             xgboost: 1.7.6
2025-04-19 22:29:32,491:INFO:            catboost: Not installed
2025-04-19 22:29:32,491:INFO:              kmodes: Not installed
2025-04-19 22:29:32,491:INFO:             mlxtend: Not installed
2025-04-19 22:29:32,491:INFO:       statsforecast: Not installed
2025-04-19 22:29:32,492:INFO:        tune_sklearn: Not installed
2025-04-19 22:29:32,492:INFO:                 ray: Not installed
2025-04-19 22:29:32,492:INFO:            hyperopt: Not installed
2025-04-19 22:29:32,492:INFO:              optuna: Not installed
2025-04-19 22:29:32,492:INFO:               skopt: Not installed
2025-04-19 22:29:32,492:INFO:              mlflow: Not installed
2025-04-19 22:29:32,492:INFO:              gradio: Not installed
2025-04-19 22:29:32,492:INFO:             fastapi: Not installed
2025-04-19 22:29:32,492:INFO:             uvicorn: Not installed
2025-04-19 22:29:32,492:INFO:              m2cgen: Not installed
2025-04-19 22:29:32,492:INFO:           evidently: Not installed
2025-04-19 22:29:32,492:INFO:               fugue: Not installed
2025-04-19 22:29:32,492:INFO:           streamlit: 1.42.0
2025-04-19 22:29:32,492:INFO:             prophet: Not installed
2025-04-19 22:29:32,492:INFO:None
2025-04-19 22:29:32,492:INFO:Set up data.
2025-04-19 22:29:32,503:INFO:Set up train/test split.
2025-04-19 22:29:32,509:INFO:Set up index.
2025-04-19 22:29:32,510:INFO:Set up folding strategy.
2025-04-19 22:29:32,510:INFO:Assigning column types.
2025-04-19 22:29:32,513:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 22:29:32,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:29:32,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:29:32,581:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:29:32,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:29:32,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:29:32,624:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:29:32,652:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:29:32,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:29:32,655:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 22:29:32,705:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:29:32,740:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:29:32,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:29:32,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:29:32,816:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:29:32,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:29:32,819:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 22:29:32,892:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:29:32,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:29:32,964:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:29:32,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:29:32,968:INFO:Preparing preprocessing pipeline...
2025-04-19 22:29:32,968:INFO:Set up simple imputation.
2025-04-19 22:29:32,972:INFO:Set up encoding of ordinal features.
2025-04-19 22:29:32,974:INFO:Set up encoding of categorical features.
2025-04-19 22:29:32,974:INFO:Set up imbalanced handling.
2025-04-19 22:29:32,974:INFO:Set up feature normalization.
2025-04-19 22:29:33,138:INFO:Finished creating preprocessing pipeline.
2025-04-19 22:29:33,166:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'P...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 22:29:33,167:INFO:Creating final display dataframe.
2025-04-19 22:29:33,579:INFO:Setup _display_container:                     Description             Value
0                    Session id              1058
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 35)
4        Transformed data shape        (1548, 53)
5   Transformed train set shape        (1230, 53)
6    Transformed test set shape         (318, 53)
7               Ignore features                 1
8              Ordinal features                 2
9              Numeric features                25
10         Categorical features                 8
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              227e
2025-04-19 22:29:33,652:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:29:33,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:29:33,730:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:29:33,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:29:33,733:INFO:setup() successfully completed in 1.54s...............
2025-04-19 22:29:36,924:INFO:Initializing compare_models()
2025-04-19 22:29:36,924:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 22:29:36,924:INFO:Checking exceptions
2025-04-19 22:29:36,927:INFO:Preparing display monitor
2025-04-19 22:29:36,950:INFO:Initializing Logistic Regression
2025-04-19 22:29:36,950:INFO:Total runtime is 0.0 minutes
2025-04-19 22:29:36,952:INFO:SubProcess create_model() called ==================================
2025-04-19 22:29:36,952:INFO:Initializing create_model()
2025-04-19 22:29:36,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:36,953:INFO:Checking exceptions
2025-04-19 22:29:36,953:INFO:Importing libraries
2025-04-19 22:29:36,954:INFO:Copying training dataset
2025-04-19 22:29:36,958:INFO:Defining folds
2025-04-19 22:29:36,958:INFO:Declaring metric variables
2025-04-19 22:29:36,961:INFO:Importing untrained model
2025-04-19 22:29:36,966:INFO:Logistic Regression Imported successfully
2025-04-19 22:29:36,973:INFO:Starting cross validation
2025-04-19 22:29:36,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:40,607:INFO:Calculating mean and std
2025-04-19 22:29:40,608:INFO:Creating metrics dataframe
2025-04-19 22:29:41,019:INFO:Uploading results into container
2025-04-19 22:29:41,020:INFO:Uploading model into container now
2025-04-19 22:29:41,020:INFO:_master_model_container: 1
2025-04-19 22:29:41,021:INFO:_display_container: 2
2025-04-19 22:29:41,021:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1058, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 22:29:41,021:INFO:create_model() successfully completed......................................
2025-04-19 22:29:41,135:INFO:SubProcess create_model() end ==================================
2025-04-19 22:29:41,135:INFO:Creating metrics dataframe
2025-04-19 22:29:41,143:INFO:Initializing K Neighbors Classifier
2025-04-19 22:29:41,143:INFO:Total runtime is 0.0698862353960673 minutes
2025-04-19 22:29:41,148:INFO:SubProcess create_model() called ==================================
2025-04-19 22:29:41,149:INFO:Initializing create_model()
2025-04-19 22:29:41,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:41,149:INFO:Checking exceptions
2025-04-19 22:29:41,149:INFO:Importing libraries
2025-04-19 22:29:41,149:INFO:Copying training dataset
2025-04-19 22:29:41,156:INFO:Defining folds
2025-04-19 22:29:41,157:INFO:Declaring metric variables
2025-04-19 22:29:41,161:INFO:Importing untrained model
2025-04-19 22:29:41,164:INFO:K Neighbors Classifier Imported successfully
2025-04-19 22:29:41,172:INFO:Starting cross validation
2025-04-19 22:29:41,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:44,887:INFO:Calculating mean and std
2025-04-19 22:29:44,888:INFO:Creating metrics dataframe
2025-04-19 22:29:45,298:INFO:Uploading results into container
2025-04-19 22:29:45,299:INFO:Uploading model into container now
2025-04-19 22:29:45,299:INFO:_master_model_container: 2
2025-04-19 22:29:45,299:INFO:_display_container: 2
2025-04-19 22:29:45,299:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 22:29:45,299:INFO:create_model() successfully completed......................................
2025-04-19 22:29:45,428:INFO:SubProcess create_model() end ==================================
2025-04-19 22:29:45,428:INFO:Creating metrics dataframe
2025-04-19 22:29:45,441:INFO:Initializing Naive Bayes
2025-04-19 22:29:45,441:INFO:Total runtime is 0.1415131409962972 minutes
2025-04-19 22:29:45,445:INFO:SubProcess create_model() called ==================================
2025-04-19 22:29:45,445:INFO:Initializing create_model()
2025-04-19 22:29:45,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:45,446:INFO:Checking exceptions
2025-04-19 22:29:45,446:INFO:Importing libraries
2025-04-19 22:29:45,446:INFO:Copying training dataset
2025-04-19 22:29:45,452:INFO:Defining folds
2025-04-19 22:29:45,452:INFO:Declaring metric variables
2025-04-19 22:29:45,457:INFO:Importing untrained model
2025-04-19 22:29:45,460:INFO:Naive Bayes Imported successfully
2025-04-19 22:29:45,466:INFO:Starting cross validation
2025-04-19 22:29:45,468:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:49,164:INFO:Calculating mean and std
2025-04-19 22:29:49,165:INFO:Creating metrics dataframe
2025-04-19 22:29:49,582:INFO:Uploading results into container
2025-04-19 22:29:49,583:INFO:Uploading model into container now
2025-04-19 22:29:49,583:INFO:_master_model_container: 3
2025-04-19 22:29:49,583:INFO:_display_container: 2
2025-04-19 22:29:49,583:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 22:29:49,583:INFO:create_model() successfully completed......................................
2025-04-19 22:29:49,690:INFO:SubProcess create_model() end ==================================
2025-04-19 22:29:49,691:INFO:Creating metrics dataframe
2025-04-19 22:29:49,700:INFO:Initializing Decision Tree Classifier
2025-04-19 22:29:49,700:INFO:Total runtime is 0.21249987681706745 minutes
2025-04-19 22:29:49,702:INFO:SubProcess create_model() called ==================================
2025-04-19 22:29:49,702:INFO:Initializing create_model()
2025-04-19 22:29:49,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:49,703:INFO:Checking exceptions
2025-04-19 22:29:49,703:INFO:Importing libraries
2025-04-19 22:29:49,703:INFO:Copying training dataset
2025-04-19 22:29:49,707:INFO:Defining folds
2025-04-19 22:29:49,707:INFO:Declaring metric variables
2025-04-19 22:29:49,712:INFO:Importing untrained model
2025-04-19 22:29:49,714:INFO:Decision Tree Classifier Imported successfully
2025-04-19 22:29:49,720:INFO:Starting cross validation
2025-04-19 22:29:49,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:53,557:INFO:Calculating mean and std
2025-04-19 22:29:53,558:INFO:Creating metrics dataframe
2025-04-19 22:29:53,998:INFO:Uploading results into container
2025-04-19 22:29:53,999:INFO:Uploading model into container now
2025-04-19 22:29:53,999:INFO:_master_model_container: 4
2025-04-19 22:29:53,999:INFO:_display_container: 2
2025-04-19 22:29:53,999:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1058, splitter='best')
2025-04-19 22:29:54,000:INFO:create_model() successfully completed......................................
2025-04-19 22:29:54,105:INFO:SubProcess create_model() end ==================================
2025-04-19 22:29:54,105:INFO:Creating metrics dataframe
2025-04-19 22:29:54,115:INFO:Initializing SVM - Linear Kernel
2025-04-19 22:29:54,115:INFO:Total runtime is 0.2860759099324544 minutes
2025-04-19 22:29:54,118:INFO:SubProcess create_model() called ==================================
2025-04-19 22:29:54,118:INFO:Initializing create_model()
2025-04-19 22:29:54,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:54,118:INFO:Checking exceptions
2025-04-19 22:29:54,118:INFO:Importing libraries
2025-04-19 22:29:54,119:INFO:Copying training dataset
2025-04-19 22:29:54,123:INFO:Defining folds
2025-04-19 22:29:54,124:INFO:Declaring metric variables
2025-04-19 22:29:54,127:INFO:Importing untrained model
2025-04-19 22:29:54,131:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 22:29:54,136:INFO:Starting cross validation
2025-04-19 22:29:54,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:54,579:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,731:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,732:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,763:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,780:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,782:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,809:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,814:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,815:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:54,823:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:29:57,828:INFO:Calculating mean and std
2025-04-19 22:29:57,829:INFO:Creating metrics dataframe
2025-04-19 22:29:58,239:INFO:Uploading results into container
2025-04-19 22:29:58,240:INFO:Uploading model into container now
2025-04-19 22:29:58,240:INFO:_master_model_container: 5
2025-04-19 22:29:58,240:INFO:_display_container: 2
2025-04-19 22:29:58,240:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1058, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 22:29:58,240:INFO:create_model() successfully completed......................................
2025-04-19 22:29:58,350:INFO:SubProcess create_model() end ==================================
2025-04-19 22:29:58,352:INFO:Creating metrics dataframe
2025-04-19 22:29:58,362:INFO:Initializing Ridge Classifier
2025-04-19 22:29:58,362:INFO:Total runtime is 0.3568590561548869 minutes
2025-04-19 22:29:58,366:INFO:SubProcess create_model() called ==================================
2025-04-19 22:29:58,367:INFO:Initializing create_model()
2025-04-19 22:29:58,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:29:58,367:INFO:Checking exceptions
2025-04-19 22:29:58,367:INFO:Importing libraries
2025-04-19 22:29:58,367:INFO:Copying training dataset
2025-04-19 22:29:58,373:INFO:Defining folds
2025-04-19 22:29:58,373:INFO:Declaring metric variables
2025-04-19 22:29:58,377:INFO:Importing untrained model
2025-04-19 22:29:58,381:INFO:Ridge Classifier Imported successfully
2025-04-19 22:29:58,389:INFO:Starting cross validation
2025-04-19 22:29:58,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:29:58,809:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:58,949:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:58,974:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:58,995:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:58,995:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:59,064:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:59,064:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:59,067:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:59,078:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:29:59,092:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:30:02,047:INFO:Calculating mean and std
2025-04-19 22:30:02,048:INFO:Creating metrics dataframe
2025-04-19 22:30:02,497:INFO:Uploading results into container
2025-04-19 22:30:02,498:INFO:Uploading model into container now
2025-04-19 22:30:02,498:INFO:_master_model_container: 6
2025-04-19 22:30:02,498:INFO:_display_container: 2
2025-04-19 22:30:02,498:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1058, solver='auto',
                tol=0.0001)
2025-04-19 22:30:02,499:INFO:create_model() successfully completed......................................
2025-04-19 22:30:02,622:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:02,622:INFO:Creating metrics dataframe
2025-04-19 22:30:02,635:INFO:Initializing Random Forest Classifier
2025-04-19 22:30:02,635:INFO:Total runtime is 0.42808540662129724 minutes
2025-04-19 22:30:02,638:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:02,639:INFO:Initializing create_model()
2025-04-19 22:30:02,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:02,639:INFO:Checking exceptions
2025-04-19 22:30:02,639:INFO:Importing libraries
2025-04-19 22:30:02,639:INFO:Copying training dataset
2025-04-19 22:30:02,644:INFO:Defining folds
2025-04-19 22:30:02,644:INFO:Declaring metric variables
2025-04-19 22:30:02,648:INFO:Importing untrained model
2025-04-19 22:30:02,652:INFO:Random Forest Classifier Imported successfully
2025-04-19 22:30:02,659:INFO:Starting cross validation
2025-04-19 22:30:02,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:07,426:INFO:Calculating mean and std
2025-04-19 22:30:07,427:INFO:Creating metrics dataframe
2025-04-19 22:30:07,888:INFO:Uploading results into container
2025-04-19 22:30:07,888:INFO:Uploading model into container now
2025-04-19 22:30:07,889:INFO:_master_model_container: 7
2025-04-19 22:30:07,889:INFO:_display_container: 2
2025-04-19 22:30:07,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:30:07,890:INFO:create_model() successfully completed......................................
2025-04-19 22:30:08,000:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:08,000:INFO:Creating metrics dataframe
2025-04-19 22:30:08,011:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 22:30:08,011:INFO:Total runtime is 0.5176905910174052 minutes
2025-04-19 22:30:08,014:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:08,015:INFO:Initializing create_model()
2025-04-19 22:30:08,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:08,015:INFO:Checking exceptions
2025-04-19 22:30:08,015:INFO:Importing libraries
2025-04-19 22:30:08,015:INFO:Copying training dataset
2025-04-19 22:30:08,020:INFO:Defining folds
2025-04-19 22:30:08,020:INFO:Declaring metric variables
2025-04-19 22:30:08,024:INFO:Importing untrained model
2025-04-19 22:30:08,028:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 22:30:08,035:INFO:Starting cross validation
2025-04-19 22:30:08,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:08,340:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,341:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,347:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,357:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,371:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,375:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,379:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,382:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,384:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:08,396:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:30:12,032:INFO:Calculating mean and std
2025-04-19 22:30:12,033:INFO:Creating metrics dataframe
2025-04-19 22:30:12,503:INFO:Uploading results into container
2025-04-19 22:30:12,504:INFO:Uploading model into container now
2025-04-19 22:30:12,505:INFO:_master_model_container: 8
2025-04-19 22:30:12,505:INFO:_display_container: 2
2025-04-19 22:30:12,505:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 22:30:12,505:INFO:create_model() successfully completed......................................
2025-04-19 22:30:12,614:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:12,614:INFO:Creating metrics dataframe
2025-04-19 22:30:12,628:INFO:Initializing Ada Boost Classifier
2025-04-19 22:30:12,628:INFO:Total runtime is 0.5946334679921468 minutes
2025-04-19 22:30:12,632:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:12,632:INFO:Initializing create_model()
2025-04-19 22:30:12,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:12,632:INFO:Checking exceptions
2025-04-19 22:30:12,632:INFO:Importing libraries
2025-04-19 22:30:12,632:INFO:Copying training dataset
2025-04-19 22:30:12,639:INFO:Defining folds
2025-04-19 22:30:12,639:INFO:Declaring metric variables
2025-04-19 22:30:12,643:INFO:Importing untrained model
2025-04-19 22:30:12,647:INFO:Ada Boost Classifier Imported successfully
2025-04-19 22:30:12,653:INFO:Starting cross validation
2025-04-19 22:30:12,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:17,313:INFO:Calculating mean and std
2025-04-19 22:30:17,314:INFO:Creating metrics dataframe
2025-04-19 22:30:17,776:INFO:Uploading results into container
2025-04-19 22:30:17,777:INFO:Uploading model into container now
2025-04-19 22:30:17,777:INFO:_master_model_container: 9
2025-04-19 22:30:17,777:INFO:_display_container: 2
2025-04-19 22:30:17,778:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1058)
2025-04-19 22:30:17,778:INFO:create_model() successfully completed......................................
2025-04-19 22:30:17,898:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:17,898:INFO:Creating metrics dataframe
2025-04-19 22:30:17,911:INFO:Initializing Gradient Boosting Classifier
2025-04-19 22:30:17,911:INFO:Total runtime is 0.6826893250147501 minutes
2025-04-19 22:30:17,916:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:17,916:INFO:Initializing create_model()
2025-04-19 22:30:17,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:17,916:INFO:Checking exceptions
2025-04-19 22:30:17,916:INFO:Importing libraries
2025-04-19 22:30:17,917:INFO:Copying training dataset
2025-04-19 22:30:17,922:INFO:Defining folds
2025-04-19 22:30:17,922:INFO:Declaring metric variables
2025-04-19 22:30:17,927:INFO:Importing untrained model
2025-04-19 22:30:17,929:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 22:30:17,937:INFO:Starting cross validation
2025-04-19 22:30:17,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:23,380:INFO:Calculating mean and std
2025-04-19 22:30:23,382:INFO:Creating metrics dataframe
2025-04-19 22:30:23,867:INFO:Uploading results into container
2025-04-19 22:30:23,867:INFO:Uploading model into container now
2025-04-19 22:30:23,868:INFO:_master_model_container: 10
2025-04-19 22:30:23,868:INFO:_display_container: 2
2025-04-19 22:30:23,869:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:30:23,869:INFO:create_model() successfully completed......................................
2025-04-19 22:30:23,973:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:23,974:INFO:Creating metrics dataframe
2025-04-19 22:30:23,984:INFO:Initializing Linear Discriminant Analysis
2025-04-19 22:30:23,984:INFO:Total runtime is 0.7839024225870768 minutes
2025-04-19 22:30:23,988:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:23,989:INFO:Initializing create_model()
2025-04-19 22:30:23,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:23,989:INFO:Checking exceptions
2025-04-19 22:30:23,989:INFO:Importing libraries
2025-04-19 22:30:23,989:INFO:Copying training dataset
2025-04-19 22:30:23,994:INFO:Defining folds
2025-04-19 22:30:23,994:INFO:Declaring metric variables
2025-04-19 22:30:23,998:INFO:Importing untrained model
2025-04-19 22:30:24,002:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 22:30:24,007:INFO:Starting cross validation
2025-04-19 22:30:24,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:28,383:INFO:Calculating mean and std
2025-04-19 22:30:28,384:INFO:Creating metrics dataframe
2025-04-19 22:30:28,891:INFO:Uploading results into container
2025-04-19 22:30:28,891:INFO:Uploading model into container now
2025-04-19 22:30:28,892:INFO:_master_model_container: 11
2025-04-19 22:30:28,892:INFO:_display_container: 2
2025-04-19 22:30:28,893:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 22:30:28,893:INFO:create_model() successfully completed......................................
2025-04-19 22:30:29,017:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:29,017:INFO:Creating metrics dataframe
2025-04-19 22:30:29,030:INFO:Initializing Extra Trees Classifier
2025-04-19 22:30:29,030:INFO:Total runtime is 0.8679927031199137 minutes
2025-04-19 22:30:29,034:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:29,035:INFO:Initializing create_model()
2025-04-19 22:30:29,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:29,035:INFO:Checking exceptions
2025-04-19 22:30:29,035:INFO:Importing libraries
2025-04-19 22:30:29,035:INFO:Copying training dataset
2025-04-19 22:30:29,042:INFO:Defining folds
2025-04-19 22:30:29,042:INFO:Declaring metric variables
2025-04-19 22:30:29,048:INFO:Importing untrained model
2025-04-19 22:30:29,052:INFO:Extra Trees Classifier Imported successfully
2025-04-19 22:30:29,060:INFO:Starting cross validation
2025-04-19 22:30:29,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:34,081:INFO:Calculating mean and std
2025-04-19 22:30:34,081:INFO:Creating metrics dataframe
2025-04-19 22:30:34,581:INFO:Uploading results into container
2025-04-19 22:30:34,582:INFO:Uploading model into container now
2025-04-19 22:30:34,582:INFO:_master_model_container: 12
2025-04-19 22:30:34,582:INFO:_display_container: 2
2025-04-19 22:30:34,583:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:30:34,583:INFO:create_model() successfully completed......................................
2025-04-19 22:30:34,685:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:34,685:INFO:Creating metrics dataframe
2025-04-19 22:30:34,696:INFO:Initializing Extreme Gradient Boosting
2025-04-19 22:30:34,696:INFO:Total runtime is 0.9624355435371399 minutes
2025-04-19 22:30:34,701:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:34,701:INFO:Initializing create_model()
2025-04-19 22:30:34,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:34,701:INFO:Checking exceptions
2025-04-19 22:30:34,701:INFO:Importing libraries
2025-04-19 22:30:34,701:INFO:Copying training dataset
2025-04-19 22:30:34,706:INFO:Defining folds
2025-04-19 22:30:34,706:INFO:Declaring metric variables
2025-04-19 22:30:34,710:INFO:Importing untrained model
2025-04-19 22:30:34,714:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 22:30:34,719:INFO:Starting cross validation
2025-04-19 22:30:34,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:39,855:INFO:Calculating mean and std
2025-04-19 22:30:39,857:INFO:Creating metrics dataframe
2025-04-19 22:30:40,367:INFO:Uploading results into container
2025-04-19 22:30:40,367:INFO:Uploading model into container now
2025-04-19 22:30:40,368:INFO:_master_model_container: 13
2025-04-19 22:30:40,368:INFO:_display_container: 2
2025-04-19 22:30:40,369:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 22:30:40,369:INFO:create_model() successfully completed......................................
2025-04-19 22:30:40,474:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:40,474:INFO:Creating metrics dataframe
2025-04-19 22:30:40,487:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 22:30:40,487:INFO:Total runtime is 1.0589414993921915 minutes
2025-04-19 22:30:40,489:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:40,489:INFO:Initializing create_model()
2025-04-19 22:30:40,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:40,489:INFO:Checking exceptions
2025-04-19 22:30:40,491:INFO:Importing libraries
2025-04-19 22:30:40,491:INFO:Copying training dataset
2025-04-19 22:30:40,496:INFO:Defining folds
2025-04-19 22:30:40,496:INFO:Declaring metric variables
2025-04-19 22:30:40,499:INFO:Importing untrained model
2025-04-19 22:30:40,504:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 22:30:40,511:INFO:Starting cross validation
2025-04-19 22:30:40,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:48,643:INFO:Calculating mean and std
2025-04-19 22:30:48,645:INFO:Creating metrics dataframe
2025-04-19 22:30:49,174:INFO:Uploading results into container
2025-04-19 22:30:49,175:INFO:Uploading model into container now
2025-04-19 22:30:49,176:INFO:_master_model_container: 14
2025-04-19 22:30:49,176:INFO:_display_container: 2
2025-04-19 22:30:49,176:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1058, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 22:30:49,176:INFO:create_model() successfully completed......................................
2025-04-19 22:30:49,288:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:49,288:INFO:Creating metrics dataframe
2025-04-19 22:30:49,300:INFO:Initializing Dummy Classifier
2025-04-19 22:30:49,300:INFO:Total runtime is 1.2058369318644204 minutes
2025-04-19 22:30:49,303:INFO:SubProcess create_model() called ==================================
2025-04-19 22:30:49,305:INFO:Initializing create_model()
2025-04-19 22:30:49,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13240E1D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:49,305:INFO:Checking exceptions
2025-04-19 22:30:49,305:INFO:Importing libraries
2025-04-19 22:30:49,305:INFO:Copying training dataset
2025-04-19 22:30:49,312:INFO:Defining folds
2025-04-19 22:30:49,312:INFO:Declaring metric variables
2025-04-19 22:30:49,315:INFO:Importing untrained model
2025-04-19 22:30:49,318:INFO:Dummy Classifier Imported successfully
2025-04-19 22:30:49,326:INFO:Starting cross validation
2025-04-19 22:30:49,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:30:49,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:49,900:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:49,901:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:49,949:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:49,952:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:49,966:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:50,025:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:50,052:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:50,076:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:50,079:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:30:53,870:INFO:Calculating mean and std
2025-04-19 22:30:53,871:INFO:Creating metrics dataframe
2025-04-19 22:30:54,378:INFO:Uploading results into container
2025-04-19 22:30:54,379:INFO:Uploading model into container now
2025-04-19 22:30:54,379:INFO:_master_model_container: 15
2025-04-19 22:30:54,379:INFO:_display_container: 2
2025-04-19 22:30:54,379:INFO:DummyClassifier(constant=None, random_state=1058, strategy='prior')
2025-04-19 22:30:54,379:INFO:create_model() successfully completed......................................
2025-04-19 22:30:54,491:INFO:SubProcess create_model() end ==================================
2025-04-19 22:30:54,491:INFO:Creating metrics dataframe
2025-04-19 22:30:54,514:INFO:Initializing create_model()
2025-04-19 22:30:54,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B81C0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:30:54,514:INFO:Checking exceptions
2025-04-19 22:30:54,517:INFO:Importing libraries
2025-04-19 22:30:54,517:INFO:Copying training dataset
2025-04-19 22:30:54,523:INFO:Defining folds
2025-04-19 22:30:54,523:INFO:Declaring metric variables
2025-04-19 22:30:54,523:INFO:Importing untrained model
2025-04-19 22:30:54,523:INFO:Declaring custom model
2025-04-19 22:30:54,525:INFO:Random Forest Classifier Imported successfully
2025-04-19 22:30:54,526:INFO:Cross validation set to False
2025-04-19 22:30:54,526:INFO:Fitting Model
2025-04-19 22:30:55,388:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:30:55,388:INFO:create_model() successfully completed......................................
2025-04-19 22:30:55,523:INFO:_master_model_container: 15
2025-04-19 22:30:55,523:INFO:_display_container: 2
2025-04-19 22:30:55,525:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:30:55,525:INFO:compare_models() successfully completed......................................
2025-04-19 22:39:23,756:INFO:PyCaret ClassificationExperiment
2025-04-19 22:39:23,756:INFO:Logging name: clf-default-name
2025-04-19 22:39:23,756:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 22:39:23,756:INFO:version 3.0.4
2025-04-19 22:39:23,756:INFO:Initializing setup()
2025-04-19 22:39:23,756:INFO:self.USI: 35e4
2025-04-19 22:39:23,756:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 22:39:23,756:INFO:Checking environment
2025-04-19 22:39:23,756:INFO:python_version: 3.10.5
2025-04-19 22:39:23,756:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 22:39:23,756:INFO:machine: AMD64
2025-04-19 22:39:23,756:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 22:39:23,761:INFO:Memory: svmem(total=25042907136, available=11757072384, percent=53.1, used=13285834752, free=11757072384)
2025-04-19 22:39:23,762:INFO:Physical Core: 6
2025-04-19 22:39:23,762:INFO:Logical Core: 12
2025-04-19 22:39:23,762:INFO:Checking libraries
2025-04-19 22:39:23,762:INFO:System:
2025-04-19 22:39:23,762:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 22:39:23,762:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 22:39:23,762:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 22:39:23,762:INFO:PyCaret required dependencies:
2025-04-19 22:39:23,762:INFO:                 pip: 25.0.1
2025-04-19 22:39:23,762:INFO:          setuptools: 58.1.0
2025-04-19 22:39:23,762:INFO:             pycaret: 3.0.4
2025-04-19 22:39:23,762:INFO:             IPython: 8.29.0
2025-04-19 22:39:23,762:INFO:          ipywidgets: 8.1.6
2025-04-19 22:39:23,762:INFO:                tqdm: 4.67.1
2025-04-19 22:39:23,762:INFO:               numpy: 1.23.5
2025-04-19 22:39:23,762:INFO:              pandas: 1.5.3
2025-04-19 22:39:23,762:INFO:              jinja2: 3.1.4
2025-04-19 22:39:23,762:INFO:               scipy: 1.11.4
2025-04-19 22:39:23,762:INFO:              joblib: 1.3.2
2025-04-19 22:39:23,762:INFO:             sklearn: 1.2.2
2025-04-19 22:39:23,762:INFO:                pyod: 2.0.4
2025-04-19 22:39:23,762:INFO:            imblearn: 0.10.1
2025-04-19 22:39:23,762:INFO:   category_encoders: 2.7.0
2025-04-19 22:39:23,762:INFO:            lightgbm: 4.6.0
2025-04-19 22:39:23,762:INFO:               numba: 0.60.0
2025-04-19 22:39:23,762:INFO:            requests: 2.32.3
2025-04-19 22:39:23,763:INFO:          matplotlib: 3.7.5
2025-04-19 22:39:23,763:INFO:          scikitplot: 0.3.7
2025-04-19 22:39:23,763:INFO:         yellowbrick: 1.5
2025-04-19 22:39:23,763:INFO:              plotly: 5.24.1
2025-04-19 22:39:23,763:INFO:    plotly-resampler: Not installed
2025-04-19 22:39:23,763:INFO:             kaleido: 0.2.1
2025-04-19 22:39:23,763:INFO:           schemdraw: 0.15
2025-04-19 22:39:23,763:INFO:         statsmodels: 0.14.4
2025-04-19 22:39:23,763:INFO:              sktime: 0.26.0
2025-04-19 22:39:23,763:INFO:               tbats: 1.1.3
2025-04-19 22:39:23,763:INFO:            pmdarima: 2.0.4
2025-04-19 22:39:23,763:INFO:              psutil: 6.1.0
2025-04-19 22:39:23,763:INFO:          markupsafe: 3.0.2
2025-04-19 22:39:23,763:INFO:             pickle5: Not installed
2025-04-19 22:39:23,763:INFO:         cloudpickle: 3.1.1
2025-04-19 22:39:23,763:INFO:         deprecation: 2.1.0
2025-04-19 22:39:23,763:INFO:              xxhash: 3.5.0
2025-04-19 22:39:23,763:INFO:           wurlitzer: Not installed
2025-04-19 22:39:23,763:INFO:PyCaret optional dependencies:
2025-04-19 22:39:23,763:INFO:                shap: Not installed
2025-04-19 22:39:23,763:INFO:           interpret: Not installed
2025-04-19 22:39:23,763:INFO:                umap: Not installed
2025-04-19 22:39:23,763:INFO:    pandas_profiling: Not installed
2025-04-19 22:39:23,763:INFO:  explainerdashboard: Not installed
2025-04-19 22:39:23,763:INFO:             autoviz: Not installed
2025-04-19 22:39:23,763:INFO:           fairlearn: Not installed
2025-04-19 22:39:23,763:INFO:          deepchecks: Not installed
2025-04-19 22:39:23,763:INFO:             xgboost: 1.7.6
2025-04-19 22:39:23,763:INFO:            catboost: Not installed
2025-04-19 22:39:23,763:INFO:              kmodes: Not installed
2025-04-19 22:39:23,763:INFO:             mlxtend: Not installed
2025-04-19 22:39:23,763:INFO:       statsforecast: Not installed
2025-04-19 22:39:23,763:INFO:        tune_sklearn: Not installed
2025-04-19 22:39:23,763:INFO:                 ray: Not installed
2025-04-19 22:39:23,763:INFO:            hyperopt: Not installed
2025-04-19 22:39:23,763:INFO:              optuna: Not installed
2025-04-19 22:39:23,763:INFO:               skopt: Not installed
2025-04-19 22:39:23,763:INFO:              mlflow: Not installed
2025-04-19 22:39:23,763:INFO:              gradio: Not installed
2025-04-19 22:39:23,765:INFO:             fastapi: Not installed
2025-04-19 22:39:23,765:INFO:             uvicorn: Not installed
2025-04-19 22:39:23,765:INFO:              m2cgen: Not installed
2025-04-19 22:39:23,765:INFO:           evidently: Not installed
2025-04-19 22:39:23,765:INFO:               fugue: Not installed
2025-04-19 22:39:23,765:INFO:           streamlit: 1.42.0
2025-04-19 22:39:23,765:INFO:             prophet: Not installed
2025-04-19 22:39:23,765:INFO:None
2025-04-19 22:39:23,765:INFO:Set up data.
2025-04-19 22:39:49,174:INFO:PyCaret ClassificationExperiment
2025-04-19 22:39:49,175:INFO:Logging name: clf-default-name
2025-04-19 22:39:49,175:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 22:39:49,175:INFO:version 3.0.4
2025-04-19 22:39:49,175:INFO:Initializing setup()
2025-04-19 22:39:49,175:INFO:self.USI: 69bc
2025-04-19 22:39:49,175:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 22:39:49,175:INFO:Checking environment
2025-04-19 22:39:49,175:INFO:python_version: 3.10.5
2025-04-19 22:39:49,175:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 22:39:49,175:INFO:machine: AMD64
2025-04-19 22:39:49,175:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 22:39:49,180:INFO:Memory: svmem(total=25042907136, available=11767578624, percent=53.0, used=13275328512, free=11767578624)
2025-04-19 22:39:49,181:INFO:Physical Core: 6
2025-04-19 22:39:49,181:INFO:Logical Core: 12
2025-04-19 22:39:49,181:INFO:Checking libraries
2025-04-19 22:39:49,181:INFO:System:
2025-04-19 22:39:49,181:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 22:39:49,181:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 22:39:49,181:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 22:39:49,181:INFO:PyCaret required dependencies:
2025-04-19 22:39:49,181:INFO:                 pip: 25.0.1
2025-04-19 22:39:49,181:INFO:          setuptools: 58.1.0
2025-04-19 22:39:49,181:INFO:             pycaret: 3.0.4
2025-04-19 22:39:49,181:INFO:             IPython: 8.29.0
2025-04-19 22:39:49,181:INFO:          ipywidgets: 8.1.6
2025-04-19 22:39:49,181:INFO:                tqdm: 4.67.1
2025-04-19 22:39:49,181:INFO:               numpy: 1.23.5
2025-04-19 22:39:49,181:INFO:              pandas: 1.5.3
2025-04-19 22:39:49,181:INFO:              jinja2: 3.1.4
2025-04-19 22:39:49,181:INFO:               scipy: 1.11.4
2025-04-19 22:39:49,181:INFO:              joblib: 1.3.2
2025-04-19 22:39:49,181:INFO:             sklearn: 1.2.2
2025-04-19 22:39:49,181:INFO:                pyod: 2.0.4
2025-04-19 22:39:49,181:INFO:            imblearn: 0.10.1
2025-04-19 22:39:49,181:INFO:   category_encoders: 2.7.0
2025-04-19 22:39:49,181:INFO:            lightgbm: 4.6.0
2025-04-19 22:39:49,181:INFO:               numba: 0.60.0
2025-04-19 22:39:49,182:INFO:            requests: 2.32.3
2025-04-19 22:39:49,182:INFO:          matplotlib: 3.7.5
2025-04-19 22:39:49,182:INFO:          scikitplot: 0.3.7
2025-04-19 22:39:49,182:INFO:         yellowbrick: 1.5
2025-04-19 22:39:49,182:INFO:              plotly: 5.24.1
2025-04-19 22:39:49,182:INFO:    plotly-resampler: Not installed
2025-04-19 22:39:49,182:INFO:             kaleido: 0.2.1
2025-04-19 22:39:49,182:INFO:           schemdraw: 0.15
2025-04-19 22:39:49,182:INFO:         statsmodels: 0.14.4
2025-04-19 22:39:49,182:INFO:              sktime: 0.26.0
2025-04-19 22:39:49,182:INFO:               tbats: 1.1.3
2025-04-19 22:39:49,182:INFO:            pmdarima: 2.0.4
2025-04-19 22:39:49,182:INFO:              psutil: 6.1.0
2025-04-19 22:39:49,182:INFO:          markupsafe: 3.0.2
2025-04-19 22:39:49,182:INFO:             pickle5: Not installed
2025-04-19 22:39:49,182:INFO:         cloudpickle: 3.1.1
2025-04-19 22:39:49,182:INFO:         deprecation: 2.1.0
2025-04-19 22:39:49,182:INFO:              xxhash: 3.5.0
2025-04-19 22:39:49,182:INFO:           wurlitzer: Not installed
2025-04-19 22:39:49,182:INFO:PyCaret optional dependencies:
2025-04-19 22:39:49,182:INFO:                shap: Not installed
2025-04-19 22:39:49,182:INFO:           interpret: Not installed
2025-04-19 22:39:49,182:INFO:                umap: Not installed
2025-04-19 22:39:49,182:INFO:    pandas_profiling: Not installed
2025-04-19 22:39:49,182:INFO:  explainerdashboard: Not installed
2025-04-19 22:39:49,182:INFO:             autoviz: Not installed
2025-04-19 22:39:49,182:INFO:           fairlearn: Not installed
2025-04-19 22:39:49,182:INFO:          deepchecks: Not installed
2025-04-19 22:39:49,182:INFO:             xgboost: 1.7.6
2025-04-19 22:39:49,182:INFO:            catboost: Not installed
2025-04-19 22:39:49,182:INFO:              kmodes: Not installed
2025-04-19 22:39:49,182:INFO:             mlxtend: Not installed
2025-04-19 22:39:49,182:INFO:       statsforecast: Not installed
2025-04-19 22:39:49,183:INFO:        tune_sklearn: Not installed
2025-04-19 22:39:49,183:INFO:                 ray: Not installed
2025-04-19 22:39:49,183:INFO:            hyperopt: Not installed
2025-04-19 22:39:49,183:INFO:              optuna: Not installed
2025-04-19 22:39:49,183:INFO:               skopt: Not installed
2025-04-19 22:39:49,183:INFO:              mlflow: Not installed
2025-04-19 22:39:49,183:INFO:              gradio: Not installed
2025-04-19 22:39:49,183:INFO:             fastapi: Not installed
2025-04-19 22:39:49,183:INFO:             uvicorn: Not installed
2025-04-19 22:39:49,183:INFO:              m2cgen: Not installed
2025-04-19 22:39:49,183:INFO:           evidently: Not installed
2025-04-19 22:39:49,183:INFO:               fugue: Not installed
2025-04-19 22:39:49,183:INFO:           streamlit: 1.42.0
2025-04-19 22:39:49,183:INFO:             prophet: Not installed
2025-04-19 22:39:49,183:INFO:None
2025-04-19 22:39:49,183:INFO:Set up data.
2025-04-19 22:39:49,189:INFO:Set up train/test split.
2025-04-19 22:39:49,193:INFO:Set up index.
2025-04-19 22:39:49,193:INFO:Set up folding strategy.
2025-04-19 22:39:49,193:INFO:Assigning column types.
2025-04-19 22:39:49,196:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 22:39:49,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:39:49,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:39:49,266:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:39:49,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:39:49,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:39:49,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:39:49,342:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:39:49,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:39:49,344:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 22:39:49,387:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:39:49,413:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:39:49,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:39:49,469:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:39:49,496:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:39:49,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:39:49,498:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 22:39:49,565:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:39:49,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:39:49,635:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:39:49,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:39:49,638:INFO:Preparing preprocessing pipeline...
2025-04-19 22:39:49,639:INFO:Set up simple imputation.
2025-04-19 22:39:49,641:INFO:Set up encoding of ordinal features.
2025-04-19 22:39:49,643:INFO:Set up encoding of categorical features.
2025-04-19 22:39:49,643:INFO:Set up removing outliers.
2025-04-19 22:39:49,643:INFO:Set up imbalanced handling.
2025-04-19 22:39:49,643:INFO:Set up feature normalization.
2025-04-19 22:39:49,859:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:39:50,025:INFO:Finished creating preprocessing pipeline.
2025-04-19 22:39:50,053:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['DistanceFromHome',
                                             'NumCompaniesWorked',
                                             'MonthlyRate'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprec...
                                                               n_jobs=1,
                                                               random_state=1058,
                                                               threshold=0.05))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 22:39:50,053:INFO:Creating final display dataframe.
2025-04-19 22:39:50,344:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:39:50,888:INFO:Setup _display_container:                     Description             Value
0                    Session id              1058
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 11)
4        Transformed data shape        (1500, 27)
5   Transformed train set shape        (1182, 27)
6    Transformed test set shape         (318, 27)
7               Ignore features                 1
8              Ordinal features                 2
9              Numeric features                 3
10         Categorical features                 6
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              69bc
2025-04-19 22:39:50,958:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:39:50,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:39:51,032:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:39:51,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:39:51,036:INFO:setup() successfully completed in 2.25s...............
2025-04-19 22:39:55,970:INFO:Initializing compare_models()
2025-04-19 22:39:55,970:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 22:39:55,970:INFO:Checking exceptions
2025-04-19 22:39:55,974:INFO:Preparing display monitor
2025-04-19 22:39:55,996:INFO:Initializing Logistic Regression
2025-04-19 22:39:55,996:INFO:Total runtime is 0.0 minutes
2025-04-19 22:39:55,999:INFO:SubProcess create_model() called ==================================
2025-04-19 22:39:55,999:INFO:Initializing create_model()
2025-04-19 22:39:56,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:39:56,000:INFO:Checking exceptions
2025-04-19 22:39:56,000:INFO:Importing libraries
2025-04-19 22:39:56,000:INFO:Copying training dataset
2025-04-19 22:39:56,007:INFO:Defining folds
2025-04-19 22:39:56,007:INFO:Declaring metric variables
2025-04-19 22:39:56,011:INFO:Importing untrained model
2025-04-19 22:39:56,015:INFO:Logistic Regression Imported successfully
2025-04-19 22:39:56,020:INFO:Starting cross validation
2025-04-19 22:39:56,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:39:58,687:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:04,180:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:06,117:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:06,733:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:06,744:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:06,747:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:06,754:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:06,761:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:06,765:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:06,765:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2025-04-19 22:40:09,995:INFO:Calculating mean and std
2025-04-19 22:40:09,996:INFO:Creating metrics dataframe
2025-04-19 22:40:10,549:INFO:Uploading results into container
2025-04-19 22:40:10,551:INFO:Uploading model into container now
2025-04-19 22:40:10,551:INFO:_master_model_container: 1
2025-04-19 22:40:10,551:INFO:_display_container: 2
2025-04-19 22:40:10,552:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1058, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 22:40:10,552:INFO:create_model() successfully completed......................................
2025-04-19 22:40:10,704:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:10,704:INFO:Creating metrics dataframe
2025-04-19 22:40:10,713:INFO:Initializing K Neighbors Classifier
2025-04-19 22:40:10,713:INFO:Total runtime is 0.24528363943099976 minutes
2025-04-19 22:40:10,717:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:10,717:INFO:Initializing create_model()
2025-04-19 22:40:10,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:10,717:INFO:Checking exceptions
2025-04-19 22:40:10,717:INFO:Importing libraries
2025-04-19 22:40:10,717:INFO:Copying training dataset
2025-04-19 22:40:10,721:INFO:Defining folds
2025-04-19 22:40:10,721:INFO:Declaring metric variables
2025-04-19 22:40:10,725:INFO:Importing untrained model
2025-04-19 22:40:10,729:INFO:K Neighbors Classifier Imported successfully
2025-04-19 22:40:10,735:INFO:Starting cross validation
2025-04-19 22:40:10,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:40:15,989:INFO:Calculating mean and std
2025-04-19 22:40:15,991:INFO:Creating metrics dataframe
2025-04-19 22:40:16,552:INFO:Uploading results into container
2025-04-19 22:40:16,553:INFO:Uploading model into container now
2025-04-19 22:40:16,553:INFO:_master_model_container: 2
2025-04-19 22:40:16,553:INFO:_display_container: 2
2025-04-19 22:40:16,554:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 22:40:16,554:INFO:create_model() successfully completed......................................
2025-04-19 22:40:16,697:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:16,697:INFO:Creating metrics dataframe
2025-04-19 22:40:16,707:INFO:Initializing Naive Bayes
2025-04-19 22:40:16,707:INFO:Total runtime is 0.34518129428227745 minutes
2025-04-19 22:40:16,710:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:16,711:INFO:Initializing create_model()
2025-04-19 22:40:16,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:16,711:INFO:Checking exceptions
2025-04-19 22:40:16,711:INFO:Importing libraries
2025-04-19 22:40:16,711:INFO:Copying training dataset
2025-04-19 22:40:16,717:INFO:Defining folds
2025-04-19 22:40:16,717:INFO:Declaring metric variables
2025-04-19 22:40:16,722:INFO:Importing untrained model
2025-04-19 22:40:16,726:INFO:Naive Bayes Imported successfully
2025-04-19 22:40:16,733:INFO:Starting cross validation
2025-04-19 22:40:16,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:40:21,242:INFO:Calculating mean and std
2025-04-19 22:40:21,243:INFO:Creating metrics dataframe
2025-04-19 22:40:21,793:INFO:Uploading results into container
2025-04-19 22:40:21,793:INFO:Uploading model into container now
2025-04-19 22:40:21,793:INFO:_master_model_container: 3
2025-04-19 22:40:21,795:INFO:_display_container: 2
2025-04-19 22:40:21,795:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 22:40:21,795:INFO:create_model() successfully completed......................................
2025-04-19 22:40:21,930:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:21,930:INFO:Creating metrics dataframe
2025-04-19 22:40:21,940:INFO:Initializing Decision Tree Classifier
2025-04-19 22:40:21,940:INFO:Total runtime is 0.4324002265930176 minutes
2025-04-19 22:40:21,945:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:21,945:INFO:Initializing create_model()
2025-04-19 22:40:21,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:21,945:INFO:Checking exceptions
2025-04-19 22:40:21,945:INFO:Importing libraries
2025-04-19 22:40:21,945:INFO:Copying training dataset
2025-04-19 22:40:21,950:INFO:Defining folds
2025-04-19 22:40:21,950:INFO:Declaring metric variables
2025-04-19 22:40:21,956:INFO:Importing untrained model
2025-04-19 22:40:21,960:INFO:Decision Tree Classifier Imported successfully
2025-04-19 22:40:21,968:INFO:Starting cross validation
2025-04-19 22:40:21,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:40:26,621:INFO:Calculating mean and std
2025-04-19 22:40:26,622:INFO:Creating metrics dataframe
2025-04-19 22:40:27,171:INFO:Uploading results into container
2025-04-19 22:40:27,172:INFO:Uploading model into container now
2025-04-19 22:40:27,172:INFO:_master_model_container: 4
2025-04-19 22:40:27,172:INFO:_display_container: 2
2025-04-19 22:40:27,174:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1058, splitter='best')
2025-04-19 22:40:27,174:INFO:create_model() successfully completed......................................
2025-04-19 22:40:27,312:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:27,313:INFO:Creating metrics dataframe
2025-04-19 22:40:27,322:INFO:Initializing SVM - Linear Kernel
2025-04-19 22:40:27,322:INFO:Total runtime is 0.5221070329348246 minutes
2025-04-19 22:40:27,325:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:27,325:INFO:Initializing create_model()
2025-04-19 22:40:27,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:27,327:INFO:Checking exceptions
2025-04-19 22:40:27,327:INFO:Importing libraries
2025-04-19 22:40:27,327:INFO:Copying training dataset
2025-04-19 22:40:27,331:INFO:Defining folds
2025-04-19 22:40:27,333:INFO:Declaring metric variables
2025-04-19 22:40:27,337:INFO:Importing untrained model
2025-04-19 22:40:27,341:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 22:40:27,346:INFO:Starting cross validation
2025-04-19 22:40:27,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:40:27,740:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,748:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,753:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,757:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,761:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,779:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,780:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,792:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,890:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:27,906:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:40:31,859:INFO:Calculating mean and std
2025-04-19 22:40:31,860:INFO:Creating metrics dataframe
2025-04-19 22:40:32,406:INFO:Uploading results into container
2025-04-19 22:40:32,407:INFO:Uploading model into container now
2025-04-19 22:40:32,407:INFO:_master_model_container: 5
2025-04-19 22:40:32,408:INFO:_display_container: 2
2025-04-19 22:40:32,408:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1058, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 22:40:32,408:INFO:create_model() successfully completed......................................
2025-04-19 22:40:32,539:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:32,539:INFO:Creating metrics dataframe
2025-04-19 22:40:32,549:INFO:Initializing Ridge Classifier
2025-04-19 22:40:32,549:INFO:Total runtime is 0.6092137018839519 minutes
2025-04-19 22:40:32,552:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:32,552:INFO:Initializing create_model()
2025-04-19 22:40:32,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:32,552:INFO:Checking exceptions
2025-04-19 22:40:32,552:INFO:Importing libraries
2025-04-19 22:40:32,552:INFO:Copying training dataset
2025-04-19 22:40:32,559:INFO:Defining folds
2025-04-19 22:40:32,559:INFO:Declaring metric variables
2025-04-19 22:40:32,564:INFO:Importing untrained model
2025-04-19 22:40:32,567:INFO:Ridge Classifier Imported successfully
2025-04-19 22:40:32,574:INFO:Starting cross validation
2025-04-19 22:40:32,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:40:32,935:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:32,943:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:32,964:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:32,976:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:32,977:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:32,983:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:32,983:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:32,987:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:32,993:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:33,005:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:40:37,139:INFO:Calculating mean and std
2025-04-19 22:40:37,140:INFO:Creating metrics dataframe
2025-04-19 22:40:37,700:INFO:Uploading results into container
2025-04-19 22:40:37,701:INFO:Uploading model into container now
2025-04-19 22:40:37,702:INFO:_master_model_container: 6
2025-04-19 22:40:37,702:INFO:_display_container: 2
2025-04-19 22:40:37,702:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1058, solver='auto',
                tol=0.0001)
2025-04-19 22:40:37,702:INFO:create_model() successfully completed......................................
2025-04-19 22:40:37,856:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:37,856:INFO:Creating metrics dataframe
2025-04-19 22:40:37,867:INFO:Initializing Random Forest Classifier
2025-04-19 22:40:37,867:INFO:Total runtime is 0.6978540778160096 minutes
2025-04-19 22:40:37,870:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:37,870:INFO:Initializing create_model()
2025-04-19 22:40:37,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:37,870:INFO:Checking exceptions
2025-04-19 22:40:37,870:INFO:Importing libraries
2025-04-19 22:40:37,870:INFO:Copying training dataset
2025-04-19 22:40:37,877:INFO:Defining folds
2025-04-19 22:40:37,877:INFO:Declaring metric variables
2025-04-19 22:40:37,881:INFO:Importing untrained model
2025-04-19 22:40:37,885:INFO:Random Forest Classifier Imported successfully
2025-04-19 22:40:37,891:INFO:Starting cross validation
2025-04-19 22:40:37,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:40:43,341:INFO:Calculating mean and std
2025-04-19 22:40:43,342:INFO:Creating metrics dataframe
2025-04-19 22:40:43,890:INFO:Uploading results into container
2025-04-19 22:40:43,892:INFO:Uploading model into container now
2025-04-19 22:40:43,892:INFO:_master_model_container: 7
2025-04-19 22:40:43,892:INFO:_display_container: 2
2025-04-19 22:40:43,892:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:40:43,894:INFO:create_model() successfully completed......................................
2025-04-19 22:40:44,051:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:44,051:INFO:Creating metrics dataframe
2025-04-19 22:40:44,061:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 22:40:44,063:INFO:Total runtime is 0.8011110583941142 minutes
2025-04-19 22:40:44,067:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:44,067:INFO:Initializing create_model()
2025-04-19 22:40:44,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:44,067:INFO:Checking exceptions
2025-04-19 22:40:44,067:INFO:Importing libraries
2025-04-19 22:40:44,067:INFO:Copying training dataset
2025-04-19 22:40:44,073:INFO:Defining folds
2025-04-19 22:40:44,074:INFO:Declaring metric variables
2025-04-19 22:40:44,083:INFO:Importing untrained model
2025-04-19 22:40:44,087:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 22:40:44,094:INFO:Starting cross validation
2025-04-19 22:40:44,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:40:44,361:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,368:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,370:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,384:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,396:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,396:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,400:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,412:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,415:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:44,419:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:40:48,856:INFO:Calculating mean and std
2025-04-19 22:40:48,857:INFO:Creating metrics dataframe
2025-04-19 22:40:49,470:INFO:Uploading results into container
2025-04-19 22:40:49,471:INFO:Uploading model into container now
2025-04-19 22:40:49,471:INFO:_master_model_container: 8
2025-04-19 22:40:49,472:INFO:_display_container: 2
2025-04-19 22:40:49,472:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 22:40:49,472:INFO:create_model() successfully completed......................................
2025-04-19 22:40:49,604:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:49,604:INFO:Creating metrics dataframe
2025-04-19 22:40:49,614:INFO:Initializing Ada Boost Classifier
2025-04-19 22:40:49,614:INFO:Total runtime is 0.8936340769131979 minutes
2025-04-19 22:40:49,617:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:49,617:INFO:Initializing create_model()
2025-04-19 22:40:49,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:49,619:INFO:Checking exceptions
2025-04-19 22:40:49,619:INFO:Importing libraries
2025-04-19 22:40:49,619:INFO:Copying training dataset
2025-04-19 22:40:49,623:INFO:Defining folds
2025-04-19 22:40:49,623:INFO:Declaring metric variables
2025-04-19 22:40:49,631:INFO:Importing untrained model
2025-04-19 22:40:49,636:INFO:Ada Boost Classifier Imported successfully
2025-04-19 22:40:49,644:INFO:Starting cross validation
2025-04-19 22:40:49,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:40:54,707:INFO:Calculating mean and std
2025-04-19 22:40:54,709:INFO:Creating metrics dataframe
2025-04-19 22:40:55,264:INFO:Uploading results into container
2025-04-19 22:40:55,265:INFO:Uploading model into container now
2025-04-19 22:40:55,265:INFO:_master_model_container: 9
2025-04-19 22:40:55,265:INFO:_display_container: 2
2025-04-19 22:40:55,266:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1058)
2025-04-19 22:40:55,266:INFO:create_model() successfully completed......................................
2025-04-19 22:40:55,402:INFO:SubProcess create_model() end ==================================
2025-04-19 22:40:55,402:INFO:Creating metrics dataframe
2025-04-19 22:40:55,413:INFO:Initializing Gradient Boosting Classifier
2025-04-19 22:40:55,413:INFO:Total runtime is 0.9902822613716126 minutes
2025-04-19 22:40:55,416:INFO:SubProcess create_model() called ==================================
2025-04-19 22:40:55,417:INFO:Initializing create_model()
2025-04-19 22:40:55,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:40:55,417:INFO:Checking exceptions
2025-04-19 22:40:55,417:INFO:Importing libraries
2025-04-19 22:40:55,417:INFO:Copying training dataset
2025-04-19 22:40:55,424:INFO:Defining folds
2025-04-19 22:40:55,428:INFO:Declaring metric variables
2025-04-19 22:40:55,433:INFO:Importing untrained model
2025-04-19 22:40:55,438:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 22:40:55,446:INFO:Starting cross validation
2025-04-19 22:40:55,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:41:00,874:INFO:Calculating mean and std
2025-04-19 22:41:00,875:INFO:Creating metrics dataframe
2025-04-19 22:41:01,437:INFO:Uploading results into container
2025-04-19 22:41:01,438:INFO:Uploading model into container now
2025-04-19 22:41:01,438:INFO:_master_model_container: 10
2025-04-19 22:41:01,438:INFO:_display_container: 2
2025-04-19 22:41:01,440:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:41:01,440:INFO:create_model() successfully completed......................................
2025-04-19 22:41:01,579:INFO:SubProcess create_model() end ==================================
2025-04-19 22:41:01,579:INFO:Creating metrics dataframe
2025-04-19 22:41:01,591:INFO:Initializing Linear Discriminant Analysis
2025-04-19 22:41:01,591:INFO:Total runtime is 1.0932573477427165 minutes
2025-04-19 22:41:01,594:INFO:SubProcess create_model() called ==================================
2025-04-19 22:41:01,595:INFO:Initializing create_model()
2025-04-19 22:41:01,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:41:01,595:INFO:Checking exceptions
2025-04-19 22:41:01,595:INFO:Importing libraries
2025-04-19 22:41:01,595:INFO:Copying training dataset
2025-04-19 22:41:01,599:INFO:Defining folds
2025-04-19 22:41:01,599:INFO:Declaring metric variables
2025-04-19 22:41:01,604:INFO:Importing untrained model
2025-04-19 22:41:01,607:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 22:41:01,612:INFO:Starting cross validation
2025-04-19 22:41:01,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:41:06,471:INFO:Calculating mean and std
2025-04-19 22:41:06,473:INFO:Creating metrics dataframe
2025-04-19 22:41:07,047:INFO:Uploading results into container
2025-04-19 22:41:07,048:INFO:Uploading model into container now
2025-04-19 22:41:07,048:INFO:_master_model_container: 11
2025-04-19 22:41:07,048:INFO:_display_container: 2
2025-04-19 22:41:07,049:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 22:41:07,049:INFO:create_model() successfully completed......................................
2025-04-19 22:41:07,190:INFO:SubProcess create_model() end ==================================
2025-04-19 22:41:07,190:INFO:Creating metrics dataframe
2025-04-19 22:41:07,202:INFO:Initializing Extra Trees Classifier
2025-04-19 22:41:07,203:INFO:Total runtime is 1.186776081720988 minutes
2025-04-19 22:41:07,205:INFO:SubProcess create_model() called ==================================
2025-04-19 22:41:07,206:INFO:Initializing create_model()
2025-04-19 22:41:07,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:41:07,206:INFO:Checking exceptions
2025-04-19 22:41:07,206:INFO:Importing libraries
2025-04-19 22:41:07,206:INFO:Copying training dataset
2025-04-19 22:41:07,210:INFO:Defining folds
2025-04-19 22:41:07,210:INFO:Declaring metric variables
2025-04-19 22:41:07,215:INFO:Importing untrained model
2025-04-19 22:41:07,219:INFO:Extra Trees Classifier Imported successfully
2025-04-19 22:41:07,225:INFO:Starting cross validation
2025-04-19 22:41:07,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:41:12,776:INFO:Calculating mean and std
2025-04-19 22:41:12,777:INFO:Creating metrics dataframe
2025-04-19 22:41:13,350:INFO:Uploading results into container
2025-04-19 22:41:13,351:INFO:Uploading model into container now
2025-04-19 22:41:13,351:INFO:_master_model_container: 12
2025-04-19 22:41:13,351:INFO:_display_container: 2
2025-04-19 22:41:13,352:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:41:13,352:INFO:create_model() successfully completed......................................
2025-04-19 22:41:13,488:INFO:SubProcess create_model() end ==================================
2025-04-19 22:41:13,488:INFO:Creating metrics dataframe
2025-04-19 22:41:13,503:INFO:Initializing Extreme Gradient Boosting
2025-04-19 22:41:13,503:INFO:Total runtime is 1.2917798598607382 minutes
2025-04-19 22:41:13,507:INFO:SubProcess create_model() called ==================================
2025-04-19 22:41:13,509:INFO:Initializing create_model()
2025-04-19 22:41:13,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:41:13,509:INFO:Checking exceptions
2025-04-19 22:41:13,509:INFO:Importing libraries
2025-04-19 22:41:13,509:INFO:Copying training dataset
2025-04-19 22:41:13,514:INFO:Defining folds
2025-04-19 22:41:13,515:INFO:Declaring metric variables
2025-04-19 22:41:13,519:INFO:Importing untrained model
2025-04-19 22:41:13,523:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 22:41:13,532:INFO:Starting cross validation
2025-04-19 22:41:13,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:41:20,511:INFO:Calculating mean and std
2025-04-19 22:41:20,512:INFO:Creating metrics dataframe
2025-04-19 22:41:21,110:INFO:Uploading results into container
2025-04-19 22:41:21,110:INFO:Uploading model into container now
2025-04-19 22:41:21,111:INFO:_master_model_container: 13
2025-04-19 22:41:21,111:INFO:_display_container: 2
2025-04-19 22:41:21,112:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 22:41:21,112:INFO:create_model() successfully completed......................................
2025-04-19 22:41:21,257:INFO:SubProcess create_model() end ==================================
2025-04-19 22:41:21,257:INFO:Creating metrics dataframe
2025-04-19 22:41:21,269:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 22:41:21,269:INFO:Total runtime is 1.421214532852173 minutes
2025-04-19 22:41:21,272:INFO:SubProcess create_model() called ==================================
2025-04-19 22:41:21,272:INFO:Initializing create_model()
2025-04-19 22:41:21,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:41:21,272:INFO:Checking exceptions
2025-04-19 22:41:21,273:INFO:Importing libraries
2025-04-19 22:41:21,273:INFO:Copying training dataset
2025-04-19 22:41:21,278:INFO:Defining folds
2025-04-19 22:41:21,278:INFO:Declaring metric variables
2025-04-19 22:41:21,281:INFO:Importing untrained model
2025-04-19 22:41:21,285:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 22:41:21,291:INFO:Starting cross validation
2025-04-19 22:41:21,300:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:41:28,264:INFO:Calculating mean and std
2025-04-19 22:41:28,266:INFO:Creating metrics dataframe
2025-04-19 22:41:28,880:INFO:Uploading results into container
2025-04-19 22:41:28,881:INFO:Uploading model into container now
2025-04-19 22:41:28,881:INFO:_master_model_container: 14
2025-04-19 22:41:28,881:INFO:_display_container: 2
2025-04-19 22:41:28,882:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1058, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 22:41:28,882:INFO:create_model() successfully completed......................................
2025-04-19 22:41:29,014:INFO:SubProcess create_model() end ==================================
2025-04-19 22:41:29,014:INFO:Creating metrics dataframe
2025-04-19 22:41:29,028:INFO:Initializing Dummy Classifier
2025-04-19 22:41:29,028:INFO:Total runtime is 1.5505328257878623 minutes
2025-04-19 22:41:29,031:INFO:SubProcess create_model() called ==================================
2025-04-19 22:41:29,031:INFO:Initializing create_model()
2025-04-19 22:41:29,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1324F4070>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:41:29,031:INFO:Checking exceptions
2025-04-19 22:41:29,031:INFO:Importing libraries
2025-04-19 22:41:29,032:INFO:Copying training dataset
2025-04-19 22:41:29,037:INFO:Defining folds
2025-04-19 22:41:29,037:INFO:Declaring metric variables
2025-04-19 22:41:29,040:INFO:Importing untrained model
2025-04-19 22:41:29,045:INFO:Dummy Classifier Imported successfully
2025-04-19 22:41:29,052:INFO:Starting cross validation
2025-04-19 22:41:29,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:41:29,543:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,546:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,553:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,562:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,567:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,569:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,576:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,576:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,583:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:29,592:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:41:34,048:INFO:Calculating mean and std
2025-04-19 22:41:34,050:INFO:Creating metrics dataframe
2025-04-19 22:41:34,662:INFO:Uploading results into container
2025-04-19 22:41:34,662:INFO:Uploading model into container now
2025-04-19 22:41:34,662:INFO:_master_model_container: 15
2025-04-19 22:41:34,663:INFO:_display_container: 2
2025-04-19 22:41:34,663:INFO:DummyClassifier(constant=None, random_state=1058, strategy='prior')
2025-04-19 22:41:34,663:INFO:create_model() successfully completed......................................
2025-04-19 22:41:34,797:INFO:SubProcess create_model() end ==================================
2025-04-19 22:41:34,797:INFO:Creating metrics dataframe
2025-04-19 22:41:34,818:INFO:Initializing create_model()
2025-04-19 22:41:34,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771EBF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:41:34,820:INFO:Checking exceptions
2025-04-19 22:41:34,821:INFO:Importing libraries
2025-04-19 22:41:34,821:INFO:Copying training dataset
2025-04-19 22:41:34,825:INFO:Defining folds
2025-04-19 22:41:34,825:INFO:Declaring metric variables
2025-04-19 22:41:34,825:INFO:Importing untrained model
2025-04-19 22:41:34,827:INFO:Declaring custom model
2025-04-19 22:41:34,827:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 22:41:34,835:INFO:Cross validation set to False
2025-04-19 22:41:34,835:INFO:Fitting Model
2025-04-19 22:41:35,822:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:41:35,822:INFO:create_model() successfully completed......................................
2025-04-19 22:41:35,995:INFO:_master_model_container: 15
2025-04-19 22:41:35,995:INFO:_display_container: 2
2025-04-19 22:41:35,995:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:41:35,995:INFO:compare_models() successfully completed......................................
2025-04-19 22:42:02,466:INFO:PyCaret ClassificationExperiment
2025-04-19 22:42:02,466:INFO:Logging name: clf-default-name
2025-04-19 22:42:02,466:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 22:42:02,466:INFO:version 3.0.4
2025-04-19 22:42:02,466:INFO:Initializing setup()
2025-04-19 22:42:02,466:INFO:self.USI: 7dab
2025-04-19 22:42:02,466:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 22:42:02,466:INFO:Checking environment
2025-04-19 22:42:02,466:INFO:python_version: 3.10.5
2025-04-19 22:42:02,466:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 22:42:02,466:INFO:machine: AMD64
2025-04-19 22:42:02,466:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 22:42:02,473:INFO:Memory: svmem(total=25042907136, available=10372280320, percent=58.6, used=14670626816, free=10372280320)
2025-04-19 22:42:02,473:INFO:Physical Core: 6
2025-04-19 22:42:02,473:INFO:Logical Core: 12
2025-04-19 22:42:02,473:INFO:Checking libraries
2025-04-19 22:42:02,473:INFO:System:
2025-04-19 22:42:02,473:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 22:42:02,473:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 22:42:02,473:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 22:42:02,473:INFO:PyCaret required dependencies:
2025-04-19 22:42:02,473:INFO:                 pip: 25.0.1
2025-04-19 22:42:02,473:INFO:          setuptools: 58.1.0
2025-04-19 22:42:02,473:INFO:             pycaret: 3.0.4
2025-04-19 22:42:02,473:INFO:             IPython: 8.29.0
2025-04-19 22:42:02,473:INFO:          ipywidgets: 8.1.6
2025-04-19 22:42:02,473:INFO:                tqdm: 4.67.1
2025-04-19 22:42:02,473:INFO:               numpy: 1.23.5
2025-04-19 22:42:02,473:INFO:              pandas: 1.5.3
2025-04-19 22:42:02,473:INFO:              jinja2: 3.1.4
2025-04-19 22:42:02,473:INFO:               scipy: 1.11.4
2025-04-19 22:42:02,474:INFO:              joblib: 1.3.2
2025-04-19 22:42:02,474:INFO:             sklearn: 1.2.2
2025-04-19 22:42:02,474:INFO:                pyod: 2.0.4
2025-04-19 22:42:02,474:INFO:            imblearn: 0.10.1
2025-04-19 22:42:02,474:INFO:   category_encoders: 2.7.0
2025-04-19 22:42:02,474:INFO:            lightgbm: 4.6.0
2025-04-19 22:42:02,474:INFO:               numba: 0.60.0
2025-04-19 22:42:02,474:INFO:            requests: 2.32.3
2025-04-19 22:42:02,474:INFO:          matplotlib: 3.7.5
2025-04-19 22:42:02,474:INFO:          scikitplot: 0.3.7
2025-04-19 22:42:02,474:INFO:         yellowbrick: 1.5
2025-04-19 22:42:02,474:INFO:              plotly: 5.24.1
2025-04-19 22:42:02,474:INFO:    plotly-resampler: Not installed
2025-04-19 22:42:02,474:INFO:             kaleido: 0.2.1
2025-04-19 22:42:02,474:INFO:           schemdraw: 0.15
2025-04-19 22:42:02,474:INFO:         statsmodels: 0.14.4
2025-04-19 22:42:02,474:INFO:              sktime: 0.26.0
2025-04-19 22:42:02,474:INFO:               tbats: 1.1.3
2025-04-19 22:42:02,474:INFO:            pmdarima: 2.0.4
2025-04-19 22:42:02,474:INFO:              psutil: 6.1.0
2025-04-19 22:42:02,474:INFO:          markupsafe: 3.0.2
2025-04-19 22:42:02,474:INFO:             pickle5: Not installed
2025-04-19 22:42:02,474:INFO:         cloudpickle: 3.1.1
2025-04-19 22:42:02,474:INFO:         deprecation: 2.1.0
2025-04-19 22:42:02,475:INFO:              xxhash: 3.5.0
2025-04-19 22:42:02,475:INFO:           wurlitzer: Not installed
2025-04-19 22:42:02,475:INFO:PyCaret optional dependencies:
2025-04-19 22:42:02,475:INFO:                shap: Not installed
2025-04-19 22:42:02,475:INFO:           interpret: Not installed
2025-04-19 22:42:02,475:INFO:                umap: Not installed
2025-04-19 22:42:02,475:INFO:    pandas_profiling: Not installed
2025-04-19 22:42:02,475:INFO:  explainerdashboard: Not installed
2025-04-19 22:42:02,475:INFO:             autoviz: Not installed
2025-04-19 22:42:02,475:INFO:           fairlearn: Not installed
2025-04-19 22:42:02,475:INFO:          deepchecks: Not installed
2025-04-19 22:42:02,475:INFO:             xgboost: 1.7.6
2025-04-19 22:42:02,475:INFO:            catboost: Not installed
2025-04-19 22:42:02,476:INFO:              kmodes: Not installed
2025-04-19 22:42:02,476:INFO:             mlxtend: Not installed
2025-04-19 22:42:02,476:INFO:       statsforecast: Not installed
2025-04-19 22:42:02,476:INFO:        tune_sklearn: Not installed
2025-04-19 22:42:02,476:INFO:                 ray: Not installed
2025-04-19 22:42:02,476:INFO:            hyperopt: Not installed
2025-04-19 22:42:02,476:INFO:              optuna: Not installed
2025-04-19 22:42:02,476:INFO:               skopt: Not installed
2025-04-19 22:42:02,476:INFO:              mlflow: Not installed
2025-04-19 22:42:02,476:INFO:              gradio: Not installed
2025-04-19 22:42:02,476:INFO:             fastapi: Not installed
2025-04-19 22:42:02,476:INFO:             uvicorn: Not installed
2025-04-19 22:42:02,476:INFO:              m2cgen: Not installed
2025-04-19 22:42:02,476:INFO:           evidently: Not installed
2025-04-19 22:42:02,476:INFO:               fugue: Not installed
2025-04-19 22:42:02,476:INFO:           streamlit: 1.42.0
2025-04-19 22:42:02,476:INFO:             prophet: Not installed
2025-04-19 22:42:02,476:INFO:None
2025-04-19 22:42:02,476:INFO:Set up data.
2025-04-19 22:42:02,482:INFO:Set up train/test split.
2025-04-19 22:42:02,487:INFO:Set up index.
2025-04-19 22:42:02,487:INFO:Set up folding strategy.
2025-04-19 22:42:02,487:INFO:Assigning column types.
2025-04-19 22:42:02,490:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 22:42:02,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:42:02,533:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:42:02,560:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:42:02,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:42:02,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:42:02,605:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:42:02,629:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:42:02,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:42:02,633:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 22:42:02,677:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:42:02,704:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:42:02,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:42:02,750:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:42:02,776:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:42:02,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:42:02,780:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 22:42:02,851:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:42:02,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:42:02,924:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:42:02,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:42:02,928:INFO:Preparing preprocessing pipeline...
2025-04-19 22:42:02,929:INFO:Set up simple imputation.
2025-04-19 22:42:02,932:INFO:Set up encoding of ordinal features.
2025-04-19 22:42:02,934:INFO:Set up encoding of categorical features.
2025-04-19 22:42:02,934:INFO:Set up imbalanced handling.
2025-04-19 22:42:03,044:INFO:Finished creating preprocessing pipeline.
2025-04-19 22:42:03,073:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['DistanceFromHome',
                                             'NumCompaniesWorked',
                                             'MonthlyRate'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprec...
                                    transformer=OneHotEncoder(cols=['MaritalStatus',
                                                                    'Department',
                                                                    'JobRole',
                                                                    'EducationField'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-04-19 22:42:03,073:INFO:Creating final display dataframe.
2025-04-19 22:42:03,490:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 10)
4        Transformed data shape        (1548, 27)
5   Transformed train set shape        (1230, 27)
6    Transformed test set shape         (318, 27)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              7dab
2025-04-19 22:42:03,560:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:42:03,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:42:03,636:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:42:03,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:42:03,638:INFO:setup() successfully completed in 1.64s...............
2025-04-19 22:42:04,941:INFO:Initializing compare_models()
2025-04-19 22:42:04,941:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 22:42:04,941:INFO:Checking exceptions
2025-04-19 22:42:04,944:INFO:Preparing display monitor
2025-04-19 22:42:04,965:INFO:Initializing Logistic Regression
2025-04-19 22:42:04,965:INFO:Total runtime is 0.0 minutes
2025-04-19 22:42:04,968:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:04,969:INFO:Initializing create_model()
2025-04-19 22:42:04,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:04,969:INFO:Checking exceptions
2025-04-19 22:42:04,969:INFO:Importing libraries
2025-04-19 22:42:04,969:INFO:Copying training dataset
2025-04-19 22:42:04,976:INFO:Defining folds
2025-04-19 22:42:04,976:INFO:Declaring metric variables
2025-04-19 22:42:04,980:INFO:Importing untrained model
2025-04-19 22:42:04,983:INFO:Logistic Regression Imported successfully
2025-04-19 22:42:04,991:INFO:Starting cross validation
2025-04-19 22:42:04,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:42:10,009:INFO:Calculating mean and std
2025-04-19 22:42:10,012:INFO:Creating metrics dataframe
2025-04-19 22:42:10,610:INFO:Uploading results into container
2025-04-19 22:42:10,611:INFO:Uploading model into container now
2025-04-19 22:42:10,611:INFO:_master_model_container: 1
2025-04-19 22:42:10,611:INFO:_display_container: 2
2025-04-19 22:42:10,612:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 22:42:10,612:INFO:create_model() successfully completed......................................
2025-04-19 22:42:10,761:INFO:SubProcess create_model() end ==================================
2025-04-19 22:42:10,761:INFO:Creating metrics dataframe
2025-04-19 22:42:10,770:INFO:Initializing K Neighbors Classifier
2025-04-19 22:42:10,770:INFO:Total runtime is 0.0967426578203837 minutes
2025-04-19 22:42:10,772:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:10,772:INFO:Initializing create_model()
2025-04-19 22:42:10,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:10,774:INFO:Checking exceptions
2025-04-19 22:42:10,774:INFO:Importing libraries
2025-04-19 22:42:10,774:INFO:Copying training dataset
2025-04-19 22:42:10,779:INFO:Defining folds
2025-04-19 22:42:10,779:INFO:Declaring metric variables
2025-04-19 22:42:10,783:INFO:Importing untrained model
2025-04-19 22:42:10,790:INFO:K Neighbors Classifier Imported successfully
2025-04-19 22:42:10,796:INFO:Starting cross validation
2025-04-19 22:42:10,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:42:15,938:INFO:Calculating mean and std
2025-04-19 22:42:15,939:INFO:Creating metrics dataframe
2025-04-19 22:42:16,561:INFO:Uploading results into container
2025-04-19 22:42:16,561:INFO:Uploading model into container now
2025-04-19 22:42:16,562:INFO:_master_model_container: 2
2025-04-19 22:42:16,562:INFO:_display_container: 2
2025-04-19 22:42:16,562:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 22:42:16,562:INFO:create_model() successfully completed......................................
2025-04-19 22:42:16,709:INFO:SubProcess create_model() end ==================================
2025-04-19 22:42:16,709:INFO:Creating metrics dataframe
2025-04-19 22:42:16,718:INFO:Initializing Naive Bayes
2025-04-19 22:42:16,718:INFO:Total runtime is 0.1958722472190857 minutes
2025-04-19 22:42:16,720:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:16,720:INFO:Initializing create_model()
2025-04-19 22:42:16,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:16,721:INFO:Checking exceptions
2025-04-19 22:42:16,721:INFO:Importing libraries
2025-04-19 22:42:16,721:INFO:Copying training dataset
2025-04-19 22:42:16,726:INFO:Defining folds
2025-04-19 22:42:16,726:INFO:Declaring metric variables
2025-04-19 22:42:16,730:INFO:Importing untrained model
2025-04-19 22:42:16,734:INFO:Naive Bayes Imported successfully
2025-04-19 22:42:16,741:INFO:Starting cross validation
2025-04-19 22:42:16,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:42:21,805:INFO:Calculating mean and std
2025-04-19 22:42:21,806:INFO:Creating metrics dataframe
2025-04-19 22:42:22,794:INFO:Uploading results into container
2025-04-19 22:42:22,795:INFO:Uploading model into container now
2025-04-19 22:42:22,795:INFO:_master_model_container: 3
2025-04-19 22:42:22,795:INFO:_display_container: 2
2025-04-19 22:42:22,797:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 22:42:22,797:INFO:create_model() successfully completed......................................
2025-04-19 22:42:22,974:INFO:SubProcess create_model() end ==================================
2025-04-19 22:42:22,974:INFO:Creating metrics dataframe
2025-04-19 22:42:22,990:INFO:Initializing Decision Tree Classifier
2025-04-19 22:42:22,990:INFO:Total runtime is 0.30040604670842486 minutes
2025-04-19 22:42:22,995:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:22,996:INFO:Initializing create_model()
2025-04-19 22:42:22,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:22,996:INFO:Checking exceptions
2025-04-19 22:42:22,996:INFO:Importing libraries
2025-04-19 22:42:22,996:INFO:Copying training dataset
2025-04-19 22:42:23,005:INFO:Defining folds
2025-04-19 22:42:23,005:INFO:Declaring metric variables
2025-04-19 22:42:23,015:INFO:Importing untrained model
2025-04-19 22:42:23,023:INFO:Decision Tree Classifier Imported successfully
2025-04-19 22:42:23,035:INFO:Starting cross validation
2025-04-19 22:42:23,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:42:31,966:INFO:Calculating mean and std
2025-04-19 22:42:31,968:INFO:Creating metrics dataframe
2025-04-19 22:42:32,690:INFO:Uploading results into container
2025-04-19 22:42:32,691:INFO:Uploading model into container now
2025-04-19 22:42:32,691:INFO:_master_model_container: 4
2025-04-19 22:42:32,692:INFO:_display_container: 2
2025-04-19 22:42:32,692:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2025-04-19 22:42:32,692:INFO:create_model() successfully completed......................................
2025-04-19 22:42:32,829:INFO:SubProcess create_model() end ==================================
2025-04-19 22:42:32,831:INFO:Creating metrics dataframe
2025-04-19 22:42:32,841:INFO:Initializing SVM - Linear Kernel
2025-04-19 22:42:32,841:INFO:Total runtime is 0.4645929018656413 minutes
2025-04-19 22:42:32,844:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:32,844:INFO:Initializing create_model()
2025-04-19 22:42:32,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:32,844:INFO:Checking exceptions
2025-04-19 22:42:32,844:INFO:Importing libraries
2025-04-19 22:42:32,845:INFO:Copying training dataset
2025-04-19 22:42:32,849:INFO:Defining folds
2025-04-19 22:42:32,849:INFO:Declaring metric variables
2025-04-19 22:42:32,853:INFO:Importing untrained model
2025-04-19 22:42:32,858:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 22:42:32,867:INFO:Starting cross validation
2025-04-19 22:42:32,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:42:33,197:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,209:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,211:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,216:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:42:33,220:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,227:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,231:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:42:33,235:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,237:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,240:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:42:33,242:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:42:33,255:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,260:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:42:33,261:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,261:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:42:33,267:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:42:37,773:INFO:Calculating mean and std
2025-04-19 22:42:37,774:INFO:Creating metrics dataframe
2025-04-19 22:42:38,405:INFO:Uploading results into container
2025-04-19 22:42:38,406:INFO:Uploading model into container now
2025-04-19 22:42:38,406:INFO:_master_model_container: 5
2025-04-19 22:42:38,406:INFO:_display_container: 2
2025-04-19 22:42:38,407:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 22:42:38,407:INFO:create_model() successfully completed......................................
2025-04-19 22:42:38,539:INFO:SubProcess create_model() end ==================================
2025-04-19 22:42:38,539:INFO:Creating metrics dataframe
2025-04-19 22:42:38,554:INFO:Initializing Ridge Classifier
2025-04-19 22:42:38,554:INFO:Total runtime is 0.559808341662089 minutes
2025-04-19 22:42:38,557:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:38,559:INFO:Initializing create_model()
2025-04-19 22:42:38,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:38,559:INFO:Checking exceptions
2025-04-19 22:42:38,559:INFO:Importing libraries
2025-04-19 22:42:38,559:INFO:Copying training dataset
2025-04-19 22:42:38,563:INFO:Defining folds
2025-04-19 22:42:38,564:INFO:Declaring metric variables
2025-04-19 22:42:38,569:INFO:Importing untrained model
2025-04-19 22:42:38,576:INFO:Ridge Classifier Imported successfully
2025-04-19 22:42:38,626:INFO:Starting cross validation
2025-04-19 22:42:38,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:42:38,954:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:38,957:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:38,963:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:38,967:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:38,968:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:38,977:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:38,990:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:38,992:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:39,004:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:39,020:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:42:43,548:INFO:Calculating mean and std
2025-04-19 22:42:43,549:INFO:Creating metrics dataframe
2025-04-19 22:42:44,162:INFO:Uploading results into container
2025-04-19 22:42:44,163:INFO:Uploading model into container now
2025-04-19 22:42:44,163:INFO:_master_model_container: 6
2025-04-19 22:42:44,163:INFO:_display_container: 2
2025-04-19 22:42:44,163:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-04-19 22:42:44,163:INFO:create_model() successfully completed......................................
2025-04-19 22:42:44,305:INFO:SubProcess create_model() end ==================================
2025-04-19 22:42:44,306:INFO:Creating metrics dataframe
2025-04-19 22:42:44,316:INFO:Initializing Random Forest Classifier
2025-04-19 22:42:44,316:INFO:Total runtime is 0.6558455109596253 minutes
2025-04-19 22:42:44,320:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:44,321:INFO:Initializing create_model()
2025-04-19 22:42:44,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:44,321:INFO:Checking exceptions
2025-04-19 22:42:44,321:INFO:Importing libraries
2025-04-19 22:42:44,321:INFO:Copying training dataset
2025-04-19 22:42:44,325:INFO:Defining folds
2025-04-19 22:42:44,325:INFO:Declaring metric variables
2025-04-19 22:42:44,330:INFO:Importing untrained model
2025-04-19 22:42:44,334:INFO:Random Forest Classifier Imported successfully
2025-04-19 22:42:44,343:INFO:Starting cross validation
2025-04-19 22:42:44,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:42:50,072:INFO:Calculating mean and std
2025-04-19 22:42:50,074:INFO:Creating metrics dataframe
2025-04-19 22:42:50,708:INFO:Uploading results into container
2025-04-19 22:42:50,709:INFO:Uploading model into container now
2025-04-19 22:42:50,710:INFO:_master_model_container: 7
2025-04-19 22:42:50,710:INFO:_display_container: 2
2025-04-19 22:42:50,710:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2025-04-19 22:42:50,711:INFO:create_model() successfully completed......................................
2025-04-19 22:42:50,850:INFO:SubProcess create_model() end ==================================
2025-04-19 22:42:50,850:INFO:Creating metrics dataframe
2025-04-19 22:42:50,861:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 22:42:50,861:INFO:Total runtime is 0.7649263143539429 minutes
2025-04-19 22:42:50,865:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:50,866:INFO:Initializing create_model()
2025-04-19 22:42:50,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:50,866:INFO:Checking exceptions
2025-04-19 22:42:50,866:INFO:Importing libraries
2025-04-19 22:42:50,866:INFO:Copying training dataset
2025-04-19 22:42:50,871:INFO:Defining folds
2025-04-19 22:42:50,871:INFO:Declaring metric variables
2025-04-19 22:42:50,875:INFO:Importing untrained model
2025-04-19 22:42:50,880:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 22:42:50,886:INFO:Starting cross validation
2025-04-19 22:42:50,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:42:51,107:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,109:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,111:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,119:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,120:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,127:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,142:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,150:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,158:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:51,161:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:42:55,886:INFO:Calculating mean and std
2025-04-19 22:42:55,887:INFO:Creating metrics dataframe
2025-04-19 22:42:56,523:INFO:Uploading results into container
2025-04-19 22:42:56,524:INFO:Uploading model into container now
2025-04-19 22:42:56,524:INFO:_master_model_container: 8
2025-04-19 22:42:56,524:INFO:_display_container: 2
2025-04-19 22:42:56,525:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 22:42:56,525:INFO:create_model() successfully completed......................................
2025-04-19 22:42:56,656:INFO:SubProcess create_model() end ==================================
2025-04-19 22:42:56,656:INFO:Creating metrics dataframe
2025-04-19 22:42:56,666:INFO:Initializing Ada Boost Classifier
2025-04-19 22:42:56,666:INFO:Total runtime is 0.8616748929023743 minutes
2025-04-19 22:42:56,670:INFO:SubProcess create_model() called ==================================
2025-04-19 22:42:56,670:INFO:Initializing create_model()
2025-04-19 22:42:56,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:42:56,671:INFO:Checking exceptions
2025-04-19 22:42:56,671:INFO:Importing libraries
2025-04-19 22:42:56,671:INFO:Copying training dataset
2025-04-19 22:42:56,675:INFO:Defining folds
2025-04-19 22:42:56,675:INFO:Declaring metric variables
2025-04-19 22:42:56,681:INFO:Importing untrained model
2025-04-19 22:42:56,685:INFO:Ada Boost Classifier Imported successfully
2025-04-19 22:42:56,692:INFO:Starting cross validation
2025-04-19 22:42:56,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:43:02,162:INFO:Calculating mean and std
2025-04-19 22:43:02,163:INFO:Creating metrics dataframe
2025-04-19 22:43:02,810:INFO:Uploading results into container
2025-04-19 22:43:02,811:INFO:Uploading model into container now
2025-04-19 22:43:02,811:INFO:_master_model_container: 9
2025-04-19 22:43:02,811:INFO:_display_container: 2
2025-04-19 22:43:02,811:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2025-04-19 22:43:02,812:INFO:create_model() successfully completed......................................
2025-04-19 22:43:02,956:INFO:SubProcess create_model() end ==================================
2025-04-19 22:43:02,956:INFO:Creating metrics dataframe
2025-04-19 22:43:02,967:INFO:Initializing Gradient Boosting Classifier
2025-04-19 22:43:02,967:INFO:Total runtime is 0.9666997075080872 minutes
2025-04-19 22:43:02,971:INFO:SubProcess create_model() called ==================================
2025-04-19 22:43:02,971:INFO:Initializing create_model()
2025-04-19 22:43:02,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:43:02,971:INFO:Checking exceptions
2025-04-19 22:43:02,971:INFO:Importing libraries
2025-04-19 22:43:02,971:INFO:Copying training dataset
2025-04-19 22:43:02,975:INFO:Defining folds
2025-04-19 22:43:02,975:INFO:Declaring metric variables
2025-04-19 22:43:02,980:INFO:Importing untrained model
2025-04-19 22:43:02,983:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 22:43:02,990:INFO:Starting cross validation
2025-04-19 22:43:02,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:43:08,854:INFO:Calculating mean and std
2025-04-19 22:43:08,855:INFO:Creating metrics dataframe
2025-04-19 22:43:09,508:INFO:Uploading results into container
2025-04-19 22:43:09,509:INFO:Uploading model into container now
2025-04-19 22:43:09,510:INFO:_master_model_container: 10
2025-04-19 22:43:09,510:INFO:_display_container: 2
2025-04-19 22:43:09,510:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:43:09,510:INFO:create_model() successfully completed......................................
2025-04-19 22:43:09,638:INFO:SubProcess create_model() end ==================================
2025-04-19 22:43:09,638:INFO:Creating metrics dataframe
2025-04-19 22:43:09,649:INFO:Initializing Linear Discriminant Analysis
2025-04-19 22:43:09,649:INFO:Total runtime is 1.0780656218528748 minutes
2025-04-19 22:43:09,652:INFO:SubProcess create_model() called ==================================
2025-04-19 22:43:09,653:INFO:Initializing create_model()
2025-04-19 22:43:09,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:43:09,653:INFO:Checking exceptions
2025-04-19 22:43:09,653:INFO:Importing libraries
2025-04-19 22:43:09,653:INFO:Copying training dataset
2025-04-19 22:43:09,659:INFO:Defining folds
2025-04-19 22:43:09,659:INFO:Declaring metric variables
2025-04-19 22:43:09,665:INFO:Importing untrained model
2025-04-19 22:43:09,674:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 22:43:09,690:INFO:Starting cross validation
2025-04-19 22:43:09,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:43:14,965:INFO:Calculating mean and std
2025-04-19 22:43:14,966:INFO:Creating metrics dataframe
2025-04-19 22:43:15,639:INFO:Uploading results into container
2025-04-19 22:43:15,640:INFO:Uploading model into container now
2025-04-19 22:43:15,640:INFO:_master_model_container: 11
2025-04-19 22:43:15,641:INFO:_display_container: 2
2025-04-19 22:43:15,641:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 22:43:15,641:INFO:create_model() successfully completed......................................
2025-04-19 22:43:15,773:INFO:SubProcess create_model() end ==================================
2025-04-19 22:43:15,773:INFO:Creating metrics dataframe
2025-04-19 22:43:15,784:INFO:Initializing Extra Trees Classifier
2025-04-19 22:43:15,784:INFO:Total runtime is 1.1803159793217977 minutes
2025-04-19 22:43:15,787:INFO:SubProcess create_model() called ==================================
2025-04-19 22:43:15,787:INFO:Initializing create_model()
2025-04-19 22:43:15,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:43:15,787:INFO:Checking exceptions
2025-04-19 22:43:15,787:INFO:Importing libraries
2025-04-19 22:43:15,787:INFO:Copying training dataset
2025-04-19 22:43:15,791:INFO:Defining folds
2025-04-19 22:43:15,791:INFO:Declaring metric variables
2025-04-19 22:43:15,794:INFO:Importing untrained model
2025-04-19 22:43:15,798:INFO:Extra Trees Classifier Imported successfully
2025-04-19 22:43:15,804:INFO:Starting cross validation
2025-04-19 22:43:15,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:43:21,751:INFO:Calculating mean and std
2025-04-19 22:43:21,752:INFO:Creating metrics dataframe
2025-04-19 22:43:22,403:INFO:Uploading results into container
2025-04-19 22:43:22,405:INFO:Uploading model into container now
2025-04-19 22:43:22,405:INFO:_master_model_container: 12
2025-04-19 22:43:22,406:INFO:_display_container: 2
2025-04-19 22:43:22,406:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2025-04-19 22:43:22,406:INFO:create_model() successfully completed......................................
2025-04-19 22:43:22,535:INFO:SubProcess create_model() end ==================================
2025-04-19 22:43:22,535:INFO:Creating metrics dataframe
2025-04-19 22:43:22,546:INFO:Initializing Extreme Gradient Boosting
2025-04-19 22:43:22,546:INFO:Total runtime is 1.2930111805597941 minutes
2025-04-19 22:43:22,550:INFO:SubProcess create_model() called ==================================
2025-04-19 22:43:22,550:INFO:Initializing create_model()
2025-04-19 22:43:22,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:43:22,550:INFO:Checking exceptions
2025-04-19 22:43:22,550:INFO:Importing libraries
2025-04-19 22:43:22,550:INFO:Copying training dataset
2025-04-19 22:43:22,554:INFO:Defining folds
2025-04-19 22:43:22,554:INFO:Declaring metric variables
2025-04-19 22:43:22,558:INFO:Importing untrained model
2025-04-19 22:43:22,564:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 22:43:22,571:INFO:Starting cross validation
2025-04-19 22:43:22,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:43:28,385:INFO:Calculating mean and std
2025-04-19 22:43:28,388:INFO:Creating metrics dataframe
2025-04-19 22:43:29,062:INFO:Uploading results into container
2025-04-19 22:43:29,063:INFO:Uploading model into container now
2025-04-19 22:43:29,064:INFO:_master_model_container: 13
2025-04-19 22:43:29,064:INFO:_display_container: 2
2025-04-19 22:43:29,065:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 22:43:29,065:INFO:create_model() successfully completed......................................
2025-04-19 22:43:29,206:INFO:SubProcess create_model() end ==================================
2025-04-19 22:43:29,206:INFO:Creating metrics dataframe
2025-04-19 22:43:29,218:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 22:43:29,218:INFO:Total runtime is 1.404209558169047 minutes
2025-04-19 22:43:29,221:INFO:SubProcess create_model() called ==================================
2025-04-19 22:43:29,221:INFO:Initializing create_model()
2025-04-19 22:43:29,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:43:29,221:INFO:Checking exceptions
2025-04-19 22:43:29,221:INFO:Importing libraries
2025-04-19 22:43:29,221:INFO:Copying training dataset
2025-04-19 22:43:29,226:INFO:Defining folds
2025-04-19 22:43:29,226:INFO:Declaring metric variables
2025-04-19 22:43:29,230:INFO:Importing untrained model
2025-04-19 22:43:29,236:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 22:43:29,243:INFO:Starting cross validation
2025-04-19 22:43:29,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:43:36,681:INFO:Calculating mean and std
2025-04-19 22:43:36,681:INFO:Creating metrics dataframe
2025-04-19 22:43:37,376:INFO:Uploading results into container
2025-04-19 22:43:37,377:INFO:Uploading model into container now
2025-04-19 22:43:37,378:INFO:_master_model_container: 14
2025-04-19 22:43:37,378:INFO:_display_container: 2
2025-04-19 22:43:37,378:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 22:43:37,379:INFO:create_model() successfully completed......................................
2025-04-19 22:43:37,517:INFO:SubProcess create_model() end ==================================
2025-04-19 22:43:37,517:INFO:Creating metrics dataframe
2025-04-19 22:43:37,527:INFO:Initializing Dummy Classifier
2025-04-19 22:43:37,529:INFO:Total runtime is 1.5427217920621237 minutes
2025-04-19 22:43:37,531:INFO:SubProcess create_model() called ==================================
2025-04-19 22:43:37,531:INFO:Initializing create_model()
2025-04-19 22:43:37,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C132EDBFA0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:43:37,531:INFO:Checking exceptions
2025-04-19 22:43:37,533:INFO:Importing libraries
2025-04-19 22:43:37,533:INFO:Copying training dataset
2025-04-19 22:43:37,537:INFO:Defining folds
2025-04-19 22:43:37,537:INFO:Declaring metric variables
2025-04-19 22:43:37,540:INFO:Importing untrained model
2025-04-19 22:43:37,544:INFO:Dummy Classifier Imported successfully
2025-04-19 22:43:37,553:INFO:Starting cross validation
2025-04-19 22:43:37,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:43:37,953:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:37,970:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:37,975:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:37,977:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:37,977:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:37,979:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:37,980:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:37,991:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:37,998:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:38,017:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:43:43,050:INFO:Calculating mean and std
2025-04-19 22:43:43,054:INFO:Creating metrics dataframe
2025-04-19 22:43:43,747:INFO:Uploading results into container
2025-04-19 22:43:43,747:INFO:Uploading model into container now
2025-04-19 22:43:43,748:INFO:_master_model_container: 15
2025-04-19 22:43:43,748:INFO:_display_container: 2
2025-04-19 22:43:43,748:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-04-19 22:43:43,748:INFO:create_model() successfully completed......................................
2025-04-19 22:43:43,878:INFO:SubProcess create_model() end ==================================
2025-04-19 22:43:43,878:INFO:Creating metrics dataframe
2025-04-19 22:43:43,899:INFO:Initializing create_model()
2025-04-19 22:43:43,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1332A8FA0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:43:43,900:INFO:Checking exceptions
2025-04-19 22:43:43,902:INFO:Importing libraries
2025-04-19 22:43:43,902:INFO:Copying training dataset
2025-04-19 22:43:43,909:INFO:Defining folds
2025-04-19 22:43:43,910:INFO:Declaring metric variables
2025-04-19 22:43:43,910:INFO:Importing untrained model
2025-04-19 22:43:43,910:INFO:Declaring custom model
2025-04-19 22:43:43,912:INFO:Dummy Classifier Imported successfully
2025-04-19 22:43:43,913:INFO:Cross validation set to False
2025-04-19 22:43:43,913:INFO:Fitting Model
2025-04-19 22:43:44,551:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-04-19 22:43:44,551:INFO:create_model() successfully completed......................................
2025-04-19 22:43:44,715:INFO:_master_model_container: 15
2025-04-19 22:43:44,715:INFO:_display_container: 2
2025-04-19 22:43:44,715:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-04-19 22:43:44,715:INFO:compare_models() successfully completed......................................
2025-04-19 22:43:58,025:INFO:PyCaret ClassificationExperiment
2025-04-19 22:43:58,025:INFO:Logging name: clf-default-name
2025-04-19 22:43:58,025:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 22:43:58,025:INFO:version 3.0.4
2025-04-19 22:43:58,025:INFO:Initializing setup()
2025-04-19 22:43:58,025:INFO:self.USI: 1ae3
2025-04-19 22:43:58,025:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 22:43:58,025:INFO:Checking environment
2025-04-19 22:43:58,025:INFO:python_version: 3.10.5
2025-04-19 22:43:58,025:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 22:43:58,025:INFO:machine: AMD64
2025-04-19 22:43:58,025:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 22:43:58,031:INFO:Memory: svmem(total=25042907136, available=9871990784, percent=60.6, used=15170916352, free=9871990784)
2025-04-19 22:43:58,031:INFO:Physical Core: 6
2025-04-19 22:43:58,031:INFO:Logical Core: 12
2025-04-19 22:43:58,031:INFO:Checking libraries
2025-04-19 22:43:58,031:INFO:System:
2025-04-19 22:43:58,033:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 22:43:58,033:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 22:43:58,033:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 22:43:58,033:INFO:PyCaret required dependencies:
2025-04-19 22:43:58,033:INFO:                 pip: 25.0.1
2025-04-19 22:43:58,033:INFO:          setuptools: 58.1.0
2025-04-19 22:43:58,033:INFO:             pycaret: 3.0.4
2025-04-19 22:43:58,033:INFO:             IPython: 8.29.0
2025-04-19 22:43:58,033:INFO:          ipywidgets: 8.1.6
2025-04-19 22:43:58,033:INFO:                tqdm: 4.67.1
2025-04-19 22:43:58,033:INFO:               numpy: 1.23.5
2025-04-19 22:43:58,033:INFO:              pandas: 1.5.3
2025-04-19 22:43:58,033:INFO:              jinja2: 3.1.4
2025-04-19 22:43:58,033:INFO:               scipy: 1.11.4
2025-04-19 22:43:58,033:INFO:              joblib: 1.3.2
2025-04-19 22:43:58,033:INFO:             sklearn: 1.2.2
2025-04-19 22:43:58,033:INFO:                pyod: 2.0.4
2025-04-19 22:43:58,033:INFO:            imblearn: 0.10.1
2025-04-19 22:43:58,033:INFO:   category_encoders: 2.7.0
2025-04-19 22:43:58,033:INFO:            lightgbm: 4.6.0
2025-04-19 22:43:58,033:INFO:               numba: 0.60.0
2025-04-19 22:43:58,033:INFO:            requests: 2.32.3
2025-04-19 22:43:58,033:INFO:          matplotlib: 3.7.5
2025-04-19 22:43:58,033:INFO:          scikitplot: 0.3.7
2025-04-19 22:43:58,033:INFO:         yellowbrick: 1.5
2025-04-19 22:43:58,034:INFO:              plotly: 5.24.1
2025-04-19 22:43:58,034:INFO:    plotly-resampler: Not installed
2025-04-19 22:43:58,034:INFO:             kaleido: 0.2.1
2025-04-19 22:43:58,034:INFO:           schemdraw: 0.15
2025-04-19 22:43:58,034:INFO:         statsmodels: 0.14.4
2025-04-19 22:43:58,034:INFO:              sktime: 0.26.0
2025-04-19 22:43:58,034:INFO:               tbats: 1.1.3
2025-04-19 22:43:58,034:INFO:            pmdarima: 2.0.4
2025-04-19 22:43:58,034:INFO:              psutil: 6.1.0
2025-04-19 22:43:58,034:INFO:          markupsafe: 3.0.2
2025-04-19 22:43:58,034:INFO:             pickle5: Not installed
2025-04-19 22:43:58,034:INFO:         cloudpickle: 3.1.1
2025-04-19 22:43:58,034:INFO:         deprecation: 2.1.0
2025-04-19 22:43:58,034:INFO:              xxhash: 3.5.0
2025-04-19 22:43:58,034:INFO:           wurlitzer: Not installed
2025-04-19 22:43:58,034:INFO:PyCaret optional dependencies:
2025-04-19 22:43:58,034:INFO:                shap: Not installed
2025-04-19 22:43:58,034:INFO:           interpret: Not installed
2025-04-19 22:43:58,034:INFO:                umap: Not installed
2025-04-19 22:43:58,034:INFO:    pandas_profiling: Not installed
2025-04-19 22:43:58,034:INFO:  explainerdashboard: Not installed
2025-04-19 22:43:58,034:INFO:             autoviz: Not installed
2025-04-19 22:43:58,034:INFO:           fairlearn: Not installed
2025-04-19 22:43:58,034:INFO:          deepchecks: Not installed
2025-04-19 22:43:58,034:INFO:             xgboost: 1.7.6
2025-04-19 22:43:58,034:INFO:            catboost: Not installed
2025-04-19 22:43:58,034:INFO:              kmodes: Not installed
2025-04-19 22:43:58,034:INFO:             mlxtend: Not installed
2025-04-19 22:43:58,034:INFO:       statsforecast: Not installed
2025-04-19 22:43:58,034:INFO:        tune_sklearn: Not installed
2025-04-19 22:43:58,034:INFO:                 ray: Not installed
2025-04-19 22:43:58,034:INFO:            hyperopt: Not installed
2025-04-19 22:43:58,034:INFO:              optuna: Not installed
2025-04-19 22:43:58,034:INFO:               skopt: Not installed
2025-04-19 22:43:58,034:INFO:              mlflow: Not installed
2025-04-19 22:43:58,034:INFO:              gradio: Not installed
2025-04-19 22:43:58,034:INFO:             fastapi: Not installed
2025-04-19 22:43:58,034:INFO:             uvicorn: Not installed
2025-04-19 22:43:58,034:INFO:              m2cgen: Not installed
2025-04-19 22:43:58,034:INFO:           evidently: Not installed
2025-04-19 22:43:58,034:INFO:               fugue: Not installed
2025-04-19 22:43:58,034:INFO:           streamlit: 1.42.0
2025-04-19 22:43:58,034:INFO:             prophet: Not installed
2025-04-19 22:43:58,034:INFO:None
2025-04-19 22:43:58,034:INFO:Set up data.
2025-04-19 22:43:58,042:INFO:Set up train/test split.
2025-04-19 22:43:58,046:INFO:Set up index.
2025-04-19 22:43:58,046:INFO:Set up folding strategy.
2025-04-19 22:43:58,046:INFO:Assigning column types.
2025-04-19 22:43:58,050:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 22:43:58,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:43:58,091:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:43:58,118:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:43:58,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:43:58,164:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:43:58,165:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:43:58,190:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:43:58,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:43:58,193:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 22:43:58,241:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:43:58,269:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:43:58,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:43:58,326:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:43:58,359:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:43:58,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:43:58,362:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 22:43:58,431:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:43:58,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:43:58,500:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:43:58,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:43:58,503:INFO:Preparing preprocessing pipeline...
2025-04-19 22:43:58,504:INFO:Set up simple imputation.
2025-04-19 22:43:58,508:INFO:Set up encoding of ordinal features.
2025-04-19 22:43:58,510:INFO:Set up encoding of categorical features.
2025-04-19 22:43:58,510:INFO:Set up imbalanced handling.
2025-04-19 22:43:58,510:INFO:Set up feature normalization.
2025-04-19 22:43:58,637:INFO:Finished creating preprocessing pipeline.
2025-04-19 22:43:58,664:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['DistanceFromHome',
                                             'NumCompaniesWorked',
                                             'MonthlyRate'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprec...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 22:43:58,665:INFO:Creating final display dataframe.
2025-04-19 22:43:58,966:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 10)
4        Transformed data shape        (1548, 27)
5   Transformed train set shape        (1230, 27)
6    Transformed test set shape         (318, 27)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              1ae3
2025-04-19 22:43:59,033:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:43:59,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:43:59,103:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:43:59,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:43:59,105:INFO:setup() successfully completed in 1.62s...............
2025-04-19 22:44:00,888:INFO:Initializing compare_models()
2025-04-19 22:44:00,888:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 22:44:00,888:INFO:Checking exceptions
2025-04-19 22:44:00,892:INFO:Preparing display monitor
2025-04-19 22:44:00,919:INFO:Initializing Logistic Regression
2025-04-19 22:44:00,919:INFO:Total runtime is 0.0 minutes
2025-04-19 22:44:00,926:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:00,928:INFO:Initializing create_model()
2025-04-19 22:44:00,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:00,928:INFO:Checking exceptions
2025-04-19 22:44:00,928:INFO:Importing libraries
2025-04-19 22:44:00,928:INFO:Copying training dataset
2025-04-19 22:44:00,931:INFO:Defining folds
2025-04-19 22:44:00,931:INFO:Declaring metric variables
2025-04-19 22:44:00,937:INFO:Importing untrained model
2025-04-19 22:44:00,943:INFO:Logistic Regression Imported successfully
2025-04-19 22:44:00,952:INFO:Starting cross validation
2025-04-19 22:44:00,954:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:44:06,733:INFO:Calculating mean and std
2025-04-19 22:44:06,735:INFO:Creating metrics dataframe
2025-04-19 22:44:07,424:INFO:Uploading results into container
2025-04-19 22:44:07,424:INFO:Uploading model into container now
2025-04-19 22:44:07,426:INFO:_master_model_container: 1
2025-04-19 22:44:07,426:INFO:_display_container: 2
2025-04-19 22:44:07,426:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 22:44:07,426:INFO:create_model() successfully completed......................................
2025-04-19 22:44:07,631:INFO:SubProcess create_model() end ==================================
2025-04-19 22:44:07,631:INFO:Creating metrics dataframe
2025-04-19 22:44:07,653:INFO:Initializing K Neighbors Classifier
2025-04-19 22:44:07,653:INFO:Total runtime is 0.11223580837249755 minutes
2025-04-19 22:44:07,660:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:07,662:INFO:Initializing create_model()
2025-04-19 22:44:07,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:07,662:INFO:Checking exceptions
2025-04-19 22:44:07,663:INFO:Importing libraries
2025-04-19 22:44:07,663:INFO:Copying training dataset
2025-04-19 22:44:07,674:INFO:Defining folds
2025-04-19 22:44:07,674:INFO:Declaring metric variables
2025-04-19 22:44:07,684:INFO:Importing untrained model
2025-04-19 22:44:07,692:INFO:K Neighbors Classifier Imported successfully
2025-04-19 22:44:07,708:INFO:Starting cross validation
2025-04-19 22:44:07,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:44:15,832:INFO:Calculating mean and std
2025-04-19 22:44:15,834:INFO:Creating metrics dataframe
2025-04-19 22:44:16,500:INFO:Uploading results into container
2025-04-19 22:44:16,500:INFO:Uploading model into container now
2025-04-19 22:44:16,501:INFO:_master_model_container: 2
2025-04-19 22:44:16,501:INFO:_display_container: 2
2025-04-19 22:44:16,501:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 22:44:16,501:INFO:create_model() successfully completed......................................
2025-04-19 22:44:16,651:INFO:SubProcess create_model() end ==================================
2025-04-19 22:44:16,651:INFO:Creating metrics dataframe
2025-04-19 22:44:16,661:INFO:Initializing Naive Bayes
2025-04-19 22:44:16,661:INFO:Total runtime is 0.2623710831006368 minutes
2025-04-19 22:44:16,664:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:16,665:INFO:Initializing create_model()
2025-04-19 22:44:16,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:16,665:INFO:Checking exceptions
2025-04-19 22:44:16,665:INFO:Importing libraries
2025-04-19 22:44:16,665:INFO:Copying training dataset
2025-04-19 22:44:16,670:INFO:Defining folds
2025-04-19 22:44:16,671:INFO:Declaring metric variables
2025-04-19 22:44:16,674:INFO:Importing untrained model
2025-04-19 22:44:16,679:INFO:Naive Bayes Imported successfully
2025-04-19 22:44:16,688:INFO:Starting cross validation
2025-04-19 22:44:16,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:44:22,210:INFO:Calculating mean and std
2025-04-19 22:44:22,211:INFO:Creating metrics dataframe
2025-04-19 22:44:22,918:INFO:Uploading results into container
2025-04-19 22:44:22,919:INFO:Uploading model into container now
2025-04-19 22:44:22,920:INFO:_master_model_container: 3
2025-04-19 22:44:22,920:INFO:_display_container: 2
2025-04-19 22:44:22,920:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 22:44:22,920:INFO:create_model() successfully completed......................................
2025-04-19 22:44:23,062:INFO:SubProcess create_model() end ==================================
2025-04-19 22:44:23,063:INFO:Creating metrics dataframe
2025-04-19 22:44:23,072:INFO:Initializing Decision Tree Classifier
2025-04-19 22:44:23,072:INFO:Total runtime is 0.36921424468358355 minutes
2025-04-19 22:44:23,075:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:23,075:INFO:Initializing create_model()
2025-04-19 22:44:23,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:23,075:INFO:Checking exceptions
2025-04-19 22:44:23,075:INFO:Importing libraries
2025-04-19 22:44:23,075:INFO:Copying training dataset
2025-04-19 22:44:23,080:INFO:Defining folds
2025-04-19 22:44:23,080:INFO:Declaring metric variables
2025-04-19 22:44:23,083:INFO:Importing untrained model
2025-04-19 22:44:23,089:INFO:Decision Tree Classifier Imported successfully
2025-04-19 22:44:23,096:INFO:Starting cross validation
2025-04-19 22:44:23,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:44:28,685:INFO:Calculating mean and std
2025-04-19 22:44:28,686:INFO:Creating metrics dataframe
2025-04-19 22:44:29,373:INFO:Uploading results into container
2025-04-19 22:44:29,374:INFO:Uploading model into container now
2025-04-19 22:44:29,374:INFO:_master_model_container: 4
2025-04-19 22:44:29,374:INFO:_display_container: 2
2025-04-19 22:44:29,375:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2025-04-19 22:44:29,375:INFO:create_model() successfully completed......................................
2025-04-19 22:44:29,524:INFO:SubProcess create_model() end ==================================
2025-04-19 22:44:29,524:INFO:Creating metrics dataframe
2025-04-19 22:44:29,537:INFO:Initializing SVM - Linear Kernel
2025-04-19 22:44:29,537:INFO:Total runtime is 0.4769593278566996 minutes
2025-04-19 22:44:29,540:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:29,540:INFO:Initializing create_model()
2025-04-19 22:44:29,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:29,540:INFO:Checking exceptions
2025-04-19 22:44:29,540:INFO:Importing libraries
2025-04-19 22:44:29,540:INFO:Copying training dataset
2025-04-19 22:44:29,547:INFO:Defining folds
2025-04-19 22:44:29,547:INFO:Declaring metric variables
2025-04-19 22:44:29,552:INFO:Importing untrained model
2025-04-19 22:44:29,558:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 22:44:29,564:INFO:Starting cross validation
2025-04-19 22:44:29,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:44:29,897:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,911:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,916:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,926:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,933:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,943:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,950:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,959:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,962:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:29,983:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:44:35,080:INFO:Calculating mean and std
2025-04-19 22:44:35,081:INFO:Creating metrics dataframe
2025-04-19 22:44:35,761:INFO:Uploading results into container
2025-04-19 22:44:35,763:INFO:Uploading model into container now
2025-04-19 22:44:35,763:INFO:_master_model_container: 5
2025-04-19 22:44:35,763:INFO:_display_container: 2
2025-04-19 22:44:35,764:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 22:44:35,764:INFO:create_model() successfully completed......................................
2025-04-19 22:44:35,895:INFO:SubProcess create_model() end ==================================
2025-04-19 22:44:35,895:INFO:Creating metrics dataframe
2025-04-19 22:44:35,904:INFO:Initializing Ridge Classifier
2025-04-19 22:44:35,904:INFO:Total runtime is 0.5830879052480061 minutes
2025-04-19 22:44:35,908:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:35,908:INFO:Initializing create_model()
2025-04-19 22:44:35,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:35,908:INFO:Checking exceptions
2025-04-19 22:44:35,908:INFO:Importing libraries
2025-04-19 22:44:35,908:INFO:Copying training dataset
2025-04-19 22:44:35,913:INFO:Defining folds
2025-04-19 22:44:35,913:INFO:Declaring metric variables
2025-04-19 22:44:35,920:INFO:Importing untrained model
2025-04-19 22:44:35,927:INFO:Ridge Classifier Imported successfully
2025-04-19 22:44:35,933:INFO:Starting cross validation
2025-04-19 22:44:35,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:44:36,280:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,290:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,292:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,300:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,300:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,313:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,322:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,330:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,336:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:36,339:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:44:41,381:INFO:Calculating mean and std
2025-04-19 22:44:41,382:INFO:Creating metrics dataframe
2025-04-19 22:44:42,070:INFO:Uploading results into container
2025-04-19 22:44:42,071:INFO:Uploading model into container now
2025-04-19 22:44:42,071:INFO:_master_model_container: 6
2025-04-19 22:44:42,071:INFO:_display_container: 2
2025-04-19 22:44:42,072:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-04-19 22:44:42,072:INFO:create_model() successfully completed......................................
2025-04-19 22:44:42,270:INFO:SubProcess create_model() end ==================================
2025-04-19 22:44:42,270:INFO:Creating metrics dataframe
2025-04-19 22:44:42,281:INFO:Initializing Random Forest Classifier
2025-04-19 22:44:42,281:INFO:Total runtime is 0.6893566926320394 minutes
2025-04-19 22:44:42,284:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:42,284:INFO:Initializing create_model()
2025-04-19 22:44:42,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:42,284:INFO:Checking exceptions
2025-04-19 22:44:42,284:INFO:Importing libraries
2025-04-19 22:44:42,284:INFO:Copying training dataset
2025-04-19 22:44:42,289:INFO:Defining folds
2025-04-19 22:44:42,289:INFO:Declaring metric variables
2025-04-19 22:44:42,292:INFO:Importing untrained model
2025-04-19 22:44:42,296:INFO:Random Forest Classifier Imported successfully
2025-04-19 22:44:42,302:INFO:Starting cross validation
2025-04-19 22:44:42,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:44:48,560:INFO:Calculating mean and std
2025-04-19 22:44:48,562:INFO:Creating metrics dataframe
2025-04-19 22:44:49,301:INFO:Uploading results into container
2025-04-19 22:44:49,302:INFO:Uploading model into container now
2025-04-19 22:44:49,302:INFO:_master_model_container: 7
2025-04-19 22:44:49,302:INFO:_display_container: 2
2025-04-19 22:44:49,303:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2025-04-19 22:44:49,303:INFO:create_model() successfully completed......................................
2025-04-19 22:44:49,430:INFO:SubProcess create_model() end ==================================
2025-04-19 22:44:49,430:INFO:Creating metrics dataframe
2025-04-19 22:44:49,439:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 22:44:49,439:INFO:Total runtime is 0.8086649894714355 minutes
2025-04-19 22:44:49,442:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:49,442:INFO:Initializing create_model()
2025-04-19 22:44:49,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:49,442:INFO:Checking exceptions
2025-04-19 22:44:49,442:INFO:Importing libraries
2025-04-19 22:44:49,442:INFO:Copying training dataset
2025-04-19 22:44:49,448:INFO:Defining folds
2025-04-19 22:44:49,448:INFO:Declaring metric variables
2025-04-19 22:44:49,450:INFO:Importing untrained model
2025-04-19 22:44:49,453:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 22:44:49,459:INFO:Starting cross validation
2025-04-19 22:44:49,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:44:49,696:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,699:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,699:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,710:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,741:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,772:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,774:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,774:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,789:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:49,792:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 22:44:55,061:INFO:Calculating mean and std
2025-04-19 22:44:55,061:INFO:Creating metrics dataframe
2025-04-19 22:44:55,784:INFO:Uploading results into container
2025-04-19 22:44:55,784:INFO:Uploading model into container now
2025-04-19 22:44:55,785:INFO:_master_model_container: 8
2025-04-19 22:44:55,785:INFO:_display_container: 2
2025-04-19 22:44:55,786:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 22:44:55,786:INFO:create_model() successfully completed......................................
2025-04-19 22:44:55,916:INFO:SubProcess create_model() end ==================================
2025-04-19 22:44:55,916:INFO:Creating metrics dataframe
2025-04-19 22:44:55,928:INFO:Initializing Ada Boost Classifier
2025-04-19 22:44:55,928:INFO:Total runtime is 0.9168064753214518 minutes
2025-04-19 22:44:55,930:INFO:SubProcess create_model() called ==================================
2025-04-19 22:44:55,931:INFO:Initializing create_model()
2025-04-19 22:44:55,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:44:55,931:INFO:Checking exceptions
2025-04-19 22:44:55,931:INFO:Importing libraries
2025-04-19 22:44:55,931:INFO:Copying training dataset
2025-04-19 22:44:55,936:INFO:Defining folds
2025-04-19 22:44:55,937:INFO:Declaring metric variables
2025-04-19 22:44:55,939:INFO:Importing untrained model
2025-04-19 22:44:55,943:INFO:Ada Boost Classifier Imported successfully
2025-04-19 22:44:55,950:INFO:Starting cross validation
2025-04-19 22:44:55,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:45:02,570:INFO:Calculating mean and std
2025-04-19 22:45:02,571:INFO:Creating metrics dataframe
2025-04-19 22:45:03,261:INFO:Uploading results into container
2025-04-19 22:45:03,261:INFO:Uploading model into container now
2025-04-19 22:45:03,262:INFO:_master_model_container: 9
2025-04-19 22:45:03,262:INFO:_display_container: 2
2025-04-19 22:45:03,263:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2025-04-19 22:45:03,263:INFO:create_model() successfully completed......................................
2025-04-19 22:45:03,391:INFO:SubProcess create_model() end ==================================
2025-04-19 22:45:03,391:INFO:Creating metrics dataframe
2025-04-19 22:45:03,403:INFO:Initializing Gradient Boosting Classifier
2025-04-19 22:45:03,403:INFO:Total runtime is 1.041396927833557 minutes
2025-04-19 22:45:03,404:INFO:SubProcess create_model() called ==================================
2025-04-19 22:45:03,406:INFO:Initializing create_model()
2025-04-19 22:45:03,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:45:03,406:INFO:Checking exceptions
2025-04-19 22:45:03,406:INFO:Importing libraries
2025-04-19 22:45:03,406:INFO:Copying training dataset
2025-04-19 22:45:03,409:INFO:Defining folds
2025-04-19 22:45:03,409:INFO:Declaring metric variables
2025-04-19 22:45:03,413:INFO:Importing untrained model
2025-04-19 22:45:03,416:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 22:45:03,420:INFO:Starting cross validation
2025-04-19 22:45:03,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:45:09,938:INFO:Calculating mean and std
2025-04-19 22:45:09,939:INFO:Creating metrics dataframe
2025-04-19 22:45:10,652:INFO:Uploading results into container
2025-04-19 22:45:10,654:INFO:Uploading model into container now
2025-04-19 22:45:10,655:INFO:_master_model_container: 10
2025-04-19 22:45:10,655:INFO:_display_container: 2
2025-04-19 22:45:10,656:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:45:10,656:INFO:create_model() successfully completed......................................
2025-04-19 22:45:10,806:INFO:SubProcess create_model() end ==================================
2025-04-19 22:45:10,806:INFO:Creating metrics dataframe
2025-04-19 22:45:10,819:INFO:Initializing Linear Discriminant Analysis
2025-04-19 22:45:10,819:INFO:Total runtime is 1.164994732538859 minutes
2025-04-19 22:45:10,821:INFO:SubProcess create_model() called ==================================
2025-04-19 22:45:10,821:INFO:Initializing create_model()
2025-04-19 22:45:10,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:45:10,823:INFO:Checking exceptions
2025-04-19 22:45:10,823:INFO:Importing libraries
2025-04-19 22:45:10,823:INFO:Copying training dataset
2025-04-19 22:45:10,828:INFO:Defining folds
2025-04-19 22:45:10,829:INFO:Declaring metric variables
2025-04-19 22:45:10,833:INFO:Importing untrained model
2025-04-19 22:45:10,837:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 22:45:10,846:INFO:Starting cross validation
2025-04-19 22:45:10,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:45:16,779:INFO:Calculating mean and std
2025-04-19 22:45:16,780:INFO:Creating metrics dataframe
2025-04-19 22:45:17,474:INFO:Uploading results into container
2025-04-19 22:45:17,474:INFO:Uploading model into container now
2025-04-19 22:45:17,475:INFO:_master_model_container: 11
2025-04-19 22:45:17,475:INFO:_display_container: 2
2025-04-19 22:45:17,475:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 22:45:17,475:INFO:create_model() successfully completed......................................
2025-04-19 22:45:17,610:INFO:SubProcess create_model() end ==================================
2025-04-19 22:45:17,610:INFO:Creating metrics dataframe
2025-04-19 22:45:17,623:INFO:Initializing Extra Trees Classifier
2025-04-19 22:45:17,624:INFO:Total runtime is 1.278412401676178 minutes
2025-04-19 22:45:17,628:INFO:SubProcess create_model() called ==================================
2025-04-19 22:45:17,628:INFO:Initializing create_model()
2025-04-19 22:45:17,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:45:17,628:INFO:Checking exceptions
2025-04-19 22:45:17,628:INFO:Importing libraries
2025-04-19 22:45:17,628:INFO:Copying training dataset
2025-04-19 22:45:17,634:INFO:Defining folds
2025-04-19 22:45:17,634:INFO:Declaring metric variables
2025-04-19 22:45:17,638:INFO:Importing untrained model
2025-04-19 22:45:17,642:INFO:Extra Trees Classifier Imported successfully
2025-04-19 22:45:17,650:INFO:Starting cross validation
2025-04-19 22:45:17,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:45:24,850:INFO:Calculating mean and std
2025-04-19 22:45:24,851:INFO:Creating metrics dataframe
2025-04-19 22:45:25,574:INFO:Uploading results into container
2025-04-19 22:45:25,575:INFO:Uploading model into container now
2025-04-19 22:45:25,575:INFO:_master_model_container: 12
2025-04-19 22:45:25,575:INFO:_display_container: 2
2025-04-19 22:45:25,577:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2025-04-19 22:45:25,577:INFO:create_model() successfully completed......................................
2025-04-19 22:45:25,718:INFO:SubProcess create_model() end ==================================
2025-04-19 22:45:25,718:INFO:Creating metrics dataframe
2025-04-19 22:45:25,730:INFO:Initializing Extreme Gradient Boosting
2025-04-19 22:45:25,730:INFO:Total runtime is 1.413511828581492 minutes
2025-04-19 22:45:25,733:INFO:SubProcess create_model() called ==================================
2025-04-19 22:45:25,733:INFO:Initializing create_model()
2025-04-19 22:45:25,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:45:25,733:INFO:Checking exceptions
2025-04-19 22:45:25,734:INFO:Importing libraries
2025-04-19 22:45:25,734:INFO:Copying training dataset
2025-04-19 22:45:25,738:INFO:Defining folds
2025-04-19 22:45:25,739:INFO:Declaring metric variables
2025-04-19 22:45:25,743:INFO:Importing untrained model
2025-04-19 22:45:25,745:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 22:45:25,753:INFO:Starting cross validation
2025-04-19 22:45:25,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:45:31,996:INFO:Calculating mean and std
2025-04-19 22:45:31,997:INFO:Creating metrics dataframe
2025-04-19 22:45:32,751:INFO:Uploading results into container
2025-04-19 22:45:32,753:INFO:Uploading model into container now
2025-04-19 22:45:32,753:INFO:_master_model_container: 13
2025-04-19 22:45:32,753:INFO:_display_container: 2
2025-04-19 22:45:32,754:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 22:45:32,754:INFO:create_model() successfully completed......................................
2025-04-19 22:45:32,888:INFO:SubProcess create_model() end ==================================
2025-04-19 22:45:32,888:INFO:Creating metrics dataframe
2025-04-19 22:45:32,903:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 22:45:32,903:INFO:Total runtime is 1.53306618531545 minutes
2025-04-19 22:45:32,907:INFO:SubProcess create_model() called ==================================
2025-04-19 22:45:32,907:INFO:Initializing create_model()
2025-04-19 22:45:32,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:45:32,907:INFO:Checking exceptions
2025-04-19 22:45:32,907:INFO:Importing libraries
2025-04-19 22:45:32,907:INFO:Copying training dataset
2025-04-19 22:45:32,911:INFO:Defining folds
2025-04-19 22:45:32,911:INFO:Declaring metric variables
2025-04-19 22:45:32,916:INFO:Importing untrained model
2025-04-19 22:45:32,920:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 22:45:32,928:INFO:Starting cross validation
2025-04-19 22:45:32,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:45:40,819:INFO:Calculating mean and std
2025-04-19 22:45:40,820:INFO:Creating metrics dataframe
2025-04-19 22:45:41,567:INFO:Uploading results into container
2025-04-19 22:45:41,567:INFO:Uploading model into container now
2025-04-19 22:45:41,568:INFO:_master_model_container: 14
2025-04-19 22:45:41,568:INFO:_display_container: 2
2025-04-19 22:45:41,569:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 22:45:41,569:INFO:create_model() successfully completed......................................
2025-04-19 22:45:41,699:INFO:SubProcess create_model() end ==================================
2025-04-19 22:45:41,699:INFO:Creating metrics dataframe
2025-04-19 22:45:41,711:INFO:Initializing Dummy Classifier
2025-04-19 22:45:41,711:INFO:Total runtime is 1.6798652092615762 minutes
2025-04-19 22:45:41,714:INFO:SubProcess create_model() called ==================================
2025-04-19 22:45:41,714:INFO:Initializing create_model()
2025-04-19 22:45:41,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13770FA00>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:45:41,714:INFO:Checking exceptions
2025-04-19 22:45:41,714:INFO:Importing libraries
2025-04-19 22:45:41,714:INFO:Copying training dataset
2025-04-19 22:45:41,719:INFO:Defining folds
2025-04-19 22:45:41,719:INFO:Declaring metric variables
2025-04-19 22:45:41,724:INFO:Importing untrained model
2025-04-19 22:45:41,730:INFO:Dummy Classifier Imported successfully
2025-04-19 22:45:41,737:INFO:Starting cross validation
2025-04-19 22:45:41,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:45:42,181:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,182:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,195:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,196:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,199:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,203:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,226:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,241:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,244:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:42,319:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:45:47,739:INFO:Calculating mean and std
2025-04-19 22:45:47,740:INFO:Creating metrics dataframe
2025-04-19 22:45:48,494:INFO:Uploading results into container
2025-04-19 22:45:48,495:INFO:Uploading model into container now
2025-04-19 22:45:48,496:INFO:_master_model_container: 15
2025-04-19 22:45:48,496:INFO:_display_container: 2
2025-04-19 22:45:48,496:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-04-19 22:45:48,496:INFO:create_model() successfully completed......................................
2025-04-19 22:45:48,633:INFO:SubProcess create_model() end ==================================
2025-04-19 22:45:48,633:INFO:Creating metrics dataframe
2025-04-19 22:45:48,660:INFO:Initializing create_model()
2025-04-19 22:45:48,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C1326B93C0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:45:48,660:INFO:Checking exceptions
2025-04-19 22:45:48,663:INFO:Importing libraries
2025-04-19 22:45:48,663:INFO:Copying training dataset
2025-04-19 22:45:48,667:INFO:Defining folds
2025-04-19 22:45:48,667:INFO:Declaring metric variables
2025-04-19 22:45:48,667:INFO:Importing untrained model
2025-04-19 22:45:48,667:INFO:Declaring custom model
2025-04-19 22:45:48,667:INFO:Dummy Classifier Imported successfully
2025-04-19 22:45:48,669:INFO:Cross validation set to False
2025-04-19 22:45:48,669:INFO:Fitting Model
2025-04-19 22:45:49,369:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-04-19 22:45:49,369:INFO:create_model() successfully completed......................................
2025-04-19 22:45:49,544:INFO:_master_model_container: 15
2025-04-19 22:45:49,544:INFO:_display_container: 2
2025-04-19 22:45:49,544:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-04-19 22:45:49,544:INFO:compare_models() successfully completed......................................
2025-04-19 22:56:43,550:INFO:PyCaret ClassificationExperiment
2025-04-19 22:56:43,550:INFO:Logging name: clf-default-name
2025-04-19 22:56:43,550:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 22:56:43,550:INFO:version 3.0.4
2025-04-19 22:56:43,550:INFO:Initializing setup()
2025-04-19 22:56:43,550:INFO:self.USI: a0fc
2025-04-19 22:56:43,550:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 22:56:43,550:INFO:Checking environment
2025-04-19 22:56:43,550:INFO:python_version: 3.10.5
2025-04-19 22:56:43,550:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 22:56:43,550:INFO:machine: AMD64
2025-04-19 22:56:43,550:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 22:56:43,555:INFO:Memory: svmem(total=25042907136, available=14443376640, percent=42.3, used=10599530496, free=14443376640)
2025-04-19 22:56:43,555:INFO:Physical Core: 6
2025-04-19 22:56:43,555:INFO:Logical Core: 12
2025-04-19 22:56:43,556:INFO:Checking libraries
2025-04-19 22:56:43,556:INFO:System:
2025-04-19 22:56:43,556:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 22:56:43,556:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 22:56:43,556:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 22:56:43,556:INFO:PyCaret required dependencies:
2025-04-19 22:56:43,556:INFO:                 pip: 25.0.1
2025-04-19 22:56:43,556:INFO:          setuptools: 58.1.0
2025-04-19 22:56:43,556:INFO:             pycaret: 3.0.4
2025-04-19 22:56:43,556:INFO:             IPython: 8.29.0
2025-04-19 22:56:43,556:INFO:          ipywidgets: 8.1.6
2025-04-19 22:56:43,556:INFO:                tqdm: 4.67.1
2025-04-19 22:56:43,556:INFO:               numpy: 1.23.5
2025-04-19 22:56:43,556:INFO:              pandas: 1.5.3
2025-04-19 22:56:43,556:INFO:              jinja2: 3.1.4
2025-04-19 22:56:43,556:INFO:               scipy: 1.11.4
2025-04-19 22:56:43,556:INFO:              joblib: 1.3.2
2025-04-19 22:56:43,556:INFO:             sklearn: 1.2.2
2025-04-19 22:56:43,556:INFO:                pyod: 2.0.4
2025-04-19 22:56:43,557:INFO:            imblearn: 0.10.1
2025-04-19 22:56:43,557:INFO:   category_encoders: 2.7.0
2025-04-19 22:56:43,557:INFO:            lightgbm: 4.6.0
2025-04-19 22:56:43,557:INFO:               numba: 0.60.0
2025-04-19 22:56:43,558:INFO:            requests: 2.32.3
2025-04-19 22:56:43,558:INFO:          matplotlib: 3.7.5
2025-04-19 22:56:43,558:INFO:          scikitplot: 0.3.7
2025-04-19 22:56:43,558:INFO:         yellowbrick: 1.5
2025-04-19 22:56:43,558:INFO:              plotly: 5.24.1
2025-04-19 22:56:43,558:INFO:    plotly-resampler: Not installed
2025-04-19 22:56:43,558:INFO:             kaleido: 0.2.1
2025-04-19 22:56:43,558:INFO:           schemdraw: 0.15
2025-04-19 22:56:43,558:INFO:         statsmodels: 0.14.4
2025-04-19 22:56:43,558:INFO:              sktime: 0.26.0
2025-04-19 22:56:43,558:INFO:               tbats: 1.1.3
2025-04-19 22:56:43,559:INFO:            pmdarima: 2.0.4
2025-04-19 22:56:43,559:INFO:              psutil: 6.1.0
2025-04-19 22:56:43,559:INFO:          markupsafe: 3.0.2
2025-04-19 22:56:43,559:INFO:             pickle5: Not installed
2025-04-19 22:56:43,559:INFO:         cloudpickle: 3.1.1
2025-04-19 22:56:43,559:INFO:         deprecation: 2.1.0
2025-04-19 22:56:43,559:INFO:              xxhash: 3.5.0
2025-04-19 22:56:43,559:INFO:           wurlitzer: Not installed
2025-04-19 22:56:43,559:INFO:PyCaret optional dependencies:
2025-04-19 22:56:43,559:INFO:                shap: Not installed
2025-04-19 22:56:43,559:INFO:           interpret: Not installed
2025-04-19 22:56:43,559:INFO:                umap: Not installed
2025-04-19 22:56:43,559:INFO:    pandas_profiling: Not installed
2025-04-19 22:56:43,559:INFO:  explainerdashboard: Not installed
2025-04-19 22:56:43,559:INFO:             autoviz: Not installed
2025-04-19 22:56:43,559:INFO:           fairlearn: Not installed
2025-04-19 22:56:43,559:INFO:          deepchecks: Not installed
2025-04-19 22:56:43,559:INFO:             xgboost: 1.7.6
2025-04-19 22:56:43,559:INFO:            catboost: Not installed
2025-04-19 22:56:43,559:INFO:              kmodes: Not installed
2025-04-19 22:56:43,559:INFO:             mlxtend: Not installed
2025-04-19 22:56:43,559:INFO:       statsforecast: Not installed
2025-04-19 22:56:43,559:INFO:        tune_sklearn: Not installed
2025-04-19 22:56:43,559:INFO:                 ray: Not installed
2025-04-19 22:56:43,559:INFO:            hyperopt: Not installed
2025-04-19 22:56:43,559:INFO:              optuna: Not installed
2025-04-19 22:56:43,559:INFO:               skopt: Not installed
2025-04-19 22:56:43,559:INFO:              mlflow: Not installed
2025-04-19 22:56:43,559:INFO:              gradio: Not installed
2025-04-19 22:56:43,559:INFO:             fastapi: Not installed
2025-04-19 22:56:43,559:INFO:             uvicorn: Not installed
2025-04-19 22:56:43,559:INFO:              m2cgen: Not installed
2025-04-19 22:56:43,559:INFO:           evidently: Not installed
2025-04-19 22:56:43,559:INFO:               fugue: Not installed
2025-04-19 22:56:43,559:INFO:           streamlit: 1.42.0
2025-04-19 22:56:43,559:INFO:             prophet: Not installed
2025-04-19 22:56:43,559:INFO:None
2025-04-19 22:56:43,559:INFO:Set up data.
2025-04-19 22:56:43,563:INFO:Set up train/test split.
2025-04-19 22:56:43,566:INFO:Set up index.
2025-04-19 22:56:43,566:INFO:Set up folding strategy.
2025-04-19 22:56:43,566:INFO:Assigning column types.
2025-04-19 22:56:43,569:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 22:56:43,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:56:43,608:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:56:43,633:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:56:43,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:56:43,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 22:56:43,679:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:56:43,699:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:56:43,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:56:43,707:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 22:56:43,747:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:56:43,769:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:56:43,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:56:43,816:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 22:56:43,840:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:56:43,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:56:43,843:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 22:56:43,906:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:56:43,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:56:43,976:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:56:43,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:56:43,980:INFO:Preparing preprocessing pipeline...
2025-04-19 22:56:43,981:INFO:Set up simple imputation.
2025-04-19 22:56:43,981:INFO:Set up imbalanced handling.
2025-04-19 22:56:43,981:INFO:Set up column transformation.
2025-04-19 22:56:43,981:INFO:Set up feature normalization.
2025-04-19 22:56:44,032:INFO:Finished creating preprocessing pipeline.
2025-04-19 22:56:44,039:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['OverTime', 'MaritalStatus',
                                             'DistanceFromHome', 'Department',
                                             'JobRole', 'EducationField',
                                             'NumCompaniesWorked',
                                             'MonthlyRate', 'Gender'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 22:56:44,039:INFO:Creating final display dataframe.
2025-04-19 22:56:44,137:INFO:Setup _display_container:                     Description             Value
0                    Session id              1058
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 10)
4        Transformed data shape        (1548, 10)
5   Transformed train set shape        (1230, 10)
6    Transformed test set shape         (318, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Transformation              True
15        Transformation method       yeo-johnson
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              a0fc
2025-04-19 22:56:44,207:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:56:44,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:56:44,277:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 22:56:44,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 22:56:44,282:INFO:setup() successfully completed in 1.24s...............
2025-04-19 22:56:46,630:INFO:Initializing compare_models()
2025-04-19 22:56:46,630:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 22:56:46,630:INFO:Checking exceptions
2025-04-19 22:56:46,634:INFO:Preparing display monitor
2025-04-19 22:56:46,653:INFO:Initializing Logistic Regression
2025-04-19 22:56:46,653:INFO:Total runtime is 0.0 minutes
2025-04-19 22:56:46,656:INFO:SubProcess create_model() called ==================================
2025-04-19 22:56:46,656:INFO:Initializing create_model()
2025-04-19 22:56:46,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:56:46,656:INFO:Checking exceptions
2025-04-19 22:56:46,657:INFO:Importing libraries
2025-04-19 22:56:46,657:INFO:Copying training dataset
2025-04-19 22:56:46,660:INFO:Defining folds
2025-04-19 22:56:46,660:INFO:Declaring metric variables
2025-04-19 22:56:46,664:INFO:Importing untrained model
2025-04-19 22:56:46,669:INFO:Logistic Regression Imported successfully
2025-04-19 22:56:46,675:INFO:Starting cross validation
2025-04-19 22:56:46,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:00,620:INFO:Calculating mean and std
2025-04-19 22:57:00,620:INFO:Creating metrics dataframe
2025-04-19 22:57:01,361:INFO:Uploading results into container
2025-04-19 22:57:01,361:INFO:Uploading model into container now
2025-04-19 22:57:01,361:INFO:_master_model_container: 1
2025-04-19 22:57:01,361:INFO:_display_container: 2
2025-04-19 22:57:01,364:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1058, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 22:57:01,364:INFO:create_model() successfully completed......................................
2025-04-19 22:57:01,503:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:01,503:INFO:Creating metrics dataframe
2025-04-19 22:57:01,516:INFO:Initializing K Neighbors Classifier
2025-04-19 22:57:01,516:INFO:Total runtime is 0.24771971702575685 minutes
2025-04-19 22:57:01,522:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:01,522:INFO:Initializing create_model()
2025-04-19 22:57:01,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:01,522:INFO:Checking exceptions
2025-04-19 22:57:01,522:INFO:Importing libraries
2025-04-19 22:57:01,522:INFO:Copying training dataset
2025-04-19 22:57:01,527:INFO:Defining folds
2025-04-19 22:57:01,527:INFO:Declaring metric variables
2025-04-19 22:57:01,531:INFO:Importing untrained model
2025-04-19 22:57:01,534:INFO:K Neighbors Classifier Imported successfully
2025-04-19 22:57:01,541:INFO:Starting cross validation
2025-04-19 22:57:01,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:07,925:INFO:Calculating mean and std
2025-04-19 22:57:07,926:INFO:Creating metrics dataframe
2025-04-19 22:57:08,685:INFO:Uploading results into container
2025-04-19 22:57:08,686:INFO:Uploading model into container now
2025-04-19 22:57:08,686:INFO:_master_model_container: 2
2025-04-19 22:57:08,687:INFO:_display_container: 2
2025-04-19 22:57:08,687:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 22:57:08,687:INFO:create_model() successfully completed......................................
2025-04-19 22:57:08,812:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:08,812:INFO:Creating metrics dataframe
2025-04-19 22:57:08,823:INFO:Initializing Naive Bayes
2025-04-19 22:57:08,823:INFO:Total runtime is 0.36949280500411985 minutes
2025-04-19 22:57:08,826:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:08,826:INFO:Initializing create_model()
2025-04-19 22:57:08,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:08,826:INFO:Checking exceptions
2025-04-19 22:57:08,826:INFO:Importing libraries
2025-04-19 22:57:08,826:INFO:Copying training dataset
2025-04-19 22:57:08,830:INFO:Defining folds
2025-04-19 22:57:08,830:INFO:Declaring metric variables
2025-04-19 22:57:08,835:INFO:Importing untrained model
2025-04-19 22:57:08,839:INFO:Naive Bayes Imported successfully
2025-04-19 22:57:08,845:INFO:Starting cross validation
2025-04-19 22:57:08,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:14,457:INFO:Calculating mean and std
2025-04-19 22:57:14,457:INFO:Creating metrics dataframe
2025-04-19 22:57:15,207:INFO:Uploading results into container
2025-04-19 22:57:15,207:INFO:Uploading model into container now
2025-04-19 22:57:15,207:INFO:_master_model_container: 3
2025-04-19 22:57:15,207:INFO:_display_container: 2
2025-04-19 22:57:15,207:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 22:57:15,207:INFO:create_model() successfully completed......................................
2025-04-19 22:57:15,337:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:15,337:INFO:Creating metrics dataframe
2025-04-19 22:57:15,337:INFO:Initializing Decision Tree Classifier
2025-04-19 22:57:15,337:INFO:Total runtime is 0.4780722141265869 minutes
2025-04-19 22:57:15,350:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:15,350:INFO:Initializing create_model()
2025-04-19 22:57:15,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:15,350:INFO:Checking exceptions
2025-04-19 22:57:15,351:INFO:Importing libraries
2025-04-19 22:57:15,351:INFO:Copying training dataset
2025-04-19 22:57:15,354:INFO:Defining folds
2025-04-19 22:57:15,355:INFO:Declaring metric variables
2025-04-19 22:57:15,359:INFO:Importing untrained model
2025-04-19 22:57:15,364:INFO:Decision Tree Classifier Imported successfully
2025-04-19 22:57:15,370:INFO:Starting cross validation
2025-04-19 22:57:15,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:20,929:INFO:Calculating mean and std
2025-04-19 22:57:20,930:INFO:Creating metrics dataframe
2025-04-19 22:57:21,667:INFO:Uploading results into container
2025-04-19 22:57:21,667:INFO:Uploading model into container now
2025-04-19 22:57:21,676:INFO:_master_model_container: 4
2025-04-19 22:57:21,676:INFO:_display_container: 2
2025-04-19 22:57:21,676:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1058, splitter='best')
2025-04-19 22:57:21,676:INFO:create_model() successfully completed......................................
2025-04-19 22:57:21,815:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:21,815:INFO:Creating metrics dataframe
2025-04-19 22:57:21,819:INFO:Initializing SVM - Linear Kernel
2025-04-19 22:57:21,819:INFO:Total runtime is 0.586105986436208 minutes
2025-04-19 22:57:21,827:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:21,827:INFO:Initializing create_model()
2025-04-19 22:57:21,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:21,827:INFO:Checking exceptions
2025-04-19 22:57:21,827:INFO:Importing libraries
2025-04-19 22:57:21,827:INFO:Copying training dataset
2025-04-19 22:57:21,832:INFO:Defining folds
2025-04-19 22:57:21,832:INFO:Declaring metric variables
2025-04-19 22:57:21,842:INFO:Importing untrained model
2025-04-19 22:57:21,846:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 22:57:21,852:INFO:Starting cross validation
2025-04-19 22:57:21,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:22,011:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,021:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,024:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,024:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,030:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,030:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,036:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,038:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,054:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:22,056:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 22:57:27,434:INFO:Calculating mean and std
2025-04-19 22:57:27,436:INFO:Creating metrics dataframe
2025-04-19 22:57:28,177:INFO:Uploading results into container
2025-04-19 22:57:28,177:INFO:Uploading model into container now
2025-04-19 22:57:28,177:INFO:_master_model_container: 5
2025-04-19 22:57:28,177:INFO:_display_container: 2
2025-04-19 22:57:28,177:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1058, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 22:57:28,177:INFO:create_model() successfully completed......................................
2025-04-19 22:57:28,307:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:28,307:INFO:Creating metrics dataframe
2025-04-19 22:57:28,318:INFO:Initializing Ridge Classifier
2025-04-19 22:57:28,318:INFO:Total runtime is 0.6944093982378641 minutes
2025-04-19 22:57:28,322:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:28,322:INFO:Initializing create_model()
2025-04-19 22:57:28,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:28,322:INFO:Checking exceptions
2025-04-19 22:57:28,322:INFO:Importing libraries
2025-04-19 22:57:28,322:INFO:Copying training dataset
2025-04-19 22:57:28,325:INFO:Defining folds
2025-04-19 22:57:28,325:INFO:Declaring metric variables
2025-04-19 22:57:28,333:INFO:Importing untrained model
2025-04-19 22:57:28,336:INFO:Ridge Classifier Imported successfully
2025-04-19 22:57:28,342:INFO:Starting cross validation
2025-04-19 22:57:28,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:28,493:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,500:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,516:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,520:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,520:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,520:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,537:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,538:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,538:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:28,538:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 22:57:33,997:INFO:Calculating mean and std
2025-04-19 22:57:33,998:INFO:Creating metrics dataframe
2025-04-19 22:57:34,746:INFO:Uploading results into container
2025-04-19 22:57:34,746:INFO:Uploading model into container now
2025-04-19 22:57:34,748:INFO:_master_model_container: 6
2025-04-19 22:57:34,748:INFO:_display_container: 2
2025-04-19 22:57:34,748:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1058, solver='auto',
                tol=0.0001)
2025-04-19 22:57:34,749:INFO:create_model() successfully completed......................................
2025-04-19 22:57:34,879:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:34,879:INFO:Creating metrics dataframe
2025-04-19 22:57:34,892:INFO:Initializing Random Forest Classifier
2025-04-19 22:57:34,892:INFO:Total runtime is 0.8039758165677388 minutes
2025-04-19 22:57:34,895:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:34,896:INFO:Initializing create_model()
2025-04-19 22:57:34,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:34,896:INFO:Checking exceptions
2025-04-19 22:57:34,896:INFO:Importing libraries
2025-04-19 22:57:34,896:INFO:Copying training dataset
2025-04-19 22:57:34,899:INFO:Defining folds
2025-04-19 22:57:34,899:INFO:Declaring metric variables
2025-04-19 22:57:34,903:INFO:Importing untrained model
2025-04-19 22:57:34,907:INFO:Random Forest Classifier Imported successfully
2025-04-19 22:57:34,915:INFO:Starting cross validation
2025-04-19 22:57:34,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:41,414:INFO:Calculating mean and std
2025-04-19 22:57:41,415:INFO:Creating metrics dataframe
2025-04-19 22:57:42,158:INFO:Uploading results into container
2025-04-19 22:57:42,159:INFO:Uploading model into container now
2025-04-19 22:57:42,160:INFO:_master_model_container: 7
2025-04-19 22:57:42,160:INFO:_display_container: 2
2025-04-19 22:57:42,160:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:57:42,160:INFO:create_model() successfully completed......................................
2025-04-19 22:57:42,289:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:42,289:INFO:Creating metrics dataframe
2025-04-19 22:57:42,302:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 22:57:42,302:INFO:Total runtime is 0.9274876236915588 minutes
2025-04-19 22:57:42,307:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:42,307:INFO:Initializing create_model()
2025-04-19 22:57:42,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:42,307:INFO:Checking exceptions
2025-04-19 22:57:42,307:INFO:Importing libraries
2025-04-19 22:57:42,307:INFO:Copying training dataset
2025-04-19 22:57:42,311:INFO:Defining folds
2025-04-19 22:57:42,311:INFO:Declaring metric variables
2025-04-19 22:57:42,314:INFO:Importing untrained model
2025-04-19 22:57:42,316:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 22:57:42,323:INFO:Starting cross validation
2025-04-19 22:57:42,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:48,092:INFO:Calculating mean and std
2025-04-19 22:57:48,093:INFO:Creating metrics dataframe
2025-04-19 22:57:48,854:INFO:Uploading results into container
2025-04-19 22:57:48,855:INFO:Uploading model into container now
2025-04-19 22:57:48,855:INFO:_master_model_container: 8
2025-04-19 22:57:48,856:INFO:_display_container: 2
2025-04-19 22:57:48,856:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 22:57:48,856:INFO:create_model() successfully completed......................................
2025-04-19 22:57:48,990:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:48,991:INFO:Creating metrics dataframe
2025-04-19 22:57:49,003:INFO:Initializing Ada Boost Classifier
2025-04-19 22:57:49,003:INFO:Total runtime is 1.0391617814699807 minutes
2025-04-19 22:57:49,005:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:49,005:INFO:Initializing create_model()
2025-04-19 22:57:49,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:49,005:INFO:Checking exceptions
2025-04-19 22:57:49,007:INFO:Importing libraries
2025-04-19 22:57:49,007:INFO:Copying training dataset
2025-04-19 22:57:49,011:INFO:Defining folds
2025-04-19 22:57:49,011:INFO:Declaring metric variables
2025-04-19 22:57:49,016:INFO:Importing untrained model
2025-04-19 22:57:49,019:INFO:Ada Boost Classifier Imported successfully
2025-04-19 22:57:49,027:INFO:Starting cross validation
2025-04-19 22:57:49,028:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:57:55,086:INFO:Calculating mean and std
2025-04-19 22:57:55,088:INFO:Creating metrics dataframe
2025-04-19 22:57:55,917:INFO:Uploading results into container
2025-04-19 22:57:55,917:INFO:Uploading model into container now
2025-04-19 22:57:55,917:INFO:_master_model_container: 9
2025-04-19 22:57:55,917:INFO:_display_container: 2
2025-04-19 22:57:55,920:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1058)
2025-04-19 22:57:55,920:INFO:create_model() successfully completed......................................
2025-04-19 22:57:56,052:INFO:SubProcess create_model() end ==================================
2025-04-19 22:57:56,052:INFO:Creating metrics dataframe
2025-04-19 22:57:56,062:INFO:Initializing Gradient Boosting Classifier
2025-04-19 22:57:56,062:INFO:Total runtime is 1.1568152944246926 minutes
2025-04-19 22:57:56,065:INFO:SubProcess create_model() called ==================================
2025-04-19 22:57:56,065:INFO:Initializing create_model()
2025-04-19 22:57:56,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:57:56,066:INFO:Checking exceptions
2025-04-19 22:57:56,066:INFO:Importing libraries
2025-04-19 22:57:56,066:INFO:Copying training dataset
2025-04-19 22:57:56,070:INFO:Defining folds
2025-04-19 22:57:56,070:INFO:Declaring metric variables
2025-04-19 22:57:56,071:INFO:Importing untrained model
2025-04-19 22:57:56,076:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 22:57:56,081:INFO:Starting cross validation
2025-04-19 22:57:56,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:58:02,502:INFO:Calculating mean and std
2025-04-19 22:58:02,503:INFO:Creating metrics dataframe
2025-04-19 22:58:03,287:INFO:Uploading results into container
2025-04-19 22:58:03,287:INFO:Uploading model into container now
2025-04-19 22:58:03,287:INFO:_master_model_container: 10
2025-04-19 22:58:03,287:INFO:_display_container: 2
2025-04-19 22:58:03,287:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 22:58:03,287:INFO:create_model() successfully completed......................................
2025-04-19 22:58:03,420:INFO:SubProcess create_model() end ==================================
2025-04-19 22:58:03,420:INFO:Creating metrics dataframe
2025-04-19 22:58:03,428:INFO:Initializing Linear Discriminant Analysis
2025-04-19 22:58:03,428:INFO:Total runtime is 1.2795829614003498 minutes
2025-04-19 22:58:03,433:INFO:SubProcess create_model() called ==================================
2025-04-19 22:58:03,434:INFO:Initializing create_model()
2025-04-19 22:58:03,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:58:03,434:INFO:Checking exceptions
2025-04-19 22:58:03,434:INFO:Importing libraries
2025-04-19 22:58:03,434:INFO:Copying training dataset
2025-04-19 22:58:03,437:INFO:Defining folds
2025-04-19 22:58:03,437:INFO:Declaring metric variables
2025-04-19 22:58:03,440:INFO:Importing untrained model
2025-04-19 22:58:03,443:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 22:58:03,448:INFO:Starting cross validation
2025-04-19 22:58:03,449:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:58:09,275:INFO:Calculating mean and std
2025-04-19 22:58:09,275:INFO:Creating metrics dataframe
2025-04-19 22:58:10,042:INFO:Uploading results into container
2025-04-19 22:58:10,042:INFO:Uploading model into container now
2025-04-19 22:58:10,043:INFO:_master_model_container: 11
2025-04-19 22:58:10,043:INFO:_display_container: 2
2025-04-19 22:58:10,043:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 22:58:10,043:INFO:create_model() successfully completed......................................
2025-04-19 22:58:10,167:INFO:SubProcess create_model() end ==================================
2025-04-19 22:58:10,167:INFO:Creating metrics dataframe
2025-04-19 22:58:10,183:INFO:Initializing Extra Trees Classifier
2025-04-19 22:58:10,183:INFO:Total runtime is 1.3921618024508158 minutes
2025-04-19 22:58:10,183:INFO:SubProcess create_model() called ==================================
2025-04-19 22:58:10,183:INFO:Initializing create_model()
2025-04-19 22:58:10,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:58:10,183:INFO:Checking exceptions
2025-04-19 22:58:10,183:INFO:Importing libraries
2025-04-19 22:58:10,183:INFO:Copying training dataset
2025-04-19 22:58:10,190:INFO:Defining folds
2025-04-19 22:58:10,190:INFO:Declaring metric variables
2025-04-19 22:58:10,190:INFO:Importing untrained model
2025-04-19 22:58:10,197:INFO:Extra Trees Classifier Imported successfully
2025-04-19 22:58:10,202:INFO:Starting cross validation
2025-04-19 22:58:10,203:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:58:16,772:INFO:Calculating mean and std
2025-04-19 22:58:16,772:INFO:Creating metrics dataframe
2025-04-19 22:58:17,518:INFO:Uploading results into container
2025-04-19 22:58:17,523:INFO:Uploading model into container now
2025-04-19 22:58:17,523:INFO:_master_model_container: 12
2025-04-19 22:58:17,523:INFO:_display_container: 2
2025-04-19 22:58:17,523:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:58:17,523:INFO:create_model() successfully completed......................................
2025-04-19 22:58:17,648:INFO:SubProcess create_model() end ==================================
2025-04-19 22:58:17,648:INFO:Creating metrics dataframe
2025-04-19 22:58:17,662:INFO:Initializing Extreme Gradient Boosting
2025-04-19 22:58:17,662:INFO:Total runtime is 1.516807246208191 minutes
2025-04-19 22:58:17,662:INFO:SubProcess create_model() called ==================================
2025-04-19 22:58:17,662:INFO:Initializing create_model()
2025-04-19 22:58:17,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:58:17,662:INFO:Checking exceptions
2025-04-19 22:58:17,662:INFO:Importing libraries
2025-04-19 22:58:17,662:INFO:Copying training dataset
2025-04-19 22:58:17,668:INFO:Defining folds
2025-04-19 22:58:17,668:INFO:Declaring metric variables
2025-04-19 22:58:17,673:INFO:Importing untrained model
2025-04-19 22:58:17,675:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 22:58:17,682:INFO:Starting cross validation
2025-04-19 22:58:17,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:58:25,735:INFO:Calculating mean and std
2025-04-19 22:58:25,735:INFO:Creating metrics dataframe
2025-04-19 22:58:26,517:INFO:Uploading results into container
2025-04-19 22:58:26,517:INFO:Uploading model into container now
2025-04-19 22:58:26,518:INFO:_master_model_container: 13
2025-04-19 22:58:26,518:INFO:_display_container: 2
2025-04-19 22:58:26,519:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 22:58:26,519:INFO:create_model() successfully completed......................................
2025-04-19 22:58:26,643:INFO:SubProcess create_model() end ==================================
2025-04-19 22:58:26,643:INFO:Creating metrics dataframe
2025-04-19 22:58:26,653:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 22:58:26,653:INFO:Total runtime is 1.6666640559832255 minutes
2025-04-19 22:58:26,659:INFO:SubProcess create_model() called ==================================
2025-04-19 22:58:26,659:INFO:Initializing create_model()
2025-04-19 22:58:26,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:58:26,659:INFO:Checking exceptions
2025-04-19 22:58:26,659:INFO:Importing libraries
2025-04-19 22:58:26,659:INFO:Copying training dataset
2025-04-19 22:58:26,662:INFO:Defining folds
2025-04-19 22:58:26,662:INFO:Declaring metric variables
2025-04-19 22:58:26,666:INFO:Importing untrained model
2025-04-19 22:58:26,670:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 22:58:26,674:INFO:Starting cross validation
2025-04-19 22:58:26,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:58:33,838:INFO:Calculating mean and std
2025-04-19 22:58:33,839:INFO:Creating metrics dataframe
2025-04-19 22:58:34,637:INFO:Uploading results into container
2025-04-19 22:58:34,637:INFO:Uploading model into container now
2025-04-19 22:58:34,637:INFO:_master_model_container: 14
2025-04-19 22:58:34,637:INFO:_display_container: 2
2025-04-19 22:58:34,641:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1058, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 22:58:34,641:INFO:create_model() successfully completed......................................
2025-04-19 22:58:34,766:INFO:SubProcess create_model() end ==================================
2025-04-19 22:58:34,767:INFO:Creating metrics dataframe
2025-04-19 22:58:34,778:INFO:Initializing Dummy Classifier
2025-04-19 22:58:34,778:INFO:Total runtime is 1.802077043056488 minutes
2025-04-19 22:58:34,781:INFO:SubProcess create_model() called ==================================
2025-04-19 22:58:34,781:INFO:Initializing create_model()
2025-04-19 22:58:34,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C131BFBEE0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:58:34,781:INFO:Checking exceptions
2025-04-19 22:58:34,781:INFO:Importing libraries
2025-04-19 22:58:34,781:INFO:Copying training dataset
2025-04-19 22:58:34,785:INFO:Defining folds
2025-04-19 22:58:34,785:INFO:Declaring metric variables
2025-04-19 22:58:34,788:INFO:Importing untrained model
2025-04-19 22:58:34,794:INFO:Dummy Classifier Imported successfully
2025-04-19 22:58:34,802:INFO:Starting cross validation
2025-04-19 22:58:34,802:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 22:58:34,988:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:34,998:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:35,002:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:35,006:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:35,007:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:35,012:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:35,017:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:35,025:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:35,036:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:35,037:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 22:58:40,957:INFO:Calculating mean and std
2025-04-19 22:58:40,958:INFO:Creating metrics dataframe
2025-04-19 22:58:41,760:INFO:Uploading results into container
2025-04-19 22:58:41,760:INFO:Uploading model into container now
2025-04-19 22:58:41,760:INFO:_master_model_container: 15
2025-04-19 22:58:41,760:INFO:_display_container: 2
2025-04-19 22:58:41,762:INFO:DummyClassifier(constant=None, random_state=1058, strategy='prior')
2025-04-19 22:58:41,762:INFO:create_model() successfully completed......................................
2025-04-19 22:58:41,894:INFO:SubProcess create_model() end ==================================
2025-04-19 22:58:41,894:INFO:Creating metrics dataframe
2025-04-19 22:58:41,915:INFO:Initializing create_model()
2025-04-19 22:58:41,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771F1F0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 22:58:41,915:INFO:Checking exceptions
2025-04-19 22:58:41,916:INFO:Importing libraries
2025-04-19 22:58:41,916:INFO:Copying training dataset
2025-04-19 22:58:41,921:INFO:Defining folds
2025-04-19 22:58:41,921:INFO:Declaring metric variables
2025-04-19 22:58:41,922:INFO:Importing untrained model
2025-04-19 22:58:41,922:INFO:Declaring custom model
2025-04-19 22:58:41,922:INFO:Random Forest Classifier Imported successfully
2025-04-19 22:58:41,923:INFO:Cross validation set to False
2025-04-19 22:58:41,923:INFO:Fitting Model
2025-04-19 22:58:42,799:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:58:42,799:INFO:create_model() successfully completed......................................
2025-04-19 22:58:42,959:INFO:_master_model_container: 15
2025-04-19 22:58:42,959:INFO:_display_container: 2
2025-04-19 22:58:42,959:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 22:58:42,959:INFO:compare_models() successfully completed......................................
2025-04-19 23:01:05,088:INFO:PyCaret ClassificationExperiment
2025-04-19 23:01:05,088:INFO:Logging name: clf-default-name
2025-04-19 23:01:05,088:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:01:05,088:INFO:version 3.0.4
2025-04-19 23:01:05,088:INFO:Initializing setup()
2025-04-19 23:01:05,088:INFO:self.USI: 98ff
2025-04-19 23:01:05,088:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:01:05,089:INFO:Checking environment
2025-04-19 23:01:05,089:INFO:python_version: 3.10.5
2025-04-19 23:01:05,089:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:01:05,089:INFO:machine: AMD64
2025-04-19 23:01:05,089:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:01:05,095:INFO:Memory: svmem(total=25042907136, available=12720492544, percent=49.2, used=12322414592, free=12720492544)
2025-04-19 23:01:05,095:INFO:Physical Core: 6
2025-04-19 23:01:05,095:INFO:Logical Core: 12
2025-04-19 23:01:05,095:INFO:Checking libraries
2025-04-19 23:01:05,095:INFO:System:
2025-04-19 23:01:05,095:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:01:05,095:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:01:05,095:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:01:05,095:INFO:PyCaret required dependencies:
2025-04-19 23:01:05,095:INFO:                 pip: 25.0.1
2025-04-19 23:01:05,095:INFO:          setuptools: 58.1.0
2025-04-19 23:01:05,095:INFO:             pycaret: 3.0.4
2025-04-19 23:01:05,095:INFO:             IPython: 8.29.0
2025-04-19 23:01:05,095:INFO:          ipywidgets: 8.1.6
2025-04-19 23:01:05,095:INFO:                tqdm: 4.67.1
2025-04-19 23:01:05,095:INFO:               numpy: 1.23.5
2025-04-19 23:01:05,095:INFO:              pandas: 1.5.3
2025-04-19 23:01:05,095:INFO:              jinja2: 3.1.4
2025-04-19 23:01:05,095:INFO:               scipy: 1.11.4
2025-04-19 23:01:05,095:INFO:              joblib: 1.3.2
2025-04-19 23:01:05,095:INFO:             sklearn: 1.2.2
2025-04-19 23:01:05,095:INFO:                pyod: 2.0.4
2025-04-19 23:01:05,095:INFO:            imblearn: 0.10.1
2025-04-19 23:01:05,095:INFO:   category_encoders: 2.7.0
2025-04-19 23:01:05,096:INFO:            lightgbm: 4.6.0
2025-04-19 23:01:05,096:INFO:               numba: 0.60.0
2025-04-19 23:01:05,096:INFO:            requests: 2.32.3
2025-04-19 23:01:05,096:INFO:          matplotlib: 3.7.5
2025-04-19 23:01:05,096:INFO:          scikitplot: 0.3.7
2025-04-19 23:01:05,096:INFO:         yellowbrick: 1.5
2025-04-19 23:01:05,096:INFO:              plotly: 5.24.1
2025-04-19 23:01:05,096:INFO:    plotly-resampler: Not installed
2025-04-19 23:01:05,096:INFO:             kaleido: 0.2.1
2025-04-19 23:01:05,096:INFO:           schemdraw: 0.15
2025-04-19 23:01:05,096:INFO:         statsmodels: 0.14.4
2025-04-19 23:01:05,096:INFO:              sktime: 0.26.0
2025-04-19 23:01:05,096:INFO:               tbats: 1.1.3
2025-04-19 23:01:05,096:INFO:            pmdarima: 2.0.4
2025-04-19 23:01:05,096:INFO:              psutil: 6.1.0
2025-04-19 23:01:05,096:INFO:          markupsafe: 3.0.2
2025-04-19 23:01:05,096:INFO:             pickle5: Not installed
2025-04-19 23:01:05,096:INFO:         cloudpickle: 3.1.1
2025-04-19 23:01:05,096:INFO:         deprecation: 2.1.0
2025-04-19 23:01:05,096:INFO:              xxhash: 3.5.0
2025-04-19 23:01:05,096:INFO:           wurlitzer: Not installed
2025-04-19 23:01:05,096:INFO:PyCaret optional dependencies:
2025-04-19 23:01:05,096:INFO:                shap: Not installed
2025-04-19 23:01:05,096:INFO:           interpret: Not installed
2025-04-19 23:01:05,096:INFO:                umap: Not installed
2025-04-19 23:01:05,096:INFO:    pandas_profiling: Not installed
2025-04-19 23:01:05,096:INFO:  explainerdashboard: Not installed
2025-04-19 23:01:05,096:INFO:             autoviz: Not installed
2025-04-19 23:01:05,096:INFO:           fairlearn: Not installed
2025-04-19 23:01:05,096:INFO:          deepchecks: Not installed
2025-04-19 23:01:05,096:INFO:             xgboost: 1.7.6
2025-04-19 23:01:05,096:INFO:            catboost: Not installed
2025-04-19 23:01:05,096:INFO:              kmodes: Not installed
2025-04-19 23:01:05,096:INFO:             mlxtend: Not installed
2025-04-19 23:01:05,098:INFO:       statsforecast: Not installed
2025-04-19 23:01:05,098:INFO:        tune_sklearn: Not installed
2025-04-19 23:01:05,098:INFO:                 ray: Not installed
2025-04-19 23:01:05,098:INFO:            hyperopt: Not installed
2025-04-19 23:01:05,098:INFO:              optuna: Not installed
2025-04-19 23:01:05,098:INFO:               skopt: Not installed
2025-04-19 23:01:05,098:INFO:              mlflow: Not installed
2025-04-19 23:01:05,098:INFO:              gradio: Not installed
2025-04-19 23:01:05,098:INFO:             fastapi: Not installed
2025-04-19 23:01:05,098:INFO:             uvicorn: Not installed
2025-04-19 23:01:05,098:INFO:              m2cgen: Not installed
2025-04-19 23:01:05,098:INFO:           evidently: Not installed
2025-04-19 23:01:05,098:INFO:               fugue: Not installed
2025-04-19 23:01:05,098:INFO:           streamlit: 1.42.0
2025-04-19 23:01:05,098:INFO:             prophet: Not installed
2025-04-19 23:01:05,098:INFO:None
2025-04-19 23:01:05,098:INFO:Set up data.
2025-04-19 23:01:05,103:INFO:Set up train/test split.
2025-04-19 23:01:05,108:INFO:Set up index.
2025-04-19 23:01:05,108:INFO:Set up folding strategy.
2025-04-19 23:01:05,108:INFO:Assigning column types.
2025-04-19 23:01:05,112:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:01:05,151:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:01:05,152:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:01:05,177:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:01:05,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:01:05,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:01:05,218:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:01:05,244:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:01:05,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:01:05,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:01:05,286:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:01:05,311:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:01:05,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:01:05,356:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:01:05,380:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:01:05,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:01:05,382:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:01:05,474:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:01:05,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:01:05,551:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:01:05,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:01:05,556:INFO:Preparing preprocessing pipeline...
2025-04-19 23:01:05,556:INFO:Set up simple imputation.
2025-04-19 23:01:05,560:INFO:Set up encoding of ordinal features.
2025-04-19 23:01:05,562:INFO:Set up encoding of categorical features.
2025-04-19 23:01:05,562:INFO:Set up imbalanced handling.
2025-04-19 23:01:05,562:INFO:Set up column transformation.
2025-04-19 23:01:05,562:INFO:Set up feature normalization.
2025-04-19 23:01:05,778:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:01:05,810:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['DistanceFromHome',
                                             'NumCompaniesWorked',
                                             'MonthlyRate'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprec...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 23:01:05,810:INFO:Creating final display dataframe.
2025-04-19 23:01:06,121:INFO:Setup _display_container:                     Description             Value
0                    Session id              1058
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 10)
4        Transformed data shape        (1548, 27)
5   Transformed train set shape        (1230, 27)
6    Transformed test set shape         (318, 27)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method            onehot
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              98ff
2025-04-19 23:01:06,190:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:01:06,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:01:06,262:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:01:06,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:01:06,265:INFO:setup() successfully completed in 1.72s...............
2025-04-19 23:01:07,962:INFO:Initializing compare_models()
2025-04-19 23:01:07,962:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 23:01:07,962:INFO:Checking exceptions
2025-04-19 23:01:07,966:INFO:Preparing display monitor
2025-04-19 23:01:07,988:INFO:Initializing Logistic Regression
2025-04-19 23:01:07,988:INFO:Total runtime is 0.0 minutes
2025-04-19 23:01:07,991:INFO:SubProcess create_model() called ==================================
2025-04-19 23:01:07,992:INFO:Initializing create_model()
2025-04-19 23:01:07,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:01:07,992:INFO:Checking exceptions
2025-04-19 23:01:07,992:INFO:Importing libraries
2025-04-19 23:01:07,992:INFO:Copying training dataset
2025-04-19 23:01:07,996:INFO:Defining folds
2025-04-19 23:01:07,996:INFO:Declaring metric variables
2025-04-19 23:01:07,999:INFO:Importing untrained model
2025-04-19 23:01:08,003:INFO:Logistic Regression Imported successfully
2025-04-19 23:01:08,010:INFO:Starting cross validation
2025-04-19 23:01:08,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:01:14,953:INFO:Calculating mean and std
2025-04-19 23:01:14,954:INFO:Creating metrics dataframe
2025-04-19 23:01:15,768:INFO:Uploading results into container
2025-04-19 23:01:15,768:INFO:Uploading model into container now
2025-04-19 23:01:15,768:INFO:_master_model_container: 1
2025-04-19 23:01:15,775:INFO:_display_container: 2
2025-04-19 23:01:15,776:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1058, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 23:01:15,776:INFO:create_model() successfully completed......................................
2025-04-19 23:01:16,495:INFO:SubProcess create_model() end ==================================
2025-04-19 23:01:16,496:INFO:Creating metrics dataframe
2025-04-19 23:01:16,503:INFO:Initializing K Neighbors Classifier
2025-04-19 23:01:16,503:INFO:Total runtime is 0.14191708962122598 minutes
2025-04-19 23:01:16,506:INFO:SubProcess create_model() called ==================================
2025-04-19 23:01:16,506:INFO:Initializing create_model()
2025-04-19 23:01:16,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:01:16,507:INFO:Checking exceptions
2025-04-19 23:01:16,507:INFO:Importing libraries
2025-04-19 23:01:16,507:INFO:Copying training dataset
2025-04-19 23:01:16,512:INFO:Defining folds
2025-04-19 23:01:16,512:INFO:Declaring metric variables
2025-04-19 23:01:16,521:INFO:Importing untrained model
2025-04-19 23:01:16,524:INFO:K Neighbors Classifier Imported successfully
2025-04-19 23:01:16,531:INFO:Starting cross validation
2025-04-19 23:01:16,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:01:23,124:INFO:Calculating mean and std
2025-04-19 23:01:23,125:INFO:Creating metrics dataframe
2025-04-19 23:01:23,928:INFO:Uploading results into container
2025-04-19 23:01:23,930:INFO:Uploading model into container now
2025-04-19 23:01:23,930:INFO:_master_model_container: 2
2025-04-19 23:01:23,930:INFO:_display_container: 2
2025-04-19 23:01:23,931:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 23:01:23,931:INFO:create_model() successfully completed......................................
2025-04-19 23:01:24,068:INFO:SubProcess create_model() end ==================================
2025-04-19 23:01:24,068:INFO:Creating metrics dataframe
2025-04-19 23:01:24,078:INFO:Initializing Naive Bayes
2025-04-19 23:01:24,078:INFO:Total runtime is 0.26816648642222085 minutes
2025-04-19 23:01:24,081:INFO:SubProcess create_model() called ==================================
2025-04-19 23:01:24,082:INFO:Initializing create_model()
2025-04-19 23:01:24,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:01:24,082:INFO:Checking exceptions
2025-04-19 23:01:24,082:INFO:Importing libraries
2025-04-19 23:01:24,082:INFO:Copying training dataset
2025-04-19 23:01:24,085:INFO:Defining folds
2025-04-19 23:01:24,088:INFO:Declaring metric variables
2025-04-19 23:01:24,090:INFO:Importing untrained model
2025-04-19 23:01:24,093:INFO:Naive Bayes Imported successfully
2025-04-19 23:01:24,099:INFO:Starting cross validation
2025-04-19 23:01:24,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:01:30,656:INFO:Calculating mean and std
2025-04-19 23:01:30,657:INFO:Creating metrics dataframe
2025-04-19 23:01:31,477:INFO:Uploading results into container
2025-04-19 23:01:31,478:INFO:Uploading model into container now
2025-04-19 23:01:31,479:INFO:_master_model_container: 3
2025-04-19 23:01:31,479:INFO:_display_container: 2
2025-04-19 23:01:31,480:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 23:01:31,480:INFO:create_model() successfully completed......................................
2025-04-19 23:01:31,602:INFO:SubProcess create_model() end ==================================
2025-04-19 23:01:31,602:INFO:Creating metrics dataframe
2025-04-19 23:01:31,611:INFO:Initializing Decision Tree Classifier
2025-04-19 23:01:31,611:INFO:Total runtime is 0.3937104860941569 minutes
2025-04-19 23:01:31,617:INFO:SubProcess create_model() called ==================================
2025-04-19 23:01:31,617:INFO:Initializing create_model()
2025-04-19 23:01:31,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:01:31,617:INFO:Checking exceptions
2025-04-19 23:01:31,617:INFO:Importing libraries
2025-04-19 23:01:31,617:INFO:Copying training dataset
2025-04-19 23:01:31,622:INFO:Defining folds
2025-04-19 23:01:31,623:INFO:Declaring metric variables
2025-04-19 23:01:31,626:INFO:Importing untrained model
2025-04-19 23:01:31,629:INFO:Decision Tree Classifier Imported successfully
2025-04-19 23:01:31,636:INFO:Starting cross validation
2025-04-19 23:01:31,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:01:38,168:INFO:Calculating mean and std
2025-04-19 23:01:38,170:INFO:Creating metrics dataframe
2025-04-19 23:01:39,009:INFO:Uploading results into container
2025-04-19 23:01:39,009:INFO:Uploading model into container now
2025-04-19 23:01:39,017:INFO:_master_model_container: 4
2025-04-19 23:01:39,017:INFO:_display_container: 2
2025-04-19 23:01:39,018:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1058, splitter='best')
2025-04-19 23:01:39,018:INFO:create_model() successfully completed......................................
2025-04-19 23:01:39,162:INFO:SubProcess create_model() end ==================================
2025-04-19 23:01:39,162:INFO:Creating metrics dataframe
2025-04-19 23:01:39,178:INFO:Initializing SVM - Linear Kernel
2025-04-19 23:01:39,178:INFO:Total runtime is 0.5198297421137492 minutes
2025-04-19 23:01:39,181:INFO:SubProcess create_model() called ==================================
2025-04-19 23:01:39,181:INFO:Initializing create_model()
2025-04-19 23:01:39,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:01:39,182:INFO:Checking exceptions
2025-04-19 23:01:39,182:INFO:Importing libraries
2025-04-19 23:01:39,182:INFO:Copying training dataset
2025-04-19 23:01:39,190:INFO:Defining folds
2025-04-19 23:01:39,190:INFO:Declaring metric variables
2025-04-19 23:01:39,194:INFO:Importing untrained model
2025-04-19 23:01:39,198:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 23:01:39,203:INFO:Starting cross validation
2025-04-19 23:01:39,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:01:39,608:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,628:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,630:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,635:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,658:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,667:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,669:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,683:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,688:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:39,698:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:01:45,604:INFO:Calculating mean and std
2025-04-19 23:01:45,604:INFO:Creating metrics dataframe
2025-04-19 23:01:46,418:INFO:Uploading results into container
2025-04-19 23:01:46,418:INFO:Uploading model into container now
2025-04-19 23:01:46,418:INFO:_master_model_container: 5
2025-04-19 23:01:46,418:INFO:_display_container: 2
2025-04-19 23:01:46,421:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1058, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 23:01:46,421:INFO:create_model() successfully completed......................................
2025-04-19 23:01:46,547:INFO:SubProcess create_model() end ==================================
2025-04-19 23:01:46,548:INFO:Creating metrics dataframe
2025-04-19 23:01:46,555:INFO:Initializing Ridge Classifier
2025-04-19 23:01:46,555:INFO:Total runtime is 0.6427839954694112 minutes
2025-04-19 23:01:46,560:INFO:SubProcess create_model() called ==================================
2025-04-19 23:01:46,561:INFO:Initializing create_model()
2025-04-19 23:01:46,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:01:46,561:INFO:Checking exceptions
2025-04-19 23:01:46,561:INFO:Importing libraries
2025-04-19 23:01:46,561:INFO:Copying training dataset
2025-04-19 23:01:46,564:INFO:Defining folds
2025-04-19 23:01:46,566:INFO:Declaring metric variables
2025-04-19 23:01:46,569:INFO:Importing untrained model
2025-04-19 23:01:46,575:INFO:Ridge Classifier Imported successfully
2025-04-19 23:01:46,581:INFO:Starting cross validation
2025-04-19 23:01:46,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:01:47,005:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,020:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,023:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,031:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,038:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,042:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,048:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,050:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,050:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:47,074:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:01:53,068:INFO:Calculating mean and std
2025-04-19 23:01:53,069:INFO:Creating metrics dataframe
2025-04-19 23:01:53,876:INFO:Uploading results into container
2025-04-19 23:01:53,877:INFO:Uploading model into container now
2025-04-19 23:01:53,878:INFO:_master_model_container: 6
2025-04-19 23:01:53,878:INFO:_display_container: 2
2025-04-19 23:01:53,878:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1058, solver='auto',
                tol=0.0001)
2025-04-19 23:01:53,878:INFO:create_model() successfully completed......................................
2025-04-19 23:01:54,008:INFO:SubProcess create_model() end ==================================
2025-04-19 23:01:54,008:INFO:Creating metrics dataframe
2025-04-19 23:01:54,019:INFO:Initializing Random Forest Classifier
2025-04-19 23:01:54,019:INFO:Total runtime is 0.7671717683474223 minutes
2025-04-19 23:01:54,022:INFO:SubProcess create_model() called ==================================
2025-04-19 23:01:54,022:INFO:Initializing create_model()
2025-04-19 23:01:54,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:01:54,023:INFO:Checking exceptions
2025-04-19 23:01:54,023:INFO:Importing libraries
2025-04-19 23:01:54,023:INFO:Copying training dataset
2025-04-19 23:01:54,027:INFO:Defining folds
2025-04-19 23:01:54,027:INFO:Declaring metric variables
2025-04-19 23:01:54,032:INFO:Importing untrained model
2025-04-19 23:01:54,037:INFO:Random Forest Classifier Imported successfully
2025-04-19 23:01:54,045:INFO:Starting cross validation
2025-04-19 23:01:54,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:02:01,366:INFO:Calculating mean and std
2025-04-19 23:02:01,367:INFO:Creating metrics dataframe
2025-04-19 23:02:02,183:INFO:Uploading results into container
2025-04-19 23:02:02,185:INFO:Uploading model into container now
2025-04-19 23:02:02,185:INFO:_master_model_container: 7
2025-04-19 23:02:02,185:INFO:_display_container: 2
2025-04-19 23:02:02,185:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 23:02:02,185:INFO:create_model() successfully completed......................................
2025-04-19 23:02:02,329:INFO:SubProcess create_model() end ==================================
2025-04-19 23:02:02,329:INFO:Creating metrics dataframe
2025-04-19 23:02:02,341:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 23:02:02,341:INFO:Total runtime is 0.9058746735254923 minutes
2025-04-19 23:02:02,345:INFO:SubProcess create_model() called ==================================
2025-04-19 23:02:02,345:INFO:Initializing create_model()
2025-04-19 23:02:02,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:02:02,345:INFO:Checking exceptions
2025-04-19 23:02:02,345:INFO:Importing libraries
2025-04-19 23:02:02,345:INFO:Copying training dataset
2025-04-19 23:02:02,350:INFO:Defining folds
2025-04-19 23:02:02,350:INFO:Declaring metric variables
2025-04-19 23:02:02,353:INFO:Importing untrained model
2025-04-19 23:02:02,357:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 23:02:02,364:INFO:Starting cross validation
2025-04-19 23:02:02,366:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:02:02,689:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,719:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,723:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,725:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,737:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,739:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,743:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,743:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,745:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,747:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:02:02,908:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,936:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,949:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,951:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,961:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,970:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,975:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,977:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,982:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:02,994:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:08,954:INFO:Calculating mean and std
2025-04-19 23:02:08,956:INFO:Creating metrics dataframe
2025-04-19 23:02:09,772:INFO:Uploading results into container
2025-04-19 23:02:09,772:INFO:Uploading model into container now
2025-04-19 23:02:09,773:INFO:_master_model_container: 8
2025-04-19 23:02:09,773:INFO:_display_container: 2
2025-04-19 23:02:09,773:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 23:02:09,773:INFO:create_model() successfully completed......................................
2025-04-19 23:02:09,903:INFO:SubProcess create_model() end ==================================
2025-04-19 23:02:09,903:INFO:Creating metrics dataframe
2025-04-19 23:02:09,914:INFO:Initializing Ada Boost Classifier
2025-04-19 23:02:09,914:INFO:Total runtime is 1.0320935010910035 minutes
2025-04-19 23:02:09,916:INFO:SubProcess create_model() called ==================================
2025-04-19 23:02:09,916:INFO:Initializing create_model()
2025-04-19 23:02:09,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:02:09,917:INFO:Checking exceptions
2025-04-19 23:02:09,917:INFO:Importing libraries
2025-04-19 23:02:09,917:INFO:Copying training dataset
2025-04-19 23:02:09,923:INFO:Defining folds
2025-04-19 23:02:09,923:INFO:Declaring metric variables
2025-04-19 23:02:09,926:INFO:Importing untrained model
2025-04-19 23:02:09,930:INFO:Ada Boost Classifier Imported successfully
2025-04-19 23:02:09,938:INFO:Starting cross validation
2025-04-19 23:02:09,940:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:02:17,000:INFO:Calculating mean and std
2025-04-19 23:02:17,001:INFO:Creating metrics dataframe
2025-04-19 23:02:17,828:INFO:Uploading results into container
2025-04-19 23:02:17,828:INFO:Uploading model into container now
2025-04-19 23:02:17,828:INFO:_master_model_container: 9
2025-04-19 23:02:17,828:INFO:_display_container: 2
2025-04-19 23:02:17,830:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1058)
2025-04-19 23:02:17,830:INFO:create_model() successfully completed......................................
2025-04-19 23:02:17,963:INFO:SubProcess create_model() end ==================================
2025-04-19 23:02:17,963:INFO:Creating metrics dataframe
2025-04-19 23:02:17,973:INFO:Initializing Gradient Boosting Classifier
2025-04-19 23:02:17,973:INFO:Total runtime is 1.1664170106252034 minutes
2025-04-19 23:02:17,976:INFO:SubProcess create_model() called ==================================
2025-04-19 23:02:17,977:INFO:Initializing create_model()
2025-04-19 23:02:17,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:02:17,977:INFO:Checking exceptions
2025-04-19 23:02:17,977:INFO:Importing libraries
2025-04-19 23:02:17,977:INFO:Copying training dataset
2025-04-19 23:02:17,982:INFO:Defining folds
2025-04-19 23:02:17,982:INFO:Declaring metric variables
2025-04-19 23:02:17,986:INFO:Importing untrained model
2025-04-19 23:02:17,990:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 23:02:17,998:INFO:Starting cross validation
2025-04-19 23:02:17,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:02:25,322:INFO:Calculating mean and std
2025-04-19 23:02:25,324:INFO:Creating metrics dataframe
2025-04-19 23:02:26,177:INFO:Uploading results into container
2025-04-19 23:02:26,177:INFO:Uploading model into container now
2025-04-19 23:02:26,177:INFO:_master_model_container: 10
2025-04-19 23:02:26,178:INFO:_display_container: 2
2025-04-19 23:02:26,178:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 23:02:26,178:INFO:create_model() successfully completed......................................
2025-04-19 23:02:26,327:INFO:SubProcess create_model() end ==================================
2025-04-19 23:02:26,327:INFO:Creating metrics dataframe
2025-04-19 23:02:26,338:INFO:Initializing Linear Discriminant Analysis
2025-04-19 23:02:26,338:INFO:Total runtime is 1.3058367133140565 minutes
2025-04-19 23:02:26,344:INFO:SubProcess create_model() called ==================================
2025-04-19 23:02:26,344:INFO:Initializing create_model()
2025-04-19 23:02:26,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:02:26,345:INFO:Checking exceptions
2025-04-19 23:02:26,345:INFO:Importing libraries
2025-04-19 23:02:26,345:INFO:Copying training dataset
2025-04-19 23:02:26,351:INFO:Defining folds
2025-04-19 23:02:26,351:INFO:Declaring metric variables
2025-04-19 23:02:26,355:INFO:Importing untrained model
2025-04-19 23:02:26,358:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 23:02:26,366:INFO:Starting cross validation
2025-04-19 23:02:26,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:02:26,918:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:02:33,286:INFO:Calculating mean and std
2025-04-19 23:02:33,288:INFO:Creating metrics dataframe
2025-04-19 23:02:34,136:INFO:Uploading results into container
2025-04-19 23:02:34,137:INFO:Uploading model into container now
2025-04-19 23:02:34,137:INFO:_master_model_container: 11
2025-04-19 23:02:34,138:INFO:_display_container: 2
2025-04-19 23:02:34,138:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 23:02:34,138:INFO:create_model() successfully completed......................................
2025-04-19 23:02:34,268:INFO:SubProcess create_model() end ==================================
2025-04-19 23:02:34,268:INFO:Creating metrics dataframe
2025-04-19 23:02:34,282:INFO:Initializing Extra Trees Classifier
2025-04-19 23:02:34,282:INFO:Total runtime is 1.4382374246915182 minutes
2025-04-19 23:02:34,286:INFO:SubProcess create_model() called ==================================
2025-04-19 23:02:34,286:INFO:Initializing create_model()
2025-04-19 23:02:34,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:02:34,286:INFO:Checking exceptions
2025-04-19 23:02:34,286:INFO:Importing libraries
2025-04-19 23:02:34,286:INFO:Copying training dataset
2025-04-19 23:02:34,293:INFO:Defining folds
2025-04-19 23:02:34,293:INFO:Declaring metric variables
2025-04-19 23:02:34,297:INFO:Importing untrained model
2025-04-19 23:02:34,301:INFO:Extra Trees Classifier Imported successfully
2025-04-19 23:02:34,307:INFO:Starting cross validation
2025-04-19 23:02:34,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:02:41,776:INFO:Calculating mean and std
2025-04-19 23:02:41,777:INFO:Creating metrics dataframe
2025-04-19 23:02:42,620:INFO:Uploading results into container
2025-04-19 23:02:42,620:INFO:Uploading model into container now
2025-04-19 23:02:42,620:INFO:_master_model_container: 12
2025-04-19 23:02:42,620:INFO:_display_container: 2
2025-04-19 23:02:42,624:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1058, verbose=0, warm_start=False)
2025-04-19 23:02:42,624:INFO:create_model() successfully completed......................................
2025-04-19 23:02:42,751:INFO:SubProcess create_model() end ==================================
2025-04-19 23:02:42,751:INFO:Creating metrics dataframe
2025-04-19 23:02:42,764:INFO:Initializing Extreme Gradient Boosting
2025-04-19 23:02:42,764:INFO:Total runtime is 1.5795912226041158 minutes
2025-04-19 23:02:42,767:INFO:SubProcess create_model() called ==================================
2025-04-19 23:02:42,767:INFO:Initializing create_model()
2025-04-19 23:02:42,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:02:42,767:INFO:Checking exceptions
2025-04-19 23:02:42,767:INFO:Importing libraries
2025-04-19 23:02:42,767:INFO:Copying training dataset
2025-04-19 23:02:42,773:INFO:Defining folds
2025-04-19 23:02:42,773:INFO:Declaring metric variables
2025-04-19 23:02:42,777:INFO:Importing untrained model
2025-04-19 23:02:42,783:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 23:02:42,793:INFO:Starting cross validation
2025-04-19 23:02:42,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:02:49,988:INFO:Calculating mean and std
2025-04-19 23:02:49,990:INFO:Creating metrics dataframe
2025-04-19 23:02:50,843:INFO:Uploading results into container
2025-04-19 23:02:50,843:INFO:Uploading model into container now
2025-04-19 23:02:50,843:INFO:_master_model_container: 13
2025-04-19 23:02:50,843:INFO:_display_container: 2
2025-04-19 23:02:50,845:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 23:02:50,845:INFO:create_model() successfully completed......................................
2025-04-19 23:02:50,972:INFO:SubProcess create_model() end ==================================
2025-04-19 23:02:50,972:INFO:Creating metrics dataframe
2025-04-19 23:02:50,983:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 23:02:50,985:INFO:Total runtime is 1.7166122317314148 minutes
2025-04-19 23:02:50,987:INFO:SubProcess create_model() called ==================================
2025-04-19 23:02:50,988:INFO:Initializing create_model()
2025-04-19 23:02:50,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:02:50,988:INFO:Checking exceptions
2025-04-19 23:02:50,988:INFO:Importing libraries
2025-04-19 23:02:50,988:INFO:Copying training dataset
2025-04-19 23:02:50,993:INFO:Defining folds
2025-04-19 23:02:50,993:INFO:Declaring metric variables
2025-04-19 23:02:50,999:INFO:Importing untrained model
2025-04-19 23:02:51,008:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 23:02:51,014:INFO:Starting cross validation
2025-04-19 23:02:51,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:03:00,148:INFO:Calculating mean and std
2025-04-19 23:03:00,150:INFO:Creating metrics dataframe
2025-04-19 23:03:01,038:INFO:Uploading results into container
2025-04-19 23:03:01,049:INFO:Uploading model into container now
2025-04-19 23:03:01,049:INFO:_master_model_container: 14
2025-04-19 23:03:01,050:INFO:_display_container: 2
2025-04-19 23:03:01,050:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1058, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 23:03:01,050:INFO:create_model() successfully completed......................................
2025-04-19 23:03:01,178:INFO:SubProcess create_model() end ==================================
2025-04-19 23:03:01,178:INFO:Creating metrics dataframe
2025-04-19 23:03:01,192:INFO:Initializing Dummy Classifier
2025-04-19 23:03:01,192:INFO:Total runtime is 1.886723800500234 minutes
2025-04-19 23:03:01,200:INFO:SubProcess create_model() called ==================================
2025-04-19 23:03:01,200:INFO:Initializing create_model()
2025-04-19 23:03:01,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C13773FC40>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:03:01,201:INFO:Checking exceptions
2025-04-19 23:03:01,201:INFO:Importing libraries
2025-04-19 23:03:01,201:INFO:Copying training dataset
2025-04-19 23:03:01,205:INFO:Defining folds
2025-04-19 23:03:01,205:INFO:Declaring metric variables
2025-04-19 23:03:01,210:INFO:Importing untrained model
2025-04-19 23:03:01,213:INFO:Dummy Classifier Imported successfully
2025-04-19 23:03:01,222:INFO:Starting cross validation
2025-04-19 23:03:01,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:03:01,755:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,758:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,764:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,778:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,786:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,791:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,791:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,806:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,808:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:01,838:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:03:08,294:INFO:Calculating mean and std
2025-04-19 23:03:08,295:INFO:Creating metrics dataframe
2025-04-19 23:03:09,179:INFO:Uploading results into container
2025-04-19 23:03:09,180:INFO:Uploading model into container now
2025-04-19 23:03:09,180:INFO:_master_model_container: 15
2025-04-19 23:03:09,180:INFO:_display_container: 2
2025-04-19 23:03:09,180:INFO:DummyClassifier(constant=None, random_state=1058, strategy='prior')
2025-04-19 23:03:09,181:INFO:create_model() successfully completed......................................
2025-04-19 23:03:09,317:INFO:SubProcess create_model() end ==================================
2025-04-19 23:03:09,317:INFO:Creating metrics dataframe
2025-04-19 23:03:09,340:INFO:Initializing create_model()
2025-04-19 23:03:09,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13771E3B0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1058, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:03:09,341:INFO:Checking exceptions
2025-04-19 23:03:09,342:INFO:Importing libraries
2025-04-19 23:03:09,342:INFO:Copying training dataset
2025-04-19 23:03:09,346:INFO:Defining folds
2025-04-19 23:03:09,346:INFO:Declaring metric variables
2025-04-19 23:03:09,347:INFO:Importing untrained model
2025-04-19 23:03:09,347:INFO:Declaring custom model
2025-04-19 23:03:09,347:INFO:Ridge Classifier Imported successfully
2025-04-19 23:03:09,348:INFO:Cross validation set to False
2025-04-19 23:03:09,348:INFO:Fitting Model
2025-04-19 23:03:10,238:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1058, solver='auto',
                tol=0.0001)
2025-04-19 23:03:10,238:INFO:create_model() successfully completed......................................
2025-04-19 23:03:10,398:INFO:_master_model_container: 15
2025-04-19 23:03:10,398:INFO:_display_container: 2
2025-04-19 23:03:10,398:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1058, solver='auto',
                tol=0.0001)
2025-04-19 23:03:10,398:INFO:compare_models() successfully completed......................................
2025-04-19 23:10:03,860:INFO:PyCaret ClassificationExperiment
2025-04-19 23:10:03,860:INFO:Logging name: clf-default-name
2025-04-19 23:10:03,860:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:10:03,860:INFO:version 3.0.4
2025-04-19 23:10:03,860:INFO:Initializing setup()
2025-04-19 23:10:03,860:INFO:self.USI: 24de
2025-04-19 23:10:03,860:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:10:03,860:INFO:Checking environment
2025-04-19 23:10:03,860:INFO:python_version: 3.10.5
2025-04-19 23:10:03,860:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:10:03,860:INFO:machine: AMD64
2025-04-19 23:10:03,860:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:10:03,860:INFO:Memory: svmem(total=25042907136, available=14639267840, percent=41.5, used=10403639296, free=14639267840)
2025-04-19 23:10:03,860:INFO:Physical Core: 6
2025-04-19 23:10:03,860:INFO:Logical Core: 12
2025-04-19 23:10:03,860:INFO:Checking libraries
2025-04-19 23:10:03,860:INFO:System:
2025-04-19 23:10:03,860:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:10:03,860:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:10:03,860:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:10:03,860:INFO:PyCaret required dependencies:
2025-04-19 23:10:03,860:INFO:                 pip: 25.0.1
2025-04-19 23:10:03,860:INFO:          setuptools: 58.1.0
2025-04-19 23:10:03,860:INFO:             pycaret: 3.0.4
2025-04-19 23:10:03,860:INFO:             IPython: 8.29.0
2025-04-19 23:10:03,860:INFO:          ipywidgets: 8.1.6
2025-04-19 23:10:03,860:INFO:                tqdm: 4.67.1
2025-04-19 23:10:03,860:INFO:               numpy: 1.23.5
2025-04-19 23:10:03,860:INFO:              pandas: 1.5.3
2025-04-19 23:10:03,860:INFO:              jinja2: 3.1.4
2025-04-19 23:10:03,860:INFO:               scipy: 1.11.4
2025-04-19 23:10:03,860:INFO:              joblib: 1.3.2
2025-04-19 23:10:03,860:INFO:             sklearn: 1.2.2
2025-04-19 23:10:03,860:INFO:                pyod: 2.0.4
2025-04-19 23:10:03,860:INFO:            imblearn: 0.10.1
2025-04-19 23:10:03,860:INFO:   category_encoders: 2.7.0
2025-04-19 23:10:03,860:INFO:            lightgbm: 4.6.0
2025-04-19 23:10:03,860:INFO:               numba: 0.60.0
2025-04-19 23:10:03,860:INFO:            requests: 2.32.3
2025-04-19 23:10:03,860:INFO:          matplotlib: 3.7.5
2025-04-19 23:10:03,860:INFO:          scikitplot: 0.3.7
2025-04-19 23:10:03,860:INFO:         yellowbrick: 1.5
2025-04-19 23:10:03,860:INFO:              plotly: 5.24.1
2025-04-19 23:10:03,860:INFO:    plotly-resampler: Not installed
2025-04-19 23:10:03,860:INFO:             kaleido: 0.2.1
2025-04-19 23:10:03,860:INFO:           schemdraw: 0.15
2025-04-19 23:10:03,860:INFO:         statsmodels: 0.14.4
2025-04-19 23:10:03,860:INFO:              sktime: 0.26.0
2025-04-19 23:10:03,860:INFO:               tbats: 1.1.3
2025-04-19 23:10:03,860:INFO:            pmdarima: 2.0.4
2025-04-19 23:10:03,860:INFO:              psutil: 6.1.0
2025-04-19 23:10:03,860:INFO:          markupsafe: 3.0.2
2025-04-19 23:10:03,860:INFO:             pickle5: Not installed
2025-04-19 23:10:03,860:INFO:         cloudpickle: 3.1.1
2025-04-19 23:10:03,860:INFO:         deprecation: 2.1.0
2025-04-19 23:10:03,860:INFO:              xxhash: 3.5.0
2025-04-19 23:10:03,860:INFO:           wurlitzer: Not installed
2025-04-19 23:10:03,860:INFO:PyCaret optional dependencies:
2025-04-19 23:10:03,860:INFO:                shap: Not installed
2025-04-19 23:10:03,860:INFO:           interpret: Not installed
2025-04-19 23:10:03,860:INFO:                umap: Not installed
2025-04-19 23:10:03,860:INFO:    pandas_profiling: Not installed
2025-04-19 23:10:03,860:INFO:  explainerdashboard: Not installed
2025-04-19 23:10:03,860:INFO:             autoviz: Not installed
2025-04-19 23:10:03,860:INFO:           fairlearn: Not installed
2025-04-19 23:10:03,860:INFO:          deepchecks: Not installed
2025-04-19 23:10:03,860:INFO:             xgboost: 1.7.6
2025-04-19 23:10:03,860:INFO:            catboost: Not installed
2025-04-19 23:10:03,860:INFO:              kmodes: Not installed
2025-04-19 23:10:03,860:INFO:             mlxtend: Not installed
2025-04-19 23:10:03,860:INFO:       statsforecast: Not installed
2025-04-19 23:10:03,860:INFO:        tune_sklearn: Not installed
2025-04-19 23:10:03,860:INFO:                 ray: Not installed
2025-04-19 23:10:03,860:INFO:            hyperopt: Not installed
2025-04-19 23:10:03,860:INFO:              optuna: Not installed
2025-04-19 23:10:03,860:INFO:               skopt: Not installed
2025-04-19 23:10:03,860:INFO:              mlflow: Not installed
2025-04-19 23:10:03,860:INFO:              gradio: Not installed
2025-04-19 23:10:03,860:INFO:             fastapi: Not installed
2025-04-19 23:10:03,860:INFO:             uvicorn: Not installed
2025-04-19 23:10:03,860:INFO:              m2cgen: Not installed
2025-04-19 23:10:03,860:INFO:           evidently: Not installed
2025-04-19 23:10:03,860:INFO:               fugue: Not installed
2025-04-19 23:10:03,860:INFO:           streamlit: 1.42.0
2025-04-19 23:10:03,860:INFO:             prophet: Not installed
2025-04-19 23:10:03,860:INFO:None
2025-04-19 23:10:03,860:INFO:Set up data.
2025-04-19 23:10:03,879:INFO:Set up train/test split.
2025-04-19 23:10:03,879:INFO:Set up index.
2025-04-19 23:10:03,879:INFO:Set up folding strategy.
2025-04-19 23:10:03,879:INFO:Assigning column types.
2025-04-19 23:10:03,890:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:10:03,941:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:10:03,949:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:10:03,979:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:10:03,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:10:04,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:10:04,035:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:10:04,060:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:10:04,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:10:04,064:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:10:04,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:10:04,138:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:10:04,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:10:04,184:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:10:04,211:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:10:04,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:10:04,213:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:10:04,277:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:10:04,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:10:04,345:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:10:04,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:10:04,352:INFO:Preparing preprocessing pipeline...
2025-04-19 23:10:04,352:INFO:Set up simple imputation.
2025-04-19 23:10:04,355:INFO:Set up encoding of ordinal features.
2025-04-19 23:10:04,357:INFO:Set up encoding of categorical features.
2025-04-19 23:10:04,357:INFO:Set up removing multicollinearity.
2025-04-19 23:10:04,357:INFO:Set up imbalanced handling.
2025-04-19 23:10:04,357:INFO:Set up column transformation.
2025-04-19 23:10:04,358:INFO:Set up feature normalization.
2025-04-19 23:10:04,358:INFO:Set up feature selection.
2025-04-19 23:10:04,426:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:10:04,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:11:54,259:INFO:PyCaret ClassificationExperiment
2025-04-19 23:11:54,259:INFO:Logging name: clf-default-name
2025-04-19 23:11:54,259:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:11:54,259:INFO:version 3.0.4
2025-04-19 23:11:54,259:INFO:Initializing setup()
2025-04-19 23:11:54,259:INFO:self.USI: a054
2025-04-19 23:11:54,259:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:11:54,259:INFO:Checking environment
2025-04-19 23:11:54,259:INFO:python_version: 3.10.5
2025-04-19 23:11:54,259:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:11:54,259:INFO:machine: AMD64
2025-04-19 23:11:54,259:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:11:54,265:INFO:Memory: svmem(total=25042907136, available=14570885120, percent=41.8, used=10472022016, free=14570885120)
2025-04-19 23:11:54,265:INFO:Physical Core: 6
2025-04-19 23:11:54,265:INFO:Logical Core: 12
2025-04-19 23:11:54,265:INFO:Checking libraries
2025-04-19 23:11:54,265:INFO:System:
2025-04-19 23:11:54,265:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:11:54,265:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:11:54,265:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:11:54,265:INFO:PyCaret required dependencies:
2025-04-19 23:11:54,266:INFO:                 pip: 25.0.1
2025-04-19 23:11:54,266:INFO:          setuptools: 58.1.0
2025-04-19 23:11:54,266:INFO:             pycaret: 3.0.4
2025-04-19 23:11:54,266:INFO:             IPython: 8.29.0
2025-04-19 23:11:54,266:INFO:          ipywidgets: 8.1.6
2025-04-19 23:11:54,266:INFO:                tqdm: 4.67.1
2025-04-19 23:11:54,266:INFO:               numpy: 1.23.5
2025-04-19 23:11:54,266:INFO:              pandas: 1.5.3
2025-04-19 23:11:54,266:INFO:              jinja2: 3.1.4
2025-04-19 23:11:54,266:INFO:               scipy: 1.11.4
2025-04-19 23:11:54,266:INFO:              joblib: 1.3.2
2025-04-19 23:11:54,266:INFO:             sklearn: 1.2.2
2025-04-19 23:11:54,266:INFO:                pyod: 2.0.4
2025-04-19 23:11:54,266:INFO:            imblearn: 0.10.1
2025-04-19 23:11:54,266:INFO:   category_encoders: 2.7.0
2025-04-19 23:11:54,266:INFO:            lightgbm: 4.6.0
2025-04-19 23:11:54,266:INFO:               numba: 0.60.0
2025-04-19 23:11:54,266:INFO:            requests: 2.32.3
2025-04-19 23:11:54,266:INFO:          matplotlib: 3.7.5
2025-04-19 23:11:54,266:INFO:          scikitplot: 0.3.7
2025-04-19 23:11:54,266:INFO:         yellowbrick: 1.5
2025-04-19 23:11:54,266:INFO:              plotly: 5.24.1
2025-04-19 23:11:54,266:INFO:    plotly-resampler: Not installed
2025-04-19 23:11:54,266:INFO:             kaleido: 0.2.1
2025-04-19 23:11:54,266:INFO:           schemdraw: 0.15
2025-04-19 23:11:54,266:INFO:         statsmodels: 0.14.4
2025-04-19 23:11:54,266:INFO:              sktime: 0.26.0
2025-04-19 23:11:54,266:INFO:               tbats: 1.1.3
2025-04-19 23:11:54,266:INFO:            pmdarima: 2.0.4
2025-04-19 23:11:54,266:INFO:              psutil: 6.1.0
2025-04-19 23:11:54,266:INFO:          markupsafe: 3.0.2
2025-04-19 23:11:54,266:INFO:             pickle5: Not installed
2025-04-19 23:11:54,266:INFO:         cloudpickle: 3.1.1
2025-04-19 23:11:54,266:INFO:         deprecation: 2.1.0
2025-04-19 23:11:54,266:INFO:              xxhash: 3.5.0
2025-04-19 23:11:54,266:INFO:           wurlitzer: Not installed
2025-04-19 23:11:54,266:INFO:PyCaret optional dependencies:
2025-04-19 23:11:54,268:INFO:                shap: Not installed
2025-04-19 23:11:54,268:INFO:           interpret: Not installed
2025-04-19 23:11:54,268:INFO:                umap: Not installed
2025-04-19 23:11:54,268:INFO:    pandas_profiling: Not installed
2025-04-19 23:11:54,268:INFO:  explainerdashboard: Not installed
2025-04-19 23:11:54,268:INFO:             autoviz: Not installed
2025-04-19 23:11:54,268:INFO:           fairlearn: Not installed
2025-04-19 23:11:54,268:INFO:          deepchecks: Not installed
2025-04-19 23:11:54,268:INFO:             xgboost: 1.7.6
2025-04-19 23:11:54,268:INFO:            catboost: Not installed
2025-04-19 23:11:54,268:INFO:              kmodes: Not installed
2025-04-19 23:11:54,268:INFO:             mlxtend: Not installed
2025-04-19 23:11:54,268:INFO:       statsforecast: Not installed
2025-04-19 23:11:54,268:INFO:        tune_sklearn: Not installed
2025-04-19 23:11:54,268:INFO:                 ray: Not installed
2025-04-19 23:11:54,268:INFO:            hyperopt: Not installed
2025-04-19 23:11:54,268:INFO:              optuna: Not installed
2025-04-19 23:11:54,268:INFO:               skopt: Not installed
2025-04-19 23:11:54,268:INFO:              mlflow: Not installed
2025-04-19 23:11:54,268:INFO:              gradio: Not installed
2025-04-19 23:11:54,268:INFO:             fastapi: Not installed
2025-04-19 23:11:54,268:INFO:             uvicorn: Not installed
2025-04-19 23:11:54,268:INFO:              m2cgen: Not installed
2025-04-19 23:11:54,268:INFO:           evidently: Not installed
2025-04-19 23:11:54,268:INFO:               fugue: Not installed
2025-04-19 23:11:54,268:INFO:           streamlit: 1.42.0
2025-04-19 23:11:54,268:INFO:             prophet: Not installed
2025-04-19 23:11:54,268:INFO:None
2025-04-19 23:11:54,268:INFO:Set up data.
2025-04-19 23:11:54,280:INFO:Set up train/test split.
2025-04-19 23:11:54,286:INFO:Set up index.
2025-04-19 23:11:54,286:INFO:Set up folding strategy.
2025-04-19 23:11:54,286:INFO:Assigning column types.
2025-04-19 23:11:54,288:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:11:54,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:11:54,329:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:11:54,351:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:11:54,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:11:54,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:11:54,399:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:11:54,422:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:11:54,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:11:54,427:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:11:54,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:11:54,491:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:11:54,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:11:54,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:11:54,559:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:11:54,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:11:54,562:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:11:54,630:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:11:54,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:11:54,698:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:11:54,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:11:54,703:INFO:Preparing preprocessing pipeline...
2025-04-19 23:11:54,704:INFO:Set up simple imputation.
2025-04-19 23:11:54,707:INFO:Set up encoding of ordinal features.
2025-04-19 23:11:54,708:INFO:Set up encoding of categorical features.
2025-04-19 23:11:54,708:INFO:Set up removing multicollinearity.
2025-04-19 23:11:54,708:INFO:Set up imbalanced handling.
2025-04-19 23:11:54,708:INFO:Set up column transformation.
2025-04-19 23:11:54,708:INFO:Set up feature normalization.
2025-04-19 23:11:54,708:INFO:Set up feature selection.
2025-04-19 23:11:54,774:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:11:54,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:11:55,250:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:11:55,303:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompan...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 23:11:55,303:INFO:Creating final display dataframe.
2025-04-19 23:12:05,130:INFO:PyCaret ClassificationExperiment
2025-04-19 23:12:05,130:INFO:Logging name: clf-default-name
2025-04-19 23:12:05,130:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:12:05,130:INFO:version 3.0.4
2025-04-19 23:12:05,130:INFO:Initializing setup()
2025-04-19 23:12:05,131:INFO:self.USI: 5c80
2025-04-19 23:12:05,131:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:12:05,131:INFO:Checking environment
2025-04-19 23:12:05,131:INFO:python_version: 3.10.5
2025-04-19 23:12:05,131:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:12:05,131:INFO:machine: AMD64
2025-04-19 23:12:05,131:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:12:05,137:INFO:Memory: svmem(total=25042907136, available=14615064576, percent=41.6, used=10427842560, free=14615064576)
2025-04-19 23:12:05,137:INFO:Physical Core: 6
2025-04-19 23:12:05,137:INFO:Logical Core: 12
2025-04-19 23:12:05,137:INFO:Checking libraries
2025-04-19 23:12:05,137:INFO:System:
2025-04-19 23:12:05,137:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:12:05,137:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:12:05,137:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:12:05,137:INFO:PyCaret required dependencies:
2025-04-19 23:12:05,137:INFO:                 pip: 25.0.1
2025-04-19 23:12:05,137:INFO:          setuptools: 58.1.0
2025-04-19 23:12:05,137:INFO:             pycaret: 3.0.4
2025-04-19 23:12:05,137:INFO:             IPython: 8.29.0
2025-04-19 23:12:05,137:INFO:          ipywidgets: 8.1.6
2025-04-19 23:12:05,138:INFO:                tqdm: 4.67.1
2025-04-19 23:12:05,138:INFO:               numpy: 1.23.5
2025-04-19 23:12:05,138:INFO:              pandas: 1.5.3
2025-04-19 23:12:05,138:INFO:              jinja2: 3.1.4
2025-04-19 23:12:05,138:INFO:               scipy: 1.11.4
2025-04-19 23:12:05,138:INFO:              joblib: 1.3.2
2025-04-19 23:12:05,138:INFO:             sklearn: 1.2.2
2025-04-19 23:12:05,138:INFO:                pyod: 2.0.4
2025-04-19 23:12:05,138:INFO:            imblearn: 0.10.1
2025-04-19 23:12:05,138:INFO:   category_encoders: 2.7.0
2025-04-19 23:12:05,138:INFO:            lightgbm: 4.6.0
2025-04-19 23:12:05,138:INFO:               numba: 0.60.0
2025-04-19 23:12:05,138:INFO:            requests: 2.32.3
2025-04-19 23:12:05,138:INFO:          matplotlib: 3.7.5
2025-04-19 23:12:05,138:INFO:          scikitplot: 0.3.7
2025-04-19 23:12:05,138:INFO:         yellowbrick: 1.5
2025-04-19 23:12:05,138:INFO:              plotly: 5.24.1
2025-04-19 23:12:05,138:INFO:    plotly-resampler: Not installed
2025-04-19 23:12:05,138:INFO:             kaleido: 0.2.1
2025-04-19 23:12:05,138:INFO:           schemdraw: 0.15
2025-04-19 23:12:05,138:INFO:         statsmodels: 0.14.4
2025-04-19 23:12:05,138:INFO:              sktime: 0.26.0
2025-04-19 23:12:05,138:INFO:               tbats: 1.1.3
2025-04-19 23:12:05,138:INFO:            pmdarima: 2.0.4
2025-04-19 23:12:05,138:INFO:              psutil: 6.1.0
2025-04-19 23:12:05,138:INFO:          markupsafe: 3.0.2
2025-04-19 23:12:05,138:INFO:             pickle5: Not installed
2025-04-19 23:12:05,138:INFO:         cloudpickle: 3.1.1
2025-04-19 23:12:05,138:INFO:         deprecation: 2.1.0
2025-04-19 23:12:05,138:INFO:              xxhash: 3.5.0
2025-04-19 23:12:05,138:INFO:           wurlitzer: Not installed
2025-04-19 23:12:05,138:INFO:PyCaret optional dependencies:
2025-04-19 23:12:05,138:INFO:                shap: Not installed
2025-04-19 23:12:05,139:INFO:           interpret: Not installed
2025-04-19 23:12:05,139:INFO:                umap: Not installed
2025-04-19 23:12:05,139:INFO:    pandas_profiling: Not installed
2025-04-19 23:12:05,139:INFO:  explainerdashboard: Not installed
2025-04-19 23:12:05,139:INFO:             autoviz: Not installed
2025-04-19 23:12:05,139:INFO:           fairlearn: Not installed
2025-04-19 23:12:05,139:INFO:          deepchecks: Not installed
2025-04-19 23:12:05,139:INFO:             xgboost: 1.7.6
2025-04-19 23:12:05,139:INFO:            catboost: Not installed
2025-04-19 23:12:05,139:INFO:              kmodes: Not installed
2025-04-19 23:12:05,139:INFO:             mlxtend: Not installed
2025-04-19 23:12:05,139:INFO:       statsforecast: Not installed
2025-04-19 23:12:05,139:INFO:        tune_sklearn: Not installed
2025-04-19 23:12:05,139:INFO:                 ray: Not installed
2025-04-19 23:12:05,139:INFO:            hyperopt: Not installed
2025-04-19 23:12:05,139:INFO:              optuna: Not installed
2025-04-19 23:12:05,139:INFO:               skopt: Not installed
2025-04-19 23:12:05,139:INFO:              mlflow: Not installed
2025-04-19 23:12:05,139:INFO:              gradio: Not installed
2025-04-19 23:12:05,140:INFO:             fastapi: Not installed
2025-04-19 23:12:05,140:INFO:             uvicorn: Not installed
2025-04-19 23:12:05,140:INFO:              m2cgen: Not installed
2025-04-19 23:12:05,140:INFO:           evidently: Not installed
2025-04-19 23:12:05,140:INFO:               fugue: Not installed
2025-04-19 23:12:05,140:INFO:           streamlit: 1.42.0
2025-04-19 23:12:05,140:INFO:             prophet: Not installed
2025-04-19 23:12:05,140:INFO:None
2025-04-19 23:12:05,140:INFO:Set up data.
2025-04-19 23:12:05,152:INFO:Set up train/test split.
2025-04-19 23:12:05,158:INFO:Set up index.
2025-04-19 23:12:05,158:INFO:Set up folding strategy.
2025-04-19 23:12:05,158:INFO:Assigning column types.
2025-04-19 23:12:05,161:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:12:05,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:12:05,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:12:05,228:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:05,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:05,273:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:12:05,273:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:12:05,298:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:05,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:05,301:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:12:05,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:12:05,365:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:05,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:05,408:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:12:05,433:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:05,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:05,435:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:12:05,500:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:05,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:05,576:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:05,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:05,580:INFO:Preparing preprocessing pipeline...
2025-04-19 23:12:05,581:INFO:Set up simple imputation.
2025-04-19 23:12:05,582:INFO:Set up encoding of ordinal features.
2025-04-19 23:12:05,582:INFO:Set up encoding of categorical features.
2025-04-19 23:12:05,582:INFO:Set up removing multicollinearity.
2025-04-19 23:12:05,582:INFO:Set up imbalanced handling.
2025-04-19 23:12:05,582:INFO:Set up feature normalization.
2025-04-19 23:12:05,582:INFO:Set up feature selection.
2025-04-19 23:12:05,652:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:05,656:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:06,070:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:12:06,116:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompan...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 23:12:06,116:INFO:Creating final display dataframe.
2025-04-19 23:12:41,125:INFO:PyCaret ClassificationExperiment
2025-04-19 23:12:41,125:INFO:Logging name: clf-default-name
2025-04-19 23:12:41,125:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:12:41,126:INFO:version 3.0.4
2025-04-19 23:12:41,126:INFO:Initializing setup()
2025-04-19 23:12:41,126:INFO:self.USI: d14f
2025-04-19 23:12:41,126:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:12:41,126:INFO:Checking environment
2025-04-19 23:12:41,126:INFO:python_version: 3.10.5
2025-04-19 23:12:41,126:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:12:41,126:INFO:machine: AMD64
2025-04-19 23:12:41,126:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:12:41,132:INFO:Memory: svmem(total=25042907136, available=14622105600, percent=41.6, used=10420801536, free=14622105600)
2025-04-19 23:12:41,132:INFO:Physical Core: 6
2025-04-19 23:12:41,132:INFO:Logical Core: 12
2025-04-19 23:12:41,132:INFO:Checking libraries
2025-04-19 23:12:41,132:INFO:System:
2025-04-19 23:12:41,132:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:12:41,132:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:12:41,132:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:12:41,132:INFO:PyCaret required dependencies:
2025-04-19 23:12:41,132:INFO:                 pip: 25.0.1
2025-04-19 23:12:41,132:INFO:          setuptools: 58.1.0
2025-04-19 23:12:41,132:INFO:             pycaret: 3.0.4
2025-04-19 23:12:41,132:INFO:             IPython: 8.29.0
2025-04-19 23:12:41,132:INFO:          ipywidgets: 8.1.6
2025-04-19 23:12:41,132:INFO:                tqdm: 4.67.1
2025-04-19 23:12:41,132:INFO:               numpy: 1.23.5
2025-04-19 23:12:41,133:INFO:              pandas: 1.5.3
2025-04-19 23:12:41,133:INFO:              jinja2: 3.1.4
2025-04-19 23:12:41,133:INFO:               scipy: 1.11.4
2025-04-19 23:12:41,133:INFO:              joblib: 1.3.2
2025-04-19 23:12:41,133:INFO:             sklearn: 1.2.2
2025-04-19 23:12:41,133:INFO:                pyod: 2.0.4
2025-04-19 23:12:41,133:INFO:            imblearn: 0.10.1
2025-04-19 23:12:41,133:INFO:   category_encoders: 2.7.0
2025-04-19 23:12:41,133:INFO:            lightgbm: 4.6.0
2025-04-19 23:12:41,133:INFO:               numba: 0.60.0
2025-04-19 23:12:41,133:INFO:            requests: 2.32.3
2025-04-19 23:12:41,133:INFO:          matplotlib: 3.7.5
2025-04-19 23:12:41,133:INFO:          scikitplot: 0.3.7
2025-04-19 23:12:41,133:INFO:         yellowbrick: 1.5
2025-04-19 23:12:41,134:INFO:              plotly: 5.24.1
2025-04-19 23:12:41,134:INFO:    plotly-resampler: Not installed
2025-04-19 23:12:41,134:INFO:             kaleido: 0.2.1
2025-04-19 23:12:41,134:INFO:           schemdraw: 0.15
2025-04-19 23:12:41,134:INFO:         statsmodels: 0.14.4
2025-04-19 23:12:41,134:INFO:              sktime: 0.26.0
2025-04-19 23:12:41,134:INFO:               tbats: 1.1.3
2025-04-19 23:12:41,134:INFO:            pmdarima: 2.0.4
2025-04-19 23:12:41,134:INFO:              psutil: 6.1.0
2025-04-19 23:12:41,134:INFO:          markupsafe: 3.0.2
2025-04-19 23:12:41,134:INFO:             pickle5: Not installed
2025-04-19 23:12:41,134:INFO:         cloudpickle: 3.1.1
2025-04-19 23:12:41,134:INFO:         deprecation: 2.1.0
2025-04-19 23:12:41,134:INFO:              xxhash: 3.5.0
2025-04-19 23:12:41,134:INFO:           wurlitzer: Not installed
2025-04-19 23:12:41,134:INFO:PyCaret optional dependencies:
2025-04-19 23:12:41,134:INFO:                shap: Not installed
2025-04-19 23:12:41,135:INFO:           interpret: Not installed
2025-04-19 23:12:41,135:INFO:                umap: Not installed
2025-04-19 23:12:41,135:INFO:    pandas_profiling: Not installed
2025-04-19 23:12:41,135:INFO:  explainerdashboard: Not installed
2025-04-19 23:12:41,135:INFO:             autoviz: Not installed
2025-04-19 23:12:41,135:INFO:           fairlearn: Not installed
2025-04-19 23:12:41,135:INFO:          deepchecks: Not installed
2025-04-19 23:12:41,135:INFO:             xgboost: 1.7.6
2025-04-19 23:12:41,135:INFO:            catboost: Not installed
2025-04-19 23:12:41,135:INFO:              kmodes: Not installed
2025-04-19 23:12:41,135:INFO:             mlxtend: Not installed
2025-04-19 23:12:41,135:INFO:       statsforecast: Not installed
2025-04-19 23:12:41,135:INFO:        tune_sklearn: Not installed
2025-04-19 23:12:41,135:INFO:                 ray: Not installed
2025-04-19 23:12:41,135:INFO:            hyperopt: Not installed
2025-04-19 23:12:41,135:INFO:              optuna: Not installed
2025-04-19 23:12:41,135:INFO:               skopt: Not installed
2025-04-19 23:12:41,135:INFO:              mlflow: Not installed
2025-04-19 23:12:41,135:INFO:              gradio: Not installed
2025-04-19 23:12:41,135:INFO:             fastapi: Not installed
2025-04-19 23:12:41,135:INFO:             uvicorn: Not installed
2025-04-19 23:12:41,135:INFO:              m2cgen: Not installed
2025-04-19 23:12:41,136:INFO:           evidently: Not installed
2025-04-19 23:12:41,136:INFO:               fugue: Not installed
2025-04-19 23:12:41,136:INFO:           streamlit: 1.42.0
2025-04-19 23:12:41,136:INFO:             prophet: Not installed
2025-04-19 23:12:41,136:INFO:None
2025-04-19 23:12:41,136:INFO:Set up data.
2025-04-19 23:12:41,148:INFO:Set up train/test split.
2025-04-19 23:12:41,154:INFO:Set up index.
2025-04-19 23:12:41,154:INFO:Set up folding strategy.
2025-04-19 23:12:41,154:INFO:Assigning column types.
2025-04-19 23:12:41,157:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:12:41,197:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:12:41,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:12:41,225:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:41,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:41,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:12:41,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:12:41,296:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:41,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:41,299:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:12:41,338:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:12:41,364:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:41,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:41,408:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:12:41,435:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:41,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:41,437:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:12:41,511:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:41,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:41,581:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:41,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:41,585:INFO:Preparing preprocessing pipeline...
2025-04-19 23:12:41,586:INFO:Set up simple imputation.
2025-04-19 23:12:41,589:INFO:Set up encoding of ordinal features.
2025-04-19 23:12:41,591:INFO:Set up encoding of categorical features.
2025-04-19 23:12:41,592:INFO:Set up removing multicollinearity.
2025-04-19 23:12:41,592:INFO:Set up imbalanced handling.
2025-04-19 23:12:41,592:INFO:Set up feature normalization.
2025-04-19 23:12:41,770:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:12:41,797:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompan...
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 23:12:41,797:INFO:Creating final display dataframe.
2025-04-19 23:12:42,180:INFO:Setup _display_container:                     Description             Value
0                    Session id              1058
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape        (1058, 35)
4        Transformed data shape        (1548, 52)
5   Transformed train set shape        (1230, 52)
6    Transformed test set shape         (318, 52)
7              Ordinal features                 2
8              Numeric features                26
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method            onehot
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              d14f
2025-04-19 23:12:42,248:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:42,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:42,319:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:12:42,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:12:42,322:INFO:setup() successfully completed in 1.83s...............
2025-04-19 23:12:45,314:INFO:Initializing compare_models()
2025-04-19 23:12:45,314:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 23:12:45,314:INFO:Checking exceptions
2025-04-19 23:12:45,318:INFO:Preparing display monitor
2025-04-19 23:12:45,337:INFO:Initializing Logistic Regression
2025-04-19 23:12:45,337:INFO:Total runtime is 0.0 minutes
2025-04-19 23:12:45,340:INFO:SubProcess create_model() called ==================================
2025-04-19 23:12:45,341:INFO:Initializing create_model()
2025-04-19 23:12:45,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:12:45,342:INFO:Checking exceptions
2025-04-19 23:12:45,342:INFO:Importing libraries
2025-04-19 23:12:45,342:INFO:Copying training dataset
2025-04-19 23:12:45,346:INFO:Defining folds
2025-04-19 23:12:45,346:INFO:Declaring metric variables
2025-04-19 23:12:45,350:INFO:Importing untrained model
2025-04-19 23:12:45,352:INFO:Logistic Regression Imported successfully
2025-04-19 23:12:45,360:INFO:Starting cross validation
2025-04-19 23:12:45,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:12:59,983:INFO:Calculating mean and std
2025-04-19 23:12:59,983:INFO:Creating metrics dataframe
2025-04-19 23:13:00,874:INFO:Uploading results into container
2025-04-19 23:13:00,874:INFO:Uploading model into container now
2025-04-19 23:13:00,877:INFO:_master_model_container: 1
2025-04-19 23:13:00,877:INFO:_display_container: 2
2025-04-19 23:13:00,878:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1058, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 23:13:00,878:INFO:create_model() successfully completed......................................
2025-04-19 23:13:02,315:INFO:SubProcess create_model() end ==================================
2025-04-19 23:13:02,315:INFO:Creating metrics dataframe
2025-04-19 23:13:02,326:INFO:Initializing K Neighbors Classifier
2025-04-19 23:13:02,326:INFO:Total runtime is 0.2831517775853475 minutes
2025-04-19 23:13:02,326:INFO:SubProcess create_model() called ==================================
2025-04-19 23:13:02,326:INFO:Initializing create_model()
2025-04-19 23:13:02,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:13:02,326:INFO:Checking exceptions
2025-04-19 23:13:02,326:INFO:Importing libraries
2025-04-19 23:13:02,326:INFO:Copying training dataset
2025-04-19 23:13:02,334:INFO:Defining folds
2025-04-19 23:13:02,335:INFO:Declaring metric variables
2025-04-19 23:13:02,338:INFO:Importing untrained model
2025-04-19 23:13:02,342:INFO:K Neighbors Classifier Imported successfully
2025-04-19 23:13:02,349:INFO:Starting cross validation
2025-04-19 23:13:02,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:13:10,180:INFO:Calculating mean and std
2025-04-19 23:13:10,181:INFO:Creating metrics dataframe
2025-04-19 23:13:11,070:INFO:Uploading results into container
2025-04-19 23:13:11,070:INFO:Uploading model into container now
2025-04-19 23:13:11,070:INFO:_master_model_container: 2
2025-04-19 23:13:11,070:INFO:_display_container: 2
2025-04-19 23:13:11,070:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 23:13:11,070:INFO:create_model() successfully completed......................................
2025-04-19 23:13:11,215:INFO:SubProcess create_model() end ==================================
2025-04-19 23:13:11,215:INFO:Creating metrics dataframe
2025-04-19 23:13:11,224:INFO:Initializing Naive Bayes
2025-04-19 23:13:11,224:INFO:Total runtime is 0.4314436395963033 minutes
2025-04-19 23:13:11,224:INFO:SubProcess create_model() called ==================================
2025-04-19 23:13:11,224:INFO:Initializing create_model()
2025-04-19 23:13:11,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:13:11,224:INFO:Checking exceptions
2025-04-19 23:13:11,224:INFO:Importing libraries
2025-04-19 23:13:11,224:INFO:Copying training dataset
2025-04-19 23:13:11,233:INFO:Defining folds
2025-04-19 23:13:11,233:INFO:Declaring metric variables
2025-04-19 23:13:11,237:INFO:Importing untrained model
2025-04-19 23:13:11,240:INFO:Naive Bayes Imported successfully
2025-04-19 23:13:11,245:INFO:Starting cross validation
2025-04-19 23:13:11,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:13:18,433:INFO:Calculating mean and std
2025-04-19 23:13:18,433:INFO:Creating metrics dataframe
2025-04-19 23:13:19,325:INFO:Uploading results into container
2025-04-19 23:13:19,325:INFO:Uploading model into container now
2025-04-19 23:13:19,325:INFO:_master_model_container: 3
2025-04-19 23:13:19,325:INFO:_display_container: 2
2025-04-19 23:13:19,325:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 23:13:19,325:INFO:create_model() successfully completed......................................
2025-04-19 23:13:19,460:INFO:SubProcess create_model() end ==================================
2025-04-19 23:13:19,460:INFO:Creating metrics dataframe
2025-04-19 23:13:19,475:INFO:Initializing Decision Tree Classifier
2025-04-19 23:13:19,475:INFO:Total runtime is 0.5689680377642313 minutes
2025-04-19 23:13:19,477:INFO:SubProcess create_model() called ==================================
2025-04-19 23:13:19,477:INFO:Initializing create_model()
2025-04-19 23:13:19,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:13:19,477:INFO:Checking exceptions
2025-04-19 23:13:19,477:INFO:Importing libraries
2025-04-19 23:13:19,477:INFO:Copying training dataset
2025-04-19 23:13:19,484:INFO:Defining folds
2025-04-19 23:13:19,484:INFO:Declaring metric variables
2025-04-19 23:13:19,488:INFO:Importing untrained model
2025-04-19 23:13:19,493:INFO:Decision Tree Classifier Imported successfully
2025-04-19 23:13:19,498:INFO:Starting cross validation
2025-04-19 23:13:19,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:13:26,688:INFO:Calculating mean and std
2025-04-19 23:13:26,690:INFO:Creating metrics dataframe
2025-04-19 23:13:27,595:INFO:Uploading results into container
2025-04-19 23:13:27,596:INFO:Uploading model into container now
2025-04-19 23:13:27,596:INFO:_master_model_container: 4
2025-04-19 23:13:27,596:INFO:_display_container: 2
2025-04-19 23:13:27,597:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1058, splitter='best')
2025-04-19 23:13:27,597:INFO:create_model() successfully completed......................................
2025-04-19 23:13:27,733:INFO:SubProcess create_model() end ==================================
2025-04-19 23:13:27,733:INFO:Creating metrics dataframe
2025-04-19 23:13:27,750:INFO:Initializing SVM - Linear Kernel
2025-04-19 23:13:27,750:INFO:Total runtime is 0.7068806131680806 minutes
2025-04-19 23:13:27,754:INFO:SubProcess create_model() called ==================================
2025-04-19 23:13:27,754:INFO:Initializing create_model()
2025-04-19 23:13:27,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:13:27,754:INFO:Checking exceptions
2025-04-19 23:13:27,755:INFO:Importing libraries
2025-04-19 23:13:27,755:INFO:Copying training dataset
2025-04-19 23:13:27,760:INFO:Defining folds
2025-04-19 23:13:27,760:INFO:Declaring metric variables
2025-04-19 23:13:27,764:INFO:Importing untrained model
2025-04-19 23:13:27,767:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 23:13:27,776:INFO:Starting cross validation
2025-04-19 23:13:27,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:13:28,256:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,266:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,277:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,288:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,310:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,310:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,388:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,394:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,394:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:28,435:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:13:35,863:INFO:Calculating mean and std
2025-04-19 23:13:35,865:INFO:Creating metrics dataframe
2025-04-19 23:13:37,320:INFO:Uploading results into container
2025-04-19 23:13:37,320:INFO:Uploading model into container now
2025-04-19 23:13:37,320:INFO:_master_model_container: 5
2025-04-19 23:13:37,320:INFO:_display_container: 2
2025-04-19 23:13:37,327:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1058, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 23:13:37,327:INFO:create_model() successfully completed......................................
2025-04-19 23:13:37,504:INFO:SubProcess create_model() end ==================================
2025-04-19 23:13:37,504:INFO:Creating metrics dataframe
2025-04-19 23:13:37,537:INFO:Initializing Ridge Classifier
2025-04-19 23:13:37,537:INFO:Total runtime is 0.8699976404507954 minutes
2025-04-19 23:13:37,545:INFO:SubProcess create_model() called ==================================
2025-04-19 23:13:37,546:INFO:Initializing create_model()
2025-04-19 23:13:37,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:13:37,546:INFO:Checking exceptions
2025-04-19 23:13:37,546:INFO:Importing libraries
2025-04-19 23:13:37,546:INFO:Copying training dataset
2025-04-19 23:13:37,554:INFO:Defining folds
2025-04-19 23:13:37,554:INFO:Declaring metric variables
2025-04-19 23:13:37,568:INFO:Importing untrained model
2025-04-19 23:13:37,575:INFO:Ridge Classifier Imported successfully
2025-04-19 23:13:37,586:INFO:Starting cross validation
2025-04-19 23:13:37,590:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:13:38,784:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,790:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,790:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,804:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,806:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,809:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,824:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,824:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,828:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:38,844:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:13:46,469:INFO:Calculating mean and std
2025-04-19 23:13:46,470:INFO:Creating metrics dataframe
2025-04-19 23:13:47,365:INFO:Uploading results into container
2025-04-19 23:13:47,366:INFO:Uploading model into container now
2025-04-19 23:13:47,366:INFO:_master_model_container: 6
2025-04-19 23:13:47,366:INFO:_display_container: 2
2025-04-19 23:13:47,367:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1058, solver='auto',
                tol=0.0001)
2025-04-19 23:13:47,367:INFO:create_model() successfully completed......................................
2025-04-19 23:13:47,511:INFO:SubProcess create_model() end ==================================
2025-04-19 23:13:47,511:INFO:Creating metrics dataframe
2025-04-19 23:13:47,521:INFO:Initializing Random Forest Classifier
2025-04-19 23:13:47,521:INFO:Total runtime is 1.036387781302134 minutes
2025-04-19 23:13:47,524:INFO:SubProcess create_model() called ==================================
2025-04-19 23:13:47,524:INFO:Initializing create_model()
2025-04-19 23:13:47,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:13:47,524:INFO:Checking exceptions
2025-04-19 23:13:47,524:INFO:Importing libraries
2025-04-19 23:13:47,524:INFO:Copying training dataset
2025-04-19 23:13:47,529:INFO:Defining folds
2025-04-19 23:13:47,529:INFO:Declaring metric variables
2025-04-19 23:13:47,535:INFO:Importing untrained model
2025-04-19 23:13:47,540:INFO:Random Forest Classifier Imported successfully
2025-04-19 23:13:47,547:INFO:Starting cross validation
2025-04-19 23:13:47,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:13:55,818:INFO:Calculating mean and std
2025-04-19 23:13:55,819:INFO:Creating metrics dataframe
2025-04-19 23:13:56,738:INFO:Uploading results into container
2025-04-19 23:13:56,739:INFO:Uploading model into container now
2025-04-19 23:13:56,739:INFO:_master_model_container: 7
2025-04-19 23:13:56,739:INFO:_display_container: 2
2025-04-19 23:13:56,740:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 23:13:56,740:INFO:create_model() successfully completed......................................
2025-04-19 23:13:56,880:INFO:SubProcess create_model() end ==================================
2025-04-19 23:13:56,880:INFO:Creating metrics dataframe
2025-04-19 23:13:56,889:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 23:13:56,890:INFO:Total runtime is 1.192548664410909 minutes
2025-04-19 23:13:56,894:INFO:SubProcess create_model() called ==================================
2025-04-19 23:13:56,894:INFO:Initializing create_model()
2025-04-19 23:13:56,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:13:56,894:INFO:Checking exceptions
2025-04-19 23:13:56,894:INFO:Importing libraries
2025-04-19 23:13:56,894:INFO:Copying training dataset
2025-04-19 23:13:56,898:INFO:Defining folds
2025-04-19 23:13:56,898:INFO:Declaring metric variables
2025-04-19 23:13:56,902:INFO:Importing untrained model
2025-04-19 23:13:56,908:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 23:13:56,915:INFO:Starting cross validation
2025-04-19 23:13:56,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:13:57,181:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,203:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,203:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,205:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,208:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,218:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,239:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,244:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,244:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:13:57,264:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-19 23:14:04,379:INFO:Calculating mean and std
2025-04-19 23:14:04,381:INFO:Creating metrics dataframe
2025-04-19 23:14:05,277:INFO:Uploading results into container
2025-04-19 23:14:05,278:INFO:Uploading model into container now
2025-04-19 23:14:05,279:INFO:_master_model_container: 8
2025-04-19 23:14:05,279:INFO:_display_container: 2
2025-04-19 23:14:05,279:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 23:14:05,280:INFO:create_model() successfully completed......................................
2025-04-19 23:14:05,425:INFO:SubProcess create_model() end ==================================
2025-04-19 23:14:05,425:INFO:Creating metrics dataframe
2025-04-19 23:14:05,437:INFO:Initializing Ada Boost Classifier
2025-04-19 23:14:05,437:INFO:Total runtime is 1.3349947969118752 minutes
2025-04-19 23:14:05,441:INFO:SubProcess create_model() called ==================================
2025-04-19 23:14:05,442:INFO:Initializing create_model()
2025-04-19 23:14:05,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:14:05,442:INFO:Checking exceptions
2025-04-19 23:14:05,442:INFO:Importing libraries
2025-04-19 23:14:05,442:INFO:Copying training dataset
2025-04-19 23:14:05,446:INFO:Defining folds
2025-04-19 23:14:05,446:INFO:Declaring metric variables
2025-04-19 23:14:05,451:INFO:Importing untrained model
2025-04-19 23:14:05,455:INFO:Ada Boost Classifier Imported successfully
2025-04-19 23:14:05,463:INFO:Starting cross validation
2025-04-19 23:14:05,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:14:13,460:INFO:Calculating mean and std
2025-04-19 23:14:13,461:INFO:Creating metrics dataframe
2025-04-19 23:14:14,418:INFO:Uploading results into container
2025-04-19 23:14:14,419:INFO:Uploading model into container now
2025-04-19 23:14:14,420:INFO:_master_model_container: 9
2025-04-19 23:14:14,420:INFO:_display_container: 2
2025-04-19 23:14:14,420:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1058)
2025-04-19 23:14:14,420:INFO:create_model() successfully completed......................................
2025-04-19 23:14:14,567:INFO:SubProcess create_model() end ==================================
2025-04-19 23:14:14,567:INFO:Creating metrics dataframe
2025-04-19 23:14:14,577:INFO:Initializing Gradient Boosting Classifier
2025-04-19 23:14:14,578:INFO:Total runtime is 1.4873455325762428 minutes
2025-04-19 23:14:14,581:INFO:SubProcess create_model() called ==================================
2025-04-19 23:14:14,581:INFO:Initializing create_model()
2025-04-19 23:14:14,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:14:14,581:INFO:Checking exceptions
2025-04-19 23:14:14,582:INFO:Importing libraries
2025-04-19 23:14:14,582:INFO:Copying training dataset
2025-04-19 23:14:14,586:INFO:Defining folds
2025-04-19 23:14:14,586:INFO:Declaring metric variables
2025-04-19 23:14:14,591:INFO:Importing untrained model
2025-04-19 23:14:14,597:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 23:14:14,605:INFO:Starting cross validation
2025-04-19 23:14:14,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:14:23,533:INFO:Calculating mean and std
2025-04-19 23:14:23,534:INFO:Creating metrics dataframe
2025-04-19 23:14:24,501:INFO:Uploading results into container
2025-04-19 23:14:24,502:INFO:Uploading model into container now
2025-04-19 23:14:24,502:INFO:_master_model_container: 10
2025-04-19 23:14:24,502:INFO:_display_container: 2
2025-04-19 23:14:24,503:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1058, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 23:14:24,503:INFO:create_model() successfully completed......................................
2025-04-19 23:14:24,645:INFO:SubProcess create_model() end ==================================
2025-04-19 23:14:24,645:INFO:Creating metrics dataframe
2025-04-19 23:14:24,656:INFO:Initializing Linear Discriminant Analysis
2025-04-19 23:14:24,656:INFO:Total runtime is 1.6553068717320758 minutes
2025-04-19 23:14:24,658:INFO:SubProcess create_model() called ==================================
2025-04-19 23:14:24,659:INFO:Initializing create_model()
2025-04-19 23:14:24,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:14:24,659:INFO:Checking exceptions
2025-04-19 23:14:24,659:INFO:Importing libraries
2025-04-19 23:14:24,659:INFO:Copying training dataset
2025-04-19 23:14:24,665:INFO:Defining folds
2025-04-19 23:14:24,665:INFO:Declaring metric variables
2025-04-19 23:14:24,669:INFO:Importing untrained model
2025-04-19 23:14:24,673:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 23:14:24,679:INFO:Starting cross validation
2025-04-19 23:14:24,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:14:32,416:INFO:Calculating mean and std
2025-04-19 23:14:32,416:INFO:Creating metrics dataframe
2025-04-19 23:14:33,369:INFO:Uploading results into container
2025-04-19 23:14:33,369:INFO:Uploading model into container now
2025-04-19 23:14:33,370:INFO:_master_model_container: 11
2025-04-19 23:14:33,371:INFO:_display_container: 2
2025-04-19 23:14:33,371:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 23:14:33,371:INFO:create_model() successfully completed......................................
2025-04-19 23:14:33,544:INFO:SubProcess create_model() end ==================================
2025-04-19 23:14:33,544:INFO:Creating metrics dataframe
2025-04-19 23:14:33,555:INFO:Initializing Extra Trees Classifier
2025-04-19 23:14:33,555:INFO:Total runtime is 1.8036221663157144 minutes
2025-04-19 23:14:33,558:INFO:SubProcess create_model() called ==================================
2025-04-19 23:14:33,558:INFO:Initializing create_model()
2025-04-19 23:14:33,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:14:33,558:INFO:Checking exceptions
2025-04-19 23:14:33,559:INFO:Importing libraries
2025-04-19 23:14:33,559:INFO:Copying training dataset
2025-04-19 23:14:33,564:INFO:Defining folds
2025-04-19 23:14:33,564:INFO:Declaring metric variables
2025-04-19 23:14:33,567:INFO:Importing untrained model
2025-04-19 23:14:33,574:INFO:Extra Trees Classifier Imported successfully
2025-04-19 23:14:33,582:INFO:Starting cross validation
2025-04-19 23:14:33,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:14:42,119:INFO:Calculating mean and std
2025-04-19 23:14:42,120:INFO:Creating metrics dataframe
2025-04-19 23:14:43,099:INFO:Uploading results into container
2025-04-19 23:14:43,100:INFO:Uploading model into container now
2025-04-19 23:14:43,100:INFO:_master_model_container: 12
2025-04-19 23:14:43,100:INFO:_display_container: 2
2025-04-19 23:14:43,100:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1058, verbose=0, warm_start=False)
2025-04-19 23:14:43,100:INFO:create_model() successfully completed......................................
2025-04-19 23:14:43,243:INFO:SubProcess create_model() end ==================================
2025-04-19 23:14:43,243:INFO:Creating metrics dataframe
2025-04-19 23:14:43,255:INFO:Initializing Extreme Gradient Boosting
2025-04-19 23:14:43,255:INFO:Total runtime is 1.9652874588966367 minutes
2025-04-19 23:14:43,259:INFO:SubProcess create_model() called ==================================
2025-04-19 23:14:43,259:INFO:Initializing create_model()
2025-04-19 23:14:43,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:14:43,260:INFO:Checking exceptions
2025-04-19 23:14:43,260:INFO:Importing libraries
2025-04-19 23:14:43,260:INFO:Copying training dataset
2025-04-19 23:14:43,265:INFO:Defining folds
2025-04-19 23:14:43,265:INFO:Declaring metric variables
2025-04-19 23:14:43,269:INFO:Importing untrained model
2025-04-19 23:14:43,275:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 23:14:43,281:INFO:Starting cross validation
2025-04-19 23:14:43,284:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:14:53,696:INFO:Calculating mean and std
2025-04-19 23:14:53,697:INFO:Creating metrics dataframe
2025-04-19 23:14:54,678:INFO:Uploading results into container
2025-04-19 23:14:54,678:INFO:Uploading model into container now
2025-04-19 23:14:54,679:INFO:_master_model_container: 13
2025-04-19 23:14:54,679:INFO:_display_container: 2
2025-04-19 23:14:54,679:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 23:14:54,679:INFO:create_model() successfully completed......................................
2025-04-19 23:14:54,825:INFO:SubProcess create_model() end ==================================
2025-04-19 23:14:54,825:INFO:Creating metrics dataframe
2025-04-19 23:14:54,838:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 23:14:54,838:INFO:Total runtime is 2.158348802725474 minutes
2025-04-19 23:14:54,841:INFO:SubProcess create_model() called ==================================
2025-04-19 23:14:54,841:INFO:Initializing create_model()
2025-04-19 23:14:54,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:14:54,843:INFO:Checking exceptions
2025-04-19 23:14:54,843:INFO:Importing libraries
2025-04-19 23:14:54,843:INFO:Copying training dataset
2025-04-19 23:14:54,849:INFO:Defining folds
2025-04-19 23:14:54,849:INFO:Declaring metric variables
2025-04-19 23:14:54,853:INFO:Importing untrained model
2025-04-19 23:14:54,858:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 23:14:54,866:INFO:Starting cross validation
2025-04-19 23:14:54,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:15:05,222:INFO:Calculating mean and std
2025-04-19 23:15:05,224:INFO:Creating metrics dataframe
2025-04-19 23:15:06,238:INFO:Uploading results into container
2025-04-19 23:15:06,238:INFO:Uploading model into container now
2025-04-19 23:15:06,239:INFO:_master_model_container: 14
2025-04-19 23:15:06,239:INFO:_display_container: 2
2025-04-19 23:15:06,241:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1058, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 23:15:06,241:INFO:create_model() successfully completed......................................
2025-04-19 23:15:06,395:INFO:SubProcess create_model() end ==================================
2025-04-19 23:15:06,395:INFO:Creating metrics dataframe
2025-04-19 23:15:06,406:INFO:Initializing Dummy Classifier
2025-04-19 23:15:06,406:INFO:Total runtime is 2.3511387944221496 minutes
2025-04-19 23:15:06,410:INFO:SubProcess create_model() called ==================================
2025-04-19 23:15:06,410:INFO:Initializing create_model()
2025-04-19 23:15:06,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C137685C90>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:15:06,410:INFO:Checking exceptions
2025-04-19 23:15:06,410:INFO:Importing libraries
2025-04-19 23:15:06,410:INFO:Copying training dataset
2025-04-19 23:15:06,415:INFO:Defining folds
2025-04-19 23:15:06,416:INFO:Declaring metric variables
2025-04-19 23:15:06,418:INFO:Importing untrained model
2025-04-19 23:15:06,422:INFO:Dummy Classifier Imported successfully
2025-04-19 23:15:06,429:INFO:Starting cross validation
2025-04-19 23:15:06,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:15:06,947:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:06,981:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:06,995:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:07,011:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:07,024:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:07,025:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:07,090:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:07,091:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:07,119:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:07,133:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-19 23:15:14,719:INFO:Calculating mean and std
2025-04-19 23:15:14,721:INFO:Creating metrics dataframe
2025-04-19 23:15:15,752:INFO:Uploading results into container
2025-04-19 23:15:15,753:INFO:Uploading model into container now
2025-04-19 23:15:15,754:INFO:_master_model_container: 15
2025-04-19 23:15:15,754:INFO:_display_container: 2
2025-04-19 23:15:15,754:INFO:DummyClassifier(constant=None, random_state=1058, strategy='prior')
2025-04-19 23:15:15,754:INFO:create_model() successfully completed......................................
2025-04-19 23:15:15,913:INFO:SubProcess create_model() end ==================================
2025-04-19 23:15:15,914:INFO:Creating metrics dataframe
2025-04-19 23:15:15,933:INFO:Initializing create_model()
2025-04-19 23:15:15,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13835B7C0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:15:15,934:INFO:Checking exceptions
2025-04-19 23:15:15,936:INFO:Importing libraries
2025-04-19 23:15:15,936:INFO:Copying training dataset
2025-04-19 23:15:15,942:INFO:Defining folds
2025-04-19 23:15:15,942:INFO:Declaring metric variables
2025-04-19 23:15:15,942:INFO:Importing untrained model
2025-04-19 23:15:15,942:INFO:Declaring custom model
2025-04-19 23:15:15,943:INFO:Random Forest Classifier Imported successfully
2025-04-19 23:15:15,945:INFO:Cross validation set to False
2025-04-19 23:15:15,945:INFO:Fitting Model
2025-04-19 23:15:17,204:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 23:15:17,204:INFO:create_model() successfully completed......................................
2025-04-19 23:15:17,371:INFO:_master_model_container: 15
2025-04-19 23:15:17,371:INFO:_display_container: 2
2025-04-19 23:15:17,372:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1058, verbose=0, warm_start=False)
2025-04-19 23:15:17,372:INFO:compare_models() successfully completed......................................
2025-04-19 23:16:30,200:INFO:PyCaret ClassificationExperiment
2025-04-19 23:16:30,200:INFO:Logging name: clf-default-name
2025-04-19 23:16:30,200:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:16:30,200:INFO:version 3.0.4
2025-04-19 23:16:30,200:INFO:Initializing setup()
2025-04-19 23:16:30,200:INFO:self.USI: b29f
2025-04-19 23:16:30,200:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:16:30,200:INFO:Checking environment
2025-04-19 23:16:30,200:INFO:python_version: 3.10.5
2025-04-19 23:16:30,200:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:16:30,200:INFO:machine: AMD64
2025-04-19 23:16:30,200:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:16:30,205:INFO:Memory: svmem(total=25042907136, available=9999224832, percent=60.1, used=15043682304, free=9999224832)
2025-04-19 23:16:30,205:INFO:Physical Core: 6
2025-04-19 23:16:30,207:INFO:Logical Core: 12
2025-04-19 23:16:30,207:INFO:Checking libraries
2025-04-19 23:16:30,207:INFO:System:
2025-04-19 23:16:30,207:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:16:30,207:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:16:30,207:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:16:30,207:INFO:PyCaret required dependencies:
2025-04-19 23:16:30,207:INFO:                 pip: 25.0.1
2025-04-19 23:16:30,207:INFO:          setuptools: 58.1.0
2025-04-19 23:16:30,207:INFO:             pycaret: 3.0.4
2025-04-19 23:16:30,207:INFO:             IPython: 8.29.0
2025-04-19 23:16:30,207:INFO:          ipywidgets: 8.1.6
2025-04-19 23:16:30,207:INFO:                tqdm: 4.67.1
2025-04-19 23:16:30,207:INFO:               numpy: 1.23.5
2025-04-19 23:16:30,207:INFO:              pandas: 1.5.3
2025-04-19 23:16:30,207:INFO:              jinja2: 3.1.4
2025-04-19 23:16:30,207:INFO:               scipy: 1.11.4
2025-04-19 23:16:30,207:INFO:              joblib: 1.3.2
2025-04-19 23:16:30,207:INFO:             sklearn: 1.2.2
2025-04-19 23:16:30,207:INFO:                pyod: 2.0.4
2025-04-19 23:16:30,207:INFO:            imblearn: 0.10.1
2025-04-19 23:16:30,207:INFO:   category_encoders: 2.7.0
2025-04-19 23:16:30,207:INFO:            lightgbm: 4.6.0
2025-04-19 23:16:30,207:INFO:               numba: 0.60.0
2025-04-19 23:16:30,207:INFO:            requests: 2.32.3
2025-04-19 23:16:30,207:INFO:          matplotlib: 3.7.5
2025-04-19 23:16:30,207:INFO:          scikitplot: 0.3.7
2025-04-19 23:16:30,207:INFO:         yellowbrick: 1.5
2025-04-19 23:16:30,207:INFO:              plotly: 5.24.1
2025-04-19 23:16:30,207:INFO:    plotly-resampler: Not installed
2025-04-19 23:16:30,207:INFO:             kaleido: 0.2.1
2025-04-19 23:16:30,207:INFO:           schemdraw: 0.15
2025-04-19 23:16:30,207:INFO:         statsmodels: 0.14.4
2025-04-19 23:16:30,208:INFO:              sktime: 0.26.0
2025-04-19 23:16:30,208:INFO:               tbats: 1.1.3
2025-04-19 23:16:30,208:INFO:            pmdarima: 2.0.4
2025-04-19 23:16:30,208:INFO:              psutil: 6.1.0
2025-04-19 23:16:30,208:INFO:          markupsafe: 3.0.2
2025-04-19 23:16:30,208:INFO:             pickle5: Not installed
2025-04-19 23:16:30,208:INFO:         cloudpickle: 3.1.1
2025-04-19 23:16:30,208:INFO:         deprecation: 2.1.0
2025-04-19 23:16:30,208:INFO:              xxhash: 3.5.0
2025-04-19 23:16:30,208:INFO:           wurlitzer: Not installed
2025-04-19 23:16:30,208:INFO:PyCaret optional dependencies:
2025-04-19 23:16:30,208:INFO:                shap: Not installed
2025-04-19 23:16:30,208:INFO:           interpret: Not installed
2025-04-19 23:16:30,208:INFO:                umap: Not installed
2025-04-19 23:16:30,208:INFO:    pandas_profiling: Not installed
2025-04-19 23:16:30,208:INFO:  explainerdashboard: Not installed
2025-04-19 23:16:30,208:INFO:             autoviz: Not installed
2025-04-19 23:16:30,208:INFO:           fairlearn: Not installed
2025-04-19 23:16:30,208:INFO:          deepchecks: Not installed
2025-04-19 23:16:30,208:INFO:             xgboost: 1.7.6
2025-04-19 23:16:30,209:INFO:            catboost: Not installed
2025-04-19 23:16:30,209:INFO:              kmodes: Not installed
2025-04-19 23:16:30,209:INFO:             mlxtend: Not installed
2025-04-19 23:16:30,209:INFO:       statsforecast: Not installed
2025-04-19 23:16:30,209:INFO:        tune_sklearn: Not installed
2025-04-19 23:16:30,209:INFO:                 ray: Not installed
2025-04-19 23:16:30,209:INFO:            hyperopt: Not installed
2025-04-19 23:16:30,209:INFO:              optuna: Not installed
2025-04-19 23:16:30,209:INFO:               skopt: Not installed
2025-04-19 23:16:30,209:INFO:              mlflow: Not installed
2025-04-19 23:16:30,209:INFO:              gradio: Not installed
2025-04-19 23:16:30,209:INFO:             fastapi: Not installed
2025-04-19 23:16:30,209:INFO:             uvicorn: Not installed
2025-04-19 23:16:30,209:INFO:              m2cgen: Not installed
2025-04-19 23:16:30,209:INFO:           evidently: Not installed
2025-04-19 23:16:30,209:INFO:               fugue: Not installed
2025-04-19 23:16:30,209:INFO:           streamlit: 1.42.0
2025-04-19 23:16:30,209:INFO:             prophet: Not installed
2025-04-19 23:16:30,209:INFO:None
2025-04-19 23:16:30,209:INFO:Set up data.
2025-04-19 23:16:30,221:INFO:Set up train/test split.
2025-04-19 23:16:30,226:INFO:Set up index.
2025-04-19 23:16:30,226:INFO:Set up folding strategy.
2025-04-19 23:16:30,228:INFO:Assigning column types.
2025-04-19 23:16:30,230:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:16:30,271:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:16:30,271:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:16:30,299:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:16:30,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:16:30,341:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:16:30,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:16:30,368:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:16:30,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:16:30,371:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:16:30,413:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:16:30,439:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:16:30,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:16:30,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:16:30,509:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:16:30,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:16:30,512:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:16:30,578:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:16:30,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:16:30,648:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:16:30,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:16:30,652:INFO:Preparing preprocessing pipeline...
2025-04-19 23:16:30,653:INFO:Set up simple imputation.
2025-04-19 23:16:30,655:INFO:Set up encoding of ordinal features.
2025-04-19 23:16:30,658:INFO:Set up encoding of categorical features.
2025-04-19 23:16:30,658:INFO:Set up removing multicollinearity.
2025-04-19 23:16:30,658:INFO:Set up imbalanced handling.
2025-04-19 23:16:30,658:INFO:Set up feature normalization.
2025-04-19 23:16:30,658:INFO:Set up feature selection.
2025-04-19 23:16:30,724:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:16:30,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:16:30,917:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:16:30,969:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompan...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 23:16:30,969:INFO:Creating final display dataframe.
2025-04-19 23:18:51,202:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_25512\4061920633.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  df_model.drop('EmployeeCount','Over18','StandardHours')

2025-04-19 23:21:00,212:INFO:PyCaret ClassificationExperiment
2025-04-19 23:21:00,212:INFO:Logging name: clf-default-name
2025-04-19 23:21:00,212:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:21:00,212:INFO:version 3.0.4
2025-04-19 23:21:00,212:INFO:Initializing setup()
2025-04-19 23:21:00,212:INFO:self.USI: 2502
2025-04-19 23:21:00,212:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:21:00,212:INFO:Checking environment
2025-04-19 23:21:00,212:INFO:python_version: 3.10.5
2025-04-19 23:21:00,212:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:21:00,212:INFO:machine: AMD64
2025-04-19 23:21:00,212:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:21:00,218:INFO:Memory: svmem(total=25042907136, available=14533603328, percent=42.0, used=10509303808, free=14533603328)
2025-04-19 23:21:00,219:INFO:Physical Core: 6
2025-04-19 23:21:00,219:INFO:Logical Core: 12
2025-04-19 23:21:00,219:INFO:Checking libraries
2025-04-19 23:21:00,219:INFO:System:
2025-04-19 23:21:00,219:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:21:00,219:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:21:00,219:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:21:00,219:INFO:PyCaret required dependencies:
2025-04-19 23:21:00,219:INFO:                 pip: 25.0.1
2025-04-19 23:21:00,219:INFO:          setuptools: 58.1.0
2025-04-19 23:21:00,219:INFO:             pycaret: 3.0.4
2025-04-19 23:21:00,219:INFO:             IPython: 8.29.0
2025-04-19 23:21:00,219:INFO:          ipywidgets: 8.1.6
2025-04-19 23:21:00,219:INFO:                tqdm: 4.67.1
2025-04-19 23:21:00,219:INFO:               numpy: 1.23.5
2025-04-19 23:21:00,219:INFO:              pandas: 1.5.3
2025-04-19 23:21:00,219:INFO:              jinja2: 3.1.4
2025-04-19 23:21:00,219:INFO:               scipy: 1.11.4
2025-04-19 23:21:00,219:INFO:              joblib: 1.3.2
2025-04-19 23:21:00,219:INFO:             sklearn: 1.2.2
2025-04-19 23:21:00,219:INFO:                pyod: 2.0.4
2025-04-19 23:21:00,219:INFO:            imblearn: 0.10.1
2025-04-19 23:21:00,219:INFO:   category_encoders: 2.7.0
2025-04-19 23:21:00,219:INFO:            lightgbm: 4.6.0
2025-04-19 23:21:00,219:INFO:               numba: 0.60.0
2025-04-19 23:21:00,220:INFO:            requests: 2.32.3
2025-04-19 23:21:00,220:INFO:          matplotlib: 3.7.5
2025-04-19 23:21:00,220:INFO:          scikitplot: 0.3.7
2025-04-19 23:21:00,220:INFO:         yellowbrick: 1.5
2025-04-19 23:21:00,220:INFO:              plotly: 5.24.1
2025-04-19 23:21:00,220:INFO:    plotly-resampler: Not installed
2025-04-19 23:21:00,220:INFO:             kaleido: 0.2.1
2025-04-19 23:21:00,220:INFO:           schemdraw: 0.15
2025-04-19 23:21:00,220:INFO:         statsmodels: 0.14.4
2025-04-19 23:21:00,220:INFO:              sktime: 0.26.0
2025-04-19 23:21:00,220:INFO:               tbats: 1.1.3
2025-04-19 23:21:00,220:INFO:            pmdarima: 2.0.4
2025-04-19 23:21:00,220:INFO:              psutil: 6.1.0
2025-04-19 23:21:00,220:INFO:          markupsafe: 3.0.2
2025-04-19 23:21:00,220:INFO:             pickle5: Not installed
2025-04-19 23:21:00,220:INFO:         cloudpickle: 3.1.1
2025-04-19 23:21:00,220:INFO:         deprecation: 2.1.0
2025-04-19 23:21:00,220:INFO:              xxhash: 3.5.0
2025-04-19 23:21:00,220:INFO:           wurlitzer: Not installed
2025-04-19 23:21:00,220:INFO:PyCaret optional dependencies:
2025-04-19 23:21:00,220:INFO:                shap: Not installed
2025-04-19 23:21:00,220:INFO:           interpret: Not installed
2025-04-19 23:21:00,220:INFO:                umap: Not installed
2025-04-19 23:21:00,220:INFO:    pandas_profiling: Not installed
2025-04-19 23:21:00,221:INFO:  explainerdashboard: Not installed
2025-04-19 23:21:00,221:INFO:             autoviz: Not installed
2025-04-19 23:21:00,221:INFO:           fairlearn: Not installed
2025-04-19 23:21:00,221:INFO:          deepchecks: Not installed
2025-04-19 23:21:00,221:INFO:             xgboost: 1.7.6
2025-04-19 23:21:00,221:INFO:            catboost: Not installed
2025-04-19 23:21:00,221:INFO:              kmodes: Not installed
2025-04-19 23:21:00,221:INFO:             mlxtend: Not installed
2025-04-19 23:21:00,221:INFO:       statsforecast: Not installed
2025-04-19 23:21:00,221:INFO:        tune_sklearn: Not installed
2025-04-19 23:21:00,221:INFO:                 ray: Not installed
2025-04-19 23:21:00,221:INFO:            hyperopt: Not installed
2025-04-19 23:21:00,221:INFO:              optuna: Not installed
2025-04-19 23:21:00,222:INFO:               skopt: Not installed
2025-04-19 23:21:00,222:INFO:              mlflow: Not installed
2025-04-19 23:21:00,222:INFO:              gradio: Not installed
2025-04-19 23:21:00,222:INFO:             fastapi: Not installed
2025-04-19 23:21:00,222:INFO:             uvicorn: Not installed
2025-04-19 23:21:00,222:INFO:              m2cgen: Not installed
2025-04-19 23:21:00,222:INFO:           evidently: Not installed
2025-04-19 23:21:00,222:INFO:               fugue: Not installed
2025-04-19 23:21:00,222:INFO:           streamlit: 1.42.0
2025-04-19 23:21:00,222:INFO:             prophet: Not installed
2025-04-19 23:21:00,222:INFO:None
2025-04-19 23:21:00,222:INFO:Set up data.
2025-04-19 23:21:00,232:INFO:Set up train/test split.
2025-04-19 23:21:00,237:INFO:Set up index.
2025-04-19 23:21:00,238:INFO:Set up folding strategy.
2025-04-19 23:21:00,238:INFO:Assigning column types.
2025-04-19 23:21:00,240:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:21:00,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:21:00,281:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:21:00,306:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:21:00,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:21:00,348:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:21:00,348:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:21:00,376:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:21:00,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:21:00,378:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:21:00,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:21:00,444:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:21:00,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:21:00,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:21:00,513:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:21:00,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:21:00,516:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:21:00,580:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:21:00,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:21:00,647:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:21:00,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:21:00,651:INFO:Preparing preprocessing pipeline...
2025-04-19 23:21:00,652:INFO:Set up simple imputation.
2025-04-19 23:21:00,656:INFO:Set up encoding of ordinal features.
2025-04-19 23:21:00,658:INFO:Set up encoding of categorical features.
2025-04-19 23:21:00,658:INFO:Set up removing multicollinearity.
2025-04-19 23:21:00,658:INFO:Set up imbalanced handling.
2025-04-19 23:21:00,658:INFO:Set up feature normalization.
2025-04-19 23:21:00,658:INFO:Set up feature selection.
2025-04-19 23:21:00,725:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:21:00,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:21:01,104:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:21:01,152:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'Perc...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 23:21:01,152:INFO:Creating final display dataframe.
2025-04-19 23:23:24,796:INFO:PyCaret ClassificationExperiment
2025-04-19 23:23:24,796:INFO:Logging name: clf-default-name
2025-04-19 23:23:24,796:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:23:24,797:INFO:version 3.0.4
2025-04-19 23:23:24,797:INFO:Initializing setup()
2025-04-19 23:23:24,797:INFO:self.USI: 5cf4
2025-04-19 23:23:24,797:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:23:24,797:INFO:Checking environment
2025-04-19 23:23:24,797:INFO:python_version: 3.10.5
2025-04-19 23:23:24,797:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:23:24,797:INFO:machine: AMD64
2025-04-19 23:23:24,797:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:23:24,803:INFO:Memory: svmem(total=25042907136, available=14301593600, percent=42.9, used=10741313536, free=14301593600)
2025-04-19 23:23:24,803:INFO:Physical Core: 6
2025-04-19 23:23:24,803:INFO:Logical Core: 12
2025-04-19 23:23:24,803:INFO:Checking libraries
2025-04-19 23:23:24,803:INFO:System:
2025-04-19 23:23:24,803:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:23:24,803:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:23:24,803:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:23:24,803:INFO:PyCaret required dependencies:
2025-04-19 23:23:24,803:INFO:                 pip: 25.0.1
2025-04-19 23:23:24,803:INFO:          setuptools: 58.1.0
2025-04-19 23:23:24,803:INFO:             pycaret: 3.0.4
2025-04-19 23:23:24,803:INFO:             IPython: 8.29.0
2025-04-19 23:23:24,803:INFO:          ipywidgets: 8.1.6
2025-04-19 23:23:24,803:INFO:                tqdm: 4.67.1
2025-04-19 23:23:24,803:INFO:               numpy: 1.23.5
2025-04-19 23:23:24,803:INFO:              pandas: 1.5.3
2025-04-19 23:23:24,803:INFO:              jinja2: 3.1.4
2025-04-19 23:23:24,804:INFO:               scipy: 1.11.4
2025-04-19 23:23:24,804:INFO:              joblib: 1.3.2
2025-04-19 23:23:24,804:INFO:             sklearn: 1.2.2
2025-04-19 23:23:24,804:INFO:                pyod: 2.0.4
2025-04-19 23:23:24,804:INFO:            imblearn: 0.10.1
2025-04-19 23:23:24,804:INFO:   category_encoders: 2.7.0
2025-04-19 23:23:24,804:INFO:            lightgbm: 4.6.0
2025-04-19 23:23:24,804:INFO:               numba: 0.60.0
2025-04-19 23:23:24,804:INFO:            requests: 2.32.3
2025-04-19 23:23:24,804:INFO:          matplotlib: 3.7.5
2025-04-19 23:23:24,804:INFO:          scikitplot: 0.3.7
2025-04-19 23:23:24,804:INFO:         yellowbrick: 1.5
2025-04-19 23:23:24,804:INFO:              plotly: 5.24.1
2025-04-19 23:23:24,804:INFO:    plotly-resampler: Not installed
2025-04-19 23:23:24,804:INFO:             kaleido: 0.2.1
2025-04-19 23:23:24,804:INFO:           schemdraw: 0.15
2025-04-19 23:23:24,804:INFO:         statsmodels: 0.14.4
2025-04-19 23:23:24,804:INFO:              sktime: 0.26.0
2025-04-19 23:23:24,804:INFO:               tbats: 1.1.3
2025-04-19 23:23:24,804:INFO:            pmdarima: 2.0.4
2025-04-19 23:23:24,804:INFO:              psutil: 6.1.0
2025-04-19 23:23:24,804:INFO:          markupsafe: 3.0.2
2025-04-19 23:23:24,804:INFO:             pickle5: Not installed
2025-04-19 23:23:24,804:INFO:         cloudpickle: 3.1.1
2025-04-19 23:23:24,804:INFO:         deprecation: 2.1.0
2025-04-19 23:23:24,804:INFO:              xxhash: 3.5.0
2025-04-19 23:23:24,805:INFO:           wurlitzer: Not installed
2025-04-19 23:23:24,805:INFO:PyCaret optional dependencies:
2025-04-19 23:23:24,805:INFO:                shap: Not installed
2025-04-19 23:23:24,805:INFO:           interpret: Not installed
2025-04-19 23:23:24,805:INFO:                umap: Not installed
2025-04-19 23:23:24,805:INFO:    pandas_profiling: Not installed
2025-04-19 23:23:24,805:INFO:  explainerdashboard: Not installed
2025-04-19 23:23:24,805:INFO:             autoviz: Not installed
2025-04-19 23:23:24,805:INFO:           fairlearn: Not installed
2025-04-19 23:23:24,805:INFO:          deepchecks: Not installed
2025-04-19 23:23:24,805:INFO:             xgboost: 1.7.6
2025-04-19 23:23:24,805:INFO:            catboost: Not installed
2025-04-19 23:23:24,805:INFO:              kmodes: Not installed
2025-04-19 23:23:24,805:INFO:             mlxtend: Not installed
2025-04-19 23:23:24,805:INFO:       statsforecast: Not installed
2025-04-19 23:23:24,805:INFO:        tune_sklearn: Not installed
2025-04-19 23:23:24,805:INFO:                 ray: Not installed
2025-04-19 23:23:24,805:INFO:            hyperopt: Not installed
2025-04-19 23:23:24,805:INFO:              optuna: Not installed
2025-04-19 23:23:24,805:INFO:               skopt: Not installed
2025-04-19 23:23:24,805:INFO:              mlflow: Not installed
2025-04-19 23:23:24,805:INFO:              gradio: Not installed
2025-04-19 23:23:24,805:INFO:             fastapi: Not installed
2025-04-19 23:23:24,805:INFO:             uvicorn: Not installed
2025-04-19 23:23:24,805:INFO:              m2cgen: Not installed
2025-04-19 23:23:24,805:INFO:           evidently: Not installed
2025-04-19 23:23:24,805:INFO:               fugue: Not installed
2025-04-19 23:23:24,805:INFO:           streamlit: 1.42.0
2025-04-19 23:23:24,806:INFO:             prophet: Not installed
2025-04-19 23:23:24,806:INFO:None
2025-04-19 23:23:24,806:INFO:Set up data.
2025-04-19 23:23:24,817:INFO:Set up train/test split.
2025-04-19 23:23:24,821:INFO:Set up index.
2025-04-19 23:23:24,821:INFO:Set up folding strategy.
2025-04-19 23:23:24,821:INFO:Assigning column types.
2025-04-19 23:23:24,825:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:23:24,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:23:24,867:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:23:24,894:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:24,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:24,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:23:24,938:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:23:24,964:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:24,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:24,967:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:23:25,008:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:23:25,040:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:25,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:25,095:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:23:25,124:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:25,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:25,127:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:23:25,194:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:25,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:25,262:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:25,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:25,265:INFO:Preparing preprocessing pipeline...
2025-04-19 23:23:25,266:INFO:Set up simple imputation.
2025-04-19 23:23:25,269:INFO:Set up encoding of ordinal features.
2025-04-19 23:23:25,272:INFO:Set up encoding of categorical features.
2025-04-19 23:23:25,272:INFO:Set up removing multicollinearity.
2025-04-19 23:23:25,272:INFO:Set up imbalanced handling.
2025-04-19 23:23:25,272:INFO:Set up feature selection.
2025-04-19 23:23:25,337:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:25,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:25,687:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:23:25,733:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'Perc...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 23:23:25,733:INFO:Creating final display dataframe.
2025-04-19 23:23:44,922:INFO:PyCaret ClassificationExperiment
2025-04-19 23:23:44,922:INFO:Logging name: clf-default-name
2025-04-19 23:23:44,922:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:23:44,922:INFO:version 3.0.4
2025-04-19 23:23:44,923:INFO:Initializing setup()
2025-04-19 23:23:44,923:INFO:self.USI: f97b
2025-04-19 23:23:44,923:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:23:44,923:INFO:Checking environment
2025-04-19 23:23:44,923:INFO:python_version: 3.10.5
2025-04-19 23:23:44,923:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:23:44,923:INFO:machine: AMD64
2025-04-19 23:23:44,923:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:23:44,929:INFO:Memory: svmem(total=25042907136, available=14291025920, percent=42.9, used=10751881216, free=14291025920)
2025-04-19 23:23:44,929:INFO:Physical Core: 6
2025-04-19 23:23:44,929:INFO:Logical Core: 12
2025-04-19 23:23:44,929:INFO:Checking libraries
2025-04-19 23:23:44,929:INFO:System:
2025-04-19 23:23:44,929:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:23:44,929:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:23:44,929:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:23:44,929:INFO:PyCaret required dependencies:
2025-04-19 23:23:44,929:INFO:                 pip: 25.0.1
2025-04-19 23:23:44,929:INFO:          setuptools: 58.1.0
2025-04-19 23:23:44,929:INFO:             pycaret: 3.0.4
2025-04-19 23:23:44,929:INFO:             IPython: 8.29.0
2025-04-19 23:23:44,929:INFO:          ipywidgets: 8.1.6
2025-04-19 23:23:44,929:INFO:                tqdm: 4.67.1
2025-04-19 23:23:44,930:INFO:               numpy: 1.23.5
2025-04-19 23:23:44,930:INFO:              pandas: 1.5.3
2025-04-19 23:23:44,930:INFO:              jinja2: 3.1.4
2025-04-19 23:23:44,930:INFO:               scipy: 1.11.4
2025-04-19 23:23:44,930:INFO:              joblib: 1.3.2
2025-04-19 23:23:44,930:INFO:             sklearn: 1.2.2
2025-04-19 23:23:44,930:INFO:                pyod: 2.0.4
2025-04-19 23:23:44,930:INFO:            imblearn: 0.10.1
2025-04-19 23:23:44,930:INFO:   category_encoders: 2.7.0
2025-04-19 23:23:44,930:INFO:            lightgbm: 4.6.0
2025-04-19 23:23:44,930:INFO:               numba: 0.60.0
2025-04-19 23:23:44,930:INFO:            requests: 2.32.3
2025-04-19 23:23:44,930:INFO:          matplotlib: 3.7.5
2025-04-19 23:23:44,930:INFO:          scikitplot: 0.3.7
2025-04-19 23:23:44,930:INFO:         yellowbrick: 1.5
2025-04-19 23:23:44,930:INFO:              plotly: 5.24.1
2025-04-19 23:23:44,930:INFO:    plotly-resampler: Not installed
2025-04-19 23:23:44,930:INFO:             kaleido: 0.2.1
2025-04-19 23:23:44,930:INFO:           schemdraw: 0.15
2025-04-19 23:23:44,930:INFO:         statsmodels: 0.14.4
2025-04-19 23:23:44,930:INFO:              sktime: 0.26.0
2025-04-19 23:23:44,930:INFO:               tbats: 1.1.3
2025-04-19 23:23:44,930:INFO:            pmdarima: 2.0.4
2025-04-19 23:23:44,930:INFO:              psutil: 6.1.0
2025-04-19 23:23:44,930:INFO:          markupsafe: 3.0.2
2025-04-19 23:23:44,930:INFO:             pickle5: Not installed
2025-04-19 23:23:44,930:INFO:         cloudpickle: 3.1.1
2025-04-19 23:23:44,930:INFO:         deprecation: 2.1.0
2025-04-19 23:23:44,930:INFO:              xxhash: 3.5.0
2025-04-19 23:23:44,931:INFO:           wurlitzer: Not installed
2025-04-19 23:23:44,931:INFO:PyCaret optional dependencies:
2025-04-19 23:23:44,931:INFO:                shap: Not installed
2025-04-19 23:23:44,931:INFO:           interpret: Not installed
2025-04-19 23:23:44,931:INFO:                umap: Not installed
2025-04-19 23:23:44,931:INFO:    pandas_profiling: Not installed
2025-04-19 23:23:44,931:INFO:  explainerdashboard: Not installed
2025-04-19 23:23:44,931:INFO:             autoviz: Not installed
2025-04-19 23:23:44,931:INFO:           fairlearn: Not installed
2025-04-19 23:23:44,931:INFO:          deepchecks: Not installed
2025-04-19 23:23:44,931:INFO:             xgboost: 1.7.6
2025-04-19 23:23:44,931:INFO:            catboost: Not installed
2025-04-19 23:23:44,931:INFO:              kmodes: Not installed
2025-04-19 23:23:44,931:INFO:             mlxtend: Not installed
2025-04-19 23:23:44,931:INFO:       statsforecast: Not installed
2025-04-19 23:23:44,931:INFO:        tune_sklearn: Not installed
2025-04-19 23:23:44,931:INFO:                 ray: Not installed
2025-04-19 23:23:44,931:INFO:            hyperopt: Not installed
2025-04-19 23:23:44,931:INFO:              optuna: Not installed
2025-04-19 23:23:44,931:INFO:               skopt: Not installed
2025-04-19 23:23:44,931:INFO:              mlflow: Not installed
2025-04-19 23:23:44,931:INFO:              gradio: Not installed
2025-04-19 23:23:44,931:INFO:             fastapi: Not installed
2025-04-19 23:23:44,931:INFO:             uvicorn: Not installed
2025-04-19 23:23:44,931:INFO:              m2cgen: Not installed
2025-04-19 23:23:44,931:INFO:           evidently: Not installed
2025-04-19 23:23:44,931:INFO:               fugue: Not installed
2025-04-19 23:23:44,931:INFO:           streamlit: 1.42.0
2025-04-19 23:23:44,931:INFO:             prophet: Not installed
2025-04-19 23:23:44,931:INFO:None
2025-04-19 23:23:44,931:INFO:Set up data.
2025-04-19 23:23:44,943:INFO:Set up train/test split.
2025-04-19 23:23:44,949:INFO:Set up index.
2025-04-19 23:23:44,949:INFO:Set up folding strategy.
2025-04-19 23:23:44,949:INFO:Assigning column types.
2025-04-19 23:23:44,952:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:23:44,995:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:23:44,996:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:23:45,023:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:45,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:45,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:23:45,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:23:45,100:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:45,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:45,103:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:23:45,148:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:23:45,174:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:45,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:45,216:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:23:45,241:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:45,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:45,244:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:23:45,308:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:45,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:45,380:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:45,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:45,383:INFO:Preparing preprocessing pipeline...
2025-04-19 23:23:45,383:INFO:Set up simple imputation.
2025-04-19 23:23:45,387:INFO:Set up encoding of ordinal features.
2025-04-19 23:23:45,389:INFO:Set up encoding of categorical features.
2025-04-19 23:23:45,389:INFO:Set up removing multicollinearity.
2025-04-19 23:23:45,389:INFO:Set up imbalanced handling.
2025-04-19 23:23:45,389:INFO:Set up feature selection.
2025-04-19 23:23:45,457:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:23:45,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:23:45,622:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:23:45,673:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'Perc...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 23:23:45,673:INFO:Creating final display dataframe.
2025-04-19 23:25:24,579:INFO:PyCaret ClassificationExperiment
2025-04-19 23:25:24,579:INFO:Logging name: clf-default-name
2025-04-19 23:25:24,579:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:25:24,579:INFO:version 3.0.4
2025-04-19 23:25:24,579:INFO:Initializing setup()
2025-04-19 23:25:24,579:INFO:self.USI: 45ba
2025-04-19 23:25:24,579:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:25:24,579:INFO:Checking environment
2025-04-19 23:25:24,579:INFO:python_version: 3.10.5
2025-04-19 23:25:24,579:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:25:24,580:INFO:machine: AMD64
2025-04-19 23:25:24,580:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:25:24,585:INFO:Memory: svmem(total=25042907136, available=14133452800, percent=43.6, used=10909454336, free=14133452800)
2025-04-19 23:25:24,586:INFO:Physical Core: 6
2025-04-19 23:25:24,586:INFO:Logical Core: 12
2025-04-19 23:25:24,586:INFO:Checking libraries
2025-04-19 23:25:24,586:INFO:System:
2025-04-19 23:25:24,586:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:25:24,586:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:25:24,586:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:25:24,586:INFO:PyCaret required dependencies:
2025-04-19 23:25:24,586:INFO:                 pip: 25.0.1
2025-04-19 23:25:24,586:INFO:          setuptools: 58.1.0
2025-04-19 23:25:24,586:INFO:             pycaret: 3.0.4
2025-04-19 23:25:24,586:INFO:             IPython: 8.29.0
2025-04-19 23:25:24,586:INFO:          ipywidgets: 8.1.6
2025-04-19 23:25:24,586:INFO:                tqdm: 4.67.1
2025-04-19 23:25:24,586:INFO:               numpy: 1.23.5
2025-04-19 23:25:24,586:INFO:              pandas: 1.5.3
2025-04-19 23:25:24,586:INFO:              jinja2: 3.1.4
2025-04-19 23:25:24,586:INFO:               scipy: 1.11.4
2025-04-19 23:25:24,586:INFO:              joblib: 1.3.2
2025-04-19 23:25:24,586:INFO:             sklearn: 1.2.2
2025-04-19 23:25:24,586:INFO:                pyod: 2.0.4
2025-04-19 23:25:24,586:INFO:            imblearn: 0.10.1
2025-04-19 23:25:24,586:INFO:   category_encoders: 2.7.0
2025-04-19 23:25:24,587:INFO:            lightgbm: 4.6.0
2025-04-19 23:25:24,587:INFO:               numba: 0.60.0
2025-04-19 23:25:24,587:INFO:            requests: 2.32.3
2025-04-19 23:25:24,587:INFO:          matplotlib: 3.7.5
2025-04-19 23:25:24,587:INFO:          scikitplot: 0.3.7
2025-04-19 23:25:24,587:INFO:         yellowbrick: 1.5
2025-04-19 23:25:24,587:INFO:              plotly: 5.24.1
2025-04-19 23:25:24,587:INFO:    plotly-resampler: Not installed
2025-04-19 23:25:24,587:INFO:             kaleido: 0.2.1
2025-04-19 23:25:24,587:INFO:           schemdraw: 0.15
2025-04-19 23:25:24,587:INFO:         statsmodels: 0.14.4
2025-04-19 23:25:24,587:INFO:              sktime: 0.26.0
2025-04-19 23:25:24,587:INFO:               tbats: 1.1.3
2025-04-19 23:25:24,587:INFO:            pmdarima: 2.0.4
2025-04-19 23:25:24,587:INFO:              psutil: 6.1.0
2025-04-19 23:25:24,587:INFO:          markupsafe: 3.0.2
2025-04-19 23:25:24,587:INFO:             pickle5: Not installed
2025-04-19 23:25:24,587:INFO:         cloudpickle: 3.1.1
2025-04-19 23:25:24,587:INFO:         deprecation: 2.1.0
2025-04-19 23:25:24,587:INFO:              xxhash: 3.5.0
2025-04-19 23:25:24,587:INFO:           wurlitzer: Not installed
2025-04-19 23:25:24,587:INFO:PyCaret optional dependencies:
2025-04-19 23:25:24,587:INFO:                shap: Not installed
2025-04-19 23:25:24,588:INFO:           interpret: Not installed
2025-04-19 23:25:24,588:INFO:                umap: Not installed
2025-04-19 23:25:24,588:INFO:    pandas_profiling: Not installed
2025-04-19 23:25:24,588:INFO:  explainerdashboard: Not installed
2025-04-19 23:25:24,588:INFO:             autoviz: Not installed
2025-04-19 23:25:24,588:INFO:           fairlearn: Not installed
2025-04-19 23:25:24,588:INFO:          deepchecks: Not installed
2025-04-19 23:25:24,588:INFO:             xgboost: 1.7.6
2025-04-19 23:25:24,588:INFO:            catboost: Not installed
2025-04-19 23:25:24,588:INFO:              kmodes: Not installed
2025-04-19 23:25:24,588:INFO:             mlxtend: Not installed
2025-04-19 23:25:24,588:INFO:       statsforecast: Not installed
2025-04-19 23:25:24,588:INFO:        tune_sklearn: Not installed
2025-04-19 23:25:24,588:INFO:                 ray: Not installed
2025-04-19 23:25:24,588:INFO:            hyperopt: Not installed
2025-04-19 23:25:24,588:INFO:              optuna: Not installed
2025-04-19 23:25:24,588:INFO:               skopt: Not installed
2025-04-19 23:25:24,588:INFO:              mlflow: Not installed
2025-04-19 23:25:24,588:INFO:              gradio: Not installed
2025-04-19 23:25:24,588:INFO:             fastapi: Not installed
2025-04-19 23:25:24,589:INFO:             uvicorn: Not installed
2025-04-19 23:25:24,589:INFO:              m2cgen: Not installed
2025-04-19 23:25:24,589:INFO:           evidently: Not installed
2025-04-19 23:25:24,589:INFO:               fugue: Not installed
2025-04-19 23:25:24,589:INFO:           streamlit: 1.42.0
2025-04-19 23:25:24,589:INFO:             prophet: Not installed
2025-04-19 23:25:24,589:INFO:None
2025-04-19 23:25:24,589:INFO:Set up data.
2025-04-19 23:25:24,600:INFO:Set up train/test split.
2025-04-19 23:25:24,606:INFO:Set up index.
2025-04-19 23:25:24,606:INFO:Set up folding strategy.
2025-04-19 23:25:24,606:INFO:Assigning column types.
2025-04-19 23:25:24,609:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:25:24,652:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:25:24,652:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:25:24,677:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:24,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:24,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:25:24,723:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:25:24,750:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:24,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:24,752:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:25:24,800:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:25:24,828:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:24,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:24,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:25:24,901:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:24,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:24,905:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:25:24,976:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:24,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:25,049:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:25,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:25,053:INFO:Preparing preprocessing pipeline...
2025-04-19 23:25:25,054:INFO:Set up simple imputation.
2025-04-19 23:25:25,057:INFO:Set up encoding of ordinal features.
2025-04-19 23:25:25,059:INFO:Set up encoding of categorical features.
2025-04-19 23:25:25,059:INFO:Set up imbalanced handling.
2025-04-19 23:25:25,059:INFO:Set up feature selection.
2025-04-19 23:25:25,126:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:25,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:25,477:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:25:25,523:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'Perc...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 23:25:25,523:INFO:Creating final display dataframe.
2025-04-19 23:25:33,079:INFO:PyCaret ClassificationExperiment
2025-04-19 23:25:33,079:INFO:Logging name: clf-default-name
2025-04-19 23:25:33,079:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:25:33,079:INFO:version 3.0.4
2025-04-19 23:25:33,079:INFO:Initializing setup()
2025-04-19 23:25:33,080:INFO:self.USI: 6f8c
2025-04-19 23:25:33,080:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:25:33,080:INFO:Checking environment
2025-04-19 23:25:33,080:INFO:python_version: 3.10.5
2025-04-19 23:25:33,080:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:25:33,080:INFO:machine: AMD64
2025-04-19 23:25:33,080:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:25:33,090:INFO:Memory: svmem(total=25042907136, available=14129496064, percent=43.6, used=10913411072, free=14129496064)
2025-04-19 23:25:33,090:INFO:Physical Core: 6
2025-04-19 23:25:33,090:INFO:Logical Core: 12
2025-04-19 23:25:33,090:INFO:Checking libraries
2025-04-19 23:25:33,090:INFO:System:
2025-04-19 23:25:33,090:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:25:33,091:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:25:33,091:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:25:33,091:INFO:PyCaret required dependencies:
2025-04-19 23:25:33,091:INFO:                 pip: 25.0.1
2025-04-19 23:25:33,091:INFO:          setuptools: 58.1.0
2025-04-19 23:25:33,091:INFO:             pycaret: 3.0.4
2025-04-19 23:25:33,091:INFO:             IPython: 8.29.0
2025-04-19 23:25:33,091:INFO:          ipywidgets: 8.1.6
2025-04-19 23:25:33,091:INFO:                tqdm: 4.67.1
2025-04-19 23:25:33,091:INFO:               numpy: 1.23.5
2025-04-19 23:25:33,091:INFO:              pandas: 1.5.3
2025-04-19 23:25:33,091:INFO:              jinja2: 3.1.4
2025-04-19 23:25:33,091:INFO:               scipy: 1.11.4
2025-04-19 23:25:33,091:INFO:              joblib: 1.3.2
2025-04-19 23:25:33,091:INFO:             sklearn: 1.2.2
2025-04-19 23:25:33,091:INFO:                pyod: 2.0.4
2025-04-19 23:25:33,091:INFO:            imblearn: 0.10.1
2025-04-19 23:25:33,091:INFO:   category_encoders: 2.7.0
2025-04-19 23:25:33,091:INFO:            lightgbm: 4.6.0
2025-04-19 23:25:33,091:INFO:               numba: 0.60.0
2025-04-19 23:25:33,091:INFO:            requests: 2.32.3
2025-04-19 23:25:33,092:INFO:          matplotlib: 3.7.5
2025-04-19 23:25:33,092:INFO:          scikitplot: 0.3.7
2025-04-19 23:25:33,092:INFO:         yellowbrick: 1.5
2025-04-19 23:25:33,092:INFO:              plotly: 5.24.1
2025-04-19 23:25:33,092:INFO:    plotly-resampler: Not installed
2025-04-19 23:25:33,092:INFO:             kaleido: 0.2.1
2025-04-19 23:25:33,092:INFO:           schemdraw: 0.15
2025-04-19 23:25:33,092:INFO:         statsmodels: 0.14.4
2025-04-19 23:25:33,092:INFO:              sktime: 0.26.0
2025-04-19 23:25:33,092:INFO:               tbats: 1.1.3
2025-04-19 23:25:33,092:INFO:            pmdarima: 2.0.4
2025-04-19 23:25:33,092:INFO:              psutil: 6.1.0
2025-04-19 23:25:33,092:INFO:          markupsafe: 3.0.2
2025-04-19 23:25:33,092:INFO:             pickle5: Not installed
2025-04-19 23:25:33,092:INFO:         cloudpickle: 3.1.1
2025-04-19 23:25:33,092:INFO:         deprecation: 2.1.0
2025-04-19 23:25:33,092:INFO:              xxhash: 3.5.0
2025-04-19 23:25:33,092:INFO:           wurlitzer: Not installed
2025-04-19 23:25:33,092:INFO:PyCaret optional dependencies:
2025-04-19 23:25:33,092:INFO:                shap: Not installed
2025-04-19 23:25:33,092:INFO:           interpret: Not installed
2025-04-19 23:25:33,092:INFO:                umap: Not installed
2025-04-19 23:25:33,092:INFO:    pandas_profiling: Not installed
2025-04-19 23:25:33,092:INFO:  explainerdashboard: Not installed
2025-04-19 23:25:33,092:INFO:             autoviz: Not installed
2025-04-19 23:25:33,092:INFO:           fairlearn: Not installed
2025-04-19 23:25:33,092:INFO:          deepchecks: Not installed
2025-04-19 23:25:33,092:INFO:             xgboost: 1.7.6
2025-04-19 23:25:33,092:INFO:            catboost: Not installed
2025-04-19 23:25:33,092:INFO:              kmodes: Not installed
2025-04-19 23:25:33,092:INFO:             mlxtend: Not installed
2025-04-19 23:25:33,092:INFO:       statsforecast: Not installed
2025-04-19 23:25:33,092:INFO:        tune_sklearn: Not installed
2025-04-19 23:25:33,092:INFO:                 ray: Not installed
2025-04-19 23:25:33,092:INFO:            hyperopt: Not installed
2025-04-19 23:25:33,092:INFO:              optuna: Not installed
2025-04-19 23:25:33,092:INFO:               skopt: Not installed
2025-04-19 23:25:33,092:INFO:              mlflow: Not installed
2025-04-19 23:25:33,092:INFO:              gradio: Not installed
2025-04-19 23:25:33,092:INFO:             fastapi: Not installed
2025-04-19 23:25:33,092:INFO:             uvicorn: Not installed
2025-04-19 23:25:33,092:INFO:              m2cgen: Not installed
2025-04-19 23:25:33,092:INFO:           evidently: Not installed
2025-04-19 23:25:33,092:INFO:               fugue: Not installed
2025-04-19 23:25:33,092:INFO:           streamlit: 1.42.0
2025-04-19 23:25:33,092:INFO:             prophet: Not installed
2025-04-19 23:25:33,092:INFO:None
2025-04-19 23:25:33,092:INFO:Set up data.
2025-04-19 23:25:33,105:INFO:Set up train/test split.
2025-04-19 23:25:33,112:INFO:Set up index.
2025-04-19 23:25:33,112:INFO:Set up folding strategy.
2025-04-19 23:25:33,112:INFO:Assigning column types.
2025-04-19 23:25:33,115:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:25:33,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:25:33,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:25:33,179:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:33,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:33,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:25:33,220:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:25:33,246:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:33,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:33,249:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:25:33,290:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:25:33,314:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:33,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:33,357:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:25:33,384:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:33,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:33,386:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:25:33,455:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:33,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:33,520:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:33,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:33,525:INFO:Preparing preprocessing pipeline...
2025-04-19 23:25:33,526:INFO:Set up simple imputation.
2025-04-19 23:25:33,529:INFO:Set up encoding of ordinal features.
2025-04-19 23:25:33,532:INFO:Set up encoding of categorical features.
2025-04-19 23:25:33,532:INFO:Set up imbalanced handling.
2025-04-19 23:25:33,532:INFO:Set up feature selection.
2025-04-19 23:25:33,597:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:25:33,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:25:33,751:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:25:33,800:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['EmployeeId', 'Age', 'DailyRate',
                                             'DistanceFromHome', 'Education',
                                             'EnvironmentSatisfaction',
                                             'HourlyRate', 'JobInvolvement',
                                             'JobLevel', 'JobSatisfaction',
                                             'MonthlyIncome', 'MonthlyRate',
                                             'NumCompaniesWorked',
                                             'Perc...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=6,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-04-19 23:25:33,800:INFO:Creating final display dataframe.
2025-04-19 23:26:48,566:INFO:PyCaret ClassificationExperiment
2025-04-19 23:26:48,566:INFO:Logging name: clf-default-name
2025-04-19 23:26:48,566:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-19 23:26:48,566:INFO:version 3.0.4
2025-04-19 23:26:48,566:INFO:Initializing setup()
2025-04-19 23:26:48,566:INFO:self.USI: 9b54
2025-04-19 23:26:48,566:INFO:self._variable_keys: {'seed', '_ml_usecase', 'fold_shuffle_param', 'pipeline', 'memory', 'X_train', 'logging_param', 'fold_generator', 'target_param', 'is_multiclass', 'gpu_param', 'log_plots_param', 'USI', 'fold_groups_param', '_available_plots', 'fix_imbalance', 'gpu_n_jobs_param', 'html_param', 'y_test', 'idx', 'exp_name_log', 'X_test', 'n_jobs_param', 'X', 'y', 'y_train', 'data', 'exp_id'}
2025-04-19 23:26:48,566:INFO:Checking environment
2025-04-19 23:26:48,566:INFO:python_version: 3.10.5
2025-04-19 23:26:48,566:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-19 23:26:48,566:INFO:machine: AMD64
2025-04-19 23:26:48,566:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-19 23:26:48,573:INFO:Memory: svmem(total=25042907136, available=14057033728, percent=43.9, used=10985873408, free=14057033728)
2025-04-19 23:26:48,573:INFO:Physical Core: 6
2025-04-19 23:26:48,573:INFO:Logical Core: 12
2025-04-19 23:26:48,573:INFO:Checking libraries
2025-04-19 23:26:48,573:INFO:System:
2025-04-19 23:26:48,574:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-19 23:26:48,574:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-19 23:26:48,574:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-19 23:26:48,574:INFO:PyCaret required dependencies:
2025-04-19 23:26:48,574:INFO:                 pip: 25.0.1
2025-04-19 23:26:48,574:INFO:          setuptools: 58.1.0
2025-04-19 23:26:48,574:INFO:             pycaret: 3.0.4
2025-04-19 23:26:48,574:INFO:             IPython: 8.29.0
2025-04-19 23:26:48,574:INFO:          ipywidgets: 8.1.6
2025-04-19 23:26:48,574:INFO:                tqdm: 4.67.1
2025-04-19 23:26:48,574:INFO:               numpy: 1.23.5
2025-04-19 23:26:48,574:INFO:              pandas: 1.5.3
2025-04-19 23:26:48,574:INFO:              jinja2: 3.1.4
2025-04-19 23:26:48,574:INFO:               scipy: 1.11.4
2025-04-19 23:26:48,574:INFO:              joblib: 1.3.2
2025-04-19 23:26:48,574:INFO:             sklearn: 1.2.2
2025-04-19 23:26:48,574:INFO:                pyod: 2.0.4
2025-04-19 23:26:48,574:INFO:            imblearn: 0.10.1
2025-04-19 23:26:48,574:INFO:   category_encoders: 2.7.0
2025-04-19 23:26:48,574:INFO:            lightgbm: 4.6.0
2025-04-19 23:26:48,574:INFO:               numba: 0.60.0
2025-04-19 23:26:48,574:INFO:            requests: 2.32.3
2025-04-19 23:26:48,574:INFO:          matplotlib: 3.7.5
2025-04-19 23:26:48,574:INFO:          scikitplot: 0.3.7
2025-04-19 23:26:48,574:INFO:         yellowbrick: 1.5
2025-04-19 23:26:48,574:INFO:              plotly: 5.24.1
2025-04-19 23:26:48,575:INFO:    plotly-resampler: Not installed
2025-04-19 23:26:48,575:INFO:             kaleido: 0.2.1
2025-04-19 23:26:48,575:INFO:           schemdraw: 0.15
2025-04-19 23:26:48,575:INFO:         statsmodels: 0.14.4
2025-04-19 23:26:48,575:INFO:              sktime: 0.26.0
2025-04-19 23:26:48,575:INFO:               tbats: 1.1.3
2025-04-19 23:26:48,575:INFO:            pmdarima: 2.0.4
2025-04-19 23:26:48,575:INFO:              psutil: 6.1.0
2025-04-19 23:26:48,575:INFO:          markupsafe: 3.0.2
2025-04-19 23:26:48,575:INFO:             pickle5: Not installed
2025-04-19 23:26:48,575:INFO:         cloudpickle: 3.1.1
2025-04-19 23:26:48,575:INFO:         deprecation: 2.1.0
2025-04-19 23:26:48,575:INFO:              xxhash: 3.5.0
2025-04-19 23:26:48,575:INFO:           wurlitzer: Not installed
2025-04-19 23:26:48,575:INFO:PyCaret optional dependencies:
2025-04-19 23:26:48,576:INFO:                shap: Not installed
2025-04-19 23:26:48,576:INFO:           interpret: Not installed
2025-04-19 23:26:48,576:INFO:                umap: Not installed
2025-04-19 23:26:48,576:INFO:    pandas_profiling: Not installed
2025-04-19 23:26:48,576:INFO:  explainerdashboard: Not installed
2025-04-19 23:26:48,576:INFO:             autoviz: Not installed
2025-04-19 23:26:48,576:INFO:           fairlearn: Not installed
2025-04-19 23:26:48,576:INFO:          deepchecks: Not installed
2025-04-19 23:26:48,576:INFO:             xgboost: 1.7.6
2025-04-19 23:26:48,576:INFO:            catboost: Not installed
2025-04-19 23:26:48,576:INFO:              kmodes: Not installed
2025-04-19 23:26:48,576:INFO:             mlxtend: Not installed
2025-04-19 23:26:48,576:INFO:       statsforecast: Not installed
2025-04-19 23:26:48,576:INFO:        tune_sklearn: Not installed
2025-04-19 23:26:48,576:INFO:                 ray: Not installed
2025-04-19 23:26:48,576:INFO:            hyperopt: Not installed
2025-04-19 23:26:48,576:INFO:              optuna: Not installed
2025-04-19 23:26:48,576:INFO:               skopt: Not installed
2025-04-19 23:26:48,576:INFO:              mlflow: Not installed
2025-04-19 23:26:48,576:INFO:              gradio: Not installed
2025-04-19 23:26:48,576:INFO:             fastapi: Not installed
2025-04-19 23:26:48,576:INFO:             uvicorn: Not installed
2025-04-19 23:26:48,576:INFO:              m2cgen: Not installed
2025-04-19 23:26:48,576:INFO:           evidently: Not installed
2025-04-19 23:26:48,578:INFO:               fugue: Not installed
2025-04-19 23:26:48,578:INFO:           streamlit: 1.42.0
2025-04-19 23:26:48,578:INFO:             prophet: Not installed
2025-04-19 23:26:48,578:INFO:None
2025-04-19 23:26:48,578:INFO:Set up data.
2025-04-19 23:26:48,589:INFO:Set up train/test split.
2025-04-19 23:26:48,592:INFO:Set up index.
2025-04-19 23:26:48,592:INFO:Set up folding strategy.
2025-04-19 23:26:48,592:INFO:Assigning column types.
2025-04-19 23:26:48,596:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-19 23:26:48,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:26:48,652:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:26:48,679:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:26:48,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:26:48,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-19 23:26:48,722:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:26:48,747:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:26:48,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:26:48,751:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-19 23:26:48,794:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:26:48,825:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:26:48,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:26:48,878:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-19 23:26:48,907:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:26:48,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:26:48,911:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-19 23:26:48,979:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:26:48,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:26:49,050:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:26:49,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:26:49,054:INFO:Preparing preprocessing pipeline...
2025-04-19 23:26:49,055:INFO:Set up simple imputation.
2025-04-19 23:26:49,055:INFO:Set up feature normalization.
2025-04-19 23:26:49,075:INFO:Finished creating preprocessing pipeline.
2025-04-19 23:26:49,079:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-19 23:26:49,079:INFO:Creating final display dataframe.
2025-04-19 23:26:49,147:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (828, 32)
4        Transformed data shape         (828, 31)
5   Transformed train set shape         (579, 31)
6    Transformed test set shape         (249, 31)
7               Ignore features                 1
8              Numeric features                30
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              9b54
2025-04-19 23:26:49,216:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:26:49,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:26:49,287:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-19 23:26:49,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-19 23:26:49,290:INFO:setup() successfully completed in 1.44s...............
2025-04-19 23:26:52,707:INFO:Initializing compare_models()
2025-04-19 23:26:52,707:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-19 23:26:52,707:INFO:Checking exceptions
2025-04-19 23:26:52,711:INFO:Preparing display monitor
2025-04-19 23:26:52,732:INFO:Initializing Logistic Regression
2025-04-19 23:26:52,732:INFO:Total runtime is 0.0 minutes
2025-04-19 23:26:52,735:INFO:SubProcess create_model() called ==================================
2025-04-19 23:26:52,735:INFO:Initializing create_model()
2025-04-19 23:26:52,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:26:52,735:INFO:Checking exceptions
2025-04-19 23:26:52,736:INFO:Importing libraries
2025-04-19 23:26:52,736:INFO:Copying training dataset
2025-04-19 23:26:52,740:INFO:Defining folds
2025-04-19 23:26:52,740:INFO:Declaring metric variables
2025-04-19 23:26:52,743:INFO:Importing untrained model
2025-04-19 23:26:52,747:INFO:Logistic Regression Imported successfully
2025-04-19 23:26:52,755:INFO:Starting cross validation
2025-04-19 23:26:52,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:27:10,679:INFO:Calculating mean and std
2025-04-19 23:27:10,680:INFO:Creating metrics dataframe
2025-04-19 23:27:11,698:INFO:Uploading results into container
2025-04-19 23:27:11,699:INFO:Uploading model into container now
2025-04-19 23:27:11,699:INFO:_master_model_container: 1
2025-04-19 23:27:11,699:INFO:_display_container: 2
2025-04-19 23:27:11,700:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-19 23:27:11,700:INFO:create_model() successfully completed......................................
2025-04-19 23:27:16,403:INFO:SubProcess create_model() end ==================================
2025-04-19 23:27:16,403:INFO:Creating metrics dataframe
2025-04-19 23:27:16,412:INFO:Initializing K Neighbors Classifier
2025-04-19 23:27:16,413:INFO:Total runtime is 0.39467604557673136 minutes
2025-04-19 23:27:16,415:INFO:SubProcess create_model() called ==================================
2025-04-19 23:27:16,416:INFO:Initializing create_model()
2025-04-19 23:27:16,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:27:16,416:INFO:Checking exceptions
2025-04-19 23:27:16,416:INFO:Importing libraries
2025-04-19 23:27:16,416:INFO:Copying training dataset
2025-04-19 23:27:16,420:INFO:Defining folds
2025-04-19 23:27:16,421:INFO:Declaring metric variables
2025-04-19 23:27:16,426:INFO:Importing untrained model
2025-04-19 23:27:16,436:INFO:K Neighbors Classifier Imported successfully
2025-04-19 23:27:16,442:INFO:Starting cross validation
2025-04-19 23:27:16,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:27:25,016:INFO:Calculating mean and std
2025-04-19 23:27:25,017:INFO:Creating metrics dataframe
2025-04-19 23:27:26,046:INFO:Uploading results into container
2025-04-19 23:27:26,047:INFO:Uploading model into container now
2025-04-19 23:27:26,047:INFO:_master_model_container: 2
2025-04-19 23:27:26,047:INFO:_display_container: 2
2025-04-19 23:27:26,048:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-19 23:27:26,048:INFO:create_model() successfully completed......................................
2025-04-19 23:27:26,208:INFO:SubProcess create_model() end ==================================
2025-04-19 23:27:26,208:INFO:Creating metrics dataframe
2025-04-19 23:27:26,218:INFO:Initializing Naive Bayes
2025-04-19 23:27:26,218:INFO:Total runtime is 0.5580920656522115 minutes
2025-04-19 23:27:26,223:INFO:SubProcess create_model() called ==================================
2025-04-19 23:27:26,223:INFO:Initializing create_model()
2025-04-19 23:27:26,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:27:26,223:INFO:Checking exceptions
2025-04-19 23:27:26,223:INFO:Importing libraries
2025-04-19 23:27:26,223:INFO:Copying training dataset
2025-04-19 23:27:26,228:INFO:Defining folds
2025-04-19 23:27:26,228:INFO:Declaring metric variables
2025-04-19 23:27:26,232:INFO:Importing untrained model
2025-04-19 23:27:26,237:INFO:Naive Bayes Imported successfully
2025-04-19 23:27:26,245:INFO:Starting cross validation
2025-04-19 23:27:26,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:27:34,095:INFO:Calculating mean and std
2025-04-19 23:27:34,096:INFO:Creating metrics dataframe
2025-04-19 23:27:35,136:INFO:Uploading results into container
2025-04-19 23:27:35,137:INFO:Uploading model into container now
2025-04-19 23:27:35,138:INFO:_master_model_container: 3
2025-04-19 23:27:35,138:INFO:_display_container: 2
2025-04-19 23:27:35,138:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-19 23:27:35,139:INFO:create_model() successfully completed......................................
2025-04-19 23:27:35,296:INFO:SubProcess create_model() end ==================================
2025-04-19 23:27:35,298:INFO:Creating metrics dataframe
2025-04-19 23:27:35,308:INFO:Initializing Decision Tree Classifier
2025-04-19 23:27:35,309:INFO:Total runtime is 0.709615671634674 minutes
2025-04-19 23:27:35,312:INFO:SubProcess create_model() called ==================================
2025-04-19 23:27:35,312:INFO:Initializing create_model()
2025-04-19 23:27:35,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:27:35,313:INFO:Checking exceptions
2025-04-19 23:27:35,313:INFO:Importing libraries
2025-04-19 23:27:35,313:INFO:Copying training dataset
2025-04-19 23:27:35,318:INFO:Defining folds
2025-04-19 23:27:35,318:INFO:Declaring metric variables
2025-04-19 23:27:35,323:INFO:Importing untrained model
2025-04-19 23:27:35,333:INFO:Decision Tree Classifier Imported successfully
2025-04-19 23:27:35,340:INFO:Starting cross validation
2025-04-19 23:27:35,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:27:43,077:INFO:Calculating mean and std
2025-04-19 23:27:43,078:INFO:Creating metrics dataframe
2025-04-19 23:27:44,097:INFO:Uploading results into container
2025-04-19 23:27:44,099:INFO:Uploading model into container now
2025-04-19 23:27:44,099:INFO:_master_model_container: 4
2025-04-19 23:27:44,099:INFO:_display_container: 2
2025-04-19 23:27:44,100:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-19 23:27:44,100:INFO:create_model() successfully completed......................................
2025-04-19 23:27:44,261:INFO:SubProcess create_model() end ==================================
2025-04-19 23:27:44,261:INFO:Creating metrics dataframe
2025-04-19 23:27:44,270:INFO:Initializing SVM - Linear Kernel
2025-04-19 23:27:44,270:INFO:Total runtime is 0.8589613397916157 minutes
2025-04-19 23:27:44,272:INFO:SubProcess create_model() called ==================================
2025-04-19 23:27:44,272:INFO:Initializing create_model()
2025-04-19 23:27:44,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:27:44,272:INFO:Checking exceptions
2025-04-19 23:27:44,273:INFO:Importing libraries
2025-04-19 23:27:44,273:INFO:Copying training dataset
2025-04-19 23:27:44,276:INFO:Defining folds
2025-04-19 23:27:44,276:INFO:Declaring metric variables
2025-04-19 23:27:44,283:INFO:Importing untrained model
2025-04-19 23:27:44,290:INFO:SVM - Linear Kernel Imported successfully
2025-04-19 23:27:44,298:INFO:Starting cross validation
2025-04-19 23:27:44,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:27:44,402:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,412:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,415:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,422:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,425:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,427:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,430:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,441:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,445:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:44,455:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-19 23:27:52,165:INFO:Calculating mean and std
2025-04-19 23:27:52,166:INFO:Creating metrics dataframe
2025-04-19 23:27:53,172:INFO:Uploading results into container
2025-04-19 23:27:53,172:INFO:Uploading model into container now
2025-04-19 23:27:53,172:INFO:_master_model_container: 5
2025-04-19 23:27:53,172:INFO:_display_container: 2
2025-04-19 23:27:53,173:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-19 23:27:53,173:INFO:create_model() successfully completed......................................
2025-04-19 23:27:53,334:INFO:SubProcess create_model() end ==================================
2025-04-19 23:27:53,334:INFO:Creating metrics dataframe
2025-04-19 23:27:53,343:INFO:Initializing Ridge Classifier
2025-04-19 23:27:53,344:INFO:Total runtime is 1.0101968447367349 minutes
2025-04-19 23:27:53,346:INFO:SubProcess create_model() called ==================================
2025-04-19 23:27:53,346:INFO:Initializing create_model()
2025-04-19 23:27:53,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:27:53,347:INFO:Checking exceptions
2025-04-19 23:27:53,347:INFO:Importing libraries
2025-04-19 23:27:53,347:INFO:Copying training dataset
2025-04-19 23:27:53,350:INFO:Defining folds
2025-04-19 23:27:53,350:INFO:Declaring metric variables
2025-04-19 23:27:53,356:INFO:Importing untrained model
2025-04-19 23:27:53,362:INFO:Ridge Classifier Imported successfully
2025-04-19 23:27:53,371:INFO:Starting cross validation
2025-04-19 23:27:53,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:27:53,472:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,483:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,489:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,498:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,518:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,519:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,520:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,523:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,526:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:27:53,526:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-19 23:28:01,259:INFO:Calculating mean and std
2025-04-19 23:28:01,260:INFO:Creating metrics dataframe
2025-04-19 23:28:02,263:INFO:Uploading results into container
2025-04-19 23:28:02,264:INFO:Uploading model into container now
2025-04-19 23:28:02,264:INFO:_master_model_container: 6
2025-04-19 23:28:02,264:INFO:_display_container: 2
2025-04-19 23:28:02,264:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-19 23:28:02,264:INFO:create_model() successfully completed......................................
2025-04-19 23:28:02,417:INFO:SubProcess create_model() end ==================================
2025-04-19 23:28:02,418:INFO:Creating metrics dataframe
2025-04-19 23:28:02,428:INFO:Initializing Random Forest Classifier
2025-04-19 23:28:02,428:INFO:Total runtime is 1.161591859658559 minutes
2025-04-19 23:28:02,431:INFO:SubProcess create_model() called ==================================
2025-04-19 23:28:02,432:INFO:Initializing create_model()
2025-04-19 23:28:02,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:28:02,432:INFO:Checking exceptions
2025-04-19 23:28:02,433:INFO:Importing libraries
2025-04-19 23:28:02,433:INFO:Copying training dataset
2025-04-19 23:28:02,438:INFO:Defining folds
2025-04-19 23:28:02,438:INFO:Declaring metric variables
2025-04-19 23:28:02,443:INFO:Importing untrained model
2025-04-19 23:28:02,448:INFO:Random Forest Classifier Imported successfully
2025-04-19 23:28:02,455:INFO:Starting cross validation
2025-04-19 23:28:02,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:28:10,879:INFO:Calculating mean and std
2025-04-19 23:28:10,880:INFO:Creating metrics dataframe
2025-04-19 23:28:11,916:INFO:Uploading results into container
2025-04-19 23:28:11,917:INFO:Uploading model into container now
2025-04-19 23:28:11,917:INFO:_master_model_container: 7
2025-04-19 23:28:11,918:INFO:_display_container: 2
2025-04-19 23:28:11,918:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-19 23:28:11,918:INFO:create_model() successfully completed......................................
2025-04-19 23:28:12,077:INFO:SubProcess create_model() end ==================================
2025-04-19 23:28:12,077:INFO:Creating metrics dataframe
2025-04-19 23:28:12,086:INFO:Initializing Quadratic Discriminant Analysis
2025-04-19 23:28:12,086:INFO:Total runtime is 1.3225696404774983 minutes
2025-04-19 23:28:12,089:INFO:SubProcess create_model() called ==================================
2025-04-19 23:28:12,090:INFO:Initializing create_model()
2025-04-19 23:28:12,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:28:12,090:INFO:Checking exceptions
2025-04-19 23:28:12,090:INFO:Importing libraries
2025-04-19 23:28:12,090:INFO:Copying training dataset
2025-04-19 23:28:12,094:INFO:Defining folds
2025-04-19 23:28:12,094:INFO:Declaring metric variables
2025-04-19 23:28:12,097:INFO:Importing untrained model
2025-04-19 23:28:12,103:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-19 23:28:12,114:INFO:Starting cross validation
2025-04-19 23:28:12,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:28:20,111:INFO:Calculating mean and std
2025-04-19 23:28:20,113:INFO:Creating metrics dataframe
2025-04-19 23:28:21,121:INFO:Uploading results into container
2025-04-19 23:28:21,122:INFO:Uploading model into container now
2025-04-19 23:28:21,123:INFO:_master_model_container: 8
2025-04-19 23:28:21,123:INFO:_display_container: 2
2025-04-19 23:28:21,124:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-19 23:28:21,124:INFO:create_model() successfully completed......................................
2025-04-19 23:28:21,282:INFO:SubProcess create_model() end ==================================
2025-04-19 23:28:21,282:INFO:Creating metrics dataframe
2025-04-19 23:28:21,293:INFO:Initializing Ada Boost Classifier
2025-04-19 23:28:21,293:INFO:Total runtime is 1.4760172684987385 minutes
2025-04-19 23:28:21,296:INFO:SubProcess create_model() called ==================================
2025-04-19 23:28:21,297:INFO:Initializing create_model()
2025-04-19 23:28:21,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:28:21,297:INFO:Checking exceptions
2025-04-19 23:28:21,297:INFO:Importing libraries
2025-04-19 23:28:21,297:INFO:Copying training dataset
2025-04-19 23:28:21,302:INFO:Defining folds
2025-04-19 23:28:21,303:INFO:Declaring metric variables
2025-04-19 23:28:21,308:INFO:Importing untrained model
2025-04-19 23:28:21,317:INFO:Ada Boost Classifier Imported successfully
2025-04-19 23:28:21,327:INFO:Starting cross validation
2025-04-19 23:28:21,327:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:28:29,415:INFO:Calculating mean and std
2025-04-19 23:28:29,416:INFO:Creating metrics dataframe
2025-04-19 23:28:30,451:INFO:Uploading results into container
2025-04-19 23:28:30,452:INFO:Uploading model into container now
2025-04-19 23:28:30,453:INFO:_master_model_container: 9
2025-04-19 23:28:30,453:INFO:_display_container: 2
2025-04-19 23:28:30,453:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-19 23:28:30,453:INFO:create_model() successfully completed......................................
2025-04-19 23:28:30,611:INFO:SubProcess create_model() end ==================================
2025-04-19 23:28:30,611:INFO:Creating metrics dataframe
2025-04-19 23:28:30,621:INFO:Initializing Gradient Boosting Classifier
2025-04-19 23:28:30,622:INFO:Total runtime is 1.6314992030461628 minutes
2025-04-19 23:28:30,625:INFO:SubProcess create_model() called ==================================
2025-04-19 23:28:30,625:INFO:Initializing create_model()
2025-04-19 23:28:30,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:28:30,626:INFO:Checking exceptions
2025-04-19 23:28:30,626:INFO:Importing libraries
2025-04-19 23:28:30,626:INFO:Copying training dataset
2025-04-19 23:28:30,629:INFO:Defining folds
2025-04-19 23:28:30,629:INFO:Declaring metric variables
2025-04-19 23:28:30,634:INFO:Importing untrained model
2025-04-19 23:28:30,641:INFO:Gradient Boosting Classifier Imported successfully
2025-04-19 23:28:30,647:INFO:Starting cross validation
2025-04-19 23:28:30,647:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:28:38,967:INFO:Calculating mean and std
2025-04-19 23:28:38,968:INFO:Creating metrics dataframe
2025-04-19 23:28:40,008:INFO:Uploading results into container
2025-04-19 23:28:40,009:INFO:Uploading model into container now
2025-04-19 23:28:40,009:INFO:_master_model_container: 10
2025-04-19 23:28:40,009:INFO:_display_container: 2
2025-04-19 23:28:40,011:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-19 23:28:40,011:INFO:create_model() successfully completed......................................
2025-04-19 23:28:40,180:INFO:SubProcess create_model() end ==================================
2025-04-19 23:28:40,180:INFO:Creating metrics dataframe
2025-04-19 23:28:40,190:INFO:Initializing Linear Discriminant Analysis
2025-04-19 23:28:40,190:INFO:Total runtime is 1.7909692923227944 minutes
2025-04-19 23:28:40,194:INFO:SubProcess create_model() called ==================================
2025-04-19 23:28:40,195:INFO:Initializing create_model()
2025-04-19 23:28:40,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:28:40,195:INFO:Checking exceptions
2025-04-19 23:28:40,195:INFO:Importing libraries
2025-04-19 23:28:40,195:INFO:Copying training dataset
2025-04-19 23:28:40,200:INFO:Defining folds
2025-04-19 23:28:40,200:INFO:Declaring metric variables
2025-04-19 23:28:40,206:INFO:Importing untrained model
2025-04-19 23:28:40,211:INFO:Linear Discriminant Analysis Imported successfully
2025-04-19 23:28:40,219:INFO:Starting cross validation
2025-04-19 23:28:40,222:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:28:48,325:INFO:Calculating mean and std
2025-04-19 23:28:48,326:INFO:Creating metrics dataframe
2025-04-19 23:28:49,368:INFO:Uploading results into container
2025-04-19 23:28:49,370:INFO:Uploading model into container now
2025-04-19 23:28:49,370:INFO:_master_model_container: 11
2025-04-19 23:28:49,370:INFO:_display_container: 2
2025-04-19 23:28:49,370:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-19 23:28:49,371:INFO:create_model() successfully completed......................................
2025-04-19 23:28:49,533:INFO:SubProcess create_model() end ==================================
2025-04-19 23:28:49,533:INFO:Creating metrics dataframe
2025-04-19 23:28:49,544:INFO:Initializing Extra Trees Classifier
2025-04-19 23:28:49,544:INFO:Total runtime is 1.9468676884969074 minutes
2025-04-19 23:28:49,548:INFO:SubProcess create_model() called ==================================
2025-04-19 23:28:49,548:INFO:Initializing create_model()
2025-04-19 23:28:49,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:28:49,548:INFO:Checking exceptions
2025-04-19 23:28:49,548:INFO:Importing libraries
2025-04-19 23:28:49,548:INFO:Copying training dataset
2025-04-19 23:28:49,552:INFO:Defining folds
2025-04-19 23:28:49,552:INFO:Declaring metric variables
2025-04-19 23:28:49,556:INFO:Importing untrained model
2025-04-19 23:28:49,559:INFO:Extra Trees Classifier Imported successfully
2025-04-19 23:28:49,569:INFO:Starting cross validation
2025-04-19 23:28:49,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:28:58,190:INFO:Calculating mean and std
2025-04-19 23:28:58,191:INFO:Creating metrics dataframe
2025-04-19 23:28:59,256:INFO:Uploading results into container
2025-04-19 23:28:59,257:INFO:Uploading model into container now
2025-04-19 23:28:59,258:INFO:_master_model_container: 12
2025-04-19 23:28:59,258:INFO:_display_container: 2
2025-04-19 23:28:59,258:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-19 23:28:59,258:INFO:create_model() successfully completed......................................
2025-04-19 23:28:59,410:INFO:SubProcess create_model() end ==================================
2025-04-19 23:28:59,410:INFO:Creating metrics dataframe
2025-04-19 23:28:59,420:INFO:Initializing Extreme Gradient Boosting
2025-04-19 23:28:59,420:INFO:Total runtime is 2.111473075548808 minutes
2025-04-19 23:28:59,423:INFO:SubProcess create_model() called ==================================
2025-04-19 23:28:59,424:INFO:Initializing create_model()
2025-04-19 23:28:59,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:28:59,424:INFO:Checking exceptions
2025-04-19 23:28:59,424:INFO:Importing libraries
2025-04-19 23:28:59,424:INFO:Copying training dataset
2025-04-19 23:28:59,428:INFO:Defining folds
2025-04-19 23:28:59,429:INFO:Declaring metric variables
2025-04-19 23:28:59,432:INFO:Importing untrained model
2025-04-19 23:28:59,439:INFO:Extreme Gradient Boosting Imported successfully
2025-04-19 23:28:59,447:INFO:Starting cross validation
2025-04-19 23:28:59,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:29:09,399:INFO:Calculating mean and std
2025-04-19 23:29:09,400:INFO:Creating metrics dataframe
2025-04-19 23:29:10,478:INFO:Uploading results into container
2025-04-19 23:29:10,478:INFO:Uploading model into container now
2025-04-19 23:29:10,479:INFO:_master_model_container: 13
2025-04-19 23:29:10,479:INFO:_display_container: 2
2025-04-19 23:29:10,480:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-19 23:29:10,480:INFO:create_model() successfully completed......................................
2025-04-19 23:29:10,644:INFO:SubProcess create_model() end ==================================
2025-04-19 23:29:10,644:INFO:Creating metrics dataframe
2025-04-19 23:29:10,658:INFO:Initializing Light Gradient Boosting Machine
2025-04-19 23:29:10,658:INFO:Total runtime is 2.298761010169983 minutes
2025-04-19 23:29:10,661:INFO:SubProcess create_model() called ==================================
2025-04-19 23:29:10,661:INFO:Initializing create_model()
2025-04-19 23:29:10,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:29:10,661:INFO:Checking exceptions
2025-04-19 23:29:10,661:INFO:Importing libraries
2025-04-19 23:29:10,661:INFO:Copying training dataset
2025-04-19 23:29:10,665:INFO:Defining folds
2025-04-19 23:29:10,665:INFO:Declaring metric variables
2025-04-19 23:29:10,669:INFO:Importing untrained model
2025-04-19 23:29:10,674:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-19 23:29:10,680:INFO:Starting cross validation
2025-04-19 23:29:10,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:29:34,154:INFO:Calculating mean and std
2025-04-19 23:29:34,155:INFO:Creating metrics dataframe
2025-04-19 23:29:35,224:INFO:Uploading results into container
2025-04-19 23:29:35,226:INFO:Uploading model into container now
2025-04-19 23:29:35,226:INFO:_master_model_container: 14
2025-04-19 23:29:35,227:INFO:_display_container: 2
2025-04-19 23:29:35,228:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-19 23:29:35,228:INFO:create_model() successfully completed......................................
2025-04-19 23:29:35,387:INFO:SubProcess create_model() end ==================================
2025-04-19 23:29:35,387:INFO:Creating metrics dataframe
2025-04-19 23:29:35,400:INFO:Initializing Dummy Classifier
2025-04-19 23:29:35,400:INFO:Total runtime is 2.7111383636792503 minutes
2025-04-19 23:29:35,402:INFO:SubProcess create_model() called ==================================
2025-04-19 23:29:35,403:INFO:Initializing create_model()
2025-04-19 23:29:35,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C1376877F0>, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:29:35,403:INFO:Checking exceptions
2025-04-19 23:29:35,403:INFO:Importing libraries
2025-04-19 23:29:35,403:INFO:Copying training dataset
2025-04-19 23:29:35,406:INFO:Defining folds
2025-04-19 23:29:35,406:INFO:Declaring metric variables
2025-04-19 23:29:35,415:INFO:Importing untrained model
2025-04-19 23:29:35,420:INFO:Dummy Classifier Imported successfully
2025-04-19 23:29:35,429:INFO:Starting cross validation
2025-04-19 23:29:35,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-19 23:29:43,562:INFO:Calculating mean and std
2025-04-19 23:29:43,564:INFO:Creating metrics dataframe
2025-04-19 23:29:44,699:INFO:Uploading results into container
2025-04-19 23:29:44,699:INFO:Uploading model into container now
2025-04-19 23:29:44,700:INFO:_master_model_container: 15
2025-04-19 23:29:44,700:INFO:_display_container: 2
2025-04-19 23:29:44,700:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-19 23:29:44,700:INFO:create_model() successfully completed......................................
2025-04-19 23:29:44,865:INFO:SubProcess create_model() end ==================================
2025-04-19 23:29:44,865:INFO:Creating metrics dataframe
2025-04-19 23:29:44,888:INFO:Initializing create_model()
2025-04-19 23:29:44,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-19 23:29:44,888:INFO:Checking exceptions
2025-04-19 23:29:44,889:INFO:Importing libraries
2025-04-19 23:29:44,889:INFO:Copying training dataset
2025-04-19 23:29:44,893:INFO:Defining folds
2025-04-19 23:29:44,893:INFO:Declaring metric variables
2025-04-19 23:29:44,894:INFO:Importing untrained model
2025-04-19 23:29:44,894:INFO:Declaring custom model
2025-04-19 23:29:44,894:INFO:Extra Trees Classifier Imported successfully
2025-04-19 23:29:44,895:INFO:Cross validation set to False
2025-04-19 23:29:44,895:INFO:Fitting Model
2025-04-19 23:29:45,928:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-19 23:29:45,928:INFO:create_model() successfully completed......................................
2025-04-19 23:29:46,111:INFO:_master_model_container: 15
2025-04-19 23:29:46,111:INFO:_display_container: 2
2025-04-19 23:29:46,111:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-19 23:29:46,112:INFO:compare_models() successfully completed......................................
2025-04-19 23:31:22,291:INFO:Initializing evaluate_model()
2025-04-19 23:31:22,291:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-19 23:31:22,300:INFO:Initializing plot_model()
2025-04-19 23:31:22,300:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:31:22,300:INFO:Checking exceptions
2025-04-19 23:31:22,325:INFO:Preloading libraries
2025-04-19 23:31:22,335:INFO:Copying training dataset
2025-04-19 23:31:22,335:INFO:Plot type: pipeline
2025-04-19 23:31:22,526:INFO:Visual Rendered Successfully
2025-04-19 23:31:22,683:INFO:plot_model() successfully completed......................................
2025-04-19 23:31:26,869:INFO:Initializing plot_model()
2025-04-19 23:31:26,869:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:31:26,869:INFO:Checking exceptions
2025-04-19 23:31:26,902:INFO:Preloading libraries
2025-04-19 23:31:26,910:INFO:Copying training dataset
2025-04-19 23:31:26,910:INFO:Plot type: parameter
2025-04-19 23:31:26,913:INFO:Visual Rendered Successfully
2025-04-19 23:31:27,073:INFO:plot_model() successfully completed......................................
2025-04-19 23:31:31,110:INFO:Initializing plot_model()
2025-04-19 23:31:31,110:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:31:31,110:INFO:Checking exceptions
2025-04-19 23:31:31,142:INFO:Preloading libraries
2025-04-19 23:31:31,148:INFO:Copying training dataset
2025-04-19 23:31:31,148:INFO:Plot type: auc
2025-04-19 23:31:31,219:INFO:Fitting Model
2025-04-19 23:31:31,219:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2025-04-19 23:31:31,219:INFO:Scoring test/hold-out set
2025-04-19 23:31:31,514:INFO:Visual Rendered Successfully
2025-04-19 23:31:31,668:INFO:plot_model() successfully completed......................................
2025-04-19 23:31:31,838:INFO:Initializing plot_model()
2025-04-19 23:31:31,838:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:31:31,838:INFO:Checking exceptions
2025-04-19 23:31:31,874:INFO:Preloading libraries
2025-04-19 23:31:31,886:INFO:Copying training dataset
2025-04-19 23:31:31,887:INFO:Plot type: learning
2025-04-19 23:31:31,991:INFO:Fitting Model
2025-04-19 23:31:35,124:INFO:Visual Rendered Successfully
2025-04-19 23:31:35,295:INFO:plot_model() successfully completed......................................
2025-04-19 23:31:38,854:INFO:Initializing plot_model()
2025-04-19 23:31:38,855:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:31:38,855:INFO:Checking exceptions
2025-04-19 23:31:38,888:INFO:Preloading libraries
2025-04-19 23:31:38,895:INFO:Copying training dataset
2025-04-19 23:31:38,895:INFO:Plot type: confusion_matrix
2025-04-19 23:31:38,966:INFO:Fitting Model
2025-04-19 23:31:38,966:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2025-04-19 23:31:38,966:INFO:Scoring test/hold-out set
2025-04-19 23:31:39,161:INFO:Visual Rendered Successfully
2025-04-19 23:31:39,328:INFO:plot_model() successfully completed......................................
2025-04-19 23:31:43,671:INFO:Initializing plot_model()
2025-04-19 23:31:43,671:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:31:43,673:INFO:Checking exceptions
2025-04-19 23:31:43,709:INFO:Preloading libraries
2025-04-19 23:31:43,717:INFO:Copying training dataset
2025-04-19 23:31:43,717:INFO:Plot type: threshold
2025-04-19 23:31:43,802:INFO:Fitting Model
2025-04-19 23:31:51,611:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names
  warnings.warn(

2025-04-19 23:31:51,627:INFO:Scoring test/hold-out set
2025-04-19 23:31:52,001:INFO:Visual Rendered Successfully
2025-04-19 23:31:52,173:INFO:plot_model() successfully completed......................................
2025-04-19 23:31:52,213:INFO:Initializing plot_model()
2025-04-19 23:31:52,213:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:31:52,213:INFO:Checking exceptions
2025-04-19 23:31:52,238:INFO:Preloading libraries
2025-04-19 23:31:52,247:INFO:Copying training dataset
2025-04-19 23:31:52,247:INFO:Plot type: tree
2025-04-19 23:31:53,551:INFO:Plotting decision trees
2025-04-19 23:32:19,421:INFO:Initializing evaluate_model()
2025-04-19 23:32:19,421:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-19 23:32:19,434:INFO:Initializing plot_model()
2025-04-19 23:32:19,434:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:32:19,434:INFO:Checking exceptions
2025-04-19 23:32:19,471:INFO:Preloading libraries
2025-04-19 23:32:19,480:INFO:Copying training dataset
2025-04-19 23:32:19,480:INFO:Plot type: pipeline
2025-04-19 23:32:20,733:INFO:Visual Rendered Successfully
2025-04-19 23:32:21,057:INFO:plot_model() successfully completed......................................
2025-04-19 23:32:21,080:INFO:Initializing plot_model()
2025-04-19 23:32:21,080:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, system=True)
2025-04-19 23:32:21,081:INFO:Checking exceptions
2025-04-19 23:32:21,111:INFO:Preloading libraries
2025-04-19 23:32:21,118:INFO:Copying training dataset
2025-04-19 23:32:21,120:INFO:Plot type: pipeline
2025-04-19 23:32:21,267:INFO:Visual Rendered Successfully
2025-04-19 23:32:21,598:INFO:plot_model() successfully completed......................................
2025-04-19 23:32:25,494:INFO:Initializing finalize_model()
2025-04-19 23:32:25,494:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-19 23:32:25,495:INFO:Finalizing ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-19 23:32:25,499:INFO:Initializing create_model()
2025-04-19 23:32:25,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C13ABD1960>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-04-19 23:32:25,499:INFO:Checking exceptions
2025-04-19 23:32:25,501:INFO:Importing libraries
2025-04-19 23:32:25,501:INFO:Copying training dataset
2025-04-19 23:32:25,501:INFO:Defining folds
2025-04-19 23:32:25,501:INFO:Declaring metric variables
2025-04-19 23:32:25,501:INFO:Importing untrained model
2025-04-19 23:32:25,501:INFO:Declaring custom model
2025-04-19 23:32:25,502:INFO:Extra Trees Classifier Imported successfully
2025-04-19 23:32:25,503:INFO:Cross validation set to False
2025-04-19 23:32:25,503:INFO:Fitting Model
2025-04-19 23:32:25,776:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-19 23:32:25,776:INFO:create_model() successfully completed......................................
2025-04-19 23:32:26,083:INFO:_master_model_container: 15
2025-04-19 23:32:26,083:INFO:_display_container: 2
2025-04-19 23:32:26,088:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-19 23:32:26,088:INFO:finalize_model() successfully completed......................................
2025-04-19 23:32:26,403:INFO:Initializing save_model()
2025-04-19 23:32:26,403:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False), model_name=model_attrition, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-04-19 23:32:26,403:INFO:Adding model into prep_pipe
2025-04-19 23:32:26,403:WARNING:Only Model saved as it was a pipeline.
2025-04-19 23:32:26,443:INFO:model_attrition.pkl saved in current working directory
2025-04-19 23:32:26,448:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-19 23:32:26,448:INFO:save_model() successfully completed......................................
2025-04-20 16:34:12,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:34:12,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:34:12,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:34:12,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:34:48,244:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_2408\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-20 16:34:57,752:INFO:PyCaret ClassificationExperiment
2025-04-20 16:34:57,752:INFO:Logging name: clf-default-name
2025-04-20 16:34:57,752:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-20 16:34:57,752:INFO:version 3.0.4
2025-04-20 16:34:57,752:INFO:Initializing setup()
2025-04-20 16:34:57,752:INFO:self.USI: ccb5
2025-04-20 16:34:57,752:INFO:self._variable_keys: {'X', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'gpu_param', 'exp_id', 'data', 'seed', 'fold_groups_param', 'fold_generator', 'y', 'pipeline', 'fix_imbalance', 'y_test', 'target_param', 'logging_param', '_available_plots', 'X_train', 'X_test', 'y_train', 'idx', 'memory', 'exp_name_log', 'USI', '_ml_usecase', 'gpu_n_jobs_param', 'n_jobs_param', 'log_plots_param'}
2025-04-20 16:34:57,752:INFO:Checking environment
2025-04-20 16:34:57,753:INFO:python_version: 3.10.5
2025-04-20 16:34:57,753:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-20 16:34:57,753:INFO:machine: AMD64
2025-04-20 16:34:57,753:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-20 16:34:57,758:INFO:Memory: svmem(total=25042907136, available=11192561664, percent=55.3, used=13850345472, free=11192561664)
2025-04-20 16:34:57,758:INFO:Physical Core: 6
2025-04-20 16:34:57,758:INFO:Logical Core: 12
2025-04-20 16:34:57,758:INFO:Checking libraries
2025-04-20 16:34:57,758:INFO:System:
2025-04-20 16:34:57,758:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-20 16:34:57,758:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-20 16:34:57,759:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-20 16:34:57,759:INFO:PyCaret required dependencies:
2025-04-20 16:34:57,822:INFO:                 pip: 25.0.1
2025-04-20 16:34:57,823:INFO:          setuptools: 58.1.0
2025-04-20 16:34:57,823:INFO:             pycaret: 3.0.4
2025-04-20 16:34:57,823:INFO:             IPython: 8.29.0
2025-04-20 16:34:57,823:INFO:          ipywidgets: 8.1.6
2025-04-20 16:34:57,823:INFO:                tqdm: 4.67.1
2025-04-20 16:34:57,823:INFO:               numpy: 1.23.5
2025-04-20 16:34:57,823:INFO:              pandas: 1.5.3
2025-04-20 16:34:57,823:INFO:              jinja2: 3.1.4
2025-04-20 16:34:57,823:INFO:               scipy: 1.11.4
2025-04-20 16:34:57,823:INFO:              joblib: 1.3.2
2025-04-20 16:34:57,823:INFO:             sklearn: 1.2.2
2025-04-20 16:34:57,823:INFO:                pyod: 2.0.4
2025-04-20 16:34:57,823:INFO:            imblearn: 0.10.1
2025-04-20 16:34:57,823:INFO:   category_encoders: 2.7.0
2025-04-20 16:34:57,823:INFO:            lightgbm: 4.6.0
2025-04-20 16:34:57,823:INFO:               numba: 0.60.0
2025-04-20 16:34:57,823:INFO:            requests: 2.32.3
2025-04-20 16:34:57,823:INFO:          matplotlib: 3.7.5
2025-04-20 16:34:57,823:INFO:          scikitplot: 0.3.7
2025-04-20 16:34:57,823:INFO:         yellowbrick: 1.5
2025-04-20 16:34:57,823:INFO:              plotly: 5.24.1
2025-04-20 16:34:57,823:INFO:    plotly-resampler: Not installed
2025-04-20 16:34:57,823:INFO:             kaleido: 0.2.1
2025-04-20 16:34:57,823:INFO:           schemdraw: 0.15
2025-04-20 16:34:57,823:INFO:         statsmodels: 0.14.4
2025-04-20 16:34:57,823:INFO:              sktime: 0.26.0
2025-04-20 16:34:57,823:INFO:               tbats: 1.1.3
2025-04-20 16:34:57,823:INFO:            pmdarima: 2.0.4
2025-04-20 16:34:57,823:INFO:              psutil: 6.1.0
2025-04-20 16:34:57,823:INFO:          markupsafe: 3.0.2
2025-04-20 16:34:57,823:INFO:             pickle5: Not installed
2025-04-20 16:34:57,823:INFO:         cloudpickle: 3.1.1
2025-04-20 16:34:57,823:INFO:         deprecation: 2.1.0
2025-04-20 16:34:57,823:INFO:              xxhash: 3.5.0
2025-04-20 16:34:57,823:INFO:           wurlitzer: Not installed
2025-04-20 16:34:57,823:INFO:PyCaret optional dependencies:
2025-04-20 16:34:57,834:INFO:                shap: Not installed
2025-04-20 16:34:57,834:INFO:           interpret: Not installed
2025-04-20 16:34:57,834:INFO:                umap: Not installed
2025-04-20 16:34:57,834:INFO:    pandas_profiling: Not installed
2025-04-20 16:34:57,834:INFO:  explainerdashboard: Not installed
2025-04-20 16:34:57,834:INFO:             autoviz: Not installed
2025-04-20 16:34:57,834:INFO:           fairlearn: Not installed
2025-04-20 16:34:57,834:INFO:          deepchecks: Not installed
2025-04-20 16:34:57,834:INFO:             xgboost: 1.7.6
2025-04-20 16:34:57,834:INFO:            catboost: Not installed
2025-04-20 16:34:57,834:INFO:              kmodes: Not installed
2025-04-20 16:34:57,834:INFO:             mlxtend: Not installed
2025-04-20 16:34:57,834:INFO:       statsforecast: Not installed
2025-04-20 16:34:57,834:INFO:        tune_sklearn: Not installed
2025-04-20 16:34:57,834:INFO:                 ray: Not installed
2025-04-20 16:34:57,834:INFO:            hyperopt: Not installed
2025-04-20 16:34:57,834:INFO:              optuna: Not installed
2025-04-20 16:34:57,834:INFO:               skopt: Not installed
2025-04-20 16:34:57,834:INFO:              mlflow: Not installed
2025-04-20 16:34:57,835:INFO:              gradio: Not installed
2025-04-20 16:34:57,835:INFO:             fastapi: Not installed
2025-04-20 16:34:57,835:INFO:             uvicorn: Not installed
2025-04-20 16:34:57,835:INFO:              m2cgen: Not installed
2025-04-20 16:34:57,835:INFO:           evidently: Not installed
2025-04-20 16:34:57,835:INFO:               fugue: Not installed
2025-04-20 16:34:57,835:INFO:           streamlit: 1.42.0
2025-04-20 16:34:57,835:INFO:             prophet: Not installed
2025-04-20 16:34:57,835:INFO:None
2025-04-20 16:34:57,835:INFO:Set up data.
2025-04-20 16:34:57,843:INFO:Set up train/test split.
2025-04-20 16:34:57,847:INFO:Set up index.
2025-04-20 16:34:57,847:INFO:Set up folding strategy.
2025-04-20 16:34:57,847:INFO:Assigning column types.
2025-04-20 16:34:57,849:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-20 16:34:57,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 16:34:57,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 16:34:57,926:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:34:57,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:34:57,959:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 16:34:57,960:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 16:34:57,980:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:34:57,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:34:57,982:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-20 16:34:58,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 16:34:58,032:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:34:58,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:34:58,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 16:34:58,084:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:34:58,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:34:58,086:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-20 16:34:58,138:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:34:58,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:34:58,192:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:34:58,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:34:58,199:INFO:Preparing preprocessing pipeline...
2025-04-20 16:34:58,200:INFO:Set up simple imputation.
2025-04-20 16:34:58,200:INFO:Set up feature normalization.
2025-04-20 16:34:58,218:INFO:Finished creating preprocessing pipeline.
2025-04-20 16:34:58,223:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField', 'EmployeeCount',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobS...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-04-20 16:34:58,223:INFO:Creating final display dataframe.
2025-04-20 16:34:58,279:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (828, 35)
4        Transformed data shape         (828, 34)
5   Transformed train set shape         (579, 34)
6    Transformed test set shape         (249, 34)
7               Ignore features                 1
8              Numeric features                33
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              ccb5
2025-04-20 16:34:58,333:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:34:58,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:34:58,393:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:34:58,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:34:58,396:INFO:setup() successfully completed in 1.81s...............
2025-04-20 16:37:33,600:INFO:PyCaret ClassificationExperiment
2025-04-20 16:37:33,600:INFO:Logging name: clf-default-name
2025-04-20 16:37:33,600:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-20 16:37:33,600:INFO:version 3.0.4
2025-04-20 16:37:33,600:INFO:Initializing setup()
2025-04-20 16:37:33,600:INFO:self.USI: 51fb
2025-04-20 16:37:33,600:INFO:self._variable_keys: {'X', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'gpu_param', 'exp_id', 'data', 'seed', 'fold_groups_param', 'fold_generator', 'y', 'pipeline', 'fix_imbalance', 'y_test', 'target_param', 'logging_param', '_available_plots', 'X_train', 'X_test', 'y_train', 'idx', 'memory', 'exp_name_log', 'USI', '_ml_usecase', 'gpu_n_jobs_param', 'n_jobs_param', 'log_plots_param'}
2025-04-20 16:37:33,600:INFO:Checking environment
2025-04-20 16:37:33,600:INFO:python_version: 3.10.5
2025-04-20 16:37:33,600:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-20 16:37:33,600:INFO:machine: AMD64
2025-04-20 16:37:33,600:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-20 16:37:33,612:INFO:Memory: svmem(total=25042907136, available=14364692480, percent=42.6, used=10678214656, free=14364692480)
2025-04-20 16:37:33,612:INFO:Physical Core: 6
2025-04-20 16:37:33,612:INFO:Logical Core: 12
2025-04-20 16:37:33,612:INFO:Checking libraries
2025-04-20 16:37:33,612:INFO:System:
2025-04-20 16:37:33,612:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-20 16:37:33,612:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-20 16:37:33,612:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-20 16:37:33,612:INFO:PyCaret required dependencies:
2025-04-20 16:37:33,612:INFO:                 pip: 25.0.1
2025-04-20 16:37:33,612:INFO:          setuptools: 58.1.0
2025-04-20 16:37:33,612:INFO:             pycaret: 3.0.4
2025-04-20 16:37:33,612:INFO:             IPython: 8.29.0
2025-04-20 16:37:33,612:INFO:          ipywidgets: 8.1.6
2025-04-20 16:37:33,612:INFO:                tqdm: 4.67.1
2025-04-20 16:37:33,613:INFO:               numpy: 1.23.5
2025-04-20 16:37:33,613:INFO:              pandas: 1.5.3
2025-04-20 16:37:33,613:INFO:              jinja2: 3.1.4
2025-04-20 16:37:33,613:INFO:               scipy: 1.11.4
2025-04-20 16:37:33,613:INFO:              joblib: 1.3.2
2025-04-20 16:37:33,613:INFO:             sklearn: 1.2.2
2025-04-20 16:37:33,613:INFO:                pyod: 2.0.4
2025-04-20 16:37:33,613:INFO:            imblearn: 0.10.1
2025-04-20 16:37:33,613:INFO:   category_encoders: 2.7.0
2025-04-20 16:37:33,613:INFO:            lightgbm: 4.6.0
2025-04-20 16:37:33,613:INFO:               numba: 0.60.0
2025-04-20 16:37:33,613:INFO:            requests: 2.32.3
2025-04-20 16:37:33,613:INFO:          matplotlib: 3.7.5
2025-04-20 16:37:33,613:INFO:          scikitplot: 0.3.7
2025-04-20 16:37:33,613:INFO:         yellowbrick: 1.5
2025-04-20 16:37:33,613:INFO:              plotly: 5.24.1
2025-04-20 16:37:33,613:INFO:    plotly-resampler: Not installed
2025-04-20 16:37:33,613:INFO:             kaleido: 0.2.1
2025-04-20 16:37:33,613:INFO:           schemdraw: 0.15
2025-04-20 16:37:33,613:INFO:         statsmodels: 0.14.4
2025-04-20 16:37:33,613:INFO:              sktime: 0.26.0
2025-04-20 16:37:33,613:INFO:               tbats: 1.1.3
2025-04-20 16:37:33,613:INFO:            pmdarima: 2.0.4
2025-04-20 16:37:33,613:INFO:              psutil: 6.1.0
2025-04-20 16:37:33,613:INFO:          markupsafe: 3.0.2
2025-04-20 16:37:33,613:INFO:             pickle5: Not installed
2025-04-20 16:37:33,613:INFO:         cloudpickle: 3.1.1
2025-04-20 16:37:33,615:INFO:         deprecation: 2.1.0
2025-04-20 16:37:33,615:INFO:              xxhash: 3.5.0
2025-04-20 16:37:33,615:INFO:           wurlitzer: Not installed
2025-04-20 16:37:33,615:INFO:PyCaret optional dependencies:
2025-04-20 16:37:33,615:INFO:                shap: Not installed
2025-04-20 16:37:33,615:INFO:           interpret: Not installed
2025-04-20 16:37:33,615:INFO:                umap: Not installed
2025-04-20 16:37:33,615:INFO:    pandas_profiling: Not installed
2025-04-20 16:37:33,615:INFO:  explainerdashboard: Not installed
2025-04-20 16:37:33,615:INFO:             autoviz: Not installed
2025-04-20 16:37:33,615:INFO:           fairlearn: Not installed
2025-04-20 16:37:33,615:INFO:          deepchecks: Not installed
2025-04-20 16:37:33,615:INFO:             xgboost: 1.7.6
2025-04-20 16:37:33,615:INFO:            catboost: Not installed
2025-04-20 16:37:33,615:INFO:              kmodes: Not installed
2025-04-20 16:37:33,615:INFO:             mlxtend: Not installed
2025-04-20 16:37:33,615:INFO:       statsforecast: Not installed
2025-04-20 16:37:33,615:INFO:        tune_sklearn: Not installed
2025-04-20 16:37:33,615:INFO:                 ray: Not installed
2025-04-20 16:37:33,615:INFO:            hyperopt: Not installed
2025-04-20 16:37:33,615:INFO:              optuna: Not installed
2025-04-20 16:37:33,615:INFO:               skopt: Not installed
2025-04-20 16:37:33,615:INFO:              mlflow: Not installed
2025-04-20 16:37:33,615:INFO:              gradio: Not installed
2025-04-20 16:37:33,615:INFO:             fastapi: Not installed
2025-04-20 16:37:33,615:INFO:             uvicorn: Not installed
2025-04-20 16:37:33,615:INFO:              m2cgen: Not installed
2025-04-20 16:37:33,615:INFO:           evidently: Not installed
2025-04-20 16:37:33,615:INFO:               fugue: Not installed
2025-04-20 16:37:33,615:INFO:           streamlit: 1.42.0
2025-04-20 16:37:33,615:INFO:             prophet: Not installed
2025-04-20 16:37:33,615:INFO:None
2025-04-20 16:37:33,615:INFO:Set up data.
2025-04-20 16:37:33,620:INFO:Set up train/test split.
2025-04-20 16:37:33,620:INFO:Set up index.
2025-04-20 16:37:33,620:INFO:Set up folding strategy.
2025-04-20 16:37:33,620:INFO:Assigning column types.
2025-04-20 16:37:33,628:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-20 16:37:33,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 16:37:33,660:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 16:37:33,679:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:37:33,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:37:33,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 16:37:33,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 16:37:33,730:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:37:33,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:37:33,730:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-20 16:37:33,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 16:37:33,785:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:37:33,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:37:33,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 16:37:33,838:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:37:33,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:37:33,838:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-20 16:37:33,896:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:37:33,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:37:33,960:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:37:33,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:37:33,963:INFO:Preparing preprocessing pipeline...
2025-04-20 16:37:33,963:INFO:Set up simple imputation.
2025-04-20 16:37:33,968:INFO:Set up column name cleaning.
2025-04-20 16:37:33,984:INFO:Finished creating preprocessing pipeline.
2025-04-20 16:37:33,989:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatis...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-04-20 16:37:33,989:INFO:Creating final display dataframe.
2025-04-20 16:37:34,054:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (821, 33)
4        Transformed data shape         (821, 32)
5   Transformed train set shape         (574, 32)
6    Transformed test set shape         (247, 32)
7               Ignore features                 1
8              Numeric features                31
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              51fb
2025-04-20 16:37:34,119:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:37:34,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:37:34,181:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 16:37:34,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 16:37:34,184:INFO:setup() successfully completed in 1.14s...............
2025-04-20 16:37:38,098:INFO:Initializing compare_models()
2025-04-20 16:37:38,098:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-20 16:37:38,098:INFO:Checking exceptions
2025-04-20 16:37:38,101:INFO:Preparing display monitor
2025-04-20 16:37:38,121:INFO:Initializing Logistic Regression
2025-04-20 16:37:38,121:INFO:Total runtime is 0.0 minutes
2025-04-20 16:37:38,124:INFO:SubProcess create_model() called ==================================
2025-04-20 16:37:38,125:INFO:Initializing create_model()
2025-04-20 16:37:38,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:37:38,125:INFO:Checking exceptions
2025-04-20 16:37:38,125:INFO:Importing libraries
2025-04-20 16:37:38,125:INFO:Copying training dataset
2025-04-20 16:37:38,129:INFO:Defining folds
2025-04-20 16:37:38,129:INFO:Declaring metric variables
2025-04-20 16:37:38,132:INFO:Importing untrained model
2025-04-20 16:37:38,134:INFO:Logistic Regression Imported successfully
2025-04-20 16:37:38,141:INFO:Starting cross validation
2025-04-20 16:37:38,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:37:50,580:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,626:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,636:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,640:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,662:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,666:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,678:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,695:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,698:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:37:50,714:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 16:38:00,804:INFO:Calculating mean and std
2025-04-20 16:38:00,805:INFO:Creating metrics dataframe
2025-04-20 16:38:01,979:INFO:Uploading results into container
2025-04-20 16:38:01,979:INFO:Uploading model into container now
2025-04-20 16:38:01,979:INFO:_master_model_container: 1
2025-04-20 16:38:01,979:INFO:_display_container: 2
2025-04-20 16:38:01,982:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-20 16:38:01,982:INFO:create_model() successfully completed......................................
2025-04-20 16:38:02,090:INFO:SubProcess create_model() end ==================================
2025-04-20 16:38:02,090:INFO:Creating metrics dataframe
2025-04-20 16:38:02,101:INFO:Initializing K Neighbors Classifier
2025-04-20 16:38:02,101:INFO:Total runtime is 0.39967288573582965 minutes
2025-04-20 16:38:02,105:INFO:SubProcess create_model() called ==================================
2025-04-20 16:38:02,106:INFO:Initializing create_model()
2025-04-20 16:38:02,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:38:02,106:INFO:Checking exceptions
2025-04-20 16:38:02,106:INFO:Importing libraries
2025-04-20 16:38:02,106:INFO:Copying training dataset
2025-04-20 16:38:02,114:INFO:Defining folds
2025-04-20 16:38:02,114:INFO:Declaring metric variables
2025-04-20 16:38:02,119:INFO:Importing untrained model
2025-04-20 16:38:02,126:INFO:K Neighbors Classifier Imported successfully
2025-04-20 16:38:02,135:INFO:Starting cross validation
2025-04-20 16:38:02,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:38:13,061:INFO:Calculating mean and std
2025-04-20 16:38:13,062:INFO:Creating metrics dataframe
2025-04-20 16:38:14,288:INFO:Uploading results into container
2025-04-20 16:38:14,291:INFO:Uploading model into container now
2025-04-20 16:38:14,291:INFO:_master_model_container: 2
2025-04-20 16:38:14,293:INFO:_display_container: 2
2025-04-20 16:38:14,293:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-20 16:38:14,293:INFO:create_model() successfully completed......................................
2025-04-20 16:38:14,388:INFO:SubProcess create_model() end ==================================
2025-04-20 16:38:14,388:INFO:Creating metrics dataframe
2025-04-20 16:38:14,400:INFO:Initializing Naive Bayes
2025-04-20 16:38:14,400:INFO:Total runtime is 0.6046430150667826 minutes
2025-04-20 16:38:14,408:INFO:SubProcess create_model() called ==================================
2025-04-20 16:38:14,408:INFO:Initializing create_model()
2025-04-20 16:38:14,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:38:14,408:INFO:Checking exceptions
2025-04-20 16:38:14,408:INFO:Importing libraries
2025-04-20 16:38:14,410:INFO:Copying training dataset
2025-04-20 16:38:14,415:INFO:Defining folds
2025-04-20 16:38:14,415:INFO:Declaring metric variables
2025-04-20 16:38:14,425:INFO:Importing untrained model
2025-04-20 16:38:14,428:INFO:Naive Bayes Imported successfully
2025-04-20 16:38:14,438:INFO:Starting cross validation
2025-04-20 16:38:14,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:38:24,672:INFO:Calculating mean and std
2025-04-20 16:38:24,672:INFO:Creating metrics dataframe
2025-04-20 16:38:25,851:INFO:Uploading results into container
2025-04-20 16:38:25,852:INFO:Uploading model into container now
2025-04-20 16:38:25,852:INFO:_master_model_container: 3
2025-04-20 16:38:25,854:INFO:_display_container: 2
2025-04-20 16:38:25,854:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-20 16:38:25,854:INFO:create_model() successfully completed......................................
2025-04-20 16:38:25,948:INFO:SubProcess create_model() end ==================================
2025-04-20 16:38:25,948:INFO:Creating metrics dataframe
2025-04-20 16:38:25,962:INFO:Initializing Decision Tree Classifier
2025-04-20 16:38:25,962:INFO:Total runtime is 0.7973426063855489 minutes
2025-04-20 16:38:25,965:INFO:SubProcess create_model() called ==================================
2025-04-20 16:38:25,966:INFO:Initializing create_model()
2025-04-20 16:38:25,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:38:25,966:INFO:Checking exceptions
2025-04-20 16:38:25,966:INFO:Importing libraries
2025-04-20 16:38:25,966:INFO:Copying training dataset
2025-04-20 16:38:25,972:INFO:Defining folds
2025-04-20 16:38:25,972:INFO:Declaring metric variables
2025-04-20 16:38:25,978:INFO:Importing untrained model
2025-04-20 16:38:25,986:INFO:Decision Tree Classifier Imported successfully
2025-04-20 16:38:25,996:INFO:Starting cross validation
2025-04-20 16:38:25,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:38:36,436:INFO:Calculating mean and std
2025-04-20 16:38:36,440:INFO:Creating metrics dataframe
2025-04-20 16:38:37,599:INFO:Uploading results into container
2025-04-20 16:38:37,599:INFO:Uploading model into container now
2025-04-20 16:38:37,601:INFO:_master_model_container: 4
2025-04-20 16:38:37,601:INFO:_display_container: 2
2025-04-20 16:38:37,601:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-20 16:38:37,602:INFO:create_model() successfully completed......................................
2025-04-20 16:38:37,698:INFO:SubProcess create_model() end ==================================
2025-04-20 16:38:37,698:INFO:Creating metrics dataframe
2025-04-20 16:38:37,708:INFO:Initializing SVM - Linear Kernel
2025-04-20 16:38:37,708:INFO:Total runtime is 0.9931223352750143 minutes
2025-04-20 16:38:37,714:INFO:SubProcess create_model() called ==================================
2025-04-20 16:38:37,714:INFO:Initializing create_model()
2025-04-20 16:38:37,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:38:37,715:INFO:Checking exceptions
2025-04-20 16:38:37,715:INFO:Importing libraries
2025-04-20 16:38:37,715:INFO:Copying training dataset
2025-04-20 16:38:37,722:INFO:Defining folds
2025-04-20 16:38:37,722:INFO:Declaring metric variables
2025-04-20 16:38:37,728:INFO:Importing untrained model
2025-04-20 16:38:37,734:INFO:SVM - Linear Kernel Imported successfully
2025-04-20 16:38:37,743:INFO:Starting cross validation
2025-04-20 16:38:37,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:38:37,860:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,862:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,868:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-20 16:38:37,878:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,882:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,886:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,894:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,894:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,908:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,912:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:37,916:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-20 16:38:37,919:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 16:38:47,897:INFO:Calculating mean and std
2025-04-20 16:38:47,898:INFO:Creating metrics dataframe
2025-04-20 16:38:49,125:INFO:Uploading results into container
2025-04-20 16:38:49,128:INFO:Uploading model into container now
2025-04-20 16:38:49,128:INFO:_master_model_container: 5
2025-04-20 16:38:49,128:INFO:_display_container: 2
2025-04-20 16:38:49,128:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-20 16:38:49,128:INFO:create_model() successfully completed......................................
2025-04-20 16:38:49,229:INFO:SubProcess create_model() end ==================================
2025-04-20 16:38:49,229:INFO:Creating metrics dataframe
2025-04-20 16:38:49,241:INFO:Initializing Ridge Classifier
2025-04-20 16:38:49,241:INFO:Total runtime is 1.1853402733802796 minutes
2025-04-20 16:38:49,253:INFO:SubProcess create_model() called ==================================
2025-04-20 16:38:49,255:INFO:Initializing create_model()
2025-04-20 16:38:49,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:38:49,255:INFO:Checking exceptions
2025-04-20 16:38:49,256:INFO:Importing libraries
2025-04-20 16:38:49,256:INFO:Copying training dataset
2025-04-20 16:38:49,265:INFO:Defining folds
2025-04-20 16:38:49,265:INFO:Declaring metric variables
2025-04-20 16:38:49,273:INFO:Importing untrained model
2025-04-20 16:38:49,280:INFO:Ridge Classifier Imported successfully
2025-04-20 16:38:49,290:INFO:Starting cross validation
2025-04-20 16:38:49,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:38:49,420:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,422:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,426:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,426:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,434:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,436:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,452:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,454:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,460:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:49,460:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 16:38:56,790:INFO:Calculating mean and std
2025-04-20 16:38:56,791:INFO:Creating metrics dataframe
2025-04-20 16:38:57,485:INFO:Uploading results into container
2025-04-20 16:38:57,485:INFO:Uploading model into container now
2025-04-20 16:38:57,486:INFO:_master_model_container: 6
2025-04-20 16:38:57,486:INFO:_display_container: 2
2025-04-20 16:38:57,487:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-20 16:38:57,487:INFO:create_model() successfully completed......................................
2025-04-20 16:38:57,567:INFO:SubProcess create_model() end ==================================
2025-04-20 16:38:57,567:INFO:Creating metrics dataframe
2025-04-20 16:38:57,575:INFO:Initializing Random Forest Classifier
2025-04-20 16:38:57,575:INFO:Total runtime is 1.3242335041364035 minutes
2025-04-20 16:38:57,577:INFO:SubProcess create_model() called ==================================
2025-04-20 16:38:57,578:INFO:Initializing create_model()
2025-04-20 16:38:57,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:38:57,578:INFO:Checking exceptions
2025-04-20 16:38:57,578:INFO:Importing libraries
2025-04-20 16:38:57,578:INFO:Copying training dataset
2025-04-20 16:38:57,582:INFO:Defining folds
2025-04-20 16:38:57,582:INFO:Declaring metric variables
2025-04-20 16:38:57,585:INFO:Importing untrained model
2025-04-20 16:38:57,591:INFO:Random Forest Classifier Imported successfully
2025-04-20 16:38:57,604:INFO:Starting cross validation
2025-04-20 16:38:57,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:39:04,501:INFO:Calculating mean and std
2025-04-20 16:39:04,503:INFO:Creating metrics dataframe
2025-04-20 16:39:05,193:INFO:Uploading results into container
2025-04-20 16:39:05,194:INFO:Uploading model into container now
2025-04-20 16:39:05,194:INFO:_master_model_container: 7
2025-04-20 16:39:05,194:INFO:_display_container: 2
2025-04-20 16:39:05,194:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-20 16:39:05,196:INFO:create_model() successfully completed......................................
2025-04-20 16:39:05,276:INFO:SubProcess create_model() end ==================================
2025-04-20 16:39:05,277:INFO:Creating metrics dataframe
2025-04-20 16:39:05,284:INFO:Initializing Quadratic Discriminant Analysis
2025-04-20 16:39:05,285:INFO:Total runtime is 1.452724345525106 minutes
2025-04-20 16:39:05,287:INFO:SubProcess create_model() called ==================================
2025-04-20 16:39:05,288:INFO:Initializing create_model()
2025-04-20 16:39:05,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:39:05,288:INFO:Checking exceptions
2025-04-20 16:39:05,288:INFO:Importing libraries
2025-04-20 16:39:05,288:INFO:Copying training dataset
2025-04-20 16:39:05,290:INFO:Defining folds
2025-04-20 16:39:05,290:INFO:Declaring metric variables
2025-04-20 16:39:05,293:INFO:Importing untrained model
2025-04-20 16:39:05,296:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-20 16:39:05,305:INFO:Starting cross validation
2025-04-20 16:39:05,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:39:11,498:INFO:Calculating mean and std
2025-04-20 16:39:11,499:INFO:Creating metrics dataframe
2025-04-20 16:39:12,190:INFO:Uploading results into container
2025-04-20 16:39:12,190:INFO:Uploading model into container now
2025-04-20 16:39:12,191:INFO:_master_model_container: 8
2025-04-20 16:39:12,191:INFO:_display_container: 2
2025-04-20 16:39:12,191:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-20 16:39:12,191:INFO:create_model() successfully completed......................................
2025-04-20 16:39:12,272:INFO:SubProcess create_model() end ==================================
2025-04-20 16:39:12,273:INFO:Creating metrics dataframe
2025-04-20 16:39:12,282:INFO:Initializing Ada Boost Classifier
2025-04-20 16:39:12,282:INFO:Total runtime is 1.5693483988444012 minutes
2025-04-20 16:39:12,285:INFO:SubProcess create_model() called ==================================
2025-04-20 16:39:12,285:INFO:Initializing create_model()
2025-04-20 16:39:12,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:39:12,285:INFO:Checking exceptions
2025-04-20 16:39:12,285:INFO:Importing libraries
2025-04-20 16:39:12,285:INFO:Copying training dataset
2025-04-20 16:39:12,289:INFO:Defining folds
2025-04-20 16:39:12,289:INFO:Declaring metric variables
2025-04-20 16:39:12,293:INFO:Importing untrained model
2025-04-20 16:39:12,298:INFO:Ada Boost Classifier Imported successfully
2025-04-20 16:39:12,306:INFO:Starting cross validation
2025-04-20 16:39:12,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:39:18,797:INFO:Calculating mean and std
2025-04-20 16:39:18,798:INFO:Creating metrics dataframe
2025-04-20 16:39:19,497:INFO:Uploading results into container
2025-04-20 16:39:19,497:INFO:Uploading model into container now
2025-04-20 16:39:19,497:INFO:_master_model_container: 9
2025-04-20 16:39:19,499:INFO:_display_container: 2
2025-04-20 16:39:19,499:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-20 16:39:19,499:INFO:create_model() successfully completed......................................
2025-04-20 16:39:19,581:INFO:SubProcess create_model() end ==================================
2025-04-20 16:39:19,581:INFO:Creating metrics dataframe
2025-04-20 16:39:19,590:INFO:Initializing Gradient Boosting Classifier
2025-04-20 16:39:19,590:INFO:Total runtime is 1.6911437551180524 minutes
2025-04-20 16:39:19,592:INFO:SubProcess create_model() called ==================================
2025-04-20 16:39:19,592:INFO:Initializing create_model()
2025-04-20 16:39:19,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:39:19,593:INFO:Checking exceptions
2025-04-20 16:39:19,593:INFO:Importing libraries
2025-04-20 16:39:19,593:INFO:Copying training dataset
2025-04-20 16:39:19,596:INFO:Defining folds
2025-04-20 16:39:19,598:INFO:Declaring metric variables
2025-04-20 16:39:19,603:INFO:Importing untrained model
2025-04-20 16:39:19,609:INFO:Gradient Boosting Classifier Imported successfully
2025-04-20 16:39:19,614:INFO:Starting cross validation
2025-04-20 16:39:19,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:39:26,234:INFO:Calculating mean and std
2025-04-20 16:39:26,236:INFO:Creating metrics dataframe
2025-04-20 16:39:26,966:INFO:Uploading results into container
2025-04-20 16:39:26,966:INFO:Uploading model into container now
2025-04-20 16:39:26,967:INFO:_master_model_container: 10
2025-04-20 16:39:26,967:INFO:_display_container: 2
2025-04-20 16:39:26,967:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-20 16:39:26,967:INFO:create_model() successfully completed......................................
2025-04-20 16:39:27,048:INFO:SubProcess create_model() end ==================================
2025-04-20 16:39:27,048:INFO:Creating metrics dataframe
2025-04-20 16:39:27,056:INFO:Initializing Linear Discriminant Analysis
2025-04-20 16:39:27,058:INFO:Total runtime is 1.8155890623728437 minutes
2025-04-20 16:39:27,061:INFO:SubProcess create_model() called ==================================
2025-04-20 16:39:27,061:INFO:Initializing create_model()
2025-04-20 16:39:27,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:39:27,061:INFO:Checking exceptions
2025-04-20 16:39:27,061:INFO:Importing libraries
2025-04-20 16:39:27,061:INFO:Copying training dataset
2025-04-20 16:39:27,065:INFO:Defining folds
2025-04-20 16:39:27,065:INFO:Declaring metric variables
2025-04-20 16:39:27,070:INFO:Importing untrained model
2025-04-20 16:39:27,074:INFO:Linear Discriminant Analysis Imported successfully
2025-04-20 16:39:27,081:INFO:Starting cross validation
2025-04-20 16:39:27,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:39:33,333:INFO:Calculating mean and std
2025-04-20 16:39:33,334:INFO:Creating metrics dataframe
2025-04-20 16:39:34,056:INFO:Uploading results into container
2025-04-20 16:39:34,057:INFO:Uploading model into container now
2025-04-20 16:39:34,057:INFO:_master_model_container: 11
2025-04-20 16:39:34,057:INFO:_display_container: 2
2025-04-20 16:39:34,058:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-20 16:39:34,058:INFO:create_model() successfully completed......................................
2025-04-20 16:39:34,138:INFO:SubProcess create_model() end ==================================
2025-04-20 16:39:34,138:INFO:Creating metrics dataframe
2025-04-20 16:39:34,148:INFO:Initializing Extra Trees Classifier
2025-04-20 16:39:34,149:INFO:Total runtime is 1.9337966601053875 minutes
2025-04-20 16:39:34,151:INFO:SubProcess create_model() called ==================================
2025-04-20 16:39:34,151:INFO:Initializing create_model()
2025-04-20 16:39:34,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:39:34,151:INFO:Checking exceptions
2025-04-20 16:39:34,152:INFO:Importing libraries
2025-04-20 16:39:34,152:INFO:Copying training dataset
2025-04-20 16:39:34,154:INFO:Defining folds
2025-04-20 16:39:34,155:INFO:Declaring metric variables
2025-04-20 16:39:34,157:INFO:Importing untrained model
2025-04-20 16:39:34,162:INFO:Extra Trees Classifier Imported successfully
2025-04-20 16:39:34,169:INFO:Starting cross validation
2025-04-20 16:39:34,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:39:40,993:INFO:Calculating mean and std
2025-04-20 16:39:40,994:INFO:Creating metrics dataframe
2025-04-20 16:39:41,723:INFO:Uploading results into container
2025-04-20 16:39:41,724:INFO:Uploading model into container now
2025-04-20 16:39:41,724:INFO:_master_model_container: 12
2025-04-20 16:39:41,724:INFO:_display_container: 2
2025-04-20 16:39:41,724:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 16:39:41,724:INFO:create_model() successfully completed......................................
2025-04-20 16:39:41,804:INFO:SubProcess create_model() end ==================================
2025-04-20 16:39:41,805:INFO:Creating metrics dataframe
2025-04-20 16:39:41,814:INFO:Initializing Extreme Gradient Boosting
2025-04-20 16:39:41,814:INFO:Total runtime is 2.0615459720293683 minutes
2025-04-20 16:39:41,817:INFO:SubProcess create_model() called ==================================
2025-04-20 16:39:41,817:INFO:Initializing create_model()
2025-04-20 16:39:41,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:39:41,817:INFO:Checking exceptions
2025-04-20 16:39:41,817:INFO:Importing libraries
2025-04-20 16:39:41,817:INFO:Copying training dataset
2025-04-20 16:39:41,819:INFO:Defining folds
2025-04-20 16:39:41,819:INFO:Declaring metric variables
2025-04-20 16:39:41,823:INFO:Importing untrained model
2025-04-20 16:39:41,827:INFO:Extreme Gradient Boosting Imported successfully
2025-04-20 16:39:41,836:INFO:Starting cross validation
2025-04-20 16:39:41,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:39:50,182:INFO:Calculating mean and std
2025-04-20 16:39:50,184:INFO:Creating metrics dataframe
2025-04-20 16:39:50,942:INFO:Uploading results into container
2025-04-20 16:39:50,942:INFO:Uploading model into container now
2025-04-20 16:39:50,943:INFO:_master_model_container: 13
2025-04-20 16:39:50,943:INFO:_display_container: 2
2025-04-20 16:39:50,945:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-20 16:39:50,945:INFO:create_model() successfully completed......................................
2025-04-20 16:39:51,024:INFO:SubProcess create_model() end ==================================
2025-04-20 16:39:51,024:INFO:Creating metrics dataframe
2025-04-20 16:39:51,034:INFO:Initializing Light Gradient Boosting Machine
2025-04-20 16:39:51,034:INFO:Total runtime is 2.2152141412099207 minutes
2025-04-20 16:39:51,037:INFO:SubProcess create_model() called ==================================
2025-04-20 16:39:51,037:INFO:Initializing create_model()
2025-04-20 16:39:51,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:39:51,037:INFO:Checking exceptions
2025-04-20 16:39:51,037:INFO:Importing libraries
2025-04-20 16:39:51,037:INFO:Copying training dataset
2025-04-20 16:39:51,042:INFO:Defining folds
2025-04-20 16:39:51,042:INFO:Declaring metric variables
2025-04-20 16:39:51,046:INFO:Importing untrained model
2025-04-20 16:39:51,055:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-20 16:39:51,060:INFO:Starting cross validation
2025-04-20 16:39:51,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:39:59,026:INFO:Calculating mean and std
2025-04-20 16:39:59,027:INFO:Creating metrics dataframe
2025-04-20 16:40:00,264:INFO:Uploading results into container
2025-04-20 16:40:00,265:INFO:Uploading model into container now
2025-04-20 16:40:00,266:INFO:_master_model_container: 14
2025-04-20 16:40:00,266:INFO:_display_container: 2
2025-04-20 16:40:00,267:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-20 16:40:00,267:INFO:create_model() successfully completed......................................
2025-04-20 16:40:00,367:INFO:SubProcess create_model() end ==================================
2025-04-20 16:40:00,367:INFO:Creating metrics dataframe
2025-04-20 16:40:00,384:INFO:Initializing Dummy Classifier
2025-04-20 16:40:00,384:INFO:Total runtime is 2.371055630842845 minutes
2025-04-20 16:40:00,389:INFO:SubProcess create_model() called ==================================
2025-04-20 16:40:00,389:INFO:Initializing create_model()
2025-04-20 16:40:00,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025372BEC6D0>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:40:00,389:INFO:Checking exceptions
2025-04-20 16:40:00,389:INFO:Importing libraries
2025-04-20 16:40:00,389:INFO:Copying training dataset
2025-04-20 16:40:00,398:INFO:Defining folds
2025-04-20 16:40:00,398:INFO:Declaring metric variables
2025-04-20 16:40:00,404:INFO:Importing untrained model
2025-04-20 16:40:00,410:INFO:Dummy Classifier Imported successfully
2025-04-20 16:40:00,422:INFO:Starting cross validation
2025-04-20 16:40:00,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 16:40:12,247:INFO:Calculating mean and std
2025-04-20 16:40:12,248:INFO:Creating metrics dataframe
2025-04-20 16:40:13,585:INFO:Uploading results into container
2025-04-20 16:40:13,586:INFO:Uploading model into container now
2025-04-20 16:40:13,587:INFO:_master_model_container: 15
2025-04-20 16:40:13,587:INFO:_display_container: 2
2025-04-20 16:40:13,587:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-20 16:40:13,588:INFO:create_model() successfully completed......................................
2025-04-20 16:40:13,691:INFO:SubProcess create_model() end ==================================
2025-04-20 16:40:13,691:INFO:Creating metrics dataframe
2025-04-20 16:40:13,721:INFO:Initializing create_model()
2025-04-20 16:40:13,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-20 16:40:13,722:INFO:Checking exceptions
2025-04-20 16:40:13,724:INFO:Importing libraries
2025-04-20 16:40:13,725:INFO:Copying training dataset
2025-04-20 16:40:13,732:INFO:Defining folds
2025-04-20 16:40:13,732:INFO:Declaring metric variables
2025-04-20 16:40:13,734:INFO:Importing untrained model
2025-04-20 16:40:13,734:INFO:Declaring custom model
2025-04-20 16:40:13,735:INFO:Extra Trees Classifier Imported successfully
2025-04-20 16:40:13,736:INFO:Cross validation set to False
2025-04-20 16:40:13,736:INFO:Fitting Model
2025-04-20 16:40:15,285:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 16:40:15,285:INFO:create_model() successfully completed......................................
2025-04-20 16:40:15,399:INFO:_master_model_container: 15
2025-04-20 16:40:15,401:INFO:_display_container: 2
2025-04-20 16:40:15,401:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 16:40:15,401:INFO:compare_models() successfully completed......................................
2025-04-20 16:40:31,016:INFO:Initializing evaluate_model()
2025-04-20 16:40:31,016:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-20 16:40:31,023:INFO:Initializing plot_model()
2025-04-20 16:40:31,023:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, system=True)
2025-04-20 16:40:31,023:INFO:Checking exceptions
2025-04-20 16:40:31,058:INFO:Preloading libraries
2025-04-20 16:40:31,070:INFO:Copying training dataset
2025-04-20 16:40:31,071:INFO:Plot type: pipeline
2025-04-20 16:40:31,228:INFO:Visual Rendered Successfully
2025-04-20 16:40:31,315:INFO:plot_model() successfully completed......................................
2025-04-20 16:40:41,651:INFO:Initializing finalize_model()
2025-04-20 16:40:41,653:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-20 16:40:41,653:INFO:Finalizing ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 16:40:41,655:INFO:Initializing create_model()
2025-04-20 16:40:41,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002537386D5D0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-04-20 16:40:41,656:INFO:Checking exceptions
2025-04-20 16:40:41,657:INFO:Importing libraries
2025-04-20 16:40:41,657:INFO:Copying training dataset
2025-04-20 16:40:41,657:INFO:Defining folds
2025-04-20 16:40:41,657:INFO:Declaring metric variables
2025-04-20 16:40:41,657:INFO:Importing untrained model
2025-04-20 16:40:41,657:INFO:Declaring custom model
2025-04-20 16:40:41,658:INFO:Extra Trees Classifier Imported successfully
2025-04-20 16:40:41,659:INFO:Cross validation set to False
2025-04-20 16:40:41,659:INFO:Fitting Model
2025-04-20 16:40:41,867:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatis...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 16:40:41,867:INFO:create_model() successfully completed......................................
2025-04-20 16:40:41,952:INFO:_master_model_container: 15
2025-04-20 16:40:41,952:INFO:_display_container: 2
2025-04-20 16:40:41,956:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatis...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 16:40:41,957:INFO:finalize_model() successfully completed......................................
2025-04-20 16:40:42,045:INFO:Initializing save_model()
2025-04-20 16:40:42,045:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatis...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False), model_name=model_attrition, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatis...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-04-20 16:40:42,045:INFO:Adding model into prep_pipe
2025-04-20 16:40:42,045:WARNING:Only Model saved as it was a pipeline.
2025-04-20 16:40:42,076:INFO:model_attrition.pkl saved in current working directory
2025-04-20 16:40:42,081:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatis...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 16:40:42,081:INFO:save_model() successfully completed......................................
2025-04-20 16:53:18,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:53:18,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:53:18,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:53:18,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:53:19,173:INFO:Initializing load_model()
2025-04-20 16:53:19,173:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:53:38,059:INFO:Initializing load_model()
2025-04-20 16:53:38,059:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:53:38,124:INFO:Initializing predict_model()
2025-04-20 16:53:38,124:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023381023D00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000233825505E0>)
2025-04-20 16:53:38,124:INFO:Checking exceptions
2025-04-20 16:53:38,125:INFO:Preloading libraries
2025-04-20 16:53:38,125:INFO:Set up data.
2025-04-20 16:53:38,135:INFO:Set up index.
2025-04-20 16:54:46,331:INFO:Initializing load_model()
2025-04-20 16:54:46,331:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:54:46,392:INFO:Initializing predict_model()
2025-04-20 16:54:46,392:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002338251C8E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291BE20>)
2025-04-20 16:54:46,396:INFO:Checking exceptions
2025-04-20 16:54:46,396:INFO:Preloading libraries
2025-04-20 16:54:46,396:INFO:Set up data.
2025-04-20 16:54:46,404:INFO:Set up index.
2025-04-20 16:54:49,168:INFO:Initializing load_model()
2025-04-20 16:54:49,168:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:54:49,223:INFO:Initializing predict_model()
2025-04-20 16:54:49,223:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233822BB4C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291BBE0>)
2025-04-20 16:54:49,223:INFO:Checking exceptions
2025-04-20 16:54:49,226:INFO:Preloading libraries
2025-04-20 16:54:49,226:INFO:Set up data.
2025-04-20 16:54:49,236:INFO:Set up index.
2025-04-20 16:54:58,533:INFO:Initializing load_model()
2025-04-20 16:54:58,533:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:54:58,596:INFO:Initializing predict_model()
2025-04-20 16:54:58,596:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233829D6A70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291B880>)
2025-04-20 16:54:58,596:INFO:Checking exceptions
2025-04-20 16:54:58,597:INFO:Preloading libraries
2025-04-20 16:54:58,597:INFO:Set up data.
2025-04-20 16:54:58,607:INFO:Set up index.
2025-04-20 16:55:00,276:INFO:Initializing load_model()
2025-04-20 16:55:00,276:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:00,336:INFO:Initializing predict_model()
2025-04-20 16:55:00,337:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233822BBA00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291BB50>)
2025-04-20 16:55:00,337:INFO:Checking exceptions
2025-04-20 16:55:00,337:INFO:Preloading libraries
2025-04-20 16:55:00,337:INFO:Set up data.
2025-04-20 16:55:00,346:INFO:Set up index.
2025-04-20 16:55:01,024:INFO:Initializing load_model()
2025-04-20 16:55:01,025:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:01,094:INFO:Initializing predict_model()
2025-04-20 16:55:01,096:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233822BB880>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291B7F0>)
2025-04-20 16:55:01,096:INFO:Checking exceptions
2025-04-20 16:55:01,096:INFO:Preloading libraries
2025-04-20 16:55:01,096:INFO:Set up data.
2025-04-20 16:55:01,103:INFO:Set up index.
2025-04-20 16:55:01,604:INFO:Initializing load_model()
2025-04-20 16:55:01,605:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:02,079:INFO:Initializing load_model()
2025-04-20 16:55:02,079:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:02,150:INFO:Initializing predict_model()
2025-04-20 16:55:02,150:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233CCB36E60>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023382A740D0>)
2025-04-20 16:55:02,150:INFO:Checking exceptions
2025-04-20 16:55:02,150:INFO:Preloading libraries
2025-04-20 16:55:02,150:INFO:Set up data.
2025-04-20 16:55:02,161:INFO:Set up index.
2025-04-20 16:55:03,696:INFO:Initializing load_model()
2025-04-20 16:55:03,696:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:03,768:INFO:Initializing predict_model()
2025-04-20 16:55:03,768:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023382A8D450>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023382A7C310>)
2025-04-20 16:55:03,769:INFO:Checking exceptions
2025-04-20 16:55:03,769:INFO:Preloading libraries
2025-04-20 16:55:03,769:INFO:Set up data.
2025-04-20 16:55:03,781:INFO:Set up index.
2025-04-20 16:55:05,412:INFO:Initializing load_model()
2025-04-20 16:55:05,412:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:05,462:INFO:Initializing predict_model()
2025-04-20 16:55:05,462:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023382ADB610>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291BF40>)
2025-04-20 16:55:05,462:INFO:Checking exceptions
2025-04-20 16:55:05,462:INFO:Preloading libraries
2025-04-20 16:55:05,462:INFO:Set up data.
2025-04-20 16:55:05,472:INFO:Set up index.
2025-04-20 16:55:12,086:INFO:Initializing load_model()
2025-04-20 16:55:12,086:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:12,145:INFO:Initializing predict_model()
2025-04-20 16:55:12,146:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233822BB940>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291BC70>)
2025-04-20 16:55:12,146:INFO:Checking exceptions
2025-04-20 16:55:12,146:INFO:Preloading libraries
2025-04-20 16:55:12,146:INFO:Set up data.
2025-04-20 16:55:12,156:INFO:Set up index.
2025-04-20 16:55:15,112:INFO:Initializing load_model()
2025-04-20 16:55:15,112:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:15,178:INFO:Initializing predict_model()
2025-04-20 16:55:15,178:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000233810BA050>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291BD90>)
2025-04-20 16:55:15,178:INFO:Checking exceptions
2025-04-20 16:55:15,178:INFO:Preloading libraries
2025-04-20 16:55:15,178:INFO:Set up data.
2025-04-20 16:55:15,187:INFO:Set up index.
2025-04-20 16:55:15,280:INFO:Initializing load_model()
2025-04-20 16:55:15,280:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:15,352:INFO:Initializing predict_model()
2025-04-20 16:55:15,352:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002338251E530>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002338291B7F0>)
2025-04-20 16:55:15,352:INFO:Checking exceptions
2025-04-20 16:55:15,353:INFO:Preloading libraries
2025-04-20 16:55:15,353:INFO:Set up data.
2025-04-20 16:55:15,362:INFO:Set up index.
2025-04-20 16:55:15,468:INFO:Initializing load_model()
2025-04-20 16:55:15,468:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:55:15,533:INFO:Initializing predict_model()
2025-04-20 16:55:15,536:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002338251E920>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023382A44670>)
2025-04-20 16:55:15,536:INFO:Checking exceptions
2025-04-20 16:55:15,536:INFO:Preloading libraries
2025-04-20 16:55:15,536:INFO:Set up data.
2025-04-20 16:55:15,545:INFO:Set up index.
2025-04-20 16:57:44,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:57:44,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:57:44,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:57:44,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:57:45,193:INFO:Initializing load_model()
2025-04-20 16:57:45,193:INFO:load_model(model_name=model_attrition.pkl, platform=None, authentication=None, verbose=True)
2025-04-20 16:58:29,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:58:29,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:58:29,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:58:29,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 16:58:30,528:INFO:Initializing load_model()
2025-04-20 16:58:30,528:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:58:36,420:INFO:Initializing load_model()
2025-04-20 16:58:36,420:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 16:58:36,487:INFO:Initializing predict_model()
2025-04-20 16:58:36,489:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018DB6FA6470>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018DB713FB50>)
2025-04-20 16:58:36,489:INFO:Checking exceptions
2025-04-20 16:58:36,489:INFO:Preloading libraries
2025-04-20 16:58:36,490:INFO:Set up data.
2025-04-20 16:58:36,502:INFO:Set up index.
2025-04-20 17:01:38,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:01:38,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:01:38,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:01:38,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:01:39,177:INFO:Initializing load_model()
2025-04-20 17:01:39,177:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:01:44,528:INFO:Initializing load_model()
2025-04-20 17:01:44,528:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:01:44,589:INFO:Initializing predict_model()
2025-04-20 17:01:44,589:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CB2C283F10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Age',
                                             'BusinessTravel', 'DailyRate',
                                             'Department', 'DistanceFromHome',
                                             'Education', 'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Mar...
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CB2D6B3AC0>)
2025-04-20 17:01:44,589:INFO:Checking exceptions
2025-04-20 17:01:44,590:INFO:Preloading libraries
2025-04-20 17:01:44,590:INFO:Set up data.
2025-04-20 17:01:44,599:INFO:Set up index.
2025-04-20 17:03:37,894:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_51b78518da654ca79fb81d7698152438
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,894:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_42418d7868864c959a1564c91a332c90_39e5d4385c7a43bfa47aa5e1eecb1c03
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,894:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_0ce64ddc14ce47c88067cfddba38502d
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,894:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_33cc24925fd645838664f51246f69ca2_b766bdc26b03454480b86f8d60426645
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,894:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_48bd9ba9d3d540ea9f5b381a8fc4ebb8
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,894:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_32a8b2f8678f44a0adffd53d5245a71f_48358d5290fc4437b97f277e0cbccb2a
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_6cec6428872948ffbc40b65460728e77
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_35fdb355ee064624a9a90d5ae5f789b1_d59f5cb99b154e14ac70abad04dcb6c6
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_589616af522445c1a6cd72789f85f9e9
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_af0b7c5b63244835a42cdee32c543384_26daa69d0a2d47859e814e99e7aefb3d
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_4dd94266aa234cd0b884a53f43d6f871
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_91dafeca3ede464c91ec389610637e1d_e9c668f79b25462f8c3b9a47a2c308d7
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_84deaae0dc154929ac892dfc560e24b0
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_44e673e67ecd45b084fe34cf26b66a3b_6040ae6ca0d5426a98ad62990506016d
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_7ad776414352436789965544ac993408
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_34123f504f374447ad345563b57c2c5b_f831b66c4f104f3899a8b7ded95eefa8
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_195a8ccbcf26433ab5e4360396d4d91f
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,895:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_5c94304ef9f1465eafb1479df4e5ddfd_5838959ba0044b97a545fe2cae29955f
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,896:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_7d20417c4e4b404e91f7ca22834a8d86
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,896:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_be995f9f17134631a5bd1c182dda1eea_d083843304eb4ea28c56bf8d6215b523
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,896:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_63fbb0f9c2c944e193ed88c98a384057
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,896:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_7f2f8c4ea46a42bda2ed91a39d7cf84b_ac923ceed5ec4920bfdbe3b195187322
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,896:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_50c945a3bb0e4ba9b24714649b8c6759
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,897:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_09d838e30e5a4adc84efdfbc0a860dad_010d023a853545d898def6ab743cd108
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,897:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_662aade99f3044608869370394ce7a54
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,897:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_ad7c75d7917c4817a982c1c80fe4c5a5_63bfcbaa65844a8482e08768cbcde68a
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,897:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_5aaefb4b1a034211a254648eaa258d3e
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,897:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_389aa43ea2e948928facb1422fcb066c_30d2cca709a9481485e9fcf0db359f70
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,897:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_99e0896c7ece4e9f8be0ca4bd7479bd4
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:37,897:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\zaina\AppData\Local\Temp\joblib_memmapping_folder_2408_562a6c2c86d94f609dfa6506ff1d3b95_06a652d66a204880af27d14b3ea5d60f
  warnings.warn("Failed to delete temporary folder: {}"

2025-04-20 17:03:56,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:03:56,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:03:56,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:03:56,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:04:09,431:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_17864\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-20 17:04:15,409:INFO:PyCaret ClassificationExperiment
2025-04-20 17:04:15,409:INFO:Logging name: clf-default-name
2025-04-20 17:04:15,409:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-20 17:04:15,409:INFO:version 3.0.4
2025-04-20 17:04:15,409:INFO:Initializing setup()
2025-04-20 17:04:15,409:INFO:self.USI: 723b
2025-04-20 17:04:15,409:INFO:self._variable_keys: {'exp_id', 'logging_param', 'n_jobs_param', 'USI', 'y_train', 'gpu_n_jobs_param', 'pipeline', 'y', 'X_train', 'y_test', 'html_param', 'fold_generator', 'fix_imbalance', 'X_test', 'fold_groups_param', 'seed', 'exp_name_log', 'X', 'fold_shuffle_param', 'is_multiclass', 'memory', 'log_plots_param', 'idx', 'target_param', 'data', '_ml_usecase', 'gpu_param', '_available_plots'}
2025-04-20 17:04:15,409:INFO:Checking environment
2025-04-20 17:04:15,409:INFO:python_version: 3.10.5
2025-04-20 17:04:15,409:INFO:python_build: ('tags/v3.10.5:f377153', 'Jun  6 2022 16:14:13')
2025-04-20 17:04:15,409:INFO:machine: AMD64
2025-04-20 17:04:15,409:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-20 17:04:15,416:INFO:Memory: svmem(total=25042907136, available=8508252160, percent=66.0, used=16534654976, free=8508252160)
2025-04-20 17:04:15,416:INFO:Physical Core: 6
2025-04-20 17:04:15,416:INFO:Logical Core: 12
2025-04-20 17:04:15,416:INFO:Checking libraries
2025-04-20 17:04:15,416:INFO:System:
2025-04-20 17:04:15,416:INFO:    python: 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]
2025-04-20 17:04:15,416:INFO:executable: C:\Users\zaina\AppData\Local\Programs\Python\Python310\python.exe
2025-04-20 17:04:15,416:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-20 17:04:15,416:INFO:PyCaret required dependencies:
2025-04-20 17:04:15,459:INFO:                 pip: 25.0.1
2025-04-20 17:04:15,459:INFO:          setuptools: 58.1.0
2025-04-20 17:04:15,459:INFO:             pycaret: 3.0.4
2025-04-20 17:04:15,459:INFO:             IPython: 8.29.0
2025-04-20 17:04:15,459:INFO:          ipywidgets: 8.1.6
2025-04-20 17:04:15,459:INFO:                tqdm: 4.67.1
2025-04-20 17:04:15,459:INFO:               numpy: 1.23.5
2025-04-20 17:04:15,459:INFO:              pandas: 1.5.3
2025-04-20 17:04:15,459:INFO:              jinja2: 3.1.4
2025-04-20 17:04:15,459:INFO:               scipy: 1.11.4
2025-04-20 17:04:15,459:INFO:              joblib: 1.3.2
2025-04-20 17:04:15,459:INFO:             sklearn: 1.2.2
2025-04-20 17:04:15,459:INFO:                pyod: 2.0.4
2025-04-20 17:04:15,459:INFO:            imblearn: 0.10.1
2025-04-20 17:04:15,459:INFO:   category_encoders: 2.7.0
2025-04-20 17:04:15,459:INFO:            lightgbm: 4.6.0
2025-04-20 17:04:15,459:INFO:               numba: 0.60.0
2025-04-20 17:04:15,461:INFO:            requests: 2.32.3
2025-04-20 17:04:15,461:INFO:          matplotlib: 3.7.5
2025-04-20 17:04:15,461:INFO:          scikitplot: 0.3.7
2025-04-20 17:04:15,461:INFO:         yellowbrick: 1.5
2025-04-20 17:04:15,461:INFO:              plotly: 5.24.1
2025-04-20 17:04:15,461:INFO:    plotly-resampler: Not installed
2025-04-20 17:04:15,461:INFO:             kaleido: 0.2.1
2025-04-20 17:04:15,461:INFO:           schemdraw: 0.15
2025-04-20 17:04:15,461:INFO:         statsmodels: 0.14.4
2025-04-20 17:04:15,461:INFO:              sktime: 0.26.0
2025-04-20 17:04:15,461:INFO:               tbats: 1.1.3
2025-04-20 17:04:15,461:INFO:            pmdarima: 2.0.4
2025-04-20 17:04:15,461:INFO:              psutil: 6.1.0
2025-04-20 17:04:15,461:INFO:          markupsafe: 3.0.2
2025-04-20 17:04:15,461:INFO:             pickle5: Not installed
2025-04-20 17:04:15,461:INFO:         cloudpickle: 3.1.1
2025-04-20 17:04:15,461:INFO:         deprecation: 2.1.0
2025-04-20 17:04:15,461:INFO:              xxhash: 3.5.0
2025-04-20 17:04:15,461:INFO:           wurlitzer: Not installed
2025-04-20 17:04:15,461:INFO:PyCaret optional dependencies:
2025-04-20 17:04:15,470:INFO:                shap: Not installed
2025-04-20 17:04:15,470:INFO:           interpret: Not installed
2025-04-20 17:04:15,470:INFO:                umap: Not installed
2025-04-20 17:04:15,470:INFO:    pandas_profiling: Not installed
2025-04-20 17:04:15,470:INFO:  explainerdashboard: Not installed
2025-04-20 17:04:15,470:INFO:             autoviz: Not installed
2025-04-20 17:04:15,470:INFO:           fairlearn: Not installed
2025-04-20 17:04:15,470:INFO:          deepchecks: Not installed
2025-04-20 17:04:15,471:INFO:             xgboost: 1.7.6
2025-04-20 17:04:15,471:INFO:            catboost: Not installed
2025-04-20 17:04:15,471:INFO:              kmodes: Not installed
2025-04-20 17:04:15,471:INFO:             mlxtend: Not installed
2025-04-20 17:04:15,471:INFO:       statsforecast: Not installed
2025-04-20 17:04:15,471:INFO:        tune_sklearn: Not installed
2025-04-20 17:04:15,471:INFO:                 ray: Not installed
2025-04-20 17:04:15,471:INFO:            hyperopt: Not installed
2025-04-20 17:04:15,471:INFO:              optuna: Not installed
2025-04-20 17:04:15,471:INFO:               skopt: Not installed
2025-04-20 17:04:15,471:INFO:              mlflow: Not installed
2025-04-20 17:04:15,471:INFO:              gradio: Not installed
2025-04-20 17:04:15,471:INFO:             fastapi: Not installed
2025-04-20 17:04:15,471:INFO:             uvicorn: Not installed
2025-04-20 17:04:15,471:INFO:              m2cgen: Not installed
2025-04-20 17:04:15,471:INFO:           evidently: Not installed
2025-04-20 17:04:15,471:INFO:               fugue: Not installed
2025-04-20 17:04:15,471:INFO:           streamlit: 1.42.0
2025-04-20 17:04:15,471:INFO:             prophet: Not installed
2025-04-20 17:04:15,471:INFO:None
2025-04-20 17:04:15,471:INFO:Set up data.
2025-04-20 17:04:15,479:INFO:Set up train/test split.
2025-04-20 17:04:15,483:INFO:Set up index.
2025-04-20 17:04:15,483:INFO:Set up folding strategy.
2025-04-20 17:04:15,483:INFO:Assigning column types.
2025-04-20 17:04:15,485:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-20 17:04:15,520:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 17:04:15,522:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 17:04:15,546:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 17:04:15,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 17:04:15,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-20 17:04:15,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 17:04:15,601:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 17:04:15,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 17:04:15,603:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-20 17:04:15,635:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 17:04:15,656:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 17:04:15,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 17:04:15,691:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-20 17:04:15,713:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 17:04:15,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 17:04:15,715:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-20 17:04:15,770:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 17:04:15,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 17:04:15,828:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 17:04:15,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 17:04:15,832:INFO:Preparing preprocessing pipeline...
2025-04-20 17:04:15,832:INFO:Set up simple imputation.
2025-04-20 17:04:15,845:INFO:Finished creating preprocessing pipeline.
2025-04-20 17:04:15,849:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2025-04-20 17:04:15,849:INFO:Creating final display dataframe.
2025-04-20 17:04:15,891:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target         Attrition
2                   Target type            Binary
3           Original data shape         (828, 32)
4        Transformed data shape         (828, 31)
5   Transformed train set shape         (579, 31)
6    Transformed test set shape         (249, 31)
7               Ignore features                 1
8              Numeric features                30
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              723b
2025-04-20 17:04:15,947:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 17:04:15,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 17:04:16,012:INFO:Soft dependency imported: xgboost: 1.7.6
2025-04-20 17:04:16,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-20 17:04:16,014:INFO:setup() successfully completed in 1.25s...............
2025-04-20 17:04:17,333:INFO:Initializing compare_models()
2025-04-20 17:04:17,333:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-20 17:04:17,333:INFO:Checking exceptions
2025-04-20 17:04:17,336:INFO:Preparing display monitor
2025-04-20 17:04:17,356:INFO:Initializing Logistic Regression
2025-04-20 17:04:17,356:INFO:Total runtime is 0.0 minutes
2025-04-20 17:04:17,360:INFO:SubProcess create_model() called ==================================
2025-04-20 17:04:17,360:INFO:Initializing create_model()
2025-04-20 17:04:17,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:04:17,361:INFO:Checking exceptions
2025-04-20 17:04:17,361:INFO:Importing libraries
2025-04-20 17:04:17,361:INFO:Copying training dataset
2025-04-20 17:04:17,366:INFO:Defining folds
2025-04-20 17:04:17,366:INFO:Declaring metric variables
2025-04-20 17:04:17,369:INFO:Importing untrained model
2025-04-20 17:04:17,373:INFO:Logistic Regression Imported successfully
2025-04-20 17:04:17,379:INFO:Starting cross validation
2025-04-20 17:04:17,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:04:30,561:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,563:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,569:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,598:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,606:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,623:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,641:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,641:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,647:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:30,679:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-20 17:04:42,556:INFO:Calculating mean and std
2025-04-20 17:04:42,559:INFO:Creating metrics dataframe
2025-04-20 17:04:43,845:INFO:Uploading results into container
2025-04-20 17:04:43,845:INFO:Uploading model into container now
2025-04-20 17:04:43,846:INFO:_master_model_container: 1
2025-04-20 17:04:43,846:INFO:_display_container: 2
2025-04-20 17:04:43,846:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-20 17:04:43,847:INFO:create_model() successfully completed......................................
2025-04-20 17:04:43,957:INFO:SubProcess create_model() end ==================================
2025-04-20 17:04:43,957:INFO:Creating metrics dataframe
2025-04-20 17:04:43,969:INFO:Initializing K Neighbors Classifier
2025-04-20 17:04:43,969:INFO:Total runtime is 0.44355392853418985 minutes
2025-04-20 17:04:43,975:INFO:SubProcess create_model() called ==================================
2025-04-20 17:04:43,976:INFO:Initializing create_model()
2025-04-20 17:04:43,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:04:43,976:INFO:Checking exceptions
2025-04-20 17:04:43,976:INFO:Importing libraries
2025-04-20 17:04:43,976:INFO:Copying training dataset
2025-04-20 17:04:43,983:INFO:Defining folds
2025-04-20 17:04:43,983:INFO:Declaring metric variables
2025-04-20 17:04:43,989:INFO:Importing untrained model
2025-04-20 17:04:43,997:INFO:K Neighbors Classifier Imported successfully
2025-04-20 17:04:44,006:INFO:Starting cross validation
2025-04-20 17:04:44,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:04:56,174:INFO:Calculating mean and std
2025-04-20 17:04:56,175:INFO:Creating metrics dataframe
2025-04-20 17:04:57,495:INFO:Uploading results into container
2025-04-20 17:04:57,496:INFO:Uploading model into container now
2025-04-20 17:04:57,497:INFO:_master_model_container: 2
2025-04-20 17:04:57,497:INFO:_display_container: 2
2025-04-20 17:04:57,497:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-20 17:04:57,497:INFO:create_model() successfully completed......................................
2025-04-20 17:04:57,594:INFO:SubProcess create_model() end ==================================
2025-04-20 17:04:57,595:INFO:Creating metrics dataframe
2025-04-20 17:04:57,608:INFO:Initializing Naive Bayes
2025-04-20 17:04:57,608:INFO:Total runtime is 0.6708617448806763 minutes
2025-04-20 17:04:57,615:INFO:SubProcess create_model() called ==================================
2025-04-20 17:04:57,616:INFO:Initializing create_model()
2025-04-20 17:04:57,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:04:57,619:INFO:Checking exceptions
2025-04-20 17:04:57,619:INFO:Importing libraries
2025-04-20 17:04:57,619:INFO:Copying training dataset
2025-04-20 17:04:57,633:INFO:Defining folds
2025-04-20 17:04:57,634:INFO:Declaring metric variables
2025-04-20 17:04:57,641:INFO:Importing untrained model
2025-04-20 17:04:57,648:INFO:Naive Bayes Imported successfully
2025-04-20 17:04:57,662:INFO:Starting cross validation
2025-04-20 17:04:57,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:05:09,133:INFO:Calculating mean and std
2025-04-20 17:05:09,135:INFO:Creating metrics dataframe
2025-04-20 17:05:10,442:INFO:Uploading results into container
2025-04-20 17:05:10,443:INFO:Uploading model into container now
2025-04-20 17:05:10,444:INFO:_master_model_container: 3
2025-04-20 17:05:10,444:INFO:_display_container: 2
2025-04-20 17:05:10,444:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-20 17:05:10,444:INFO:create_model() successfully completed......................................
2025-04-20 17:05:10,550:INFO:SubProcess create_model() end ==================================
2025-04-20 17:05:10,551:INFO:Creating metrics dataframe
2025-04-20 17:05:10,563:INFO:Initializing Decision Tree Classifier
2025-04-20 17:05:10,563:INFO:Total runtime is 0.8867932399113974 minutes
2025-04-20 17:05:10,568:INFO:SubProcess create_model() called ==================================
2025-04-20 17:05:10,568:INFO:Initializing create_model()
2025-04-20 17:05:10,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:05:10,570:INFO:Checking exceptions
2025-04-20 17:05:10,570:INFO:Importing libraries
2025-04-20 17:05:10,570:INFO:Copying training dataset
2025-04-20 17:05:10,579:INFO:Defining folds
2025-04-20 17:05:10,579:INFO:Declaring metric variables
2025-04-20 17:05:10,588:INFO:Importing untrained model
2025-04-20 17:05:10,595:INFO:Decision Tree Classifier Imported successfully
2025-04-20 17:05:10,607:INFO:Starting cross validation
2025-04-20 17:05:10,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:05:19,787:INFO:Calculating mean and std
2025-04-20 17:05:19,788:INFO:Creating metrics dataframe
2025-04-20 17:05:20,559:INFO:Uploading results into container
2025-04-20 17:05:20,559:INFO:Uploading model into container now
2025-04-20 17:05:20,559:INFO:_master_model_container: 4
2025-04-20 17:05:20,560:INFO:_display_container: 2
2025-04-20 17:05:20,560:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-20 17:05:20,560:INFO:create_model() successfully completed......................................
2025-04-20 17:05:20,678:INFO:SubProcess create_model() end ==================================
2025-04-20 17:05:20,678:INFO:Creating metrics dataframe
2025-04-20 17:05:20,690:INFO:Initializing SVM - Linear Kernel
2025-04-20 17:05:20,690:INFO:Total runtime is 1.0555761893590292 minutes
2025-04-20 17:05:20,696:INFO:SubProcess create_model() called ==================================
2025-04-20 17:05:20,697:INFO:Initializing create_model()
2025-04-20 17:05:20,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:05:20,697:INFO:Checking exceptions
2025-04-20 17:05:20,697:INFO:Importing libraries
2025-04-20 17:05:20,697:INFO:Copying training dataset
2025-04-20 17:05:20,702:INFO:Defining folds
2025-04-20 17:05:20,702:INFO:Declaring metric variables
2025-04-20 17:05:20,707:INFO:Importing untrained model
2025-04-20 17:05:20,712:INFO:SVM - Linear Kernel Imported successfully
2025-04-20 17:05:20,720:INFO:Starting cross validation
2025-04-20 17:05:20,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:05:20,818:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,827:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,829:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,832:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,839:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,847:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-20 17:05:20,847:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,848:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,856:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-20 17:05:20,862:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,868:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:20,877:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-04-20 17:05:20,878:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-04-20 17:05:32,447:INFO:Calculating mean and std
2025-04-20 17:05:32,448:INFO:Creating metrics dataframe
2025-04-20 17:05:33,787:INFO:Uploading results into container
2025-04-20 17:05:33,788:INFO:Uploading model into container now
2025-04-20 17:05:33,788:INFO:_master_model_container: 5
2025-04-20 17:05:33,788:INFO:_display_container: 2
2025-04-20 17:05:33,788:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-20 17:05:33,788:INFO:create_model() successfully completed......................................
2025-04-20 17:05:33,890:INFO:SubProcess create_model() end ==================================
2025-04-20 17:05:33,890:INFO:Creating metrics dataframe
2025-04-20 17:05:33,905:INFO:Initializing Ridge Classifier
2025-04-20 17:05:33,905:INFO:Total runtime is 1.2758151213328044 minutes
2025-04-20 17:05:33,909:INFO:SubProcess create_model() called ==================================
2025-04-20 17:05:33,909:INFO:Initializing create_model()
2025-04-20 17:05:33,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:05:33,909:INFO:Checking exceptions
2025-04-20 17:05:33,910:INFO:Importing libraries
2025-04-20 17:05:33,910:INFO:Copying training dataset
2025-04-20 17:05:33,916:INFO:Defining folds
2025-04-20 17:05:33,916:INFO:Declaring metric variables
2025-04-20 17:05:33,921:INFO:Importing untrained model
2025-04-20 17:05:33,928:INFO:Ridge Classifier Imported successfully
2025-04-20 17:05:33,954:INFO:Starting cross validation
2025-04-20 17:05:33,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:05:34,058:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,068:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,071:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,071:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,078:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,086:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,093:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,098:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,107:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:34,110:WARNING:C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\zaina\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-04-20 17:05:45,185:INFO:Calculating mean and std
2025-04-20 17:05:45,187:INFO:Creating metrics dataframe
2025-04-20 17:05:46,492:INFO:Uploading results into container
2025-04-20 17:05:46,493:INFO:Uploading model into container now
2025-04-20 17:05:46,493:INFO:_master_model_container: 6
2025-04-20 17:05:46,494:INFO:_display_container: 2
2025-04-20 17:05:46,494:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-04-20 17:05:46,494:INFO:create_model() successfully completed......................................
2025-04-20 17:05:46,591:INFO:SubProcess create_model() end ==================================
2025-04-20 17:05:46,591:INFO:Creating metrics dataframe
2025-04-20 17:05:46,606:INFO:Initializing Random Forest Classifier
2025-04-20 17:05:46,607:INFO:Total runtime is 1.4875259121259055 minutes
2025-04-20 17:05:46,612:INFO:SubProcess create_model() called ==================================
2025-04-20 17:05:46,612:INFO:Initializing create_model()
2025-04-20 17:05:46,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:05:46,614:INFO:Checking exceptions
2025-04-20 17:05:46,614:INFO:Importing libraries
2025-04-20 17:05:46,614:INFO:Copying training dataset
2025-04-20 17:05:46,620:INFO:Defining folds
2025-04-20 17:05:46,620:INFO:Declaring metric variables
2025-04-20 17:05:46,630:INFO:Importing untrained model
2025-04-20 17:05:46,637:INFO:Random Forest Classifier Imported successfully
2025-04-20 17:05:46,646:INFO:Starting cross validation
2025-04-20 17:05:46,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:05:58,819:INFO:Calculating mean and std
2025-04-20 17:05:58,821:INFO:Creating metrics dataframe
2025-04-20 17:06:00,130:INFO:Uploading results into container
2025-04-20 17:06:00,130:INFO:Uploading model into container now
2025-04-20 17:06:00,131:INFO:_master_model_container: 7
2025-04-20 17:06:00,131:INFO:_display_container: 2
2025-04-20 17:06:00,133:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2025-04-20 17:06:00,133:INFO:create_model() successfully completed......................................
2025-04-20 17:06:00,229:INFO:SubProcess create_model() end ==================================
2025-04-20 17:06:00,229:INFO:Creating metrics dataframe
2025-04-20 17:06:00,243:INFO:Initializing Quadratic Discriminant Analysis
2025-04-20 17:06:00,243:INFO:Total runtime is 1.7147905270258588 minutes
2025-04-20 17:06:00,248:INFO:SubProcess create_model() called ==================================
2025-04-20 17:06:00,248:INFO:Initializing create_model()
2025-04-20 17:06:00,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:06:00,248:INFO:Checking exceptions
2025-04-20 17:06:00,250:INFO:Importing libraries
2025-04-20 17:06:00,250:INFO:Copying training dataset
2025-04-20 17:06:00,256:INFO:Defining folds
2025-04-20 17:06:00,256:INFO:Declaring metric variables
2025-04-20 17:06:00,262:INFO:Importing untrained model
2025-04-20 17:06:00,268:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-20 17:06:00,278:INFO:Starting cross validation
2025-04-20 17:06:00,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:06:11,636:INFO:Calculating mean and std
2025-04-20 17:06:11,637:INFO:Creating metrics dataframe
2025-04-20 17:06:12,939:INFO:Uploading results into container
2025-04-20 17:06:12,939:INFO:Uploading model into container now
2025-04-20 17:06:12,941:INFO:_master_model_container: 8
2025-04-20 17:06:12,942:INFO:_display_container: 2
2025-04-20 17:06:12,942:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-20 17:06:12,943:INFO:create_model() successfully completed......................................
2025-04-20 17:06:13,040:INFO:SubProcess create_model() end ==================================
2025-04-20 17:06:13,040:INFO:Creating metrics dataframe
2025-04-20 17:06:13,053:INFO:Initializing Ada Boost Classifier
2025-04-20 17:06:13,053:INFO:Total runtime is 1.9282868464787803 minutes
2025-04-20 17:06:13,056:INFO:SubProcess create_model() called ==================================
2025-04-20 17:06:13,058:INFO:Initializing create_model()
2025-04-20 17:06:13,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:06:13,058:INFO:Checking exceptions
2025-04-20 17:06:13,058:INFO:Importing libraries
2025-04-20 17:06:13,058:INFO:Copying training dataset
2025-04-20 17:06:13,063:INFO:Defining folds
2025-04-20 17:06:13,063:INFO:Declaring metric variables
2025-04-20 17:06:13,070:INFO:Importing untrained model
2025-04-20 17:06:13,076:INFO:Ada Boost Classifier Imported successfully
2025-04-20 17:06:13,084:INFO:Starting cross validation
2025-04-20 17:06:13,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:06:23,586:INFO:Calculating mean and std
2025-04-20 17:06:23,587:INFO:Creating metrics dataframe
2025-04-20 17:06:24,345:INFO:Uploading results into container
2025-04-20 17:06:24,345:INFO:Uploading model into container now
2025-04-20 17:06:24,346:INFO:_master_model_container: 9
2025-04-20 17:06:24,346:INFO:_display_container: 2
2025-04-20 17:06:24,346:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2025-04-20 17:06:24,347:INFO:create_model() successfully completed......................................
2025-04-20 17:06:24,428:INFO:SubProcess create_model() end ==================================
2025-04-20 17:06:24,428:INFO:Creating metrics dataframe
2025-04-20 17:06:24,435:INFO:Initializing Gradient Boosting Classifier
2025-04-20 17:06:24,435:INFO:Total runtime is 2.117987557252248 minutes
2025-04-20 17:06:24,438:INFO:SubProcess create_model() called ==================================
2025-04-20 17:06:24,438:INFO:Initializing create_model()
2025-04-20 17:06:24,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:06:24,438:INFO:Checking exceptions
2025-04-20 17:06:24,438:INFO:Importing libraries
2025-04-20 17:06:24,440:INFO:Copying training dataset
2025-04-20 17:06:24,442:INFO:Defining folds
2025-04-20 17:06:24,442:INFO:Declaring metric variables
2025-04-20 17:06:24,445:INFO:Importing untrained model
2025-04-20 17:06:24,449:INFO:Gradient Boosting Classifier Imported successfully
2025-04-20 17:06:24,456:INFO:Starting cross validation
2025-04-20 17:06:24,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:06:36,311:INFO:Calculating mean and std
2025-04-20 17:06:36,312:INFO:Creating metrics dataframe
2025-04-20 17:06:37,689:INFO:Uploading results into container
2025-04-20 17:06:37,690:INFO:Uploading model into container now
2025-04-20 17:06:37,691:INFO:_master_model_container: 10
2025-04-20 17:06:37,691:INFO:_display_container: 2
2025-04-20 17:06:37,692:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-20 17:06:37,693:INFO:create_model() successfully completed......................................
2025-04-20 17:06:37,791:INFO:SubProcess create_model() end ==================================
2025-04-20 17:06:37,791:INFO:Creating metrics dataframe
2025-04-20 17:06:37,810:INFO:Initializing Linear Discriminant Analysis
2025-04-20 17:06:37,811:INFO:Total runtime is 2.3409165183703107 minutes
2025-04-20 17:06:37,816:INFO:SubProcess create_model() called ==================================
2025-04-20 17:06:37,816:INFO:Initializing create_model()
2025-04-20 17:06:37,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:06:37,816:INFO:Checking exceptions
2025-04-20 17:06:37,816:INFO:Importing libraries
2025-04-20 17:06:37,816:INFO:Copying training dataset
2025-04-20 17:06:37,824:INFO:Defining folds
2025-04-20 17:06:37,824:INFO:Declaring metric variables
2025-04-20 17:06:37,830:INFO:Importing untrained model
2025-04-20 17:06:37,836:INFO:Linear Discriminant Analysis Imported successfully
2025-04-20 17:06:37,845:INFO:Starting cross validation
2025-04-20 17:06:37,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:06:49,361:INFO:Calculating mean and std
2025-04-20 17:06:49,365:INFO:Creating metrics dataframe
2025-04-20 17:06:50,671:INFO:Uploading results into container
2025-04-20 17:06:50,673:INFO:Uploading model into container now
2025-04-20 17:06:50,674:INFO:_master_model_container: 11
2025-04-20 17:06:50,675:INFO:_display_container: 2
2025-04-20 17:06:50,675:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-20 17:06:50,676:INFO:create_model() successfully completed......................................
2025-04-20 17:06:50,774:INFO:SubProcess create_model() end ==================================
2025-04-20 17:06:50,774:INFO:Creating metrics dataframe
2025-04-20 17:06:50,790:INFO:Initializing Extra Trees Classifier
2025-04-20 17:06:50,790:INFO:Total runtime is 2.5572324037551883 minutes
2025-04-20 17:06:50,794:INFO:SubProcess create_model() called ==================================
2025-04-20 17:06:50,795:INFO:Initializing create_model()
2025-04-20 17:06:50,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:06:50,795:INFO:Checking exceptions
2025-04-20 17:06:50,795:INFO:Importing libraries
2025-04-20 17:06:50,795:INFO:Copying training dataset
2025-04-20 17:06:50,802:INFO:Defining folds
2025-04-20 17:06:50,802:INFO:Declaring metric variables
2025-04-20 17:06:50,807:INFO:Importing untrained model
2025-04-20 17:06:50,816:INFO:Extra Trees Classifier Imported successfully
2025-04-20 17:06:50,829:INFO:Starting cross validation
2025-04-20 17:06:50,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:07:02,059:INFO:Calculating mean and std
2025-04-20 17:07:02,061:INFO:Creating metrics dataframe
2025-04-20 17:07:02,842:INFO:Uploading results into container
2025-04-20 17:07:02,842:INFO:Uploading model into container now
2025-04-20 17:07:02,843:INFO:_master_model_container: 12
2025-04-20 17:07:02,843:INFO:_display_container: 2
2025-04-20 17:07:02,843:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 17:07:02,843:INFO:create_model() successfully completed......................................
2025-04-20 17:07:02,922:INFO:SubProcess create_model() end ==================================
2025-04-20 17:07:02,922:INFO:Creating metrics dataframe
2025-04-20 17:07:02,931:INFO:Initializing Extreme Gradient Boosting
2025-04-20 17:07:02,931:INFO:Total runtime is 2.7595859289169313 minutes
2025-04-20 17:07:02,934:INFO:SubProcess create_model() called ==================================
2025-04-20 17:07:02,934:INFO:Initializing create_model()
2025-04-20 17:07:02,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:07:02,935:INFO:Checking exceptions
2025-04-20 17:07:02,935:INFO:Importing libraries
2025-04-20 17:07:02,935:INFO:Copying training dataset
2025-04-20 17:07:02,939:INFO:Defining folds
2025-04-20 17:07:02,939:INFO:Declaring metric variables
2025-04-20 17:07:02,942:INFO:Importing untrained model
2025-04-20 17:07:02,946:INFO:Extreme Gradient Boosting Imported successfully
2025-04-20 17:07:02,955:INFO:Starting cross validation
2025-04-20 17:07:02,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:07:11,767:INFO:Calculating mean and std
2025-04-20 17:07:11,769:INFO:Creating metrics dataframe
2025-04-20 17:07:12,538:INFO:Uploading results into container
2025-04-20 17:07:12,540:INFO:Uploading model into container now
2025-04-20 17:07:12,540:INFO:_master_model_container: 13
2025-04-20 17:07:12,540:INFO:_display_container: 2
2025-04-20 17:07:12,541:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2025-04-20 17:07:12,541:INFO:create_model() successfully completed......................................
2025-04-20 17:07:12,618:INFO:SubProcess create_model() end ==================================
2025-04-20 17:07:12,618:INFO:Creating metrics dataframe
2025-04-20 17:07:12,627:INFO:Initializing Light Gradient Boosting Machine
2025-04-20 17:07:12,627:INFO:Total runtime is 2.9211800694465637 minutes
2025-04-20 17:07:12,630:INFO:SubProcess create_model() called ==================================
2025-04-20 17:07:12,630:INFO:Initializing create_model()
2025-04-20 17:07:12,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:07:12,630:INFO:Checking exceptions
2025-04-20 17:07:12,630:INFO:Importing libraries
2025-04-20 17:07:12,630:INFO:Copying training dataset
2025-04-20 17:07:12,634:INFO:Defining folds
2025-04-20 17:07:12,634:INFO:Declaring metric variables
2025-04-20 17:07:12,637:INFO:Importing untrained model
2025-04-20 17:07:12,641:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-20 17:07:12,649:INFO:Starting cross validation
2025-04-20 17:07:12,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:07:21,091:INFO:Calculating mean and std
2025-04-20 17:07:21,093:INFO:Creating metrics dataframe
2025-04-20 17:07:21,834:INFO:Uploading results into container
2025-04-20 17:07:21,835:INFO:Uploading model into container now
2025-04-20 17:07:21,836:INFO:_master_model_container: 14
2025-04-20 17:07:21,836:INFO:_display_container: 2
2025-04-20 17:07:21,836:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-20 17:07:21,836:INFO:create_model() successfully completed......................................
2025-04-20 17:07:21,916:INFO:SubProcess create_model() end ==================================
2025-04-20 17:07:21,916:INFO:Creating metrics dataframe
2025-04-20 17:07:21,926:INFO:Initializing Dummy Classifier
2025-04-20 17:07:21,926:INFO:Total runtime is 3.0761667331059774 minutes
2025-04-20 17:07:21,930:INFO:SubProcess create_model() called ==================================
2025-04-20 17:07:21,930:INFO:Initializing create_model()
2025-04-20 17:07:21,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022146E0D300>, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:07:21,930:INFO:Checking exceptions
2025-04-20 17:07:21,930:INFO:Importing libraries
2025-04-20 17:07:21,930:INFO:Copying training dataset
2025-04-20 17:07:21,936:INFO:Defining folds
2025-04-20 17:07:21,936:INFO:Declaring metric variables
2025-04-20 17:07:21,941:INFO:Importing untrained model
2025-04-20 17:07:21,946:INFO:Dummy Classifier Imported successfully
2025-04-20 17:07:21,955:INFO:Starting cross validation
2025-04-20 17:07:21,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:07:29,050:INFO:Calculating mean and std
2025-04-20 17:07:29,051:INFO:Creating metrics dataframe
2025-04-20 17:07:29,881:INFO:Uploading results into container
2025-04-20 17:07:29,882:INFO:Uploading model into container now
2025-04-20 17:07:29,883:INFO:_master_model_container: 15
2025-04-20 17:07:29,883:INFO:_display_container: 2
2025-04-20 17:07:29,883:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-04-20 17:07:29,883:INFO:create_model() successfully completed......................................
2025-04-20 17:07:29,963:INFO:SubProcess create_model() end ==================================
2025-04-20 17:07:29,963:INFO:Creating metrics dataframe
2025-04-20 17:07:29,982:INFO:Initializing create_model()
2025-04-20 17:07:29,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:07:29,982:INFO:Checking exceptions
2025-04-20 17:07:29,985:INFO:Importing libraries
2025-04-20 17:07:29,985:INFO:Copying training dataset
2025-04-20 17:07:29,988:INFO:Defining folds
2025-04-20 17:07:29,988:INFO:Declaring metric variables
2025-04-20 17:07:29,988:INFO:Importing untrained model
2025-04-20 17:07:29,988:INFO:Declaring custom model
2025-04-20 17:07:29,988:INFO:Extra Trees Classifier Imported successfully
2025-04-20 17:07:29,990:INFO:Cross validation set to False
2025-04-20 17:07:29,990:INFO:Fitting Model
2025-04-20 17:07:30,799:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 17:07:30,799:INFO:create_model() successfully completed......................................
2025-04-20 17:07:30,902:INFO:_master_model_container: 15
2025-04-20 17:07:30,902:INFO:_display_container: 2
2025-04-20 17:07:30,902:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 17:07:30,903:INFO:compare_models() successfully completed......................................
2025-04-20 17:07:43,743:INFO:Initializing evaluate_model()
2025-04-20 17:07:43,743:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-04-20 17:07:43,751:INFO:Initializing plot_model()
2025-04-20 17:07:43,751:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, system=True)
2025-04-20 17:07:43,753:INFO:Checking exceptions
2025-04-20 17:07:43,780:INFO:Preloading libraries
2025-04-20 17:07:43,787:INFO:Copying training dataset
2025-04-20 17:07:43,787:INFO:Plot type: pipeline
2025-04-20 17:07:43,914:INFO:Visual Rendered Successfully
2025-04-20 17:07:43,994:INFO:plot_model() successfully completed......................................
2025-04-20 17:07:44,701:INFO:Initializing finalize_model()
2025-04-20 17:07:44,701:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-20 17:07:44,701:INFO:Finalizing ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 17:07:44,705:INFO:Initializing create_model()
2025-04-20 17:07:44,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-04-20 17:07:44,705:INFO:Checking exceptions
2025-04-20 17:07:44,707:INFO:Importing libraries
2025-04-20 17:07:44,707:INFO:Copying training dataset
2025-04-20 17:07:44,707:INFO:Defining folds
2025-04-20 17:07:44,707:INFO:Declaring metric variables
2025-04-20 17:07:44,707:INFO:Importing untrained model
2025-04-20 17:07:44,707:INFO:Declaring custom model
2025-04-20 17:07:44,707:INFO:Extra Trees Classifier Imported successfully
2025-04-20 17:07:44,708:INFO:Cross validation set to False
2025-04-20 17:07:44,708:INFO:Fitting Model
2025-04-20 17:07:44,838:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 17:07:44,838:INFO:create_model() successfully completed......................................
2025-04-20 17:07:44,911:INFO:_master_model_container: 15
2025-04-20 17:07:44,911:INFO:_display_container: 2
2025-04-20 17:07:44,914:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 17:07:44,914:INFO:finalize_model() successfully completed......................................
2025-04-20 17:07:44,999:INFO:Initializing save_model()
2025-04-20 17:07:44,999:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False), model_name=model_attrition, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-04-20 17:07:44,999:INFO:Adding model into prep_pipe
2025-04-20 17:07:45,000:WARNING:Only Model saved as it was a pipeline.
2025-04-20 17:07:45,028:INFO:model_attrition.pkl saved in current working directory
2025-04-20 17:07:45,031:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 17:07:45,031:INFO:save_model() successfully completed......................................
2025-04-20 17:08:03,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:08:03,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:08:03,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:08:03,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:08:04,042:INFO:Initializing load_model()
2025-04-20 17:08:04,042:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:08:25,898:INFO:Initializing load_model()
2025-04-20 17:08:25,899:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:08:25,957:INFO:Initializing predict_model()
2025-04-20 17:08:25,957:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023DEE4D2EC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023DEF8820E0>)
2025-04-20 17:08:25,957:INFO:Checking exceptions
2025-04-20 17:08:25,957:INFO:Preloading libraries
2025-04-20 17:08:25,958:INFO:Set up data.
2025-04-20 17:08:25,966:INFO:Set up index.
2025-04-20 17:19:40,486:INFO:Initializing get_config()
2025-04-20 17:19:40,486:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, variable=trained_model)
2025-04-20 17:25:40,918:INFO:Initializing create_model()
2025-04-20 17:25:40,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:25:40,918:INFO:Checking exceptions
2025-04-20 17:25:40,929:INFO:Importing libraries
2025-04-20 17:25:40,929:INFO:Copying training dataset
2025-04-20 17:25:40,936:INFO:Defining folds
2025-04-20 17:25:40,936:INFO:Declaring metric variables
2025-04-20 17:25:40,941:INFO:Importing untrained model
2025-04-20 17:25:40,944:INFO:Decision Tree Classifier Imported successfully
2025-04-20 17:25:40,951:INFO:Starting cross validation
2025-04-20 17:25:40,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:25:55,692:INFO:Calculating mean and std
2025-04-20 17:25:55,693:INFO:Creating metrics dataframe
2025-04-20 17:25:55,697:INFO:Finalizing model
2025-04-20 17:25:56,451:INFO:Uploading results into container
2025-04-20 17:25:56,452:INFO:Uploading model into container now
2025-04-20 17:25:56,461:INFO:_master_model_container: 16
2025-04-20 17:25:56,461:INFO:_display_container: 3
2025-04-20 17:25:56,462:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-20 17:25:56,462:INFO:create_model() successfully completed......................................
2025-04-20 17:25:56,562:INFO:Initializing finalize_model()
2025-04-20 17:25:56,562:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-20 17:25:56,562:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2025-04-20 17:25:56,562:INFO:Initializing create_model()
2025-04-20 17:25:56,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-04-20 17:25:56,562:INFO:Checking exceptions
2025-04-20 17:25:56,562:INFO:Importing libraries
2025-04-20 17:25:56,562:INFO:Copying training dataset
2025-04-20 17:25:56,562:INFO:Defining folds
2025-04-20 17:25:56,562:INFO:Declaring metric variables
2025-04-20 17:25:56,562:INFO:Importing untrained model
2025-04-20 17:25:56,562:INFO:Declaring custom model
2025-04-20 17:25:56,562:INFO:Decision Tree Classifier Imported successfully
2025-04-20 17:25:56,562:INFO:Cross validation set to False
2025-04-20 17:25:56,562:INFO:Fitting Model
2025-04-20 17:25:56,588:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=42, splitter='best'))],
         verbose=False)
2025-04-20 17:25:56,588:INFO:create_model() successfully completed......................................
2025-04-20 17:25:56,676:INFO:_master_model_container: 16
2025-04-20 17:25:56,676:INFO:_display_container: 3
2025-04-20 17:25:56,682:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=42, splitter='best'))],
         verbose=False)
2025-04-20 17:25:56,682:INFO:finalize_model() successfully completed......................................
2025-04-20 17:25:56,775:INFO:Initializing save_model()
2025-04-20 17:25:56,775:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=42, splitter='best'))],
         verbose=False), model_name=model_attrition, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-04-20 17:25:56,775:INFO:Adding model into prep_pipe
2025-04-20 17:25:56,775:WARNING:Only Model saved as it was a pipeline.
2025-04-20 17:25:56,781:INFO:model_attrition.pkl saved in current working directory
2025-04-20 17:25:56,784:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=42, splitter='best'))],
         verbose=False)
2025-04-20 17:25:56,784:INFO:save_model() successfully completed......................................
2025-04-20 17:27:31,839:INFO:Initializing create_model()
2025-04-20 17:27:31,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2025-04-20 17:27:31,839:INFO:Checking exceptions
2025-04-20 17:27:31,853:INFO:Importing libraries
2025-04-20 17:27:31,853:INFO:Copying training dataset
2025-04-20 17:27:31,858:INFO:Defining folds
2025-04-20 17:27:31,858:INFO:Declaring metric variables
2025-04-20 17:27:31,862:INFO:Importing untrained model
2025-04-20 17:27:31,865:INFO:Extra Trees Classifier Imported successfully
2025-04-20 17:27:31,869:INFO:Starting cross validation
2025-04-20 17:27:31,871:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-20 17:27:39,348:INFO:Calculating mean and std
2025-04-20 17:27:39,350:INFO:Creating metrics dataframe
2025-04-20 17:27:39,354:INFO:Finalizing model
2025-04-20 17:27:40,339:INFO:Uploading results into container
2025-04-20 17:27:40,339:INFO:Uploading model into container now
2025-04-20 17:27:40,348:INFO:_master_model_container: 17
2025-04-20 17:27:40,348:INFO:_display_container: 4
2025-04-20 17:27:40,350:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 17:27:40,350:INFO:create_model() successfully completed......................................
2025-04-20 17:27:40,449:INFO:Initializing finalize_model()
2025-04-20 17:27:40,449:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-04-20 17:27:40,449:INFO:Finalizing ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2025-04-20 17:27:40,452:INFO:Initializing create_model()
2025-04-20 17:27:40,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221457B04F0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2025-04-20 17:27:40,452:INFO:Checking exceptions
2025-04-20 17:27:40,453:INFO:Importing libraries
2025-04-20 17:27:40,453:INFO:Copying training dataset
2025-04-20 17:27:40,454:INFO:Defining folds
2025-04-20 17:27:40,454:INFO:Declaring metric variables
2025-04-20 17:27:40,454:INFO:Importing untrained model
2025-04-20 17:27:40,454:INFO:Declaring custom model
2025-04-20 17:27:40,454:INFO:Extra Trees Classifier Imported successfully
2025-04-20 17:27:40,455:INFO:Cross validation set to False
2025-04-20 17:27:40,455:INFO:Fitting Model
2025-04-20 17:27:40,570:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 17:27:40,570:INFO:create_model() successfully completed......................................
2025-04-20 17:27:40,663:INFO:_master_model_container: 17
2025-04-20 17:27:40,663:INFO:_display_container: 4
2025-04-20 17:27:40,667:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 17:27:40,667:INFO:finalize_model() successfully completed......................................
2025-04-20 17:27:40,768:INFO:Initializing save_model()
2025-04-20 17:27:40,768:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False), model_name=model_attrition, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-04-20 17:27:40,768:INFO:Adding model into prep_pipe
2025-04-20 17:27:40,768:WARNING:Only Model saved as it was a pipeline.
2025-04-20 17:27:40,802:INFO:model_attrition.pkl saved in current working directory
2025-04-20 17:27:40,807:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'Ma...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=42,
                                      verbose=0, warm_start=False))],
         verbose=False)
2025-04-20 17:27:40,807:INFO:save_model() successfully completed......................................
2025-04-20 17:28:48,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:28:48,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:28:48,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:28:48,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:28:49,469:INFO:Initializing load_model()
2025-04-20 17:28:49,469:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:29:04,345:INFO:Initializing load_model()
2025-04-20 17:29:04,347:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:29:04,407:INFO:Initializing predict_model()
2025-04-20 17:29:04,407:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000298CA72A080>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000298CBB6AC20>)
2025-04-20 17:29:04,409:INFO:Checking exceptions
2025-04-20 17:29:04,409:INFO:Preloading libraries
2025-04-20 17:29:04,409:INFO:Set up data.
2025-04-20 17:29:04,419:INFO:Set up index.
2025-04-20 17:31:04,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:31:04,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:31:04,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:31:04,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:31:05,500:INFO:Initializing load_model()
2025-04-20 17:31:05,500:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:31:10,031:INFO:Initializing load_model()
2025-04-20 17:31:10,031:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:32:07,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:32:07,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:32:07,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:32:07,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:32:08,486:INFO:Initializing load_model()
2025-04-20 17:32:08,486:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:32:13,187:INFO:Initializing load_model()
2025-04-20 17:32:13,187:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:33:40,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:33:40,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:33:40,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:33:40,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:33:41,976:INFO:Initializing load_model()
2025-04-20 17:33:41,977:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:34:00,253:INFO:Initializing load_model()
2025-04-20 17:34:00,254:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:34:00,314:INFO:Initializing predict_model()
2025-04-20 17:34:00,314:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E70371E950>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E7038A37F0>)
2025-04-20 17:34:00,314:INFO:Checking exceptions
2025-04-20 17:34:00,314:INFO:Preloading libraries
2025-04-20 17:34:00,315:INFO:Set up data.
2025-04-20 17:34:00,325:INFO:Set up index.
2025-04-20 17:45:57,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:45:57,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:45:57,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:45:57,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:45:58,491:INFO:Initializing load_model()
2025-04-20 17:45:58,491:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:46:06,374:INFO:Initializing load_model()
2025-04-20 17:46:06,374:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:46:06,435:INFO:Initializing predict_model()
2025-04-20 17:46:06,435:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D108FDD390>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D10A396560>)
2025-04-20 17:46:06,435:INFO:Checking exceptions
2025-04-20 17:46:06,435:INFO:Preloading libraries
2025-04-20 17:46:06,436:INFO:Set up data.
2025-04-20 17:46:06,445:INFO:Set up index.
2025-04-20 17:47:29,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:47:29,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:47:29,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:47:29,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:47:30,487:INFO:Initializing load_model()
2025-04-20 17:47:30,487:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:47:35,650:INFO:Initializing load_model()
2025-04-20 17:47:35,651:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:47:35,716:INFO:Initializing predict_model()
2025-04-20 17:47:35,716:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000152734A7E50>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000152736476D0>)
2025-04-20 17:47:35,716:INFO:Checking exceptions
2025-04-20 17:47:35,716:INFO:Preloading libraries
2025-04-20 17:47:35,718:INFO:Set up data.
2025-04-20 17:47:35,726:INFO:Set up index.
2025-04-20 17:49:27,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:49:27,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:49:27,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:49:27,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:49:28,185:INFO:Initializing load_model()
2025-04-20 17:49:28,185:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:49:33,881:INFO:Initializing load_model()
2025-04-20 17:49:33,881:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:49:33,938:INFO:Initializing predict_model()
2025-04-20 17:49:33,938:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E951F97E80>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E9533C7B50>)
2025-04-20 17:49:33,938:INFO:Checking exceptions
2025-04-20 17:49:33,938:INFO:Preloading libraries
2025-04-20 17:49:33,938:INFO:Set up data.
2025-04-20 17:49:33,947:INFO:Set up index.
2025-04-20 17:52:10,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:52:10,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:52:10,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:52:10,753:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:52:12,098:INFO:Initializing load_model()
2025-04-20 17:52:12,098:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:55:08,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:55:08,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:55:08,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:55:08,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:55:08,933:INFO:Initializing load_model()
2025-04-20 17:55:08,933:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:55:17,954:INFO:Initializing load_model()
2025-04-20 17:55:17,954:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:55:18,015:INFO:Initializing predict_model()
2025-04-20 17:55:18,016:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C7C5132080>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C7C64CB7F0>)
2025-04-20 17:55:18,016:INFO:Checking exceptions
2025-04-20 17:55:18,016:INFO:Preloading libraries
2025-04-20 17:55:18,018:INFO:Set up data.
2025-04-20 17:55:18,026:INFO:Set up index.
2025-04-20 17:57:55,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:57:55,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:57:55,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:57:55,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:57:56,747:INFO:Initializing load_model()
2025-04-20 17:57:56,747:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:58:03,604:INFO:Initializing load_model()
2025-04-20 17:58:03,604:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:58:03,681:INFO:Initializing predict_model()
2025-04-20 17:58:03,681:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026775F093F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000267772A7BE0>)
2025-04-20 17:58:03,681:INFO:Checking exceptions
2025-04-20 17:58:03,681:INFO:Preloading libraries
2025-04-20 17:58:03,682:INFO:Set up data.
2025-04-20 17:58:03,692:INFO:Set up index.
2025-04-20 17:59:13,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:59:13,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:59:13,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:59:13,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 17:59:14,982:INFO:Initializing load_model()
2025-04-20 17:59:14,982:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:59:21,245:INFO:Initializing load_model()
2025-04-20 17:59:21,245:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 17:59:21,309:INFO:Initializing predict_model()
2025-04-20 17:59:21,309:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0EB29F160>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D0EC6528C0>)
2025-04-20 17:59:21,309:INFO:Checking exceptions
2025-04-20 17:59:21,309:INFO:Preloading libraries
2025-04-20 17:59:21,310:INFO:Set up data.
2025-04-20 17:59:21,321:INFO:Set up index.
2025-04-20 18:03:31,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:03:31,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:03:31,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:03:31,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:03:32,261:INFO:Initializing load_model()
2025-04-20 18:03:32,262:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:03:41,083:INFO:Initializing load_model()
2025-04-20 18:03:41,083:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:03:41,169:INFO:Initializing predict_model()
2025-04-20 18:03:41,169:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EE9F8BA320>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EE9FA4F6D0>)
2025-04-20 18:03:41,169:INFO:Checking exceptions
2025-04-20 18:03:41,169:INFO:Preloading libraries
2025-04-20 18:03:41,170:INFO:Set up data.
2025-04-20 18:03:41,179:INFO:Set up index.
2025-04-20 18:09:23,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:09:23,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:09:23,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:09:23,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:09:24,191:INFO:Initializing load_model()
2025-04-20 18:09:24,191:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:09:32,205:INFO:Initializing load_model()
2025-04-20 18:09:32,206:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:09:32,272:INFO:Initializing predict_model()
2025-04-20 18:09:32,272:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FAD53C59C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FAD5569990>)
2025-04-20 18:09:32,272:INFO:Checking exceptions
2025-04-20 18:09:32,272:INFO:Preloading libraries
2025-04-20 18:09:32,273:INFO:Set up data.
2025-04-20 18:09:32,284:INFO:Set up index.
2025-04-20 18:13:40,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:13:40,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:13:40,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:13:40,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:13:41,243:INFO:Initializing load_model()
2025-04-20 18:13:41,243:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:13:44,938:INFO:Initializing load_model()
2025-04-20 18:13:44,938:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:13:45,004:INFO:Initializing predict_model()
2025-04-20 18:13:45,004:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D4346DDE70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002D435A6FB50>)
2025-04-20 18:13:45,004:INFO:Checking exceptions
2025-04-20 18:13:45,004:INFO:Preloading libraries
2025-04-20 18:13:45,006:INFO:Set up data.
2025-04-20 18:13:45,015:INFO:Set up index.
2025-04-20 18:15:00,015:INFO:Initializing load_model()
2025-04-20 18:15:00,015:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:15:00,075:INFO:Initializing predict_model()
2025-04-20 18:15:00,076:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D434676800>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002D435AD7EB0>)
2025-04-20 18:15:00,076:INFO:Checking exceptions
2025-04-20 18:15:00,076:INFO:Preloading libraries
2025-04-20 18:15:00,076:INFO:Set up data.
2025-04-20 18:15:00,085:INFO:Set up index.
2025-04-20 18:15:02,608:INFO:Initializing load_model()
2025-04-20 18:15:02,608:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:15:02,664:INFO:Initializing predict_model()
2025-04-20 18:15:02,665:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D4346DC5E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002D435AD7D00>)
2025-04-20 18:15:02,665:INFO:Checking exceptions
2025-04-20 18:15:02,665:INFO:Preloading libraries
2025-04-20 18:15:02,665:INFO:Set up data.
2025-04-20 18:15:02,675:INFO:Set up index.
2025-04-20 18:15:25,966:INFO:Initializing load_model()
2025-04-20 18:15:25,966:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:15:26,027:INFO:Initializing predict_model()
2025-04-20 18:15:26,027:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D4346AAAD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002D435A6DBD0>)
2025-04-20 18:15:26,027:INFO:Checking exceptions
2025-04-20 18:15:26,028:INFO:Preloading libraries
2025-04-20 18:15:26,028:INFO:Set up data.
2025-04-20 18:15:26,036:INFO:Set up index.
2025-04-20 18:15:56,825:INFO:Initializing load_model()
2025-04-20 18:15:56,825:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:15:56,881:INFO:Initializing predict_model()
2025-04-20 18:15:56,881:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D435E6F970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002D435AD7D00>)
2025-04-20 18:15:56,883:INFO:Checking exceptions
2025-04-20 18:15:56,883:INFO:Preloading libraries
2025-04-20 18:15:56,883:INFO:Set up data.
2025-04-20 18:15:56,897:INFO:Set up index.
2025-04-20 18:20:41,648:INFO:Initializing load_model()
2025-04-20 18:20:41,648:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:22:52,279:INFO:Initializing load_model()
2025-04-20 18:22:52,279:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:23:59,299:INFO:Initializing load_model()
2025-04-20 18:23:59,299:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:24:33,810:INFO:Initializing load_model()
2025-04-20 18:24:33,810:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:24:47,685:INFO:Initializing load_model()
2025-04-20 18:24:47,685:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:25:01,694:INFO:Initializing load_model()
2025-04-20 18:25:01,694:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:25:01,751:INFO:Initializing predict_model()
2025-04-20 18:25:01,751:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D435E6EB60>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002D435AA6170>)
2025-04-20 18:25:01,752:INFO:Checking exceptions
2025-04-20 18:25:01,753:INFO:Preloading libraries
2025-04-20 18:25:01,753:INFO:Set up data.
2025-04-20 18:25:01,761:INFO:Set up index.
2025-04-20 18:31:26,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:31:26,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:31:26,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:31:26,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-20 18:31:33,078:INFO:Initializing load_model()
2025-04-20 18:31:33,079:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:32:25,711:INFO:Initializing load_model()
2025-04-20 18:32:25,711:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:40:17,775:INFO:Initializing load_model()
2025-04-20 18:40:17,775:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:41:56,058:INFO:Initializing load_model()
2025-04-20 18:41:56,058:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:42:53,105:INFO:Initializing load_model()
2025-04-20 18:42:53,105:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:43:23,494:INFO:Initializing load_model()
2025-04-20 18:43:23,494:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:43:25,818:INFO:Initializing load_model()
2025-04-20 18:43:25,818:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:43:25,884:INFO:Initializing predict_model()
2025-04-20 18:43:25,884:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E1B545BA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023E66B1D5A0>)
2025-04-20 18:43:25,884:INFO:Checking exceptions
2025-04-20 18:43:25,884:INFO:Preloading libraries
2025-04-20 18:43:25,885:INFO:Set up data.
2025-04-20 18:43:25,893:INFO:Set up index.
2025-04-20 18:47:22,109:INFO:Initializing load_model()
2025-04-20 18:47:22,111:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:47:24,214:INFO:Initializing load_model()
2025-04-20 18:47:24,214:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:47:24,283:INFO:Initializing predict_model()
2025-04-20 18:47:24,283:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E1B545750>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023E66CF4040>)
2025-04-20 18:47:24,283:INFO:Checking exceptions
2025-04-20 18:47:24,283:INFO:Preloading libraries
2025-04-20 18:47:24,284:INFO:Set up data.
2025-04-20 18:47:24,292:INFO:Set up index.
2025-04-20 18:49:35,060:INFO:Initializing load_model()
2025-04-20 18:49:35,060:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:49:37,873:INFO:Initializing load_model()
2025-04-20 18:49:37,873:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:49:37,934:INFO:Initializing predict_model()
2025-04-20 18:49:37,934:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E66B7AB30>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023E1C7B7D90>)
2025-04-20 18:49:37,934:INFO:Checking exceptions
2025-04-20 18:49:37,934:INFO:Preloading libraries
2025-04-20 18:49:37,934:INFO:Set up data.
2025-04-20 18:49:37,941:INFO:Set up index.
2025-04-20 18:49:53,072:INFO:Initializing load_model()
2025-04-20 18:49:53,072:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:49:53,138:INFO:Initializing predict_model()
2025-04-20 18:49:53,139:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E1C7D3D00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023E1C7B7A30>)
2025-04-20 18:49:53,139:INFO:Checking exceptions
2025-04-20 18:49:53,139:INFO:Preloading libraries
2025-04-20 18:49:53,139:INFO:Set up data.
2025-04-20 18:49:53,148:INFO:Set up index.
2025-04-20 18:49:59,257:INFO:Initializing load_model()
2025-04-20 18:49:59,257:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:50:01,218:INFO:Initializing load_model()
2025-04-20 18:50:01,218:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:50:01,275:INFO:Initializing predict_model()
2025-04-20 18:50:01,275:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E1C8E6E30>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023E1B5317E0>)
2025-04-20 18:50:01,275:INFO:Checking exceptions
2025-04-20 18:50:01,275:INFO:Preloading libraries
2025-04-20 18:50:01,275:INFO:Set up data.
2025-04-20 18:50:01,283:INFO:Set up index.
2025-04-20 18:51:52,518:INFO:Initializing load_model()
2025-04-20 18:51:52,519:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:51:59,471:INFO:Initializing load_model()
2025-04-20 18:51:59,471:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-20 18:51:59,536:INFO:Initializing predict_model()
2025-04-20 18:51:59,538:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023E66B24F70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023E1B5079A0>)
2025-04-20 18:51:59,538:INFO:Checking exceptions
2025-04-20 18:51:59,538:INFO:Preloading libraries
2025-04-20 18:51:59,538:INFO:Set up data.
2025-04-20 18:51:59,547:INFO:Set up index.
2025-04-21 08:34:31,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 08:34:31,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 08:34:31,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 08:34:31,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 08:35:06,516:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_22872\466821166.py:20: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 09:23:26,994:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_22872\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 09:41:00,050:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_22872\3345649888.py:18: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 09:41:06,379:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_22872\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 09:42:16,048:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_22872\2346097063.py:18: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 09:42:22,414:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_22872\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 09:44:49,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 09:44:49,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 09:44:49,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 09:44:49,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 09:45:36,285:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_13404\3738034258.py:18: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 09:45:42,481:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_13404\1167986845.py:17: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 10:05:18,425:WARNING:C:\Users\zaina\AppData\Local\Temp\ipykernel_13404\1146412998.py:18: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=dept_attr.index, y=dept_attr.values, palette=colors)

2025-04-21 13:10:39,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 13:10:39,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 13:10:39,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 13:10:39,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 13:10:40,720:INFO:Initializing load_model()
2025-04-21 13:10:40,721:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-21 13:11:10,105:INFO:Initializing load_model()
2025-04-21 13:11:10,105:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-21 13:11:10,173:INFO:Initializing predict_model()
2025-04-21 13:11:10,173:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C282BB820>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C28457EB0>)
2025-04-21 13:11:10,174:INFO:Checking exceptions
2025-04-21 13:11:10,174:INFO:Preloading libraries
2025-04-21 13:11:10,174:INFO:Set up data.
2025-04-21 13:11:10,183:INFO:Set up index.
2025-04-21 13:12:24,707:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 13:12:24,707:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 13:12:24,707:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 13:12:24,707:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-21 13:12:29,709:INFO:Initializing load_model()
2025-04-21 13:12:29,709:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-21 13:13:02,736:INFO:Initializing load_model()
2025-04-21 13:13:02,736:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
2025-04-21 13:13:02,803:INFO:Initializing predict_model()
2025-04-21 13:13:02,804:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000234656DA3E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\zaina\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'BusinessTravel',
                                             'DailyRate', 'Department',
                                             'DistanceFromHome', 'Education',
                                             'EducationField',
                                             'EnvironmentSatisfaction',
                                             'Gender', 'HourlyRate',
                                             'JobInvolvement', 'JobLevel',
                                             'JobRole', 'JobSatisfaction',
                                             'MaritalStatus',...
                                             'TotalWorkingYears',
                                             'TrainingTimesLastYear',
                                             'WorkLifeBalance',
                                             'YearsAtCompany',
                                             'YearsInCurrentRole',
                                             'YearsSinceLastPromotion',
                                             'YearsWithCurrManager'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 ExtraTreesClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000234656D3BE0>)
2025-04-21 13:13:02,804:INFO:Checking exceptions
2025-04-21 13:13:02,804:INFO:Preloading libraries
2025-04-21 13:13:02,805:INFO:Set up data.
2025-04-21 13:13:02,815:INFO:Set up index.
2025-04-21 13:45:47,905:INFO:Initializing load_model()
2025-04-21 13:45:47,906:INFO:load_model(model_name=model_attrition, platform=None, authentication=None, verbose=True)
